strip_unused assumes all placeholders are the same type,2
configure assumes ldconfig can be called and that CuDNN is installed in a system library location,2
Unsound GPU driver version scheme assumption in StringToDriverVersion,2
bug: BeamSearchDecoder should not assume that  when time > 0 beam will be full,2
Tensorflow installer assumes that the user uses CUDA 9.0 while CUDA 9.1 is out already.,2
Tensorflow assume the pointer size is 64bit cause problem on 32bit platform,2
Assuming to be a scripting mistake.,2
Possible wrong assumption for how a dense flow filed is stored,2
"I assume not, hence asking here.",2
can't determine number of CPU cores: assuming 4,2
"I assume that the TensorFlow team would not be willing to commit right now to supporting Rust, so I thought a separate open source project (with the option to fold into the main project later) would be the way to go.",2
"For example, I make some working changes into any one tensorflow/core/my_kernel.{cc,h} file will require the recompile of the entire:

240 tf_cuda_library(
241     name = ""kernels"",

library, which may be OK for Google assuming you guys have many cores and very fast machines, but for the average developer on say mac laptop, its insanely slow ... total compile time can range several minutes : (",2
It seems like 216 when calling cuCtxSetCurrent (which I'm assuming assigns the context to the calling CPU thread) corresponds to CUDA_ERROR_CONTEXT_ALREADY_IN_USE.,2
I assume that `convolutional.py` uses too much GPU memory.,2
./tensorflow/core/kernels/sparse_xent_op.h(58): error: explicit type is missing ("int" assumed),2
./tensorflow/core/kernels/sparse_xent_op.h(73): error: explicit type is missing ("int" assumed),2
./tensorflow/core/kernels/sparse_xent_op.h(90): error: explicit type is missing ("int" assumed),2
./tensorflow/core/kernels/sparse_xent_op.h(104): error: explicit type is missing ("int" assumed),2
"The other optimizers all implement `_apply_sparse`, so I assume this is an oversight.",2
"For simplicity lets assume for a single ""example"" that after our input pipeline we are left with a tensor with shape [2,3], perhaps:

    [[0,0,1],[1,0,0]]

and let us say that contextually we will refer to this feature as ""main_input"".",2
For Ubuntu 21.04 the manual installation instructions are a thing of the past assuming that you have installed your NVIDIA drivers from the Canonical default apt repo .,2
"# Check input assumptions set after layer building, e.g. input shape.",2
"Here we assume that the model has been compiled, i.e. it contains
            an optimizer and a loss function",2
"Assume I am having 8 GPUs ```n_gpus=8```, according to mirror strategy if we are having a batch size of 16 ```batch_size=16```, it will distribute ```2 ( batch_size / n_gpus ) ``` batch datasets to each of the GPUs.",2
"Now, assume ```batch_size``` is dynamic and changing in each iteration over the ```dataset iterator```.",2
"I assume something is wrong in the way I preprocess my data though, but not sure how to go about it.",2
So I assume there might be something wrong with TF_GraphSetTensorShape_wrapper function when dealing with high-dimensional shapes?,2
I assume there is some mismatch between versions of TF?,2
"I assume those ""so""es who return ""no, only unprotected functions found!"" are not fortified, could anybody help confirm?",2
"This is because in Java, when it loads the model: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/cc/saved_model/loader.cc#L171, it sees that the variables.index file is missing, hence makes the assumption that the graph does not have any variables.",2
I am assuming the issue is permissions related or that the file can't be found but rather than failing or giving an error it just runs indefinitely.,2
"While there seems to be a work around by manually slicing and joining, this would seem nifty to have in tf.pad already to make expressions that assume periodic boundary conditions a bit easier.",2
We assume this was done on purpose.,2
I assume the `GpuDelegate` consumes all the GPU resources for my interperter.,2
`tf.numpy_function` is assumed to be stateful.,2
"I want to have different trainable ops on each channel like (assume channel=3):
```

    ops_0 on A[ : , : , 0]
    ops_1 on A[ : , : , 1]
    ops_2 on A[ : , : , 2]

```",2
"It means i need to loop on batch (assume channel=3):

```
for m in range(batch)
    ops_0 on A_batch [ m , : , :，0 ]
    ops_1 on A_batch [ m , : , :，1 ]
    ops_2 on A_batch [ m , : , :，2 ]

```",2
"Assume we have a function that runs well in graph mode for a certain type of input, say a tensor tuple containing 2 tensors with arbitrary shape:

```
@tf.function(input_signature=[(tf.TensorSpec(None), tf.TensorSpec(None))])
def do_something(input):
    ....
    return some_result
```",2
So i assume the problem has to do with some path or something like that in my native enviorment.,2
"The test in [scatter_nd_ops_test.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/kernel_tests/scatter_nd_ops_test.py#L231) assumes that the operations are applied in a non-deterministic order, which matches what the [documentation](https://www.tensorflow.org/api_docs/python/tf/scatter_nd) says.",2
"- We assume that we have no the model graph python code, just only checkpoint files.",2
"I don't know if the error is it in the model itself, but I'm assuming that python would throw me an error and won't build the model, what he did.",2
"# assume, they're able to add up",2
"I assume the paper is accurate on its claim, since one of the authors is the father of CNN, LeCan.",2
"The simplest suggestion for me would be for tensorflow to remove the docstrings for all fully private functionality, but that's a lot of work, and I assume you use those docstrings.",2
"### The Problem
Like explicitly stated [here](http://download.tensorflow.org/paper/white_paper_tf_control_flow_implementation_2017_11_1.pdf) on page 15 ""This means that we assume that `pred` is not trainable"", the number of loop iterations is just a constant while backpropagating the gradient.",2
"**Behavior**: When `tf.image.flip_left_right` is applied to this `tf.Tensor`, the function incorrectly assumes a rank-3 shape and flips the image along the wrong axis.",2
"Tensorflow should not assume based on `shape.ndims is None` that the image is 3-dimensional and it should not call `fix_image_flip_shape` which further builds on this incorrect assumption:
https://github.com/tensorflow/tensorflow/blob/2b96f3662bd776e277f86997659e61046b56c315/tensorflow/python/ops/image_ops_impl.py#L315-L320",2
"This is a safe assumption for most regression tasks, but leads to redundant casting/reshaping for even simple classification problems.",2
Default values can be created using the current assumptions.,2
# Assume we get dataset_id and element_spec from somewhere,2
I am assuming the latter,2
"Assuming the person writing this part of the documentation wasn't aware of this and this problem is not version specific, it is very likely that the timing results are wrong accordingly when using `interleave`.",2
This is what I assumed when I coded my own custom training function.,2
# Since the values passed are from sigmoid (assumably in this case) sigmoid(x) will be replaces with y_pred,2
Currently all examples of calling `adapt()` on a preprocessing layer with a `Dataset` argument assumes a single input feature (and thus a single `Input`).,2
"This needs to be replaced with `sudo ldconfig /usr/local/lib -v` (-v is optional, only for verbose) assuming that the libtensorflow files have been extracted in `/usr/local`.",2
"This assumes a one-to-one mapping
between samples in different successive batches.",2
"If my assumption above is incorrect, then its unclear where the file ```classify_pycamera.py``` is coming from, and should maybe be explicitly mentioned.",2
I also tried some other models from the zoo assuming we might load weights from resnet based objects detection models but I got the same probleme.,2
"Any reader with a background in probability and statistics will immediately assume that these numbers represent normalized probabilities, because the rows and the columns sum to 1.0.",2
"Furthermore, because the name of the method is *binary* cross entropy, a reader is likely to assume that the rows or columns of y_pred represent the two possible binary outcomes.",2
"In fact, none of these assumptions is correct.",2
"My feeling is that a better usage example would use numbers that do not sum to 1.0, so that readers will not make the mistaken assumption that they represent normalized probabilities.",2
I assume there would be some option to have it pad the data structures in the flatbuffer model with a few zeros before beginning the float data array.,2
"My assumption is that the model is parsed somewhere, and I would like to add some instruction to make sure the TfLiteTensor->data is properly aligned.",2
# FIXME assume for now that testing uses the largest scale,2
Current TFLite conversion code seems to assume that all signatures take at least 1 input parameter.,2
We are assuming it is because of how the labels are defined in the label map file.,2
"I am a complete newbie in the usage of tflite models with C++, so you have to assume that I don't know most of the well-known things :)",2
So my assumption is that the SplitV operator in TFlite is not available with the Int8 quantization?,2
"If dtype is tf.float32 then the range should be
      [0, 1], otherwise it would converted to tf.float32 assuming that the range
      is [0, MAX], where MAX is largest positive representable number for
      int(8/16/32) data type (see `tf.image.convert_image_dtype` for details).",2
P.S. Why does softmax_cross_entropy assume one-hot encoding?,2
I would be happy to initiate the PR myself assuming its wanted.,2
I'm assuming the first mini-batch returned should be `[0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15]` instead of `[17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32]`.,2
"OpenBLAS WARNING - could not determine the L2 cache size on this system, assuming 256k",2
"In a large output of above statement, there is a line that says ""can't determine no. of CPU cores, assuming 4"".",2
My assumption is that bazel would build whatever was necessary.,2
"1. I tried adding a `sess.graph.finalize()` and I got no exceptions, thus I make the assumption that the code does not create any new nodes in each iteration.",2
I assume that the data feeding process should not be the bottleneck because in the multi-thread training the input queue is not adjusted.,2
"Specifically, assuming tensorflow is cloned into $TF_DIR, symlinked into `$TF_INSTALL_DIR`, and built by bazel in $BAZEL_TMP, this no longer works: (output sanitized manually)",2
"If I'm understanding things right, I'm assuming it should return `[3]`.",2
Assuming that there is a problem with the building of everything related to protobuf I tried to run compile_ios_protobuf.sh it resulted in the exact same error.,2
"Furthermore, in the same section is a requirement to use homebrew, and many people I know refuse to use homebrew, so they assumed that Tensorflow was unusable on mac for them.",2
"For example, assume the url is `hdfs://host:port/tfrecords/mnist-data/`.",2
"Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block.",2
">Keras Model.fit with parameter server training assumes that each worker receives the same dataset, except when it is shuffled differently.",2
.\tensorflow/core/public/session_options.h(28): error C4430: missing type specifier - int assumed.,2
"assume each request cost 100ms,  qps at least can archive 1000 / 100 * 24 = 240qps,  but permance is so bad when qps archive 150.",2
>2017-04-21 14:35:23.158362: I tensorflow/compiler/xla/service/gpu/gpu_compiler.cc:219] ptxas fatal   : SM version specified by .target is higher than default SM version assumed,2
It would be great if you can take a look or maybe let us know how we may use ```tf.math.reduce_euclidean_norm``` assuming we misused it.,2
"I assume, a reason for this issue is line 933, 934 in keras/layers/recurrent.py",2
"I assume that I miss something to modify in example code, since pre-trained models from github.com can also not detect any objects.",2
So i am assuming the problem is in the installatiuon of tensorflow.,2
I would assume that it would be okay to import a node whose inputs are already in the graph.,2
"Where if no mapping was supplied using `TF_ImportGraphDefOptionsAddInputMapping`, the validation check assumes the input nodes exist in the current import call, along side the node being imported itself, without bothering to check if the graph might already contain these nodes (which is the assumption when a mapping IS supplied).",2
"I assume it tries to summary all at the first and run `tf.summary.scalar('test', d)`.",2
"* <p><b>WARNING:</b> The caller assumes ownership of all returned {@link Tensor}s, i.e., the
     * caller must call {@link Tensor#close()} on all elements of the returned list to free up
     * resources.",2
I assume it doesn't matter,2
My assumption is that this py_func is the "finalize" function for the dataset (from `_GeneratorDataset`).,2
"My assumption is that when Python calls `tf_session.TF_DeleteSession(self._session)` that the GIL should be released, and so `PyFuncOp` should then be able to acquire it again.",2
I assume that the layer 'block1_conv1' should automatically generate output with depth 64.,2
`tf.Print` is supposed to be an identity operation so I assume it should not change type from `list` to `Tensor`.,2
"I assume, the float model graph is not yet supported by TF Lite.",2
"Assumes predictions and targets of shape `(samples, 1)`.",2
"# Assuming your GPU has 8GB of memory, adjust accordingly",2
"I have try to set the fraction of GPU memory to be allocated in tensorflow by:
`# Assume that you have 12GB of GPU memory and want to allocate ~4GB:`
`gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)`
`sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))`",2
"I'm assuming the most recent, because I just cloned it yesterday.",2
"Due (I'm assuming) to selective registration, the generated code omits many classes which would otherwise be generated in a full build.",2
"I was thinking of adding something like this to ctc_loss (assuming inputs are batch major and of shape [None, num_time_steps, num_classes]):

```
batch_size = input.shape[0]
sequence_length = input.shape[1]
sequence_lengths = tf.fill([batch_size], sequence_length)  
```",2
"I understand that a workaround is to tile the tensors, but I assume that this increases memory usage (by quite a lot when the tensors' ranks are high); something that is very limited in my current program.",2
Reproducer (assume tensorflow as tf),2
"Having loked at the target saving directory, the saver seems to create a temporary directory from shards (something I assume is done because of the model being quite big) for later use.",2
"I assume the problem has to do with the sharding mechanism, as this is the first time I've seen the saver having to save the checkpoints in shards.",2
Note: this fix could breaks old code that has float32 assumption...,2
.\tensorflow/contrib/lite/context.h(183): error C4430: missing type specifier - int assumed.,2
"When you say custom op library, I assume you mean a  distinct shared object file.",2
"# We'll assume here that I'm using Pandas, and just have floats",2
"The implicit assumption in this logic is that by the time the worker is spawned, the chief has already started its `tf.train.Server`, i.e. the scheduler should be aware of the assumption and should schedule and initialize the chief first.",2
"In the implementation of the function in `bitmap_helpers_impl.h`, the following [line](https://github.com/tensorflow/tensorflow/blob/4dcfddc5d12018a5a0fdca652b9221ed95e9eb23/tensorflow/contrib/lite/examples/label_image/bitmap_helpers_impl.h#L90) 
```
  auto output_number_of_pixels =
      wanted_height * wanted_height * wanted_channels;
```
assumes that for the input image, the height and width must be the same.",2
"these code assumes the output formats was 

 **grid * grid * (class + 5) * box** 

but in the original paper and other resource , this should be   

**grid * grid * (class + box * 5)**",2
It's unreasonable to expect the user to figure this out themselves as from an API perspective there's no reason to expect `train_and_evaluate` would work where `train` fails (one might reasonably assume `train_and_evaluate` calls `train`).,2
"# Check input assumptions set before layer building, e.g. input rank.",2
"I have successfully run retrained MobileNetV1 classifiers (that were not downloaded from TF Hub) using TensorFlow Lite without issue, so I am assuming that the problem stems from an issue with TF Lite/TOCO and TF Hub models.",2
Follow instructions in docs and build optimized for native architecture with XLA enabled (assumes fix in https://github.com/tensorflow/tensorflow/pull/14288).,2
"As for now, TF assumes that CUDA liibs are located at `CUDA_PATH/lib64/`, however Ubuntu installs CUDA to `/usr/lib/x86_64-linux-gnu/`, which makes configuration impossible: I can't specify cuda path such that it'll find `/usr/lib/x86_64-linux-gnu/libcudart.so.8.0`",2
"When loading my custom ssd mobilenet model (5621 labels), I assume the model fails to load because it hangs on the white screen before crashing and I dont see:

`I/TensorFlowInferenceInterface: Model load took 502ms, TensorFlow version: 1.4.0-rc1`
`I/TensorFlowInferenceInterface: Successfully loaded model from 'file:///android_asset/ssd_mobilenet_v1_android_export.pb'`",2
First I also assumed that pool allocator makes this problem like [above stackoverflow link](https://stackoverflow.com/questions/44966831/tensorflow-first-epoch-is-extremely-slow-maybe-related-to-pool-allocator) (**but now I think this issue is not from pool allocator**),2
And I assume that LSTM is not currently supported in tflite.,2
"We assume this was done on purpose, and we will not be expecting any data to be passed to ""out2"" during training.`",2
"We assume this was done on purpose, and we will not be expecting any data to be passed to ""out2"" during training.",2
"We assume this was done on purpose, and we will not be      
expecting any data to be passed to ""final_representation"" during training.",2
"We assume this was done on purpose, and we will not be expecting any    
data to be passed to ""oov_code"" during training.",2
"I assume this has something to do with TensorFlow continuing to work with the Tensors, not the Variables?",2
"The links are (I assume) correct, but the URLs https://www.tensorflow.org/versions/r1.5/api_docs/python and https://www.tensorflow.org/versions/r1.5/api_docs/cc redirect to https://www.tensorflow.org/api_docs/python/ and https://www.tensorflow.org/api_docs/cc/ respectively.",2
"As noted in the comments in the code for `tf.get_seed`, a `(0, 0)` seed is problematic because the C++ ops assume this means nondeterminism.",2
"At first I assumed this was because of something inherently slow about using dynamic length, but then I also noticed naively using `tf.while_loop` with rnn cell was also much faster and performed comparably to `static_rnn`.",2
"I am assuming to use `create_training_graph()` to insert min/max vars into my graph, train it, and then reuse variables to re-route an inference graph with `create_eval_graph()`.",2
"I assume this is a memory issue in a similar vein to https://github.com/tensorflow/tensorflow/issues/17048 and http://forums.fast.ai/t/tip-clear-tensorflow-gpu-memory/1979, however, the fixes mentioned there are not working.",2
Please let me know if this will violate some core assumptions TensorFlow is making and your concerns.,2
"I am running in a Jupyter notebook and my assumption about memory is that if I do a Kernel ? Restart it will run a training run again without the error, but cannot be run in two executions without this.",2
"Unfortunately, the -1 support currently assumes the -1 dimension corresponds to **positive** size.",2
"I'm assuming that the implementation is possible without having to get knee deep in CUDA C/C++ given that there's already a mean IoU feature here and I would (hopefully) just need to extend that in a backward compatible way so that it takes some optional extra information in the form of a vector of thresholds =>
 https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/metrics_impl.py#L948:",2
"Finally, the entire theory of self-normalizing networks, introduced in [4] by Klambauer et al., and the parameters for alpha and gamma for SELU activation functions, is built upon the assumptions that the weights have mean 0 and variance 1/fan_in.",2
Assuming that ijar will be smaller and hoping for the best.,2
"I tested this with Exists(), IsDirectory(), and ListDirectory() but I'm assuming it applies generally to all the tf.gfile functions that take a path argument.",2
3. the current documentation hints at sharding (e.g. `transposed_matrix_slices_from_queue_for_worker_shard`) but assumes the user knows how to set that up.,2
We are assuming the 1st  SessionRun() takes longer to upload the graph on GPU.,2
Assuming that my application scenario is n_frames = 32 is the largest size for the input tensor,2
"I assume there's a good rationale, but could additional documentation be added to explain why this change was necessary (or deemed desirable)?",2
`seq2seq.ScheduledOutputTrainingHelper.sample(...)` outputs a `tf.bool` tensor but `seq2seq.BasicDecoder.output_dtype` assumes `tf.int32` output.,2
I am assuming it is an issue with dependencies or version checks.,2
"e.g.

assume the original tensor `a` is 
```python
[[93, 69, 38, 46]
[54, 5, 1, 13]
[96, 45, 52, 50]]
```
and we want to restructure the tensor above according to the `a[:, 3]`, so output:
```python
[54, 5, 1, 13]
[[93, 69, 38, 46]
[96, 45, 52, 50]]
```",2
"The code trains a seq2seq model, and I assume the message gets printed somewhere downstream of seq2seq.dynamic_decode.",2
"However, as far as I was able to understand, all tensors quantization(weights included) is performed using function [ChooseQuantizationParams](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/kernels/internal/quantization_util.h) which assumes, that available range is [0, 255](for uint8).",2
"I had originally considered adding an extra couple of tensor endpoints to Saver which accepted a byte array wrapped in a tensor, deserialising that into the session, and one which emitted a byte array which was a serialised form of that session, but given how far down the assumption of filesystem access is in a saver I'm not sure that's the right approach.",2
So there's no problems in my `train_input_fn` and I assume this is a bug of Tensorflow.,2
"To give the model triples of batches from the original sequence `(e0, e1, e2, ...)`, we could use `tf.contrib.data.sliding_window_batch` as follows, assuming `dataset` yields `(e0, e1, e_2, ...)`:

```python
dataset = dataset.apply(window_size=batch_size, stride=1)
# yields ([e_0, ..., e_{b-1}], [e_1, ..., e_b], [e_2, ..., e_{b+1}], ...)

dataset = dataset.apply(window_size=3, stride=batch_size)
# yields:
# [[e_0, ..., e_{b-1}],     [[  e_b  , ..., e_{2b-1}],
#  [e_1, ...,   e_b  ],  ;   [e_{b+1}, ...,   e_2b  ],  ;  ...
#  [e_2, ..., e_{b+1}]]      [e_{b+2}, ..., e_{2b+1}]]
```",2
"If you are using the canned estimators as a baseline, and many beginners do, then making wrong assumptions about metrics is the worst possible option.",2
"# to [num examples, rows*columns] (assuming depth == 1)",2
"I assume that **tf.fake_quant_with_min_max_vars function** can not be differentiable due to the fact that quantization should be working based on threshold, such as round, or sign function.",2
// Assume if it's neither a PNG nor a GIF then it must be a JPEG.,2
# We assume here that the summary is called 'loss'.,2
"Also, it would be helpful if someone could answer [Tensow - XLA | Passing tensors to external functions at runtime](https://stackoverflow.com/questions/45146444/tensorflow-xla-how-are-tf-ops-lowered-to-xla-for-training) , as it is **the** important assumption of my approach that Tensorflow can allow such XLA ops.",2
"GeForce is my secondary gpu card, so I assume, that it is not related to watchdog timer.",2
With more explicit specification of layer quantization it is possible to know when the quantization assumptions change and we can track the latest releases of TF.,2
So I assumed] my static library was well generated to including all the ops I need.,2
"There's still an error, which I assume is on my end.",2
"Convert a float-array to an integer, assuming each element
        of the float-array corresponds to a bit.",2
The root of the problem is that the while_loop body in dynamic_decode assumes that sequences are independent and will finish only once.,2
Scope initialization assumes that the  'context_stack' must be in the same stacktrace thread.,2
"Assuming row-major tensor storage, the incorrect indices are in contiguous groups of 4 floats (16B), and the distance - in memory addresses - between these groups is consistent but platform dependent (e.g. 512kB stride between groups on GTX980 vs. 480kB between groups on K40m)",2
"NOTE(mrry): On Windows, we currently assume that contrib op
  libraries are statically linked into the main TensorFlow Python
  extension DLL.",2
I assume that TF shouldn't be that slow.,2
"Currently, the only way in TensorFlow to convert a dense matrix into a sparse one (assuming it has only few non-zero values) is to use `tf.where` (afaik).",2
This is fine assuming org/tensorflow/native/linux-x86_64/libtensorflow_jni.so is not built to depend on it.,2
These are partial files and the apt-get commands should work on non-Docker systems as well assuming you have the NVIDIA apt-get repositories which should be the same as listed on [tf.org](https://www.tensorflow.org/install/gpu).,2
Assumed this would truncate the window in the gradient computation or fail on some assertion but this fails ungracefully.,2
I assume that the number of rows need to remain the same but the features can vary between the two models as we are defining two separate set of features that should be used.,2
Assume images are square.,2
// assume squre picture,2
"// NOTE: the defaults within this file all assume that Abseil can select the
// proper Abseil implementation at compile-time, which will not be sufficient
// to guarantee ABI stability to package managers.",2
"Assuming the deterministic back-prop kernels are slower than the current non-deterministic ones, then the deterministic operation will be selectable using the preferred mechanism at the time.",2
"Assuming that `tf.nn.softmax` operates deterministically (I have not tested that), then this could be followed by an arithmetically robust implementation of cross-entropy (e.g. [streaming log-sum-exp](http://www.nowozin.net/sebastian/blog/streaming-log-sum-exp-computation.html)).",2
"Assume we have a function taking a tensor and a bias to be added, supposedly having the same shape.",2
Assuming 1.,2
"This can cause problems if the path is a file, as you would assume that the path is a directory after calling `mkdir()`.",2
"However, this implementation assumes that everything is really a `Functional` (since any model with a config is a `Functional`), which is what appears to be breaking us in this case.",2
"As a result, in a large Python GUI (PyQt5) application, an `import tensorflow` at application startup time resulted in many log messages unrelated to tensorflow being printed to the console; without importing tensorflow, those log messages weren't visible. (Note that the application had set the level of the root logger to `logging.DEBUG`, and added its own root-level loggers, under the assumption that it would be the only part of the Python environment working with the configuration for the root-level logger.)",2
I assumed that the Checkpoint saving would work in a similar fashion with gathering all variable tensors and having a mapping between the Tensor and its position in the graph topology and save them but the checkpoints fail to save the `Linear` layer variables in the second case.,2
"This is due to the fact that TFLite converter relies on the output ordering, but the saved model import function purposefully breaks this assumption by scrambling the inputs and outputs:
https://github.com/tensorflow/tensorflow/blob/c36991b0367a12bc81bf37dfdc5cf4793c7a8bde/tensorflow/compiler/mlir/tensorflow/translate/import_model.cc#L3708-L3721",2
"Assuming ""gs://bucket/folder"" existes, and ""gs://bucket/folder/folder1"" doesn't exist.",2
# Assuming we use mnist data set,2
"Therefore, I tried to use the `Dataset.prefetch()` methodology to achieve this, assuming a buffer will be created and (constantly) filled with data.",2
"This appears to be caused by the following line in `rnn_cell.py`, which seems to make the assumption that `time` has one dimension;",2
"My assumption is this has to do something with the memory allocation going a bit crazy and eventually triggering an OOM under the hood, but I'm not 100% sure how to get anymore data to help determine what is going on.",2
My assumption is something is moving everything over to the GPU and thus crazy allocations are happening once the entire dataset won't fit into GPU memory.,2
Assuming this is related to the virtual pip package.,2
"I didn't specify `--config=mkl` in build command, so I assume Eigen backend was used during the build.",2
My assumption is that some connection gets lost in the tf.keras.Model caused by the masking layer defined in line 64 and further connected to the concatenate layer defined in line 73 (in _articleSchedulingModel.py_).,2
Is the assumption appropriate or what else might cause this error?,2
"This error happens on both Tensorflow models I run, so I assume it's a threading problem when running the Graph in a thread that it is not the main thread.",2
I assume that droupout should have been checked there?,2
"However, current LSTM/GRU are graph functions and the backprop algorithm for graph functions assumes the inputs must be `tf.Tensor`s.",2
I assume an automatic conversion of `tf.IndexedSlices` to `tf.Tensor` should be performed.,2
Assume we're given a `GraphDef` that was serialized as `graph.as_graph_def()`.,2
# Compute minimum padding length assuming manually dilated array,2
"I assume this is a bug, but may need several help if not.",2
"However, since flatbuffers always stores the data in Little Endian format regardless of host machine endianness, the direct `reinterpret_cast<const uint32_t*>` call will retrieve the wrong value on Big Endian platforms (as `reinterpret_cast` will assume the data is in host endianness), so the retrieved value needs to be byte-swapped.",2
"I noticed that the `pywrap_tfe.TF_IsXlaEnabled()` API and this test case was added from the same [commit](https://github.com/tensorflow/tensorflow/commit/96e0b87d1e23ac1dd7a7aa984e3f479647267b32), and I assume the cause of inconsistency is that the function `SetXlaIsEnabled()` was called incorrectly.",2
"I have been trying to run inference of some CNN model using TFLite 2.4.0 with OpenCL GPU delegate enabled and found that Conv2D operator may produce NaNs, Infs and other invalid values when running on the **Mali-G51 MP4** GPU if precision loss is allowed (I assume that getting NaNs is not considered as a reasonable precision loss) and Cond2D padding is set to `same`.",2
Thus I assume that Winograd algorithm implementation for OpenCL delegate is the root cause of the issue.,2
"Again assume `_user_steps` is set (see above reasoning): First the `cardinality` might be unknown, e.g. for any TFDS dataset (and `TFRecordDataset`) it is unknown.",2
I assume that this error should not appear.,2
"I assume ```tf.split()``` cannot be quantize, and nothing to be quantize actually, since if I add ```tf.lite.OpsSet.TFLITE_BUILTINS_INT8``` to fully quantize into INT8, it tell me SPLIT_V is not supported.",2
On the EC2 instance the TF version installed is 1.15.0 and I also tried using TensorFlow 2.0 but when I did that the code failed immediately with a message indicating that tf.contrib is no longer included in TensorFlow so my assumption is that this code has not been ported to work for TF2.,2
So I assume that the convertion is OK.,2
# This assumes that your machine has 8 available GPUs.,2
As I was able to reproduce the issue with VGG16 but not ResNet50 (Both contain ReLU activations)  I assume that this is a different issue.,2
"Assume error occurs, take the true branch (line 608~609).",2
So I assumed that that huge performance is because of the fact that the TFLite example app uses a model ending with .tflite and the mobile app a protobuf file.,2
"**[Contributing](https://www.tensorflow.org/community/contribute)** - Do you
want to contribute a PR? (yes/no): - yes, BUT: I do not exactly know which part causes the issue (I assume the problem is in the Normalization layer).",2
# assuming a model with submodels called "saved_model" exists,2
(example code assuming there are _train_ and _test_ directories contain 2 classes of images to be read in using `flow_from_directory`),2
"This is not ideal, as even customized code could assume another definition of fanning.",2
"I have tried to different ways, one is simply super slow and the other one hits the 2GB limit (I assume the optimizer is kicking in and unfolding the constant matrix and overpopulation the graph, but I am not sure and my test with the config for Grappler did not work)",2
I try to restore model and use it to evaluate on ANOTHER dataset object (assuming test set of MNIST is a new dataset).,2
But it seems that it assumes all in_edges are ordered which is not the case with gtl::FlatSet.,2
"- TensorFlow installed from (source or binary): Binary (I assume that's what `pip install` does, at least)",2
I believe the issue might be caused by the fact that on compile time the shape of the tensors have to be known and the compiler assumes all the shapes within the tensoarray will be shared.,2
"Whreas https://www.tensorflow.org/api_docs/python/tf/nn/ctc_beam_search_decoder doesn't have an API for setting blank index, and it assumes to be `num_category - 1` (see https://github.com/tensorflow/tensorflow/blob/cd7da16dd6c17df428dc9ec105c0c8f11e5fd4f5/tensorflow/core/kernels/ctc_decoder_ops.cc#L331)",2
This is very unexpected - I would assume they have the same default value since they both work with CTC. Or at least both should provide API to change the blank index.,2
"'two' should assume a value of 2.0, 'one' a value of 1.0, 'three' a value of 3.0.",2
I assume the issue is that there is no uniform dimension in the regular tensors before stacking them.,2
"Intuitively I would have assumed that I can use `tf.ragged.stack` to create this uniform dimension to form a ragged tensor from several non-ragged different-dimension tensors as above, similar to the regulat `tf.stack`, which creates a new dimension.",2
"Using keras bundled with tensorflow, from one input with shape (None, num > 0) and another input with shape (None, num2 > 0, 0), the second is flattened, obtaining shape (None, 0), and, when trying to concatenate both, it fails during training because it assumes the shape of the second has double number of rows.",2
I assume it should be ```private``` instead of ```public```.,2
"> This op assumes that there is at least one id for each row in the dense tensor represented by sp_ids (i.e. there are no rows with empty features), and that all the indices of sp_ids are in canonical row-major order.",2
Assume that I have already made a previous call of `tf.concat`.,2
"Assuming my previous issue is solved, I think that the result of `plot_model` should simply ![look like this](https://github.com/durandg12/nn_pictures/blob/master/expected_model.png).",2
"Assuming the code snippet is pasted in a file called `test.py`, run:

```
$ mprof run --include-children python test.py
$ mprof plot
```",2
So i assume intel mkl is being used in M10 image where as mkl is not being used in the M9 image (Note: i have turned off visibility for cuda devices so only cpu inference is being compared) .,2
"Assume that there is tf.Assert inside of decorated function, which is independent of input argument (then defun get same graph function from graph cache, right?)",2
"[SSIM](https://www.tensorflow.org/api_docs/python/tf/image/ssim) assumes that the image batches have a shape (h, w, batch_size).",2
"But I assume this is not in general intended to produce a deadlock anyway, should it?",2
"But the title page is broken, so most users wouldn't think to look at the other pages and just assume the whole thing was broken.",2
"Currently it assumes that every model output has a corresponding target, so when doing this casting it just matches outputs and targets up one-to-one.",2
The estimator is clearly never assigned a '_distribution' attribute (this is the only line on which its referenced) so I assume this is just a typo.,2
"ordered: if True, other axis indices are assumed to be ascending.",2
I had assumed that cpp would be more faster but the results were opposite.,2
But I assume it is still a bug that is worth fixing.,2
"I assumed it would work without problems with the GPU, too, after I installed proprietary NVidia drivers (435) and the CUDA and cuDNN libraries.",2
Note that let's assume a context where the deadness analysis is disabled for forming large clusters.,2
"Assuming putting it under /wmt16/
https://drive.google.com/open?id=1ooQiWhmzmYsk2qMOfaunjTlx_z6lcUyO",2
Assuming the dataset is placed under /wmt16/.,2
"This is fine, assuming these values would have otherwise been inaccurate.",2
"I’m assuming it tests the `Switch` “dead branch”, which should be the non-used branch for inference.",2
"# NOTE: here we assume data is a single (x, y) tuple
        #       in order to provide with a minimal example",2
// assumed the out buffer is a vector,2
I'm assuming that the decreasing time is due to autotune running.,2
# Assuming you have already installed conda and are currently in no environment,2
PredictionLogger is a class with tf inheritance so I assumed the problem to be here.,2
Since AFAIK tensorflow does not use C++ exceptions (I believe it compiles with `-fno-exceptions` on Clang/GCC so I assume this is official policy) this would have to be handled with a `pragma warning (disable: 4217)` somewhere in the code.,2
I assume the (seemingly missing) Core Foundation libraries are shipped with macOS regardless.,2
So I assume most common use case is always build own copy of flatbuffers as part of build process.,2
Assuming NCCL header path is /media/disk1/fordata/web_server/project/xiaolun/cuda-10.0/lib64/../include/nccl.h,2
Assuming NCCL header path is /media/disk1/fordata/web_server/project/xiaolun/nccl_2.3.7/lib/../include/nccl.h,2
2) Assuming that the Ubuntu version will never work on CentOS I decided to go another way and try to build Tensorflow directly on CentOS.,2
"I assume it does not matter where I put bazel on the cluster, as long as it is on the cluster I will always get this error?",2
Therefore I assume that the tensorflow Go API is broken in the current master.,2
"I assume there are two actual problems: one is that the compilation is not correct, the other is that it does not prevent the test from running, but let's it work on a ""crippled"" output binary.",2
I'd be happy to submit a PR but would probably need some guidance (assuming you don't want the file names hard coded as I'm doing for my workaround).,2
"I trained the above mentioned model on my images, and then exported the graph with the --add_postprocessing_opt option (which I assume adds the TFLite_Detection_PostProcess op):
python /tf/models/research/object_detection/export_tflite_ssd_graph.py \
    --pipeline_config_path /tf/notebooks/models/ssd_mobilenet_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03/pipeline.config \
    --trained_checkpoint_prefix /tf/notebooks/model.ckpt \
    --output_directory /tf/notebooks/tflite \
    --add_postprocessing_op=true",2
It seems that the Gather function assumes that 'coords_array' is always 1-dim array.,2
"# Resize if input length different, assuming batch size is always 1.",2
"I assumed that to run the TFLite Python interpreter, I needed just a wheel of the `tflite_runtime` that I crosscompiled (`tflite_runtime-2.0.0-cp37-cp37m-linux_riscv64.whl`).",2
"Removing this line of the `BUILD.bazel` file fixes the build on my machine, but I can only assume that you added it for some reason (most likely to make the build work on an operating system that does use the `sysctl.h` header, but on which the hwloc build system does not correctly detect said header ?), which means that the actual tensorflow patch will need to be more nuanced and only perform this patch on the OS configurations where it is necessary.",2
"On master I can see the header exist, I assume the CMakeLists file isn't downloading or generating this file on compilation.",2
I assume when adding the metal delegate it changes the select cpu type (im not familiar with bazel enough to know).,2
"First I had to change the cpu_info target to darwin_x86_64 (https://github.com/tensorflow/tensorflow/issues/41039) then I assume because of the CPU name change, when linking NNAPI it tries to build with `-lrt `which is not supported by MacOS and it will fail.",2
I assume this is not the way I am supposed to do it but for some reason i had no issues with Android and iOS but MacOS has issues.,2
"Using the SELECT_TF_OPS flag helps with RFFT and ComplexAbs, but now Real (assuming tf.math.real) is not able to convert.",2
I am assuming there are limitations or issues in GPU execution during broadcasting.,2
Predict function is used by users assuming that it will work fast because we use it all the time in production.,2
"I would of assumed it has something to do with bazel getting confused by cygwin paths (e.g. it can not handle any paths that have a space character in their own build script), but that would not explain why it is using such a bizarre path in the first place.",2
"I get an error when trying to pip install tensorflow, however, I assumed that it was because I am using python 3.8, so I tried doing a special install with: `python -m pip install --upgrade https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.12.0-py3-none-any.whl` and that installed it, however when running a script that simply imports tensorflow, I get the error: `No module named '_pywrap_tensorflow_internal'` I know that it is tensorflow 1.12, but when I uninstalled and tried to do a special install of 2.2, it didn't work.",2
"Assuming the SELECT_TF_OPS option produces a model that will work on TFLite on iOS, then I guess all I need is RFFT.",2
"Confusingly, there also seems to be something called a 'CUDA driver' which I assume is something different from the NVidia driver.",2
"* In the age when models are transplantable, licensable, and/or expensive to train, any work-around solutions assuming model re-graphing or/and re-training to work around int64 issue are non-solutions.",2
The script assumes that TF is not an external dependency.,2
**Assumption: (Pls correct if wrong)**,2
Assuming NCCL header path is /usr/include,2
"I'm assuming it didn't actually finish and crashed instead, with ample recovery time after.",2
1>d:\data\documents\github\tensorflow\tensorflow\core\framework\op_kernel.h(690): error C4430: missing type specifier - int assumed.,2
1>d:\data\documents\github\tensorflow\tensorflow\core\framework\op_kernel.h(1134): error C4430: missing type specifier - int assumed.,2
"# Assume the input is sized as [batch, time, input_size], then we're going
  # to transpose to be time-majored.",2
"The issue seems to have been introduced [here](https://github.com/tensorflow/tensorflow/commit/25380986954692d947bd230e4f5d3a2d11dd3064), as the line:
`val_samples_or_steps = val_inputs and val_inputs[0].shape[0] or None`
assumes an array will be found and fails for dicts.",2
I assume we can achieve this by changing `optimizer.compute_gradients` or `tf.gradients`,2
Here is a hack-y solution that assumes the pivot is the node created immediately before `TF_AddGradients` is called (rather than using one of the inputs as the pivot).,2
// Assumes the pivot is the node created immediately before the gradient nodes.,2
"This is a reasonable assumption for usual practices in machine learning, however this prevents one from creating their own autograd system using `tf.custom_gradient`.",2
"I assumed I could do x.rank ; x.order, x.degree to get this value for a tensor.",2
By looking at the code in the micro_speech project it assumes the preprocessing mode always to be 'micro'.,2
"Let's assume `x=(x_1, x_2, x_3)` and we have some function (network) which gives us a scalar output for every x `f(x)=y`.",2
"Given a positive-definite matrix `A` (n by n) with known Cholesky factor `L` (lower triangular), and another matrix `V` (n by k), compute the Cholesky up/down-dates of `A` with respect to `VV.T`, namely find *lower-triangular matrices* `M` and `K` such that `M M.T = A + V V.T` and  `K K.T = A - V V.T` (assuming the second is positive definite).",2
The issue appears to be that `math_ops.maximum` requires a real tensor as `epsilon` is assumed to be a real-valued lower-bound on `square_sum`.,2
"Actually, Tensorflow Lite is assumed as the default for model optimization, but it is focused on Edge Devices, what are the alternatives to Cloud Deployments with Tensorflow Serving?",2
"Currently, `MirroredStrategy` and `MultiWorkerMirroredStrategy` assume a model replica including its embeddings could fit in one GPU or one machine.",2
"Cache is simply assumed False unless supplied otherwise, and if it is false, the old code path should execute.",2
# else: assume learning phase is a placeholder tensor.,2
So I assume (since this doesn't seem to be documented) that class_weight weighs based on the true labels.,2
Users of `tensorflow_dataset` I assume.,2
"Again, the determinant is very small (2.1934511e-08), for all purposes it can be assumed to be zero, so in the least, the error can be more of a warning rather than a not invertible error.",2
I assume that there is no clear specification when the loss functions are evaluated and it is also clear to me that the approach may not work with eager execution.,2
It also assumes knowledge of the ELU activation function.,2
"One would need to get the loss function, take a data point (i assume mini batches work as well) and apply the formula to it and see if it evaluates a valid learning rate.",2
I'm assuming it's quite likely this has been requested before but I couldn't find it.,2
"I assume this is on the radar somewhere, but I don't see any tracking issues, so I'm making this as tracking (and a request).",2
"The problem persists across different browsers (Firefox, Safari, Chrome, Vivaldi) and I assume it also affects other locales for which a localised devsite_app.js is not available (for instance, Belarusian be, Croatian hr, etc.)",2
"Sometimes, this is not the right assumption.",2
"I am assuming that the reason `tensorflow/addons` and `tensorflow/probability` exists, is to reduce the base install size.",2
"When I look at the types of the image data and input tensors, they inded _are_ `uint8`:

```
IMAGE_ARRAY type uint8
INPUT TENSOR [{'name': 'input_2', 'index': 22, 'shape': array([  1, 180, 180,   1], dtype=int32), 'shape_signature': array([ -1, 180, 180,   1], dtype=int32), 'dtype': <class 'numpy.uint8'>, 'quantization': (1.0, 0), 'quantization_parameters': {'scales': array([1.], dtype=float32), 'zero_points': array([0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]
```
(look only at `dtype` in the input tensor, I assume).",2
I am assuming this means that the model is working correctly and yielding valid data - and I am also assuming that 8-bit sigmoids are expected to have a bit of a roundoff error where they don't add up to exactly 256??,2
"It appears to be caused by OptimizerV2, where all the hyperparameters are assumed to be float when loading the adam optimizer, yet the optimizer saves some of the hyperparameters as integers.",2
"I assume this has something to do with shared global state across a tensorflow session, but I'm not sure if there is something that I am supposed to do to prevent these types of errors.",2
"I assume colab is more standard and thus more interesting, but my local info for completeness:
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes, a bit!
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.4.1 (also reproduces on nightly)
- Python version: 3.8.5
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A",2
"I'm guessing that, assuming that such a situation should even be allowed to arise at all, it's a result of an optimisation which takes advantage of the fact that the two predicates are essentially the same.",2
"Either way, the code in `tensorflow/compiler/tf2xla/functionalize_cond.cc` seems to assume that this will never happen.",2
"That is, it should _not_ be assumed that `output == states[0]` for `ouput, states = step_function(inputs, previous_states)` in the `keras.backend.rnn` implementation.",2
"The error seems to come from [this line](https://github.com/tensorflow/tensorflow/blob/33c47b42e04d11622a01ea279ad26e7c3c02a687/tensorflow/python/keras/engine/compile_utils.py#L261), which assumes the existence of an attribute `__name__` on any object passed by the user.",2
"//Read input image, assuming to be a sqaure image",2
So I assume it should be output_shape[axis] here?,2
"I assume some optimizing is happening in the background in newer versions, which leads to an increase in memory requirements.",2
"When it checks out for the (super)type of session hooks, it looks for **tensorflow.python.training.session_run_hook.SessionRunHook**; but ""isinstance"" method fails to do so for it assumes that their type is **tensorflow.python.training.basic_session_run_hooks** though it is not.",2
"As far as I can tell it is not already implemented in tensorflow, which surprised me since I think this is the learning rate decay rate required for theoretical convergence using the Adam optimizer in Section 4 of [the paper](https://arxiv.org/pdf/1412.6980.pdf), which has:

```python
alpha_t = alpha / sqrt(t)
```

which is the same as the first equation with `decay_rate = 0.5`, and I assume they start at `t = 1` while tensorflow starts with `global_step = 0`.",2
"If we use tf.data, we wouldn't be able to use Dataset.shard(...) on the examples themselves because we would get batches like this (assuming 4 workers in a distributed training and batch_size=3):

worker0_batch0 = [example_0, example_4, example_8]
worker0_batch1 = [example_12, example_16, example_20]
...

worker1_batch0 = [example_1, example_5, example_9]
worker1_batch1 = [example_13, example_17, example_21]
...

worker2_batch0 = [example_2, example_6, example_10]
worker2_batch1 = [example_14, example_18, example_22]
...

worker3_batch0 = [example_3, example_7, example_11]
worker3_batch1 = [example_15, example_19, example_23]
...",2
"**Assuming the size of the dataset is N, then what we really want is** 

worker0_batch0 = [example_0, example_1, example_2]
worker0_batch1 = [example_3, example_4, example_5]
...

worker1_batch0 = [example_(N/4)+0, example_(N/4)+1, example_(N/4)+2]
worker1_batch1 = [example_(N/4)+3, example_(N/4)+4, example_(N/4)+5]
...

worker2_batch0 = [example_2*(N/4)+0, example_2*(N/4)+1, example_2*(N/4)+2]
worker2_batch1 = [example_2*(N/4)+3, example_2*(N/4)+4, example_2*(N/4)+5]
...

worker3_batch0 = [example_3*(N/4)+0, example_3*(N/4)+1, example_3*(N/4)+2]
worker3_batch1 =[example_3*(N/4)+3, example_3*(N/4)+4, example_3*(N/4)+5]
...",2
"assuming that tf.where can't respect the float type of the input variable nor the floatx setting, as those change the api, better would be:

```
tf.where(f64 > 0.5, 1., 0. , dtype=tf.float64)
```",2
"But I think people would assume `assign_add` works in simple case like `assign_add(_, 0.0)` (or it should complain rather than silently give wrong results).",2
PS - I am assuming that parameters of `A` and `B` follow same naming convention in scopes.,2
Assume you call reshape,2
"* Assuming we're seeing something real, is there any suggested remediation here, with regards to our validation behavior?",2
"Assume the file example.csv contains this text:
```
1.0,2.0,3.0
4.0,5.0,6.0
```",2
"2.  As described in the doc，“For now, it is assumed that the underlying hardware platform will provide mechanisms for compressing the sparse tensors and/or accelerating the sparse tensor computations“",2
My assumption is that TensorFlow in eager mode caches the operator instance and just reuses it when the "identical" layer gets called.,2
Assumption: Multiple CUDA versions on /usr/local,2
# assuming native byte order is little endian,2
"The `tensorflow/compiler/xla/mlir_hlo/CMakeLists.txt` includes the `stablehlo` subdirectory and various includes from it, assuming it's local.",2
lets assume data_set is the batch-dataset of batch size=32 and when we take 1000 then it shows green signal but when someone will try to fit the model with this it will an error,2
"Function list_directory_v2() in the same file is written assuming the current behavior of is_directory_v2(), it assumes all errors will be mapped to false, it will throw NOT_FOUND if the object is actually a file, or if there is a permissions failure on the directory.",2
"Function walk_v2() also assumes the current behavior of all errors being mapped to false, and so a NOT_FOUND or permissions failure will cause the directory item to be reported as a file.",2
//assuming quare picture,2
#activate (assume this venvPy3_8 was created following tutorial from https://www.tensorflow.org/install/pip#linux_setup),2
tf.keras.metrics.Precision is returning precision assuming the label is binary?,2
"But I assume because this will just not evaluate it directly, but it still lacks the `Tuple` reference, although it's maybe really not relevant then.",2
"Despite having a `list` type, the above output cannot be indexed: Assuming the above output is referred to as `var`; `var[0]` throws an `IndexError: list index out of range` error.",2
I assume some behavors behind the `predict` interface are changed after the 2.4.0 to 2.12.0 upgrades.,2
"4. how to ensure even the workers are with uneven amount of data, the training process with model.fit could end elegantly instead of having to using try catch or data.repeat, as recommendation models generally assume one epoch training.",2
I assume it is an oversight.,2
"- Note that before the recent Colab update, it used cuDNN 8.0.[56] for a very long time (I assume specific Colab packages were being build), so the bug was not manifesting there; but now it does.",2
"Assume a Keras graph gets a ragged tensor with uniform row lengths in the axis 1, so for example
```python
inputs = tf.keras.layers.Input([64, None], ragged=True)
```",2
My assumption is that the reason for this behaviour is that the parameter input of this model is a Tensor instead of a List.,2
"These are my questions: (all under the assumption that tensorflow 2.x is used, not 1.x versions)",2
I am currently working around this by extracting the tf.data.Dataset and putting it into multiple queues to manually shard and putting it back into tf.data.Dataset - this works but feels very wrong and produces overhead as I assume.,2
"I got the same error with B1 too, so I assume there's an issue with the whole Efnet Family (and maybe some other models too)",2
"Because the thread-local state is not cleaned up in the old thread 0x7f4118748700, it assumes the waiter object is still reserved by itself.",2
"I believe 3) and 4) should be -inf and +inf respectively, since any sample between one +inf and another +inf will be +inf, and since there's no way to specify _different_ +infs (so that bounds are different), I think it makes sense to assume the bounds of +inf and +inf are different, and the same for -inf and -inf.",2
"And I have the `Microsof Visual C++ 2015-2022 Redistributable (x64) - 14.32.31326`, which is the reason - I assume - that I cannot install the Redistributable referenced here https://github.com/tensorflow/tensorflow/issues/8385#issuecomment-286621655",2
"I assume this is because loading a `CustomModel` without passing `custom_objects` (or registering it) gives a `keras.saving.saved_model.load.CustomModel`, which does not contain the full functionality of the original `CustomModel`?",2
# Assumes tf 2.8,2
"I was trying to make a custom layer that performs the same as Add, except uses trainable coefficients as we assume a coefficient of 1 is optimal.",2
"I have noticed as the vocab size increases, performance decreases, as I assumed it was basically a hash table with a O(1) lookup time, this shouldn't be the case.",2
Is my assumption wrong on the time complexity?,2
I have encounter this issue many times and I assume that it is normal but is that normal?,2
// SSD Mobilenet V1 Model assumes class 0 is background class,2
"Notice : Output Shape doesnt changes, which I _assume_ is the correct behavior",2
"Not sure if I need to load any runtime libs for opencl manually or not but it wasn't in any documentation, so assume I don't need to do that.",2
"The timeit tests warn clearly that there might be some caching involved for the 2.4.0 test (which isn't available for 2.5.0 I assume, I don't know why. Caching should be enabled for 2.5.0 as well if its the default behaviour)",2
Current implementation simply assumes last axis.,2
# assume there's a tf.distribute.Server running on rpi.local:2222,2
# Assumes frozen_func has one output tensor,2
I assume that `optimizer.iterations = tf.compat.v1.train.get_or_create_global_step()` this contributes to the problem.,2
"Given that there is a min check for this block of code, i assume it was not intended for us to enter this block of code if min_lr has already been achieved.",2
"[2021-04-06 00:59:57.679 Other   331] Receive command failed, assuming client exit",2
"[2021-04-06 00:59:57.681 Other   331] Receive command failed, assuming client exit",2
Using RaggedTensor I want to minimize KL loss for different segments of a weights matrix (assuming their coefficients drawn from multivariate normal distribution in each segment).,2
"Before TF 2.5, this worked, so I assume this should still work",2
It seems to assume that I am trying to use normal tf.stack when I have all elements as tensors.,2
I assumed the same process would work for boosted trees saved models.,2
"The preprocessing assumes an input
354     value range of [0, 255].",2
and when you pass h_c to feed dict it always assume the feed is on host and tries to send it to device again.,2
So I assume this is a matter of serialization of the new layer.,2
This fix assumes that if no LearningRateSchedule is used then self.model.optimizer.lr could be logged as scalar by tensorboard callback.,2
"When i fit the model with a generator, the variable Y assume as None and it shows the error above.",2
"however, if it's omitted (which is natural to assume, as the dataset itself is not repeated)
a strange error message `TypeError: 'function' object is not subscriptable` is given.",2
So I assume it is unintended.,2
## Reshaping is necessary to use sample_weight_mode="temporal" which assumes 3 dimensional output shape,2
"y1 and y2 differ, because layers.Activation(...) assumes axis=-1 by default.",2
Some of the tensors aren't being converted into uint8 and I'm not exactly sure how that is supposed to happen (I assume that is the reason the file won't compile.),2
I am expecting that I can get a custom model to work on the coral tpu. (I'm assuming I'm doing something a bit wrong but I am having so much trouble figuring out what I'm doing wrong),2
Above line assumes lr to be a float.,2
Because I assumed that protobuf files were much slower than .tflite files I tried to converted a .pb to a .tflite:,2
// assuming one input only,2
"// assume output dims to be something like (1, 1, ... ,size)",2
Converting it to an Estimator and then training it throws an exception because it assumes the input names are 'input_1' and 'input_2'.,2
"Then, under the assumption that the latest release of Tensorflow would have all the necessary ops anyway, I built Tensorflow 1.13.1 using Bazel version 0.24.0.",2
Assuming to have a model with the over-defined CustomLayer.,2
"- Assuming the output shape of prev_layer0 is (None,32,None), pool_1 outputs (None,0,None) when it should be outputting (None,32,None)",2
"- Assuming the output shape of prev_layer1 is (None,None,32), pool_2 outputs (None,None,32) correctly",2
I assume that the MSE should be equivalent to the MAE squared but I may be wrong.,2
"Assume `batch_size = 2`, `num_true = 1000`, `num_sampled = 20`, then `out_labels` will be a Tensor of size `2 x 1020` (1020 is the addition of `num_true` and `num_sampled`).",2
"It's expected that, assuming the pasted code is correct that the predict() function should result in same output as the train() output.",2
"Assuming data.txt, labels.txt and keras_model are in the same directory as the executing command run:
```bash
LD_LIBRARY_PATH=path_to_libtensorflow_lib ./BellyTF
```",2
# Assuming that channels will be the last axis,2
They make the assumption that a model's inputs will be deeper than any other node.,2
"I assume this, because the observation one can make is that `tf.summary`s inside this if condition are placed inside different name scopes depending on whether the condition is a python bool (so static w.r.t. to the tensorflow graph) or a tensorflow tensor (resulting in a dynamic `tf.cond` through autograph).",2
tensorflow/lite/micro/kernels/fully_connected.cc:135:14: error: assuming signed overflow does not occur when assuming that (X - c) > X is always false [-Werror=strict-overflow],2
./tensorflow/lite/kernels/internal/types.h:197:31: error: assuming signed overflow does not occur when assuming that (X - c) > X is always false [-Werror=strict-overflow],2
tensorflow/lite/micro/kernels/fully_connected.cc:203:14: error: assuming signed overflow does not occur when assuming that (X - c) > X is always false [-Werror=strict-overflow],2
I'm assuming the problem is just from the build files failing to default to a suitable platform and is falling back to default values.,2
"However, these can now not be ported to the Blue Pill development board (I assume, our dev board has not arrived yet).",2
"As far as I'm aware though, pip still supports `manylinux1`, so I would assume it's reasonable to support this for older installs.",2
My assumption is that it's easy to provide this build given the previous minor version used `manylinux1`.,2
"So I'm assuming only some check of bazel is failing, although the compilation itself could be executed correctly.",2
"Assumed this was transient, but it has been present for 4 days now.",2
// * We make assumption that one session has one graph.,2
"// Operation will only be added to *graph when TF_FinishOperation() is
// called (assuming TF_FinishOperation() does not return an error).",2
Newest version (Tensor RT5) claims windows support but build script (configure.py) assumes linux only.,2
The default git worker rules from bazel 0.26.1 actually assume bash.,2
I assume this might be linked to the CUDA/cuDNN revision being used but I can't find any instructions as to the versions being of CUDA/cuDNN being expected.,2
"File ""./configure.py"", line 657, in prompt_loop_or_load_from_env
    'Assuming to be a scripting mistake.' % (var_name, n_ask_attempts))",2
Assuming the latest supported version 10.1 [-Wunknown-cuda-version],2
I assume this is because of wrong version of tensorflow/stream_executor/cuda/cusparse_10_1.inc.,2
"I'm assuming something wrong with my enviroment, but how can I check it?",2
"My assumption is this is an installation issue as it seems to be some sort of critical failure, but without additional diagnostic output i am unsure what to look into. **",2
"Unfortunately, the current `tf.data` [documentation](https://www.tensorflow.org/guide/datasets) starts off assuming we already have `TFRecords` on disk without even linking how we could convert images, say `tiny imagenet` or even arbitrary images to the `TFRecord`s format.",2
"Also I understand if this issue should be moved, I assumed this was appropriate since there was no documentation demonstrating loading a saved model with the new API.",2
"Specifically, we have the following (I assume common) use case.",2
"All the ways I've come up with are pretty jank, and I assume there is a better way to do this given how elegant it was in TF 1.X.",2
"I assume it's before `flatten_atrous_conv`, so I submitted a PR.",2
"One possibility would be to hook the Dataset Iterator initialisation between epoch
combining the use of dataset.repeat(num_epochs) - (Assuming the Estimator is initialising the iterator between epochs)",2
"We are unable to write a unit test for this
        # because TensorBoard dependency assumes TensorFlow package is installed.",2
The clusterspec passed to tensorflowrun can have assumptions or explicitly setup.,2
"This would allow the network to spot sequences of letters such as, if again using the `ams` kernel (conceptually, and assuming a further `1 - distance` operation applied to make an exact match a `1` and a non-match a `0`):

```
t    h    e      p    o    r    t       o    f       a    m    s    t    e    r    d    a    m
     0    0      0    0    0    0       0    0       0    1    0    0    0    0    0    0
```",2
Assume you want to create a metric which is calculated over the full dataset (i.e. evaluating how good a model is at sorting via some regression problem).,2
"In the current implementation of ParameterServerStrategy, the `ClusterCoordinator.schedule method` assumes workers are equivalent and thus assumes the datasets on different workers are the same except they may be shuffled differently if they contain a `Dataset.shuffle` operation.",2
Let's assume that i want to make a dataset from generator function using `tf.data.Dataset.from_generator`.,2
Typical scenario: Assume that one needs to add a list that contains variable number of `tf.keras.layers.Layer` to a keras Model.,2
"But if there are in the return statement tf.pyfunction crashes, because I assume its expecting a tf.Tensor.",2
I assume TFLite has such parameters buried inside.,2
Lets assume that we have a model model_A and we want to build up a backpropagation based on 3 different loss functions.,2
"Assuming it is related to the pybind switch, is there anything that can be learned from the prior swig architecture and applied in the current process?",2
"Currently, `GradientTape`'s `batch_jacobian` method assumes that `target[i,...]` is independent of `source[j,...]` for `j != i`.",2
I am assuming that this may be causing cpu bottleneck in my model.,2
"We could see before training they perform the same,but after training, they perform different,I assume because their gradients are different,but I don't know how to fix them,by the way I have to use twice embedding_lookup",2
As (please correct me if I am mistaken here) the SavedModel format is supposed to replace the frozen graphs in TensorFlow 2.0 I assume that this format is encouraged to deploy models for inference using a GPU and should be loadable quickly.,2
I haven't gotten the time to go through the `tensorflow/python/ops/image_ops_impl.py` but I assume there is some implementation change that is causing this issue,2
"One might assume that v2.6 uses the same CUDA 11.2 as v2.5 if release notes don't report any change. (Still, it would be hard to find that information a few releases from now.)",2
I assume it's a pretty easy operation to get ported to MCU?,2
"After hitting the board reset button, I get the yellow light blinking rapidly after a few seconds (I assume it is working at this point).",2
"But this is a temporary object, so I assume I should use the scratch buffer instead.",2
I assume this is caused for reasons unknown by the TFLite conveter?,2
The model works fine in python so I assume the tensor allocator in TFLite doesn't check for this.,2
I assume the registers are different for the OV7675 as compared to OV2640 and the arduino_image_provider.cpp needs to be updated with the correct register information.,2
"The ring buffer will eventually wrap around and
  // overwrite the data, but the assumption is that the main thread is checking
  // often enough and the buffer is large enough that this call will be made
  // before that happens.",2
"This might already be implicitly assumed with the above formula, but if so, it is not very clear.",2
I assume it may correlate with `instrih.h` inclusion (based on [this](https://msdn.microsoft.com/en-us/library/26td21ds.aspx) link).,2
"Assume I have the following neural network with two inputs:

`(x, t) ---> [neural network] ---> u(x,t)`",2
"Assuming I want to batch series of inputs and propagate the cell state from one session run towards another for an epoch:

```
for batch in epoch:
  state = initial_state.eval()
  feed_dict = {initial_state: state}
  state = sess.run([final_state], feed_dict)
```",2
I assume this was not intentional since this is a breaking change and I did not see it documented in the release notes.,2
"cl : Command line warning D9024 : unrecognized source file type 'cuda', object file assumed",2
Compilation of TensorFlow on Windows currently assumes x64 as a target CPU architecture.,2
Searching .bzl files for "x64_windows" shows the many places in TF where this assumption is made.,2
My assumption was that i have to set the number of features to the number of all the features (i.e. using all features instead of a subset of the features).,2
"Assuming this has not been tested and concluded to be optimal, my prior would be to allow Nvidia to handle the optimal execution of a conv2d on `NHWC` data rather trying to transpose within TF.",2
The current code is also nonportable: it assumes special  instructions for carryless multiplication of polynomials over GF(2).,2
I assume no responsibility or liability for its use of any kind._,2
"I assume that, since you can't specify this argument anymore, it defaults to the default policy in TF 1.X of stripping the GraphDef default attributes.",2
"But in my assumption - for example consider ```mant-to-many``` sequence model trained for ```NER``` or ```Language Model``` with the following code, ```(if return_sequences==True)``` in the previous ```BiLSTM layer``` then ```Dense(n)``` and ```TimeDistributed(Dense(n))```  are exactly the same and either of them can be used.",2
Is my assumption correct?,2
"I assume the intention is to slowly move away from the shell script to something better (hence configure.py, I wager) but for now, when testing projects with the master release it would be very useful to be able to just pick all default options for the WORKSPACE without knowing about them.",2
However this guide assumes that one uses tf.data.Dataset for the input pipeline.,2
"The above mentioned tutorial assumes you can do something like this with the input pipeline:
```python
with mirrored_strategy.scope():
  dataset = tf.data.Dataset.from_tensors(([1.], [1.])).repeat(1000).batch(
      global_batch_size)
  dist_dataset = mirrored_strategy.experimental_distribute_dataset(dataset)

with mirrored_strategy.scope():
  for inputs in dist_dataset:
    print(train_step(inputs))
```",2
"I assumed this field was used for assigning a different weight to each class, but it actually is used to assign a weight to each sample in the batch.",2
"Forgive me if I'm missing something obvious here (new to Bazel) but the tf_library Bazel rule seems to assume that `tfcompile_flags` is a string, while similar rules allow lists (cc_binary's copts for example). This is a gotcha that probably could be fixed easily.",2
"Graph editor copy_with_input_replacements  visits nodes in order provided, and assumes that op referenced by ""op._original_op"" has already already been visited.",2
"When this assumption is false, it fails with KeyError inside transform.py",2
"Specifically, let us assume we have two inputs A and B.",2
"Let us also assume that A and B have their own masks, which could be different to each other.",2
Assumes it is downloaded.,2
# we assume here that horizon < m,2
I assume this is due to the server using 2 processors.,2
*this is my assumption.,2
That I assume is a per-axis operation.,2
"Therefore, I assumed a relatively good resolution like 512,720 or 800 as a square image.",2
It worked in the previous version so I am assuming the trouble is related to the tf.scan code.,2
It's due to the https://github.com/tensorflow/tensorflow/blob/ea33c1e7a25d8025e8ee405ad8ab7be261798d76/tensorflow/lite/kernels/fully_connected.cc#L835 condition that will be true if `kernel_type == kReference` no matter the type of the bias while `FullyConnectedInt16` will always assume an int64 bias and thus read the int32 bias tensor as an int64 tensor.,2
Assuming that training is running on a single machine.,2
Assuming batch_size means tokens.,2
"#assume input has dimension (batch_size,x,y)",2
"Assuming sequential runs of the python client without changing a single line of code,  the problem is that I sometimes get the error: 
`Tensorflow.python.framework.errors_impl.FailedPreconditionError: Failed to rename: .../graph.pbtxt.tmp23e44d8fdce844e6822a56dc886588e6 to: .../graph.pbtxt : The process cannot access the file because it is being used by another process.`",2
"Running the code yields this warning when data come repeatedly from Kafka topic, I assume this is due to the repeat of creating dataset:

> WARNING:tensorflow:7 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8ca6abf598> triggered tf.function retracing.",2
Apart from anything else i assume theres a way to get rid of these warnings in the terminal?,2
So I assume that the image data is fine.,2
I think the existing code was written with the assumption that shard won't be empty  (start_index % shard_dirs.size()) and caused divide by 0 error.,2
I am assuming this to be a bug as the dtype int64 must have been hardcoded for sparse tensors.,2
"On getting the GDB from my nodes, I'm seeing additional threads (apart from my pre-configured setup of 40 per node), which I'm assuming to be created by Tensorflow.",2
// TensorFlow artifacts (it is assumed that the tensorflow repo is a peer of the crash repo),2
As no value is passed to the parameter `average_across_timesteps` I'm assuming it is using the default value `True`.,2
"Ex: 
assume f,g are simple linear functions
f(x)=x'
g(x')=y",2
"A similar error is encountered when reading a text file, and a more complicated DataLossError occurs when trying to load a model from a checkpoint (but the trace includes references to ""out of range"" errors, so I assume the same underlying problem is responsible).",2
"(Here, we assume all necessary libraries (including Tensorflow) are imported)",2
I dare to assume that for a wide society of TF users and for me in particular this functionality would be of a great interest.,2
// Assume if it's not a PNG then it must be a JPEG.,2
"Examples: ( ip: input to model, op: model output, ex: expected)
_(Note: I'm assuming padding tokens are not considered for metric calculation)_
_(Note: \<start\>: 1, \<pad\>: 0, \<end\>: 2)_",2
"I assume that these are somehow serialized in the graph protobuf so that when a GraphDef is imported, the relevant collections are imported too.",2
"When it comes to the node it only takes one of the inputs to the model as the input to the node, nothing else, therefore in theory it shouldn't wait for anything (I assume it waits for something if it starts but doesn't block computation).",2
"Assume we have a keras model:
```
Conv2D
MaxPool
Conv2D
MaxPool
Flatten
Dense
Dense(SoftMax)
```",2
"I assumed that Tensorflow has calculated the norm (L2 et Frobenius) of these tensors to view their evolution through time, right ?",2
Assuming you have a messi5.jpg in the folder (https://raw.githubusercontent.com/abidrahmank/OpenCV2-Python-Tutorials/master/data/messi5.jpg),2
"This is where an extensive tutorial by Luong et al was located until several days ago, I assume it was deleted or moved by mistake.",2
"So I assume I have the wrong tensorflow/inception-version (as the default zip-version worked, and my re-trained model worked inside docker-test), but I do not know what is the right version to use due to lack of documentation / knowledle / being tf-noobie.",2
"I assume [1][100][28][28][81] is for the masks and I thought [1][100][6] would be the class ID, probability score and bounding boxes.",2
I would assume a `tf.one_hot()` modification can work.,2
"Hi, I'm getting a `ResourceExhaustedError` in the middle of a training and I'm assuming that shouldn't be possible.",2
"Assuming that this op is not implemented for float16, what is the easiest way to bypass this issue?",2
"When I try to create an array of type `float64` in JAX I get the following message:

`RuntimeError: INVALID_ARGUMENT: 64-bit data types are not yet supported on the TPU driver API. Convert inputs to float32/int32_t before using.`

which from what I can tell is from the file `tensorflow/compiler/xla/python/tpu_driver/client/tpu_client.cc` in the Tensorflow repo, which I assume is part of the TPU driver API code.",2
I'm assuming the above arugument is all I need to use?,2
"the script  need and assumes the default /usr/bin/python is linked to python 2.x wich in my case is not,",2
I assumed the global state of tensorflow is being cleaned up after the process is being terminated.,2
Let's assume we can share a pointer to the underlying data structure between C and Scala (through a Java NIO DirectMemoryBuffer for example).,2
I assumed the exception reported in the previous post might be related to the tensorflow version (I saw a tutorial hinting in that direction).,2
"The upgrade completed but now I have a broken environment, and so assuming what I am doing here is nonsense, how do I revert back to the previous tensorflow version?",2
I am following this tutorial http://www.bitfusion.io/2016/08/31/training-a-bird-classifier-with-tensorflow-and-tflearn/ I assume that training was done but the system was restarted so I can't verify if the 100 epochs were done.,2
The problem is that the name given to a histogram_summary (and I assume all summaries) does not respect name_scope.,2
I'd assume that 'weights' would be scoped to some_unique_name but I'm suspecting that it is not.,2
I am assuming that the reusability of scope is handled internally by tf.nn.dynamic_rnn function.,2
after running this cell the output is 1.14.0 so I assume the above command `!pip install tensorflow==1.14` worked,2
"I also tried the following code that works so I am assuming, there is a bug",2
I am considering calling `TF_NewOperationLocked` directly but I assume the locks are there for a reason.,2
"So I am trying to build the tensorflow library to use with the c api on jetson nano, I have a project that uses tensorflow r1.14 and I assume that I will need a r1.14 library with that, I can migrate to r1.15 if that would be easier since the r1.15 build gets further and from the issue #34429 it seems as if the compilation issue I am getting on r1.14 will not get fixed.",2
"I am not 100% sure that I am using the `tf.contrib.metrics.streaming_mean_iou` correctly, but I have played with that a lot, but there is quite lack of the documentation, so I am currently stuck assuming that there is either some bug in the `tf.contrib.metrics.streaming_mean_iou` or not enough documentation for me to make it work.",2
So I assume there might be come issues in saving and restoring the checkpoint files in `tf.train.Supervisor` or maybe I did not use `tf.train.Supervisor` correctly.,2
"# Assumes that the file contains entries as such:
#   dog
#   cat
#   flower
# where each line corresponds to a label.",2
"Assumes that the image data set resides in JPEG files located in
        the following directory structure.",2
"Assumes that the file
        contains entries as such:
          dog
          cat
          flower
        where each line corresponds to a label.",2
I assume that the `validation_batch_size` could help speed up the validation process at each epoch.,2
I assume this isn't a pun...,2
I assume the tutorial was written up based on a different python script?,2
"However, in lack of examples or documentation, assuming this is not yet implemented, I am posting it as feature request.",2
# assume input_op shape is 224x224x3（第一个卷积层的输入input_op）,2
I found all the estimator examples in the tutorial assumes there is `x`(features) and `y`(labels).,2
I could inherit from `QueueRunner` but a `QueueRunnerBase` would be ideal as much of the existing implementation assumes the use of `enqueue_ops`.,2
The elements of v are then used as the non-zero entries of a sparse matrix M (assume the coordinates are predefined).,2
"Training on ml engine with python version 2.7
ml engine runtimeVersion 1.12 for both training and serving (assuming that means tensrflow 1.12)",2
The issue is that the code in reshape_test.cc assumes that any devices which are not CPU/CPU_PARALLEL/GPU will use the bfloat16 format.,2
"This is where I assumed that the cmake build does not include tensorflow/compiler/xla, indeed I found no corresponding MSVC build files.",2
"I assume that rear camera is used to infer, and also I'm trying to record video with rear camera .",2
"Basically, java buffer is still assuming the input size is (1, 120, 160, 3).",2
"Assume these are the words present in the vocabulary: The, brown, jumped, over, dog - These words are fed to the seq2seq encoder as such",2
"# Assuming model_checkpoint_path looks something like:
            #   /my-favorite-path/cifar10_train/model.ckpt-0,
            # extract global_step from it.",2
I assume there generally isn't an issue with using math ops in a functional model in this way?,2
I assume that these files are (or should be) generated by the protocol buffer compiler.,2
There are some files in tensorflow/contrib/cmake/build/tensorflow/core/framework with similar names (like attr_value.pb.h and tensor.b.h) which I assume are generated by the protocol buffer compiler.,2
"Usually, tensorflow models have a training operation, and we just have to sess.run that operation, but I'm assuming keras is working in a different way somehow.",2
"But I'm assuming when I import tensorflow 2.0.0, it's failing to find TensorRT v6, and just using cpu instead.",2
# Assumes y_pred are probabilities and that y_true has actually 2 labels inside,2
"You can assume the infer_op read inputs from an one_shot_iterator, and I never want this loop to stop just like it is a long-run server.",2
"So, I assumed that the use case I've outlined above should be supported, and it seems surprising that it works in some cases (fewer threads than CPUs) and doesn't in others (one thread per CPU).",2
"C and C++ can run on iOS, and I assume a lot of the code is platform-agnostic.",2
I assume that TensorFlow's core C API contains CPU kernels for those obscure ops.,2
"(I have not seen anything suggesting tensorflow can be built for iOS using bazel, so I assume that this remains the recommended approach.)",2
The above test is working so I assume my model is successfully converted to .lite format.,2
"When running model.fit while using the GPU it will run fine for a random amount of iterations than suddenly stop and when looking at the activity monitor i can see that GPU% goes down to zero, also sometimes a sub-model of my autoencoder returns a tensor twice it's normal size (my assumption is that the cpu and gpu are conflicting and returning the same values so it results in a double tensor, although i have no idea if that is correct).",2
"I can provide all of my code if requested i think i have not tried a bare minimum but I'm assuming this is related to memory usage and gpu exhaustion, so i haven't bothered with testing it on a smaller case.",2
But on backpropagation (that is what I assume ) it is throwing some error.,2
"But on backprop ( I'm assuming , it is backprop only) , it fails.",2
I'm trying to train RNNs with truncated BPTT with `tf.data` (a great API by the way!) but got tripped up by [these lines](https://github.com/tensorflow/tensorflow/blob/744cf3d3e06fb63ffa40086766137daedc01a5ba/tensorflow/core/kernels/data/interleave_dataset_op.cc#L190-L195) as I've assumed an exhausted iterator would result in a new element being opened directly at the same position in the cycle (in order to pass around RNN states reliably).,2
"I assume the problem is that the `_pywrap_tensorflow.so` has tensorflow
statically linked into them, so they don't use libtensorflow.",2
"I assume this issue was caused by gradient calculation, but I don't know for sure.",2
"In particular, the code assumes that:
1. Decoder hidden states q and attention states h<sub>i</sub> are the same size (which isn't true if e.g. you want different size hidden vectors for your encoder and decoder, or you want to use bidirectional RNN for encoder but not decoder)
2. v, W<sub>h</sub> h<sub>i</sub> and W<sub>q</sub> q must also be same length `num_units`",2
In particular assumption 1 is very limiting.,2
"However, it does not look like any of the convolution layers have biases when they (I'm assuming) should.",2
I saw something like this with the initial release of 0.6.0 but it was fixed by 0.6.1 so I just pulled from master and assumed I would never see it again.,2
"Assuming these three variables are independent, I would now like a function res = f(x, p) that would compute res[i] = p(sum(signal1 + signal2 + signal3) = x[i]) for 0 < i < len(x) -1.",2
Here we assume the normal convolution function (not cross-correlation).,2
"My theory was that it was outputting 0s -- assuming an even distribution, the summed MSE loss would be 224x224x.5^2 = 12544, which is pretty close to our 11893.52930.",2
This is because `AudioProcessor.maybe_download_and_extract_dataset(...)` in `tensorflow/examples/speech_commands/input_data.py` only downloads if the file doesn't already exist (sensibly) and assumes that `tarfile.open(...).extractall(...)` will complete error-free (less sensibly) - which it won't on the partially downloaded gzipped-tar asset.,2
But assume I'm getting the derivatives of the loss w.r.t. final_layer from an external  source (e.g. a tf.placeholder named _deriv).,2
"The cause of the bug is that when TF pre-allocates the destination ndarray in self.results, it always assume batch major dimensions (hardcode).",2
I'm assuming this is incorrect?,2
"In `dense_image_warp` function it is assumed that flow vectors are stored in source location of flow vectors while for dense optical flow datasets like **Middlebury**, **MPI Sinte**, **Flying Chairs**it is not the case.",2
In Tensorflow code it assumes that flow field is stored in **Format A**.,2
"I would suggest changing the assumption to **Format B** and modify the code to do backward warping (given image 2 and flow field, it will reconstruct image 1).",2
That is 500 developer-years (assuming a month is about 160 work-hours)!,2
I assume that the problem arises due to the difference in the tensorflow versions in which the model is saved (tf2.0) and in which the model is loaded (tf1.4)?,2
# - Assuming that by this we may get relevant slices.,2
"It seems like there is an inherent assumption in Distributed TensorFlow that all nodes must share a common file system, such as google cloud or NFS.",2
"I assume it can be somehow supported by zip-ing together different DataSets, but it would be MUCH easier and more flexible if we could just pass a list of indices.",2
"Since I did not get an answer yet, I assume that this is a non-trivial problem and therefore open an issue here.",2
"Let us assume a tensor like this:

```
x = tf.constant([[1., 2., 3.],
                  [4., 5., 6.],
                  [7., 8., 9.]])
```",2
"I assume it should be faster than the `float32` policy, but it turns out not.",2
My assumption here is that 'weights' is intended to allow us to indicate that certain indices should be ignored entirely.,2
# assume inputs dim is 4.,2
"Assuming import tensorflow as tf, I have a subclassed tf.keras.Model that uses a standard tf.keras.layers.RNN layer and a custom RNN cell (subclasses tf.keras.layers.Layer).",2
"-- Well, I assume it isn't a bug.",2
"Now, assume that I would like to extract features from an internal layer of the models.",2
"3. Assuming that I train the graph with 4 GPUs, and then provide `.meta` file to someone with 8 or possibly only 1 GPU.",2
Well this is my assumption.,2
I assumed that when setting the `batch_size` in `batch_shape` to `None` or using `shape` instead that the `batch_size` would then be dynamic.,2
"My assumption is that it squeezes the dummy dimension that corresponds to the batch size=1, while it clearly shouldn't.",2
"However, if you rename version 6 to version 5, tensorflow will load, but it will stop with errors. (Actually, that's how I tracked down the problem - it mentioned version 5100 of the GPU, which I assumed meant release 5).",2
Or (Assuming deprecation) is the suggested implementation just to do all of these transformations in the `input_fn():` and just pass a sparse_column_with_integerized_feature() directly.,2
"In the Keras example, a dataset is used as well and I assume it should work with datasets consisting out of tensors.",2
Seems like tfl quantized maximum/minimum ops are assuming input tensors always have same scales?,2
// assume I'll be give a TF graph,2
"Base on the function itself (""_dynamic_""), I would assume that allowing sequence_length=None is intended (although, in either case, the documentation should be straightened out).",2
"Assuming we do want to allow seq_length=None, the offending portion within bidirectional_dynamic_rnn would appear to be:

inputs_reverse = array_ops.reverse_sequence(...seq_lengths=sequence_length...)",2
"This needs to be benchmarked, but I assume there is some cost to having to transpose the filter weights during both fprop and bprop (twice).",2
I would assume I'm using regressor from the TensorFlow in a wrong way.,2
"// Assuming graph contains single input X, with node name ""input""
    // and single ground truth placeholder, with node name ""y_true""",2
"// Assuming graph contains single loss, with node name ""loss""
    // and single training node, with node name ""train""",2
"Assumes images are already prepared (means subtracted, BGR order, ...).",2
"I would assume this is a complication with the CUDA drivers, as I occasionally (though not always) get kernel panics at the same time.",2
This is not going to be easy as we need to also compile the C++ codebase in 32 bits mode and that would cause issues with code written assuming types have a certain bit width.,2
"The docs aren't clear whether it should compute complex results or not — but it states the function accepts complex inputs, so I assume returning ""nan"" is not expected.",2
"I'm basing my assumption on this:
https://stackoverflow.com/questions/19944429/cuda-performance-penalty-when-running-in-windows",2
So tf.image for example has some elementary image processing methods already implemented which i'd assumed are optimized.,2
Some functions in the TensorFlow standard library makes an assumption that we're always feeding minibatches.,2
"One example is `tf.nn.softmax` which assumes a 2-D input of shape `[batch_size, num_classes]`.",2
It would be nice to have a second API to such subroutines that work also without an assumption of a minibatch dimension in the input tensor.,2
# This assumes that your machine has 2 available GPUs.,2
"When creating e.g. keras models I would assume, that when I run `make_generator_model` twice in eager mode that the `trainable_variable` names are identical.",2
**Why would I assume this?**,2
I didn't check what version the video driver was before the update but I assume it was 361.42?,2
Tensorflow's `cuda_diagnostics.cc` [here](https://github.com/tensorflow/tensorflow/blob/076799bdfae0057723d96f47cf78cb623c8bcd57/tensorflow/stream_executor/cuda/cuda_diagnostics.cc#L82) assumes that the GPU driver version will match `%d.%d.%d` but that doesn't seem to be a safe assumption.,2
"In my case, assume my batch is 16 as exhibted in yPred and yTrue above, shall I use

`
			loss = 1 - tf.math.divide(numerator, denominator+self.epsilon)
`
or 
`
			loss = tf.math.reduce_mean(1 - tf.math.divide(numerator, denominator+self.epsilon))
`
And for which option?",2
"I am aware that these AMD processors are not the newest ones and that it's possible to compile TensorFlow without the SSE4.1 requirement (at least, I assume so), but I wanted to raise this issue to see if you think it might be possible to make the official 1.0.0 binaries work without SSE4.1.",2
"Looking deeper into the code, I can't pinpoint why `train_batch_size` needs to be set when on a TPU, but I'm assuming it's required somewhere deeper in the code.",2
"Pull request #28724 added a `bbb` make target which produces a usable library on the Beaglebone, but when building the wheel, the code still assumes `rpi`:

https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/tools/pip_package/build_pip_package.sh#L42-L45
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/tools/pip_package/build_pip_package.sh#L85-L87
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/tools/pip_package/setup.py#L54-L56",2
The configure script calls "ldconfig" to locate the CuDNN library but this makes 2 assumptions that can be wrong:,2
1. It assumes that "ldconfig" can be called.,2
2. It assumes that the CuDNN library is installed in a system library location that is searched by ldconfig.,2
I assume this sentence was just copied from the Conv1D layer and should be removed since there is no dilation_rate argument for the LocallyConnected1D layer?,2
"I assume that it is trying to get exclusive access to the GPU, and if it can't do that, it crashes.",2
"Unfortunately the variable that the original set is called `gif_STATIC_LIBRARIES`, because it assumes it would be static.",2
"Obligatory issue template requested by tensorflowbutler (I assume that most are irrelevant, since this is a feature request):

Have I written custom code: Not yet
OS Platform and Distribution: N/A
TensorFlow installed from: N/A
TensorFlow version: N/A
Bazel version: N/A
CUDA/cuDNN version: N/A
GPU model and memory: N/A
Exact command to reproduce: N/A",2
There are a few related issues e.g. https://github.com/tensorflow/tensorflow/blob/6fdb9ad1baf7686a75f9e660178f7ac595e7fc2e/tensorflow/cc/gradients/nn_grad.cc#L164 where the code assumes the underlying object is being mutated and the parameters don't actually pass through.,2
"The image_label example assumes that decode_gif (https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/label_image/main.cc#L105) will return a 3-d tensor ([height, width, channels]) in the same way that decode_jpeg or decode_png would.",2
"Assume these are the words present in the vocabulary: _The, brown, jumped, over, dog_ - These words are fed to the seq2seq encoder as such",2
I assume this is a typo and is meant to be begin_params_axis,2
"This op assumes that there is at least one id for each row in the dense tensor
  represented by sp_mat (i.e. there are no rows with empty features, if so, 
  put 0.0 in sp_mat entry), and that all the indices of sp_mat are in
  canonical row-major order.",2
"It also assumes that all id values lie in the range [0, p0), where p0
  is the sum of the size of params along dimension 0.",2
"But I think this would be against the principle of least astonishment, since I assume most people would think that an op talking about padding would actually add padding values.",2
"- The first dimension of the input shape vector can be `src_format.size()` or `src_format.size() - 2`, in which case it is assumed that non-spatial dimensions are omitted.",2
Assume each method pushes a scope for the instance (with the class name) and for the method.,2
"If i understand correctly, this assumes that every image has the same number of bounding boxes.",2
"The root cause is that `create_file_writer(logdir)` returns a SummaryWriter python object backed by a C++ SummaryWriterInterface resource, but the mapping is not 1:1, which violates other assumptions about resource management under eager mode.",2
"Deleting a `TfLiteModel` object is ok, if one reads it from a file, because the interpreter relies on the file which is _assumed_ to stay unmodified during the lifetime of the interpreter.",2
"In short, the workaround whenever the bazel server dies is, assuming you've backed up your crosstool directory in /tmp/crosstool/:

```
bazel fetch //tensorflow/...
cp -aR /tmp/crosstool/* $bazel_build_dir/external/local_config_cuda/crosstool/
```",2
"Assuming that I have some set of files which are serialized examples, each a list of the form {file1: <...>, file2: <...>, label: <...>}, is there a simple way to serve them to the net as a tensor of shape 2N \* W \* H \* C (with image i and image i + 1 belonging to a single relation, where i is (0, 2, 4, 6, ...) i.e., [relation_n_image_1, relation_n_image_2, relation_m_image_1, ...])?",2
"Would be even better if this is corrected inside Tensorflow that it automatically detects that from_logits=True was set and then assumes that default threshold is not 0.5 anymore, but 0.0 (and maybe additional WARNING output).",2
"For reference, it takes approximately 900 ms to copy from an 1920x1080x3 OpenCV matrix to a tensor while it takes 315 ms to do session.run (which I assume includes transferring between CPU and GPU memory).",2
"To install it you have to spend hours and hours, just because you assume that all of us have prior knowledge that you have.",2
"I assume it's related to gradients, but the optimizer (I think) does a lot more than just apply the raw gradients returned from `opt.compute_gradients()`.",2
I assume this is happening because the data type conversion sees a float tensor and clips all values larger than 1.,2
Currently the example above crashes because various places in code assumes that grad function output matches type of incoming activation.,2
"- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Not sure if the project devs did, I assume not.",2
"say mask of a batch size of 1 is T,T,T,F,F,F,F,|T,T,F,F,F,F,F and X=2 (by '|', I assumed a break which indicates a row split length=7), then should get list of concatenated embeddings given by indices (1,2) (8, 9).",2
As the result the class may not be aligned correctly and create a segfault when running https://github.com/tensorflow/tensorflow/blob/f18495306f26fa2e1d3351c03838cde265eb6690/tensorflow/core/kernels/sparse_matmul_op_test.cc#L330 (which GCC vectorizes assuming the alignment),2
"Looking at how it is handled in the [v1](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/callbacks_v1.py), I think the check should be done on `self.embeddings_metadata` (assuming if it is not a string it is a dictionary).",2
"Let us assume we want to perform a moving average over incoming scalars; sometimes we want to update the statistics of that moving average, sometimes we don't.",2
"I'm trying to remap the input so I can do image space optimization with a library that assumes the network input is (width, height, channels).",2
"I'm assuming this is related to not having TF 2.0 installed, and only having T 1.13 installed.",2
"We are allowed to define `get_initial_state()` for initializing custom states, but not for validating them; I have a scalar hidden state, which raises an exception per `flat_state_spec[i].shape[1:]` (it assumes a 2D+ tensor).",2
"- New or better APIs for allowing OpKernel's to use arbitrary device resources (e.g., right now we assume either the use of StreamExecutor or EigenDevice implementations, but that's obviously not general).",2
"Assumed to be utf-8
            encoded.",2
I couldn't use the `gradient_override_map` since that would require the user to build their model within my SHAP context...and I need to assume they already have a model they have built.,2
I assume this is because the GradientTape doesn't think the "watched" tensor is connected to the output when the path through the graph includes non-differentiable operators.,2
New behavior silently breaks the code that rely on the assumption that zero cross-entropy will be returned and valid gradients will be calculated in case of labels `-1` .,2
# I assume this happens because `x` and `w` reference the same object.,2
I assume `layer_norm=True` should be set during training and `layer_norm=False` for evaluation.,2
"_The following I'm assuming came with tensorflow because I didn't install them myself:_

- Keras-Applications = 1.0.8
- Keras-Preprocessing = 1.1.0",2
"From a cursory inspection of the python source I would guess that in [line 796](https://github.com/tensorflow/tensorflow/blob/a6d8ffae097d0132989ae4688d224121ec6d8f35/tensorflow/python/ops/losses/losses_impl.py#L796), the number of classes is assumed to be `shape(onehot_labels)[1]`, rather than `shape(onehot_labels)[-1]`.",2
The former assumes a 2D labels tensor which is neither described by the documentation nor enforced by the method.,2
For `tf.contrib.layers.batch_norm` and `tf.contrib.layers.layer_norm` the assumption is that only one dimension is normalized.,2
That line assumes that Tensorflow is the main repository.,2
"This is assuming a simple text file (here named 'test_file') like this:
```
here_is_one_row
here_is_another_row
```",2
"Our instructions assume that `targetDirectory` is `~/tensorflow`, but you may choose any directory.",2
"When I add creration of Ns_r on each it too, the time is same, but I do not consider tf.gather as optimal - the elements are ordered and just repeated, while gather does not use this assumption",2
"For my case, I was using/looking at the [`tf.estimator.model_dir`](https://github.com/tensorflow/tensorflow/blob/r1.4/tensorflow/python/estimator/estimator.py#L122-L126) parameter, but for consistency I assume it would also need applying in all cases where a path is accepted such as `tf.gfile`",2
For pre-training I would assume I can feed in the same output data from the generator in batches multiple epochs.,2
Looks like there are assumptions on what it would convert correctly.,2
"For example, the log semiring assumes that all numbers in the matrices are log numbers and redefines `plus` as `logplus` (aka [logaddexp](http://docs.scipy.org/doc/numpy/reference/generated/numpy.logaddexp.html#numpy.logaddexp) or [logsumexp](http://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.misc.logsumexp.html)) and `times` as `plus`.",2
This is useful for finding the best path (assuming all matrix entries are log numbers).,2
"I assume this implies that for a denormal 32-bit floating point, `denorm`, the expression `float{bfloat16{denorm}}` should be equal to zero.",2
"[Tf docs](https://www.tensorflow.org/install/gpu#software_requirements) say that GPU support will work with CUDA 11, I assume meaning 11.* (??)",2
I assume this means that tf 2.5.0 GPU will NOT WORK with CUDA 11.3.  (??),2
"If not, I assume I must downgrade CUDA to 11.2.2 and cuDNN to 8.1.1.",2
[`strip_unused`](https://github.com/tensorflow/tensorflow/blob/5657d0dee8d87f4594b3e5902ed3e3ca8d6dfc0a/tensorflow/python/tools/strip_unused.py) assumes that all of the placeholders are of the same type which may not be the case.,2
"Assuming that there are no typos here, I am trying to understand how one should think about the `input` and `inputs` arguments of these functions as their corresponding types involve `TF_Output`, not `TF_Input`. Take `TF_SessionRun`, for instance.",2
"Correct me if I am wrong, but I think this code is assuming that, when time > 0 the beam will be full. It is true when the vocabulary is big such as is the case in machine translation.",2
`tf.function` makes invalid assumptions about arguments that are `Mapping` instances.,2
"In general, there are no requirements for `Mapping` instances to have constructors that accept `[(key, value)] ` initializers, [as assumed here](https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/util/nest.py#L145).",2
"I was expecting [2, 2, 2, 2, 2], as I would expect the dataset in memory to be replaced with the subset that I took in take(1), rather than now having (I assume) two datasets in memory, the subset dataset + the original dataset.",2
"e.g.

Let's assume someone passed an int32 tensor into ReaderReadUpTo as the third input(num_records), which should have a type of int64.",2
I assume it can point to https://arxiv.org/abs/1512.00567 instead.,2
"I want to know how this function specifies the Class Index to be used for the BLANK LABEL
Beacuse:  
  # gen_ctc_ops.ctc_loss_v2 differs from gen_ctc_ops.ctc_loss. v2 assumes the blank index to be 0, but v1 views it as the last index.",2
"Assume x = 7984, quantized_multiplier = 1583594044, shift = -9 (the simulated floating point arithmetic is `std::round(7984 * 0.0014402703931141053)`).",2
This is fine assuming org/tensorflow/native/darwin-x86_64/libtensorflow_jni.dylib is not built to depend on it.,2
"I assumed that one has thread locking (.GFile) and the other does not, but both say the same thing in the docs:
- [https://www.tensorflow.org/api_docs/python/tf/gfile/GFile](https://www.tensorflow.org/api_docs/python/tf/gfile/GFile)
- [https://www.tensorflow.org/api_docs/python/tf/gfile/FastGFile](https://www.tensorflow.org/api_docs/python/tf/gfile/FastGFile)",2
"however they call convert_image_dtype() which assumes pixels are in [0,?].",2
"After HostRecv, tensorflow will call BaseGPUDevice::Compute() on the PackOp kernel. 
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/common_runtime/gpu/gpu_device.cc#L479
Which will immediately proceed calling Compute() on the assumption that it is a GPU kernel that's going to be executed in the same stream (therefore synchronization is unnecessary).",2
### Assumptions,2
.\tensorflow/core/kernels/cuda_sparse.h(290): error C4430: missing type specifier - int assumed.,2
.\tensorflow/core/kernels/cuda_sparse.h(303): error C4430: missing type specifier - int assumed.,2
tensorflow/core/kernels/cuda_sparse.cc(512): error C4430: missing type specifier - int assumed.,2
tensorflow/core/kernels/cuda_sparse.cc(551): error C4430: missing type specifier - int assumed.,2
tensorflow/core/kernels/cuda_sparse.cc(659): error C4430: missing type specifier - int assumed.,2
tensorflow/core/kernels/cuda_sparse.cc(720): error C4430: missing type specifier - int assumed.,2
tensorflow/core/kernels/cuda_sparse.cc(852): error C4430: missing type specifier - int assumed.,2
tensorflow/core/kernels/cuda_sparse.cc(871): error C4430: missing type specifier - int assumed.,2
"I assumed the second case is true, because depthwise convolutions are probably handled differently concerning GPU optimization which might not yield the restriction of being able to specify only one of stride or dilation.",2
"I think this is because there is no attention wrapper, but I assume beam search can be done without attention",2
"If you don't use attention then you can directly pass the tiled encoder
state as the initial state (assuming your encoder and decoder cells are the
same architecture).",2
"Also, the stable versions seems to have no problem with these inputs, so I assume something went wrong with the nightly build.",2
I assume you're using it.,2
"If any of your ops seems to be not quantizable, edgetpu compiler will exit with an unknown error (they are continously working on this so there will be detailed info in future [My assumption]).",2
"@srjoglekar246 for the 1-op model, TF2.2 and TF nightly branch(I assume it is the Master branch) produced slightly results:
TF nightly:
`OutputDiff[0]: avg_error=0.00215609, std_dev=1.08443e-05, gpu_precision_loss = false`
`OutputDiff[0]: avg_error=0.00215643, std_dev=1.08542e-05, gpu_precision_loss = true`
TF 2.2 (exactly same results for gpu_precision_loss = true or false ):
`output_errors { output_errors { max_value: 0.0021719106 min_value: 0.00214503519 avg_value: 0.0021564289927482605 std_deviation: 1.0854229e-05 }`",2
So we can assume that nothing has been broken since TF2.2,2
"Assuming that it is related, is there any caching involved when reading the .tfrecord?",2
I assumed this error was related to gzip compression type when generating tfrecord.,2
Here are two things I suggest you to try (Assuming you are using 2.8 version for conversion to lite file),2
"I haven't worked on the Saver code myself, but looking through it this seems like a reasonable project for someone new to TensorFlow (assuming you have prior Python experience already).",2
Can you update us on when all these features will be available and in which tensorflow version (only 2.0 I assume)?,2
"Thus, assuming you have a complete C++11 implementation,
the compiler and its runtime will already provide the operations in a
TensorFlow build,
and handwritten assembly language is not needed in that case.",2
"It updates the BUILD file (assuming
you're building with bazel),
and adds that header file.",2
"I will do that
update
to TensorFlow assuming all is well with the change to nsync.",2
"Assuming you wish to build nsync as C++11
(which is what TensorFlow requires), at the root of the nsync tree do:
  cp -r builds/x86_64.linux.c++11 builds/s390x.linux.c++11
  cd builds/s390x.linux.c++11
  make depend test",2
"The assumption here is
that the platform will perform loads and stores atomically if
they are 32-bits and naturally aligned.",2
"> Assuming you wish to build nsync as C++11
> (which is what TensorFlow requires), at the root of the nsync tree do:
>   cp -r builds/x86_64.linux.c++11 builds/s390x.linux.c++11
>   cd builds/s390x.linux.c++11
>   make depend test",2
"The assumption here is
> that the platform will perform loads and stores atomically if
> they are 32-bits and naturally aligned.",2
"@mhyipa Assuming you just installed TensorFlow 1.3, you'll need to upgrade to cuDNN v6, and put `cudnn64_6.dll` in your `%PATH%`.",2
"Input `transforms` is a num_images x 8 or 1 x 8 matrix,
where each row corresponds to a 3 x 3 projective transformation matrix, with the
last entry assumed to be 1.",2
"I assume all 0 except `a0, b1, c2 == 1`?",2
"@reedwm, I've assumed the [tensorflow/compiler](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/compiler) will support all core ops eventually.",2
"I verified the number of flops against the EfficientNets and ResNets. `get_flops(model, batch_size=1)` consistently returns double the number of flops reported in the literature, so it's likely that the literature assumes [fused multiply-adds](https://en.wikipedia.org/wiki/Multiply%E2%80%93accumulate_operation) whereas this api does not.",2
@jdduke: I assume you mean changing `--inference_input_type=QUANTIZED_UINT8` to `--inference_input_type=FLOAT` in my conversion command?,2
> @jdduke: I assume you mean changing `--inference_input_type=QUANTIZED_UINT8` to `--inference_input_type=FLOAT` in my conversion command?,2
My assumption is that if I create graph same as google it may give me semantic predictions on my custom trained objects properly.,2
This assumption my be incorrect.,2
I assumed that the link led to the download of the actual dataset.,2
C:\users\administrator\_bazel_administrator\ybx4nglg\execroot\org_tensorflow\external\eigen_archive\Eigen\src/Core/DiagonalMatrix.h(99): error C4430: missing type specifier - int assumed.,2
Which I assume I can link these in like `.a` files on Linux and my symbols will just "be there",2
"Or I just keep making assumptions and then test them with experiments, which is a poor use of my limited resources",2
If it doesn't then it's assumed that this string is initialized (and not shared) and it gets written to.,2
"MKL, I assume, was successfully installed beforehand when I ran `apt install intel-basekit`, as per [these instructions](https://www.intel.com/content/www/us/en/developer/tools/oneapi/onemkl-download.html?operatingsystem=linux&distributions=aptpackagemanager).",2
"@guschmue Apologies, I wrongly assumed you were an internal contributor!",2
Assume that fully_know is always true..,2
OK actually I just assumed tf.mod = % but didn't think about it further...,2
An assumption I had when working on this was that sending scipy image data was reasonable - this is not the case.,2
Assume we work on vehicle recommendations for an online market.,2
"In this case and I assume in others where people deal with multiple categorical features, one could profit from a higher abstraction of **tf.one_hot** which is why I propose **tf.multi_one_hot**.",2
"# assuming we don't have the function to create the model again, we cannot relocate the tensors to anther GPU.",2
"Anyway, since you already created a PR that has been merged, I assume that the warnings will disappear in the near future and that we can close this issue.",2
"Furthermore, if you close the python process in windows, the event file is gone assuming that you attempted to delete it and got `PermissionError: [WinError 5] Access is denied:`.",2
"So i'd assume that for a C# implementation, we'd try and keep all the original python code as is (as much as possible) to save translating 60k lines (and keeping them in sync)",2
"I am familiar with this blog post, yet this post assumes that we have access to the ckpt and pipeline.config files to generate a .pb file that is compatible with tflite.",2
So for example if you want to test with tf_cnn_benchmarks.py and test resnet50 you would run this command assuming you are using 2 Xeon Phis with 72 physical cores each for a total of 288 logical cores and 144 physical.,2
"But when I look at https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/kernels/maximum_minimum.cc#L72
it looks as if it assumed that the scale and zero point is the same for both input and output.",2
"@windmaple Great news, I will test it out, I assume it is tf ver 1.14?",2
"Let's say you have 1000 images but only evaluates 100 of them, and assume they are ordered by labels.",2
"It is likely that the java code you mentioned above assumes an output ordering of tensors which isn't followed by the model, so you will have to change that part of the code.",2
"Right now, its likely that your Java code assumes `[boxes, classes, scores, num_detections]` - which is why the error says that you are trying to copy a wrong-shaped tensor into another one.",2
"1) If I choose ""nnapi-reference"" as accelerator, it works (but of course very slow), so I assume there is no error in the model or on the tensorflow side",2
It looks like `config['config']` is expected to be a dictionary here in 2.1 while its a list(https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/keras/utils/generic_utils.py#L252) but in 2.0. no such assumed deserialization happens as I see it.,2
"I'm assuming the model and dataset from your private repo code is larger than MNSIT, so try running that code in tf-nightly as well without passing in `steps_per_epoch` and let me know what you see.",2
"After TF 1.4 is finalized the nightly builds will move to the CUDA 9 +
cuDNN 7 assuming there are no issues.",2
Assuming because you said VS 2017.,2
This is happening because `model.save/load_weights` creates a `tf.train.Checkpoint` which assumes  the models have the same structure.,2
"Basically I've a bunch of images (assume 1000),  and I've two gpus.",2
I assume that is by design?,2
I was assuming I could build that with android studio doh...,2
I assume that the CPU version of 1.0.0 should function as expected?,2
">     We assume that the list is sorted, e.g., [(2, 4), (8, 16)].",2
"Assuming this does capture the core issue here, perhaps it can be a starting point to track down where it comes from.",2
But here you make strong assumptions on what Python's or TF garbage collection should look like :),2
"We set our Android NDK API level to 18 when building, but it's possible there's something wrong with the config and it's assuming API 23.",2
"For fat ones (width>height) the results weren't as good, which might be associated with some assumption in the reference, numerical difficulties (since it requires the computation of a pseudo inverse instead of an exact one) or a mistake in the code.",2
I'm assuming that you also couldn't find an implementation.,2
"As a quick test on my local, I manually created a symlink under venv/lib/python3.10/site-packages/tensorflow by `ln -s ../keras/api/_v2/keras/ keras` (assuming you have tensorflow and keras pip package installed properly), and then the IDE can resolve the package level auto completion correctly.",2
I would assume that you installed the wheel I provided above.,2
The webinar made me assume yes but now I'm under the impression that only Knights Landing is supported (which is not available?) and the Knights Corner is not supported.,2
"@yaroslavvb I'm assuming that if I run the probe op in a session together with computation of a model this would return me the peek memory usage, is that correct?",2
"The code attempts to download the data files from the MNIST web site, and assumes it's properly downloaded if the file is present locally on your system.",2
I assume that the output is calculated based on the last batch only.,2
"// Just allocate the required size for the given type assuming the
  // type has a trivial constructor.",2
"Sure, but i am assuming that:
1. You've installed Anaconda and conda command on cmd works fine.
2. Your system is a Windows one",2
"I'm assuming you're using the Java API and bringing in gpu delegates via 
`implementation 'org.tensorflow:tensorflow-lite:0.0.1-gpu-experimental'`",2
How you set (assuming raspberry pi 4) to USB3.0 compatibility mode/option?,2
"I assumed that the tensorflow was the issue, as issue #3388 was also occurring at the same moment when I ran my Keras test scripts.",2
I assume you do this in tensorflow/workspace.bzl?,2
"Of course, this assumes you are not using a pre-converted model.",2
Keras wasn't mentioned in your comments anywhere; I assumed it's for Estimator.,2
"Assuming that you have 4 classes that you want to train your model on, discretionary devs can use the below snippet that might help them:

```py
def weighted_loss(weights):
    def compute_loss(y_true, y_pred):
        true_idx = tf.cast(tf.argmax(y_true, axis=2), dtype=tf.int32)

        table = tf.lookup.StaticHashTable(
            initializer=tf.lookup.KeyValueTensorInitializer(
                keys=tf.constant([0, 1, 2, 3]),
                values=weights
            ), default_value=1.)

        weight_sample_class = table.lookup(true_idx)
        cce = tf.keras.losses.CategoricalCrossentropy()
        loss = cce(y_pred, y_true, sample_weight=weight_sample_class)
        return loss
    return compute_loss
```",2
I reckon it's due to CuDNN5.1. is this assumption true?,2
# assuming you are using the ldconfig approach,2
"After setting `CUDA_VISIBLE_DEVICES` appropriately, you can use `worker_device=""/job:worker/task:%d/gpu:0"" % (FLAGS.task_id)` as the argument to `tf.train.replica_device_setter()`, and the utilization should be balanced across the GPUs (assuming that you build the same graph in each of your worker processes, and use something like the `tf.train.Supervisor` to manage the distributed execution).",2
3. `docker exec -it jolly_lamport bash` (assuming Linux),2
I assume this is why people need to downgrade their bazel version as well to get it work.,2
Due mainly to the fact Visual Studio assumes SSE1/SSE2 when compiling for x64.,2
I saw the `-c opt` option in another website and wrongfully assumed it was equivalent to `--config=opt`...,2
"This is most likely a CUDA/cuDNN misconfiguration, assuming your TF version is the latest with GPU support, as you didn't specify.",2
The `vgg_16` model assumes its input is 224x224.,2
"I'm assuming you mean that AdamOptimizer is slower than MomentumOptimizer; Adam applies momentum to the whole variable, Momentum only applies it to slices affected.",2
.\tensorflow/lite/delegates/gpu/cl/opencl_wrapper.h(682): error C4430: missing type specifier - int assumed.,2
.\tensorflow/lite/delegates/gpu/cl/opencl_wrapper.h(687): error C4430: missing type specifier - int assumed.,2
.\tensorflow/lite/delegates/gpu/cl/opencl_wrapper.h(688): error C4430: missing type specifier - int assumed.,2
> .\tensorflow/lite/delegates/gpu/cl/opencl_wrapper.h(682): error C4430: missing type specifier - int assumed.,2
> .\tensorflow/lite/delegates/gpu/cl/opencl_wrapper.h(687): error C4430: missing type specifier - int assumed.,2
> .\tensorflow/lite/delegates/gpu/cl/opencl_wrapper.h(688): error C4430: missing type specifier - int assumed.,2
>> .\tensorflow/lite/delegates/gpu/cl/opencl_wrapper.h(682): error C4430: missing type specifier - int assumed.,2
>> .\tensorflow/lite/delegates/gpu/cl/opencl_wrapper.h(687): error C4430: missing type specifier - int assumed.,2
>> .\tensorflow/lite/delegates/gpu/cl/opencl_wrapper.h(688): error C4430: missing type specifier - int assumed.,2
I have made few assumptions in code while executing.,2
"Assuming timeit just calls external functions without doing anything else to them, things should work that way.",2
I'd also suggest using a more recent version of TensorFlow (assuming you are indeed using 1.0 as suggested by the tutorial link).,2
"I do not get the line ""Adding visible gpu devices:"" and instead get ""CPU Frequency: 3600000000 Hz"", which I assume means it is still using my CPU rather than my GPU.",2
So I'm going to assume that this works just fine and this warning will go away with 1.5 or perhaps a 1.4.2 version.,2
I assumed everyone knows how to go to the releases page or just google the MS installers.,2
"29.9 MB doesn't seem like an awful lot, but I'm assuming it has to be allocated contiguously.",2
"So, I assume there may be some incompatibility issues on your hardware.",2
"thus, assuming a square box (width == height) and depth = 3 I need to have an image of size: 299*299*3 = 268203 which currently it is not (it is 269156)",2
"I have no way, I assume, to control these additions.",2
"The only way to achieve this mix is by using tf.py_function, which is ok assuming you don't want a portable model, but which will negatively affect the performance of your graph.",2
"Now I assume two instances of tf is installed, does it mean when I run my script with python3 tfsample.py, it goes and use tensorflow-gpu installed by pip3 and when I  use python2.7 tfsample.py, it goes and use tensorflow-gpu installed by pip?",2
"I assumed you used python 2.7, as you did not respond negatively to @lxsgdsgg 's query.",2
I think the failure doesn't happen on single GPU because the concat op that's failing wouldn't exist in that case (assuming you're running on one GPU without using any distribution strategy).,2
"@jvishnuvardhan I haven't read the reference, I just saw that this piece of code was no reference, and I couldn't find where it belongs to, so I assumed it should not be in the reference box.",2
"To be more precise: when `map` executes deterministically, then assuming its inputs are `x_1, ..., x_n`, it will produce as output `f(x_1), ..., f(x_n)`.",2
"Your code makes the assumption that 0 signifies the EOS token, right?",2
"Also, having an eos_token assumes that an eos_token should be appended to each label.",2
"When is comes to platforms I would assume Windows 10 64bit and Ubuntu 18.04 LTS 64bit
would cover most of the user base on none AVX platforms.",2
"Yes, you should be able to install from source without trouble, assuming you have the dependencies installed (all called out in the installation guide).",2
"My methods still works for 0.11, but I'm not sure of 0.12, as the latest stable Bazel (which somehow I assumed is needed to compile TF 0.12) won't compile on CentOS.",2
"Data is pre-loaded on ram and every `__getitem__` step only grabs a slice from the numpy dataset, so I assume the generator is not the bottleneck and could be the eager execution disabled.",2
"Judging by the use of bazel across the documentation, I assume its a matter of waiting for bazel to support windows.",2
"Looking at the Bazel repository it says they are planning to support Android in Windows, but I didn't see any reference to building (what I assume are) native packages.",2
As this is a pretty popular example and people have little trouble with it I will assume that this isn't a bug with Tensorflow.,2
"Two folders images are not able to recognize by  tensorflow, I kept images from male folder to other two folders , then it was working fine, so am assuming the problem is with images, My question is , is there any restriction for images?",2
"That did the trick, thanks!!  (I stupidly assumed that was only relevant for the `dmg` installation.)",2
"I think race conditions or some GPU related issues might be precisely caused due to part of constructed graph not being GPU-friendly as you mentioned (I assume this implies `tf.map_fn` compatibility, or at least some part of its code), but I'm not aware of exact issue.",2
"That's very interesting, so subset of regular operations that are temporarily held with `K.batch_set_value` during weight assignment have complete support for GPU - therefore it is assumed that the whole graph, including the complement set containing gradient operations should be colocated on GPU device (however, not all gradient operations in this complement set have GPU kernels).",2
"> therefore it is assumed that the whole graph, including the complement set containing gradient operations should be colocated on GPU device",2
After the 404 are a bunch of javascript errors but I'm assuming they are there because of the missing stylesheet.,2
"Also i am assuming the same behaviour for any other formats other than `tf`, too.",2
"Right now it assumes all
        #       images in a batch have the same active_class_ids",2
"I also still can't find these in the ""standard place"" - which I assumed is what `ldconfig` was doing:
```
[stiege@archie ~]$ find /usr/lib/ -name libcublas.so*
[stiege@archie ~]$ find /lib/ -name libcublas.so*
[stiege@archie ~]$
```",2
"In this case, after correcting for some syntax errors in your snippet above, I'm assuming it was something like:

```python
import tensorflow as tf
import pandas as pd
train = pd.read_csv('Test.csv')
x = tf.placeholder(tf.float32, shape=[None, 128*128*3])
y_ = tf.placeholder(tf.float32, shape=[None, 128*256*3])
W = tf.Variable(tf.zeros([128*128*3,128*256*3]))
b = tf.Variable(tf.zeros([128*256*3]))
tf.Session().run(tf.global_variables_initializer())
```",2
Assuming it is still an internal google branch.,2
I assume the card doesn't have ECC RAM which is why the ECC readout is N/A.,2
"Assuming you are writing your own `model_fn` (not using a canned `tf.Estimator`), can you try not using `tf.estimator.WarmStartSettings` during estimator `init`, and instead directly using `tf.train.warm_start` inside your `model_fn`?",2
"In practice, people will not notice that they haven't restored the batch norm params and assume they did.",2
I'm assuming these results are being generated on the Android device?,2
If anyone can confirm my assumption,2
I am assuming that there's a reason for that and it can't be fixed.,2
"Let's **assume** that in most cases, you don't need to use the model itself to produce data (though sometimes it's not true).",2
I assume there is more copying/handling going on in the background than would be necessary.,2
"That makes sense, and it's what I was assuming.",2
Am I correct to assume that https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/learn/python/learn/dataframe is part of the new input pipeline initiative?,2
I also assume that the dataframes and transforms are intended to be closely integrated with estimators?,2
"Assume there is a large training data set which is in text format, and we need to convert it into tfrecord format.",2
Assume `dataset1` is a list of large images (e.g. 8192x8192 each) [with corresponding labels].,2
* setting a timeout on the `session.run` of the training op and assuming that a timeout is due to the queue being exhausted (but the network connection might be down or our workers might be too slow),2
"now SEND flow performs [this](https://github.com/tensorflow/tensorflow/blob/r1.3/tensorflow/core/framework/rendezvous.cc#L209) Ref() before calling the callback, since it assumes the RECV **can** be duplicated and called again.",2
I'm assuming you'll put in a bazel-build option flag for the openmp version?,2
Perhaps I'm making an undue assumption: I'm assuming that TF can estimate the memory requirement of a single op.,2
"Then you assume that once memory hits 11GB on TitanX, any new op executed will cause OOM and output needs to be placed on CPU.",2
But I think most segmentation network with resize_bilinear op will have some assumptions about the relative sizes between op and input.,2
"Assuming we find no more issues in protobuf that we have to fix at head, we can move to making protobuf a library dependency once all our fixes are in a reasonably common released version.",2
I assume that would fix this problem at the same time.,2
I'm assuming you did the same as @daeyun .,2
because the setup.py in master branch still forces numpy < 1.19 (I am assuming nightlies also have this limitation).,2
"Also, I'm assuming the problem is with the `tf.gather` ?",2
I assume similar problems exist for other ops that the shape is calculated at runtime.,2
I assume by sdist you assume source distribution to be built during `pip install`?,2
"@gunan I'm still trying to understand tensorflow's logistics (I'm mostly focused on directly hitting #252 but I've certainly managed to build it via bazel by now) but my first assumption would have been that an sdist would have invoked the requisite bazel command to build itself (under the assumption that bazel is already installed, which tends to happen for sdists, you rely on the fact that the user has already done all the external non-Python work)",2
// \* We make assumption that one session has one graph.,2
"// Node will only be added to _graph when TF_FinishNode() is called
// (assuming TF_FinishNode() does not return an error).",2
"#%% secondly,in the line where you define the placeholder(assume the placeholder is named as x)
#by doing this you can get the name of placeholder in the graph",2
"#then,before session.run(assume Placeholder:0 is the name of placeholder)",2
I assume you haven't checked with cuDNN-8.6 which is a tested configuration.,2
I think this is because it's usually very easy to overlook some details when I ask for help for my specific setup (RPI4+ARM64+Ubuntu18) and I found out that it's very common to receive help with the assumption that I'm using Raspbian or that my OS is 32-bit or I'm asking for TF lite or even thinking that Ubuntu 18 would be the same as 20.,2
"I guess it does not explicitly say Cuda SDK 7.0 IS the default, but that is what the text implies and what many people who run it are assuming, which it why they run into the issue.",2
2. Find a way not to rely on sysconfig module to get the `include` path and simply assume it's `/usr/include/python3.X` in `build_pip_package_with_cmake.sh`. This might be an OK approach since the [Dockerfile.py3#L52](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/tools/pip_package/Dockerfile.py3#L52) also assumes this is the case to begin with.,2
"I could reproduce the slowness on TF 2.1 but not TF 2.2rc0, so I'm assuming the issue has been fixed.",2
"TensorBoard expects that only one file is written to at a time, so if you have an early file A and a later file B, once B is ever written to, it assumes file A is finalized and will stop reading events from file A.",2
Please take a moment to read that (the next paragraph will assume some familiarity).,2
I assume the Inception models released last week give equally bizarre results because they were apparently trained on the same ImageNet data-set.,2
All original assumptions of SyncReplicasOptimizer seems to hold true.,2
"Though, in the case of TensorFlow, I'm assuming everything can be managed with Bazel...",2
"I assume the reason is related to how the dimensions are matching, instead of the total number of dimensions, or the number of mis-match.",2
The log messages imply you only have 1.69GB in use - I'm assuming this is quite a small GPU?,2
"@mrry Thanks for all the hard work on TF ?? Are you in a position to pin down, what remains to be done  assuming that the now merged  PR #8217 was one of the missing building blocks to a resolution?",2
(I assume you're using Jupyter/IPython.) What commands have you executed in the notebook before this error is raised?,2
EnterGradWhileContext creates a grad_ctxt for op's control_flow_context assuming that the control_flow_context is a WhileContext.,2
"Perfect, I just misinterpreted it then when I read it, for some reason I assumed that meant it was ""single-GPU options that are applied to every single GPU uniformly"".",2
"If you compile on your own machine AVX issue should not occur, **assuming** you are using the compiled TF and not the one from PyPI.",2
This assumes the time axis is 1.,2
> This assumes the time axis is 1.,2
"(I'm assuming this is a symbol conflict based on the symptoms you've posted; I haven't looked into it thoroughly, so feel free to correct me)",2
"I'm not familiar with the session bundle code, but since the problem appears to be an uninitialized model parameter, I'm assuming that the example code is either not saving the model parameters as intended, or there's some missing call in the loading code.",2
"I assume bundle_shim, will be part of TensorFlow 0.13?",2
"The zeros caching issue will affect GPU too, since (I assume) we cache GPU Tensors.",2
"to run the code above (assuming it's called DNNClassifier.py):
`./DNNClassifier.py train.txt test.txt`",2
I'm going to assume this is now fixed.,2
You're assuming Linux.,2
(My results aren't quite as bad as yours—0.2448s vs. 0.0004s—but I assume that we're hitting the same thing.),2
"Note that the problem is specifically with TensorFlow's assumptions about the emulated platform and not the image or other libraries, which run fine when emulating linux/amd64:

```
dwyatte-macbookpro:~ dwyatte$ docker run tensorflow/tensorflow:latest python -c ""import numpy as np; print(np.random.rand(10))""   
WARNING: The requested image's platform (linux/amd64) does not match the detected host platform (linux/arm64/v8) and no specific platform was requested
[0.86125896 0.40657583 0.76832123 0.77205272 0.99326573 0.513298
 0.64218547 0.15977918 0.37553315 0.56692333]
```",2
This breaks down the dynamic calculation performed when you pass sequence_length (because it assumes left-aligned inputs).,2
"I may extend this by adding a bool flag like ""right_aligned"" to the rnn call, which assumes that calculation starts at len(inputs) - max(sequence_length), and copies the initial state through appropriately.",2
"I'm not sure, 4.8+ is the safe assumption (the earliest we've tried successfully).",2
"Or when you compile Tensorflow for CPU, do you have to explicitly set some options to use these instructions, and that assumption is not correct?",2
Let's assume you simply type "env" into your shell and press Enter.,2
"3. https://www.tensorflow.org/versions/r0.8/api_docs/python/nn.html#softmax_cross_entropy_with_logits is our documentation for the math behind the op -- I cannot find similar mathematical description of SoftmaxWithLoss here: http://caffe.berkeleyvision.org/tutorial/loss.html, so I can only assume that they are the same.",2
"Never mind, I made a wrong assumption.",2
"Can you do the following:

Build //tensorflow/models/mnist:convolutional via:

bazel build -c dbg //tensorflow/models/mnist:convolutional

And run with gdb:

(assuming your python is in /usr/bin/python2.7)
gdb --args /usr/bin/python2.7 bazel-bin/tensorflow/models/mnist/convolutional

(press ""r"" to run it)

wait until it crashes; and type ""bt"" for backtrace

paste the resulting output here.",2
I had assumed based on those quoted docs that everything could be detected and configured appropriately based on compiler flags alone.,2
And i assume the time is what's called `wall time`.,2
"In the `Queue` based run, the value of accuracy is calculated at every run, even without me calling `accuracy.eval()` - I'm assuming because of the shared variables being updated since the graph has them built in.",2
"I'm assuming that's also why the `Queue` that holds the test data gets depleted fast and takes a long while to continue producing sample data, causing `QueueDequeueMany` to appear slow.",2
"I believe you work at HP Labs and I see an ""HP Inc."" that's already signed the Google Corporate CLA, so assuming your email is part of your company's CLA list, it should already work. :)",2
I assume I just need to look at ~/tensorflow/tensorflow/core/kernels/_gpu_ for a list of the gpu supported operations.,2
"I'm just going by the error message which say `@rpath/libcudart.8.0.dylib`, which I'm assuming means that `libcudart` is loaded by path relative to location in `DYLD_LIBRARY_PATH` which Apple thought was a security hazard.",2
"And assuming you already have python3-dev, pip3, numpy and wheel installed then install also the following packages:
`sudo pip3 install six mock h5py enum34`",2
"As I understand, this instruction assumes that the Linux machine has only CUDA 10.2 installed (and not 10.1 in parallel, which is a rare but possible use case).",2
"I will close this thread, assuming it is the first.",2
"- I assume the curves are grabbed on Tensorboard, right?",2
"That's why I assume the dependencies are note being handled properly and will dig a bit deeper into this CMake build to compare the differences when building via Bazel, but would also appreciate any help or thoughts from your side.",2
That's probably because I assumed I already had that installed as part of the NVIDIA software that comes with this PC.,2
That's what I get for assuming!,2
That's because I assumed I already had that installed as part of the NVIDIA software that comes with this PC.,2
I am assuming it is the block of code where the gcc path had to be changed.,2
"If that doesn't work, I suggest shooting back to 0.8 for now (assuming you don't need something that's cutting edge?).",2
"My bad, I saw the issue was still open and assumed it was waiting on a fix.",2
"@bhack You said that master (I assume 2.4.0) is compatible with h5py 3.1, but I still have this issue...",2
"> @bhack You said that master (I assume 2.4.0) is compatible with h5py 3.1, but I still have this issue...",2
"Notice that with the assumption a >> b, the first term approaches to ?a/?x and the second term vanishes.",2
"If the assumption that (a >> b) or (b >> a) is true, only then max(a, b) can be converted to a continuous function as done above.",2
"I dont know if this would be the correct way of defining this, but it should be possible (if its not already) to set the dtype of the input excplictly ( i assume there is a tf.cast in there somewhere anyways...)",2
"Assuming it does, it's for floating point models only I think.",2
"# assume input_shape = (?, 100, ?)",2
"Remove the line 
``` converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]```
as for QAT you are assuming that the model can be fully quantized.",2
Assuming it's binary.,2
"This personally made me lose a couple of days of work, as one assumes TF's documentation is correct.",2
So I assume the worker tries to read the same data in the same order after relaunch),2
I assumed it to be intended.,2
> These are partial files and the apt-get commands should work on non-Docker systems as well assuming you have the NVIDIA apt-get repositories which should be the same as listed on [tf.org](https://www.tensorflow.org/install/gpu).,2
I assume that it is a dependency problem.,2
"I assume that pybind11 is wrapper around existing python cpp communication source code which I mention in main description. 
![image](https://user-images.githubusercontent.com/27050597/91572781-5c22b000-e964-11ea-8cf7-ab413583a704.png)",2
I assume that installing these softwares wouldn't be such issue.,2
Assume if I provide bazel target also.,2
".  Assuming you only have the Intel graphics adapter, you'll need to uninstall **tensorflow-gpu** and install **tensorflow**.",2
Assuming "image_dim_ordering = 'tf'" in MobileNetDeepEstimator because we are on tensorflow.,2
I assume that the `summary_op` is only assigned a _function_ and not the actual merge operator of all summaries.,2
"seem fishy, but it couldn't be my learning set up, rate etc. (but I'd assume it shouldn't because BN should be sort of rubust to this)",2
@MisayaZ you don't need to create two batch_norm layers you can just pass train_phase (assuming it is a tf.bool) to batch_norm.,2
Given you have two GTX 1080s I am assuming you have at least a 4 core 8 thread setup.,2
That presumably would mean we'd need to get the original authors to sign the CLA in addition to myself - perhaps @prb12 or @aselle can confirm my assumption there?,2
"Your gradient argument seems reasonable, I'm going to assume that XLA will help address these issues instead of writing custom kernels.",2
"One limitation is that the xcframeworks will require you to manually disable the iOS simulator for `arm64` architecture because tensorflow (rooted in a problem in bazel-core) assumes that `arm64` is always an ios device, not a simulator.",2
"Assuming testing is positive, we should have a 0.6.0 release incorporating Python 3 support and various other features soon.",2
"I just assumed Benoit because he self assigned the feature, but I think you've got it Junli!",2
"> I just assumed Benoit because he self assigned the feature, but I think
> you've got it Junli!",2
"> > I just assumed Benoit because he self assigned the feature, but I think
> > you've got it Junli!",2
"I just assumed cltorch did work on Android, since there is an implementation of Torch that is dedicated specifically for Android.",2
I assume convolution is implemented using GEMM?,2
I assume there are quite a few folks here willing to help out.,2
"But it seems to be possible to overcome on IR level, w/o intermediate translation to OpenCL code - that's what I assumed :)",2
The Bazel build makes a lot of assumptions about paths and linker flags.,2
"The part of the tutorial where it says to change --outut_layer = final_result,  I want to do that in the android demo after loading retrained model since I'm assuming the android demo's output layer is not pointing to the final_result.",2
I guess that is because of the way the input tensor is being filled up (mapping RGB values) in the android demo (I don't have a clear idea on the "why" of this but continued working with the assumption that the input tensor was being populated correctly).,2
"@Mazecreator 
I also followed all the instructions from (http://textminingonline.com/dive-into-tensorflow-part-iii-gtx-1080-ubuntu16-04-cuda8-0-cudnn5-0-tensorflow) which I assumed very similar to what you explained.",2
"So, after padding one must assume that all examples have the same size.",2
"So, after padding one must assume
> that all examples have the same size.",2
"Ideally (assuming reasonable API/ABI stability on NVIDIA's side), TensorFlow should not be dependent on specific older versions of CUDA and cuDNN. (I'd rather understand it if the _latest_ version was required to make use of certain features.)",2
Release 0.7.1 wheels now are built assuming cuda-7.5 and cudnn v4.,2
Let's assume 10 batches.,2
# assume vals is already defined,2
"And… 4f257a2427ba0414bd7513c9b61fb835870bd3cf fp16-enables convolutions on GPU, assuming you have CUDA 7.5 or newer.",2
"I was assuming that using XLA AOT for this is more efficient because it gets rid of unneeded TF runtime bits. (ie, tiny networks perform best when restricted to 1 core, so don't need parallel scheduling)",2
"Could not parse start iter, assuming 0",2
"This could work, if you're willing and able to rewrite that non-TF program to obey the TF GPU runtime assumptions about use of stream executor contexts, memory allocators, etc.",2
"I guess that whoever wrote that code assumed it would never happen, so it could take a while to discover everything that needs to be fixed.",2
"> Looking at how it is handled in the [v1](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/callbacks_v1.py), I think the check should be done on `self.embeddings_metadata` (assuming if it is not a string it is a dictionary).",2
"I
assume that has been reported but wanted to let you know.",2
"Using the order of operations, I'm pretty sure I've been able to narrow down to which crop_and_resize operation is causing the issue (assuming it is that function), and have seen that it might be the 4th tensor param that has 0 dim.",2
I assume this will be available within the coming month.,2
"this is very useful, we are assuming that we don't use the U matrix when we have decomposed the original matrix A into U s V, since we do not calculate the derivative respect to U anywhere.",2
* Distribution strategy and Estimator do not even assume the existence of optimizer.,2
You could try this patch assuming you are building for iOS,2
I checked https://pypi.org/project/tensorflow/#files so I will assume this issue went away.,2
I'm assuming the solutions above suffice.,2
"Assuming a float tensor input on the GPU device, the Tensor metadata object is in the host's DRAM.",2
"All fixable, but really it looks like either I'm missing something or the assumptions being made in `configure` regarding these environment variables aren't reasonable (namely, that bazel never dies).",2
"@davidzchen -- assuming you mean @jmhodges gist, yes.",2
I assume that sqlite build issue is everywhere.,2
"Assuming TensorFlow is installed, run `create_graph.py` and put its output files into the repo root together with `BUILD` and `graph.config.pbtxt`, and then run `bazel build :dynamic_rnn_graph`.",2
My guess is based on the assumption that you compiled the C++ lib/binary from source while using the Python library from the official TF 2.8.0 release.,2
I'm assuming this is separate from CUDA?,2
Notice: I assume that if `batch_input_shape` is not specified it will default to some value and this issue arises randomly from the consequences.,2
> Notice: I assume that if `batch_input_shape` is not specified it will default to some value and this issue arises randomly from the consequences.,2
The Tensor header is not including itself that has been wrongly assumed by some posters.,2
This assumes you have installed the python .whl file that the build generates.,2
"Additionally for running the training scripts, it seems like there is an implicit assumption that it is running on linux with a gpu, one of the packages in their environment packages is tensorflow-gpu.",2
"This was assumed to be something that would download the correct version of tensorflow now, but instead it decided that it couldn't find a compatible version of TensorFlow for my Python version 3.6.3 (which I assume the minor rev number may have thrown off the basic logic for acceptable versions, ex. 3.5, 3.6).",2
This assumes you want to use 4 processing cores.,2
But I am assuming that the problems with the recent runs are with entirely fresh checkouts.,2
"Assuming that Modules won't get fully revived, what's the suggested way of serializing objects like above?",2
"Could you please tell me the exact commands assuming my current location is ""/home/syj"", then what commands one by one should I type?",2
"@shkr The internal fix https://github.com/tensorflow/tensorflow/commit/f66b491a06627510c1cf751fc11db2caf5aa1f25 was pushed today in https://github.com/tensorflow/tensorflow/pull/4360, so if you sync now I assume the issue will go away.",2
"I have thoroughly moved on from that project, however, so I'm just assuming it works the way it says.",2
I'm assuming you're talking about changing the working directory from where I run python and subsequently import tensorflow.,2
"So far, I've been able to avoid the collapse to zero (with 32 bit tensors) by using `AdamOptimizer` with a small step size of around 0.01 and making sure that the prior's log-prob was included in my loss (you're already doing this I assume, but just in case...).",2
"I was operating on the assumption that TF wouldn't do things so crazy that we'd reasonably expect a difference in behavior with different compilers, but maybe that's wrong.  :)",2
Please let me know if this is a good plan assuming nothing breaks.,2
My error on assuming it was related to eager.,2
I assume V100 and where you are seeing FP16 worse than FP32 as far as throughput.,2
I assume there was an issue when keras downloaded the file locally for you.,2
But I assume this is probably not related to this issue.,2
"I haven't tried it again after @mrry's fix with `shared_name`, but I assume it's not the cause, as they both are due to session restarts.",2
"I can reproduce on 1.2 but not on 1.5, so I'm assuming this is fixed and closing.",2
Seems like there should be a type check for IndexedSlices somewhere and that the default assumption that add_n can be used for all types of gradient tensors is wrong.,2
I assumed this is because of the “while True” in the run_local method.,2
"I'm assuming you're reading float data? (assumption based on your defaults being `[[]]`, which tf interprets as float32 if i'm not mistaken)",2
# Assumes non empty.,2
Closing this as I'm assuming it was due to the temporary jcenter  issue we had where the wrong version of the TF AAR was downloaded.,2
You are right that the default automatic gradient code assumes that it's always cheaper to hang on to intermediate values than recompute.,2
Assumes func takes in multiple inputs and returns a single output.,2
"The result is definitely very positive, assuming there is no error in the measurements and given the optimized graph computes the same things as the original one (I did not check this yet).",2
"Assuming we don't have duplicated recv support, we need to send the Tensor in one shot in all cases.",2
"I tested it in a few cases and seems to work in general, although it assumes indices are `tf.int32` and there may be more special cases I'm not seeing.",2
# Assumed to be a single integer value,2
"I assumed that `tf.constant` and `tf.ones` would be equivalent, but they have significantly different runtime.",2
MKL can provide a lot of improvement for CNN style models but there are some edge cases and you will need to set some environment variables as well as use the desired data format NCHW (assuming image data).,2
`cmake` did not complain when I used `-DBUILD_SHARED_LIB` so I assumed that was the correct option.,2
"Assuming it's on the larger side, are there any plans to allow it to be smaller?",2
@mohantym's assumption was wrong as if you check his output in detail he ran it in a CPU only Colab runtime.,2
"_Building:_ https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow-cpu-linux-x86_64-1.0.0.tar.gz is a pre-built Linux binary (CPU-only, I'm assuming your robot doesn't have a GPU).",2
I assume the graphdef char array can just be read in from a .pb file created from the freeze_graph.py script?,2
"Assuming I/O is the bottleneck, does it suffice to chain `from_generator` with `prefetch`?",2
"So using a threadpool for numpy operations can utilizes all cores of your system (Assuming, the arrays are large enough)",2
I assume you have Xcode installed?,2
The assumption was that >90% Keras/TF will not have a fine understanding of the consequences of applying order A or order B (and which one to go for).,2
"Assuming we cannot revert it, then I don't think we have an alternative other than a short term fix.",2
"Regarding `experimental_aggregate_gradients`, I believe that regardless of whether you're using Horovod, `apply_gradients` will not call `_aggregate_gradients` unless both `experimental_aggregate_gradients` is `True` (default, I assume) and the user is using a distribution strategy.",2
At the moment this code assumes a single worker.,2
P.s. I assume that we could consider the "bridge covered" TF ops a superset that could be mapped to *HLO ops.,2
> P.s. I assume that we could consider the "bridge covered" TF ops a superset that could be mapped to *HLO ops.,2
I assume this is not an error.,2
"If so, I think the input_size for `tf.TensorShape([100, None, 200])` is just 200 (assuming batch_size=100, variable sequence length), since the input_size is the input's depth of the RNN cell.",2
"By dynamically, I assume you are referring to at compile time, but self-contained code changes.",2
@RichDubielzig: the dataflow model of TF execution means that any operations that can be run at a given time will be run by the executor (assuming there are enough inter-op-parallelism threads to run them).,2
Have not tried TestFlight yet but assume it will fail given ad hoc does.,2
"Have not tried TestFlight yet but assume it will fail given ad hoc
> does.",2
"3. The notebook is available to everyone, hence, I assume that everyone (including developers) can play with compilation, evaluation sets, etc.",2
"You could start by pasting your [nccl-test](https://github.com/NVIDIA/nccl-tests) benchmark results, assuming your are using NCCL for multi-host all-reduce.",2
"> You could start by pasting your [nccl-test](https://github.com/NVIDIA/nccl-tests) benchmark results, assuming your are using NCCL for multi-host all-reduce.",2
"I didn’t know what the graph looked like **nmichel**, so I assumed possible input / output nodes.",2
I assume tflite assumes these values as default?,2
"2. We tried to add lazy caching of the alternative row-partitioning tensors, but had to roll it back because it breaks some assumptions made by tf.cond.",2
I assume that persistent instance of the callback was somehow holding resources from being freed.,2
"@gunan  Thank you so much; If I want the GPU version I'm assuming I should add `gpu` as such:

`tensorflow-gpu==1.2.0rc2`",2
"- the fix mentioned by PaulWoitaschek was merged before release of 1.10.0 lib, which still does NOT contain the fix and asks for the permission in question. (I assume a merge readded the code snippet)",2
"Your commit downgraded the targetSdk for the Android TFLite sample app, as jddukes commit added sdk configuration to `tensorflow/contrib/android/cmake/src/main/AndroidManifest.xml`, which I assume to be the source for building the library.",2
"If it helps, I'm using a network with an embedding layer and LSTM (CuDNNLSTM), so I assume it could be a problem with either the dense or the sparse update.",2
"That means even if we could spot the bug (assume there is one) and fix it, it won't be back ported to 1.15, not to mention 1.13/1.14.",2
"I think most heavy-duty IDEs for software development would be affected by this, but I also would have assumed the core developers would use such IDEs.",2
"In the original issue, I assumed it would be in effect in 2.1 because the change was made before the 2.1 release, but the change was never merged into the 2.1 branch.",2
"Assuming the test is passing, you may continue.",2
Safe to assume that *Python* snake folks hate *Gophers* and other rodents.,2
Here are some results and assumptions.,2
"By looking at available devices for graph construction, it is making an implicit assumption that the graph will be executed on the same device, which is often not a valid assumption.",2
I assume  you are using macOS.,2
"@rubenvereecken The workaround is based on the assumption that the train op runs on the Python main thread, while the data queues run on the child threads, which should usually be the case.",2
"I've been operating under the assumption that the custom-op container is somehow unique, but I've never known what about it is helpful.",2
"This isn't the order in which ready-made implementations of solvers from other libraries (e.g. scipy, pymanopt, cvxopt) are designed for---they assume a function exists to minimize and they can't be stepped in and out of (although many provide the caller with the option of specifying a *callback* callable).",2
"Odd, the printout doesn't say, so I'll assume it's cpython, which is supported.",2
"> Odd, the printout doesn't say, so I'll assume it's cpython, which is supported.",2
I’m assuming it isn’t being addressed cus everyone using complicated/combined models are using custom training loops,2
"yeap, firstly I assumed it was the tf.dataset, but after a dataset memory test, I realized it was these high level apis that caused the memory leak",2
"Another potential functionality, when op determinism is expected, might be for initializers to assume a seed value of `0` if one is not provided via the `seed` parameter, or to generate a seed value from `name` if `name` is provided.",2
"Oh that'll be nice. I assume it'll also potentially end up hidiing messages that I might want to see, but this should be good enough until the  tf release happens that cleans this up.",2
Is the assumption that the inferred labels should have the following structure wrong?,2
I'd assume if Sequential models are then functional models should too be?,2
I am under the assumption that this version is the CPU version of tensorflow.,2
"I have to assume that you are looking at the outputs (`predicted_ids`) of the `seq2seq.dynamic_decode` method, instantiated with the beam search decoder you mentioned, and that you translated the numerical ids back into symbols from your vocabulary.",2
"I assume it depends a lot on the task that you are trying to solve, and also on the checkpoint you are loading (is it a well trained model ?).",2
"If there was no response, I will assume it was resolved.",2
I assume it is an issue with part of the OpenGL buffer.,2
The reason for processing 256 x 144 x 130 data is that I make the assumption that my maximum sequence (in real data) has approximately `256 * 144 = 36864` time steps (each time step has 130 values/features -> unit size).,2
"@houtoms, I assume this should be fixed already with the latest CuDNN kernel?",2
"For example, assume that the model is expected to be trained with one epoch of training data, and the training input_fn is configured to throw OutOfRangeError after going through one epoch, which stops the Estimator.train.",2
By the looks of it it's safe to assume noone else is working on it.,2
So I assume that it is the version compatibility issue between Miniconda and RTX20XX Turing series.,2
I've never failed to run convnets from tf built from source (assuming you have the correct configurations during build).,2
@alexforever86 with the configuration you mentioned now do you still see this problem? (I assume it works for you).,2
Unfortunately you don't mention your TF version but I assume you use TF2.1.,2
"This blocks memory from use assuming you will need all available libraries (blas, Conv, FFT and I don't know whether there are others).",2
"This assumes you have  a saved model corresponding to the TF Keras LSTM model via something like:
model.save(""keras_lstm"", save_format='tf', signatures=concrete_func)",2
"> This assumes you have a saved model corresponding to the TF Keras LSTM model via something like:
> model.save(""keras_lstm"", save_format='tf', signatures=concrete_func)",2
So I assume you fixed a bug somewhere in clear_session() which seems to work.,2
> So I assume you fixed a bug somewhere in clear_session() which seems to work.,2
"Inside the APK there is libtensorflowlite_flex_jni.so inside /lib/amreabi-v7a, so I assume that is what you are referring to as I can find no other files referencing tensorflow.",2
Could you share the model with us so we can debug with it (assuming it's not confidential) ?,2
I'm assuming model_main_tf2.py is the main script you use to run everything?,2
The implicit assumption that the last matrix rank corresponds to the batch instances seems to be built-in the design.,2
Baking in the NN assumptions too deeply is why DistBelief ended up so inflexible.,2
"Are there more efficient ways to do it? (That is, assuming the inputs are a bunch of floats, then building an object, defining feature map, serializing to string and then parsing it seems wasteful when this is done millions+ times. For example in real-time robotics domain.)",2
"However when I removed the whole header (there is a conditional include in `Core` which I commented) it worked, so I guess there is some dependency on the stuff TF introduces and some other things from the MatrixProduct.h which fail to meet implicit assumptions in the TF code.",2
However it all worked with an assumption that packed block format is the same for all architectures.,2
"As noticed, it breaks TensorFlow because of their usage of the internal Eigen namespace and broad unchecked assumptions on data formats.",2
@jass-singh Assuming that you have already trained you model and have set the python path.,2
Later on I'll want to do some pre- or post- processing to the inputs / outputs of the image - I assume that's where the C API differs from the C++ one - correct?,2
> Later on I'll want to do some pre- or post- processing to the inputs / outputs of the image - I assume that's where the C API differs from the C++ one - correct?,2
> > Later on I'll want to do some pre- or post- processing to the inputs / outputs of the image - I assume that's where the C API differs from the C++ one - correct?,2
TF -> HLO and HLO -> TF is a different scenario - I assume you have many conversions there.,2
"Also, I am wondering how to run validation, assuming I want to train for one epoch and then run the model on the validation set I have to first call `.train` and then `.evaluate` that will re-build the graph slowing everything.",2
"One last question, it is not clear to me how to avoid the re-creation of the graph using a generic implementation (assuming no `layers` library).",2
"So assuming we have 100 epochs, we need to run 100 times the estimator in train mode and 100 times the estimator in evaluate mode.",2
Let's assume that a PR of contributor has a build error.,2
"For example, assume that `G` has a node placed in '/gpu:0', grappler will use the information from physical gpu 0 to optimize your graph in `sess2` which is not what we want.",2
And since Create ML is used for training I assumed that they also would provide acceleration for Tensorflow training.,2
>And since Create ML is used for training I assumed that they also would provide acceleration for Tensorflow training.,2
For the most part we should assume that Tensorflow won't support Apple GPUs for acceleration in the near future and likely in the distant future as well ...,2
For one it's missing the libraries (libtensorflow) and only provides the frameworks (which I assume have a subset of the functionality).,2
"Assuming loss has been steadily decreasing with no abnormality the final minibatch loss should still be just as useful for tuning assuming either overfitting is not an issue or you don't care about over fitting, which in my case is the latter.",2
> So i assume the problem has to do with some path or something like that in my native enviorment.,2
I assume this is still safe and the problem is elsewhere.,2
"Notice : Output Shape doesnt changes, which I assume is the correct behavior",2
"FYI, the build was successful on my side, so it ideally should work for you assuming your configuration is correct.",2
"I assume your static library will be called from an iOS app anyways, and you would have to use an Xcode project for it.",2
"..and 137 MB for intermediate tensors looks very similar to 137 MB of the `float32` model, so I assume there's conversion of `float16` constant tensors to `float32` constant tensors within each interpreter.",2
"> ..and 137 MB for intermediate tensors looks very similar to 137 MB of the float32 model, so I assume there's conversion of float16 constant tensors to float32 constant tensors within each interpreter.",2
I assume that the observed error message is the reason for this unexpected behavior when `MultiWorkerMirroredStrategy` is used.,2
This confirms the cutoff is half of 10.57GiB mentioned by log (I'm assuming this the BFC allocator's memory pool size).,2
"@zheng-xq Assuming a reasonable implementation of scatter_update, that would work if any type of initialization worked (or if there wasn't an error thrown while trying to use an uninitialized variable).",2
"1. For me it's a problem with a debian buster/sid container, not Ubuntu (I assume this is not distro related)",2
"(asterixes added)  I get `avx` entries when I grep `/proc/cpuinfo` as well, which I assumed meant that I have AVX support.",2
"However, I guess I'd be curious what the Tensorflow project's stance is on the CPU backend (assuming that might be what is driving AVX2).",2
As such I appreciate small advances in speed but have always assumed it would prioritize maximum compatibility first due to its unique position.,2
"Yes the assumption here is that once you get the Dataset object, you can retrieve `file_names` from it otherwise the information will get lost after map or batch functions, or any conversion to TFRecordDataset in your case.",2
"I assume it should be `core_tf_types.Tensor`, according to your comment.",2
I assume you are trying to upgrade BERT to work in Tensnorflow 2.0.,2
"I assume this is from using the incorrect labels file, when I use the pets label file in the blog post the index that triggers this error is smaller than in the error above.",2
This prevents that resource exhausted error assuming you're batch size is within reason.,2
`sckit-image` should be `scikit-image` I assume?,2
I assume that you mean Windows Subsystem Linux.,2
I have never added a new operation to TFLite and thus I don't know how to proceed (the official documentation assumes too much previous knowledge for me).,2
This is assuming you use the Estimator class.,2
**I assume I have you to thank for - so thanks**!,2
I still can't see any result from the inference but I just assume it's my bad somehow...,2
I mistakenly assumed it was the current stable release Big Sur (11.x).,2
"Right now it assumes all
    #       images in a batch have the same active_class_ids",2
"image_metas: If provided, the images are assumed to be already
            molded (i.e. resized, padded, and normalized)",2
"When you use ByteBuffer as the input argument, you need to explicitly resize the input Tensor to match the size/shape of the ByteBuffer (assuming the runtime input size might differ from the default size expected by the model).",2
Here's a solution/workaround to get TF2.10 running with TRT on Ubuntu 20.04 (assuming 22 schould work aswell):,2
"@jsimsa @sanjoy: since tf.data intentionally prevented `DatasetVariantWrapper` from being copied (I assume it is for performance reason), there should be extra logic (specific to `DatasetVariantWrapper`) to ensure we never try to copy `DatasetVariantWrapper` between devices, right?",2
"I assume the number of unsupported list of ops for quantized 8-bit and the float 32-bit should be different, right?",2
"Its on the done column in https://github.com/orgs/tensorflow/projects/4#card-17112802 so I would assume its complete, right?",2
"For example, the gradients machinery - that also assumes a static graph, so in order to support truly dynamic graphs, the gradients would also need to be made truly dynamic.",2
Is there a reason the shared library is insufficient (assuming this is for Android)?,2
@jdduke I would assume that the need for a static library here is the same basic reason for needing any static library: speed and size optimization.,2
> I would assume that the need for a static library here is the same basic reason for needing any static library: speed and size optimization.,2
> > I would assume that the need for a static library here is the same basic reason for needing any static library: speed and size optimization.,2
> @jdduke I would assume that the need for a static library here is the same basic reason for needing any static library: speed and size optimization.,2
"nvidia driver 418.43 works with linux kernel v5, but I guess for now I will assume that there is an issue with CUDA/driver and linux kernel v5.",2
I assume it can have bad effect in other scenarios but right now it looks like a bug,2
"The fact that ALL threads are name python3 thread makes me doubt the operation I did, as again from your question, I assume some of those thread should have a tensor flow related name.",2
"Since you mention multi threading, I would assume you are probably talking about MirroredStrategy which can run on multiple GPUs?",2
"@ringw cool looks like this in, I assume that currently the output dimensions are fixed?",2
"@davidzchen - I am not familiar with Bazel but assuming the that the idea behind you mentioning it being extended to run on Windows, along with the new C# rules, would be to allow us to build this repo on Windows, including the code for the potential .NET (mono) interop library?",2
"@omalleyt12 Am I right in the assumption that the change is already included in the tf-2.0-alpha release? (As TF 1.13 would raise an error if I do not provide `steps_per_epoch` and `validation_steps`, while TF2 does not)",2
Is it practice to assume a square image?,2
Is it safe to assume that from tf 2.1+ one can save and load keras models only outside the distribution scope?,2
"I have checked with the above mentioned gist and replaced the pip install command with ```pip install tf-nightly``` which should give me the latest TF 2.2.0 version as I'm assuming you meant, right?",2
"I don't really know anything about how the compiler works, but is this check in place because it was assumed that you'd always want to have an input, or because of some other limitation that would cause the compilation to fail with no feeds?",2
"Since it is a regular x86_64 architecture, I assume it is a bug but maybe not?",2
"Using the link from https://www.tensorflow.org/install/lang_c#download and assuming that the new version was in the same location, I downloaded https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow-gpu-linux-x86_64-2.3.1.tar.gz",2
"I assumed 9.1 was fine for 1.5 RC0, but it didn't work (in Windows; cf. #16014), so I had to spend a while un- and re-installing stuff.",2
I assume there is next a compacting data copy at each node before the collective op begins (which is an opportunity for compaction or precision reduction).,2
"To avoid this, the converter always assumes the users are sending normalized coordinates [here](https://github.com/tensorflow/tensorflow/blob/4fa4184a5a454eceb5b567c8b3c4fce46faf2de8/tensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc#L5918).",2
"This is the error message that i get when i run the code if that is what you are asking, so i would assume that they are similar.",2
"I assumed that tensorflow has an issue because it doesn't know about `params` in the loop (cf. [`non_sequences` in theano `scan`](http://deeplearning.net/software/theano/library/scan.html)), and extended `map_fn` to pass extra arguments to the loop.",2
"@harpone oops -- good catch! Apologies for posting untested code :). (The version that I actually got working on Friday used a static loop, but then I mistakenly assumed `tf.map_fn` would simplify it.)",2
"I threw together this function, it uses tf.map_fn and assumes a batch style input, but at least it works for batches.",2
"On a PC (which is what I assume you are running on, float is likely better).",2
"@alextp Yep discussed this in triage, we think it's either an issue with how the validation dataset is constructed or assumptions we are making about the validation dataset size.",2
"I'm getting a ResourceExhaustedError in the middle of a training and I'm assuming that shouldn't be possible. I.e., either it happens in the very first iteration, showing me my GPU doesn't have enough memory to train my model or it works until the end.",2
> I'm getting a ResourceExhaustedError in the middle of a training and I'm assuming that shouldn't be possible.,2
"I assume this is a duplicate issue of #17020, which was fixed already.",2
I assume this will work in tensorflow 1.12 and above.,2
I assumed that there is an incompatibility issue between TF 1.14 & CUDA 11.1.,2
* Assume machine this program is running on to be connected to some Wi-Fi or Ethernet network,2
"This is possibly because it assumes that since all recent Intel Macs have AVX or AVX2, it's safe to use that instruction set without actually asking the CPU if it supports it.",2
"So assuming that the device is capable of training on the entire dataset, one would expect to have a mechanism to clear the GPU memory to train the same model multiple times (which is why it is important to have the ability to ""clear"" GPU memory).",2
"Anyway, a speedup by doing a separable convolution is more noticeable for larger kernels, so for small kernels the overhead involved in doing two convolutions might be larger than the speedup, especially for what I assume is a highly-optimized convolution setting with the 3x3 kernel ([Winograd](https://arxiv.org/abs/1509.09308)).",2
That would assume the gradient is df/dz which is not right?,2
"Because dL/dz* and dL/dz are not independent: they are the conjugate of each other (L is real), and TF _always assumes_ that at the end of the line there is a real loss function to optimize.",2
Note that the upstram gradient is also interpreted as dL/db* and not dL/db. (Here L is a hypothetical real loss function which TF assumes to exist at the end of the computation).,2
"Also, assuming this gets an okay from Keras team to proceed, would you be interested in contributing?",2
"I believe ResizeBilinearGrad uses X only to determine the output shape (? I'm not sure why ResizeBilinearGrad needs X), I assume the second outputs of _ResizeBilinearGradGrad must be None.",2
"> I believe ResizeBilinearGrad uses X only to determine the output shape (? I'm not sure why ResizeBilinearGrad needs X), I assume the second outputs of _ResizeBilinearGradGrad must be None.",2
My change was for consistency for one of the tests. (One of my general philosophies for debugging is that it is better to fix something that is wrong than to assume it's irrelevant.),2
By looking at template I am assuming you have used Build from Source package and  bazel version mentioned is 0.27.1.,2
"I am assuming that your input data has varying dimensions in various steps, and you don't want to tf.function to retrace everytime that happens.",2
"I assume that providing extra method `my_model.load(filepath=..., load_format='tf')` which is in line with `my_model.save(filepath=..., save_format='tf')` with extra kwarg `load_format` if needed can be a solution that is consistent with `save()` api..",2
"I assume that this error occurs only in your machine, as it works fine in colab and in my local machine as well.",2
For example there are a lot of variables in the build system which are just assuming that /usr/lib or /usr/include is having correct libs/headers which won't be case for cross-compilation.,2
"Although I'm afraid if I have placed my layers somehow incorrectly, but that's the way I assume it needs to be done.",2
"Let's say you will `#include ""tensorflow/lite/interpreter.h""`, you may find necessary headers with the command below (Assuming you have `flattbuffers` in the upper directory and you are in `tensorflow`):
```bash
g++ --std=c++11 -I ../flatbuffers/include/ -I . -MM tensorflow/lite/interpreter.h
```",2
"Assuming you stored the checkpoint using a checkpoint as follows
```python
checkpoint_obj = tf.train.Checkpoint(optimizer=optimizer, model=pretrainedModel)
# ... store with tf.train.CheckpointManager or other means
```",2
i think some scripts don't escape `(` which is your error i assume,2
"I assumed you already have simple hello Tensorflow project, explained [here](https://www.tensorflow.org/install/lang_java)",2
"As a quick test on my local, I manually created a symlink under `venv/lib/python3.10/site-packages/tensorflow` by `ln -s ../keras/api/_v2/keras/ keras` (assuming you have tensorflow and keras pip package installed properly), and then the IDE can resolve the package level auto completion correctly.",2
"> As a quick test on my local, I manually created a symlink under `venv/lib/python3.10/site-packages/tensorflow` by `ln -s ../keras/api/_v2/keras/ keras` (assuming you have tensorflow and keras pip package installed properly), and then the IDE can resolve the package level auto completion correctly.",2
"tf.contrib is (as far as I'm aware) now removed, so resampler not being available at all might be a problem, but it would be separate from this issue specifically - assuming you have a way to get a custom op to be available to build the graph, doing the same procedure before reloading a graphdef should work.",2
"> tf.contrib is (as far as I'm aware) now removed, so resampler not being available at all might be a problem, but it would be separate from this issue specifically - assuming you have a way to get a custom op to be available to build the graph, doing the same procedure before reloading a graphdef should work.",2
However the commit you link make many assumptions that wouldn't apply.,2
"I assume, this is not the intended behavior of the tf.Dataset and Iterator API.",2
I assume that your model uses convolution.,2
I assume that you're only running on one of the GPUs though.,2
"3. No other significant differences currently stand-out to me between these model architectures (e.g. more than one of them uses dropout, so I'm assuming that it's being initialized correctly even in the troublesome model architecture).",2
I had also assumed that all the commented-out model architectures were operating deterministically.,2
Just wanted to file an issue before I assume that this behavior was unintentional.,2
"I mean, for building the Python project I assume about 10% more files need to be built, still the building process takes 90+ minutes, and it seems like it almost rebuilds everything",2
"For your conversion, let's assume it is correct.",2
"Assuming you choose option 3 (which will the easiest but will lead to a binary size increase), you should use the following flags during conversion:
```
converter.experimental_new_converter = True
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,
                                       tf.lite.OpsSet.SELECT_TF_OPS]
```",2
"By the way, I'm assuming that this nondeterminism is related to the use of CUDA `atomicAdd` in `segment_reduction_ops.h` and `segment_reduction_ops_gpu.cu.cc` (which I've scouted-out in the past).",2
"I can't find where `tf.math.segment_sum` or `tf.math.unsorted_segment_sum` are explicitly exported (with `@tf_export`), even in [`tensorflow/python/ops/math_ops.py`](https://github.com/tensorflow/tensorflow/blob/v2.3.0-rc2/tensorflow/python/ops/math_ops.py) and I'm assuming that the API linkage gets automatically generated (using [`tensorflow/core/api_def/python_api/api_def_UnsortedSegmentSum.pbtxt`](https://github.com/tensorflow/tensorflow/blob/v2.3.0-rc2/tensorflow/core/api_def/python_api/api_def_UnsortedSegmentSum.pbtxt)) and that there doesn't need to be any intermediate code.",2
"The above assumes that `tf.cast` simply discards the least-significant bits, which I'm almost certain it does (though I have not checked).",2
That still assumes that you don't have enough accumulated 64-bit floating-point rounding errors to spill up into the 32-bit mantissa.,2
"I believe that the work-around you have provided is robust in terms of making the overall operation perfectly reproducible, assuming that the maximum number of segments in a reduction is below an extremely large number (on the order of 2^17 = 131k).",2
"@gootacatchitall,
From the provided code, we can assume that you are using tensorflow 1.x which is not actively supported.",2
"> @gootacatchitall, From the provided code, we can assume that you are using tensorflow 1.x which is not actively supported.",2
"And just to clarify, my assumption with this has been that there is something in the construction of the `MLPRegressor` model that should be able to be replicated in TF (rather than a bug or otherwise in TF).",2
Assumes image_paths is the list of your image files.,2
I ran "git clone https://github.com/tensorflow/tensorflow.git" and assumed that it was the latest stable version.,2
- Assume the output of a CONV_2D is to be inspected.,2
> * Assume the output of a CONV_2D is to be inspected.,2
"How can we debug the result of ops in graph if graph's result is wrong？(**assume op single test is passed, but op may not be fully tested or there comes some platform-related bugs.**)",2
"If it's the same ""naive"" as in the paper (and I assume it is as it's the same dude who wrote the paper and implemented it), it may do the work.",2
"I am getting errors about operations being `neither a custom op nor a flex op` that I haven't attempted to solve yet, but I assume they are due to what's in my model and not a sign of a bug (well, at least not this bug).",2
I'm also assuming this was single-threaded execution?,2
I assume it's 7.4.2 am I right?,2
"This is because `half_pixel_centers` attribute was added in tf2 which assumes that pixels are 0.5, 0.5 for more reliable and correct resizes.",2
"Or at least I assume it is, based on the stack trace.",2
"However, if the issue seems to be pinpointed and fixed in TF 2.4.1, I assume that this is correct, and wil now close the issue.",2
"Assuming you don't need x86 binaries and you have ARMv8 target devices, which is true mostly.",2
"i assume the packages are already her in this repo to find:
https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/",2
"Hi,

thank for your reply and confirming my assumptions, this does indeed help me.",2
"Having said that, we heavily rely on the specific NDK/SDK toolchains that can cross compile for Android ARM 64-bit architectures with bazel and that also makes an assumption of the supported GCC, I guess.",2
I'm assuming these are the multiple graphs being produced.,2
"I think cases like this show we do need to handle sources we cannot move in tf.data; it should still be possible to do prefetching / buffering / etc on the TPU controller to hide most of the latency, assuming the generator produces data quickly enough.",2
I haven't tested myself since we need to figure out where to find some `.so` files we need in `cntorib` but I saw some projects moved to `1.15.0` so I assumed it was fixed.,2
> I haven't tested myself since we need to figure out where to find some `.so` files we need in `cntorib` but I saw some projects moved to `1.15.0` so I assumed it was fixed.,2
"This card lacks tensor cores, so perhaps some code is getting confused and taking a slow path because it assumes tensor cores are present?",2
"I am assuming that the model is using float32 type, which is a typical choice among ML model.",2
"I will assume that, you already have some knowledge about Neural Nets.",2
"> I will assume that, you already have some knowledge about Neural Nets.",2
"Also from the example you gave at the start, I assume you are using Keras.",2
"I'm getting this not implemented error...

`Gradient for IRFFT3D is not implemented.`  (I'm assuming I'll get a similar error for RFFT3D too).",2
This should allow you to get the gradients by decomposing the three-dimensional transform into a one-dimensional and a two-dimensional transform (assuming those two have gradients implemented).,2
"The author says that he doesn't know what worked, but assumes doing:
    
    sudo apt -y full-upgrade",2
"I had already built the [simple ios example project ](https://github.com/tensorflow/tensorflow/tree/r1.2/tensorflow/contrib/ios_examples) once before, hence I am assuming all the header search paths and linker paths and libs are properly set in build settings of the project.",2
"This prints `tf.Tensor([b'hi' b'there'], shape=(2,), dtype=string)` on tf-nightly, so I'm assuming this is already fixed.",2
"@nantha42, My mistake as I misunderstood the query as i assumed backpropagation till M1's output instead of M1's input.",2
I assume you converted with the instructions [here](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_on_mobile_tf2.md)?,2
@stephentandjiria Assuming your saved model has a SignatureDef defined.,2
The ModelCheckpoint callback assumes the initial step to be 0 which will not always be the case if I stop and restart training.,2
"I assume the reason the epsilon was moved is just to make it simpler to think about the effect of the epsilon, `eps=1e-6` under the square root acts like `eps=1e-3` outside of the root.",2
"I assumed that they were equivalent, but  I am obtaining different results with the same input audio.",2
Seems like each worker is trying to work on the entire dataset from this snippet instead of doing a data parallelism approach (which I kind of assume you are trying to do from the code).,2
"And within this compiling time, I assumed it is compiling time, the physical memory grows gradually until it meets some point like 1G, it suddenly goes to 6~9G depended on model.",2
Assume device_filter is not set.,2
"It turns out that the function of tf.contrib.crf.crf_decode in TensorFlow implemented with dynamic_rnn, in source code of dynamic_rnn function in TensorFlow (tf.nn.dynamic_rnn function is assigned in tensorflow/python/ops/rnn.py), it assume that the output shape of the RNN net could not be None, so I rewrite a new function ""crf_decode"" refer to the source code and finally solved it.",2
I'm assuming I would change the user flag to a directory command and location.,2
"# Assume model inputs are a flat list of tensors 
  # (does not support dictionary features)",2
# Assume the input is a dense tensor (this snippet doesn't handle ragged),2
"Note that this is assuming the variable that cell needs for each time step is
  having the same value in the forward path, and only gets updated in the
  backprop.",2
"So you could try adding --copt=-mavx512dq assuming your build machine supports this, or manually patching Eigen in your build.",2
"So assuming the TensorFlow source is in ~/src/tensorflow and my eigen fork is in ~/src/eigen you would do

cp ~/src/eigen/Eigen/src/Core/arch/AVX512/Complex.h ~/src/tensorflow/bazel-tensorflow/external/eigen-archive/Eigen/src/Core/arch/AVX512/Complex.h
cp ~/src/eigen/Eigen/src/Core/arch/AVX512/PacketMath.h  ~/src/tensorflow/bazel-tensorflow/external/eigen-archive/Eigen/src/Core/arch/AVX512/PacketMath.h",2
"So assuming the TensorFlow source is in ~/src/tensorflow and my eigen fork is in ~/src/eigen you would do
> 
> cp ~/src/eigen/Eigen/src/Core/arch/AVX512/Complex.h ~/src/tensorflow/bazel-tensorflow/external/eigen-archive/Eigen/src/Core/arch/AVX512/Complex.h
> cp ~/src/eigen/Eigen/src/Core/arch/AVX512/PacketMath.h ~/src/tensorflow/bazel-tensorflow/external/eigen-archive/Eigen/src/Core/arch/AVX512/PacketMath.h",2
This assumes that you cannot make the variables fixed shape and maintain the TPU placement.,2
It's quite obvious that the model is expecting 320x320 and the Java code assumes 300x300x3.,2
"If your OCL 1.2 support relies on the mandatory support of SPIR 1.2, I assumed dropping this latter also inversely entailed dropping opencl 1.2 compatibility.",2
I assumed that node_a and node_b were executed before node_c but when testing I saw that this is not always the case (even though it is the case in some situations),2
"I assume that nsync (as opposed to tensorflow)
does compile correctly (for example, that it can be compiled and its tests
run on Sierra.",2
"> I assume that nsync (as opposed to tensorflow)
> does compile correctly (for example, that it can be compiled and its tests
> run on Sierra.",2
"edit: when I wrote this I assumed we were talking about passing the buffer for a `tensorflow::Tensor` to a normal CUDA kernel, when this issue is about how to go in the other direction.",2
For the fitting function in Keras this is conflicting because a priori the first axis is assumed to be 'None'.,2
"Re-assigning this to @yuanbyu, who knows the current gradients code best, and would be able to estimate the changes needed. (I suspect that this would require a considerable amount of work to update the existing gradient functions, which may have latent assumptions about expecting `tf.float32` or `tf.float64` values.)",2
"It started happening on `2.12.0.dev20230202`. #59423 was merged after this nighly build, so I assume the issue comes from a tad bit before?",2
"Ubuntu 20.04 was default was gcc-9, Ubuntu 22.04 default is gcc-11, so I'd assume we'd want to stick with the 9.x tools since we're building with 20.04 now.",2
"I am not sure how to interpret these graphs, so I may be making false assumptions here.",2
"I was, therefore assuming that the issue was fixed in TF 2.5. Sorry for not reporting back on this!",2
"For functional while loops, barring some special cases, XLA assumes that the shapes produced by the while loop body stay the same on every iteration.",2
"With all shapes constantly defined a priori and the assumption that the body of `tf.while_loop` remains constant, shouldn't shape inference be straightforward?",2
However according to our current second discussion about XLA activation for the C API (see: #29878 ) I must assume that I did not activate XLA because I do not set the TF_XLA_FLAGS.,2
"Assuming the developers have a good reason for this odd behavior of `int32`, it would be useful for users to make this behavior controllable.",2
> Assuming the developers have a good reason for this odd behavior of `int32`,2
# assuming model is a keras Sequence and x is a valid input,2
"# If I got it right we would need a left multiplication with the
    # output gradient but since the expm_frechet function assumes
    # column major vectorisation while tensorflow assumes row major vectorisation
    # we can just do a right multiplication...",2
This is where a more careful look would be helpful especially since the default vectorisation in the math formulas is based on column major assumptions.,2
"This is speculation -- I'm not very familiar with Bazel -- but I wonder if you need to have a tf_cc_shared_object for libdeepspeech_model.so, and the libdeepspeech_model.so you're loading right now is the one we build for testing and assumes all of its dependencies are built and loaded as SOs as well.",2
"No, I meant to say that (I think) the `libdeepspeech_model.so` file you're loading is built under the assumption that all of the dependencies of the `tf_library` (which includes `:runtime_matmul`) are also going to be loaded dynamically (this mode is useful for running tests since you don't have to wait for the link step).",2
"But the code for cwise ops makes some assumptions about the order of types, assuming that only the first two arguments to REGISTER<N> macros should be used, in the hope that they're DT_FLOAT32 and DT_INT32:
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/cwise_ops_common.h#L413",2
"> But the code for cwise ops makes some assumptions about the order of types, assuming that only the first two arguments to REGISTER macros should be used",2
"Well assuming this kernel is relatively frequently used, it would be nice if tf worked out of the box so to speak",2
I assume this issue is addressed in the newer releases but since I can't compile it on my own I'm stuck.,2
"We are working on changing this, but at the moment the assumption that all shapes are known at compile time is baked very deeply into XLA.",2
I am assuming that the conda install yields c based binaries for all languages while the pip is bringing back something python can understand.,2
Ouch... I was using the official Tensorflow Detection Model Zoo and assumed that all the "official" models can be converted to TFLite.,2
I'm assuming "I/F" means "interface".,2
"Commenting the decorator  `@tf.function(input_signature=input_signature)` (I'm assuming that is equivalent to running eagerly):

```
saving took 0.066272 seconds
tf.version.GIT_VERSION=v2.3.0-rc2-23-gb36436b087
tf.version.VERSION=2.3.0
running ff took 3.957520 seconds
running Issue_fwd.f took 100.743039 seconds
```",2
Note that label_image example assumes there is one output and that is the probabilities of each labels.,2
> Note that label_image example assumes there is one output and that is the probabilities of each labels.,2
@ezhulenev It looks like one of the function optimization passes in Grappler is applying the layout optimizer under the assumption that all devices will be available inside the function.,2
# Assuming `ds` has 89 records in total,2
My assumption is that the new build has some incompatibility with my GPU card and Nvidia tool kit.,2
I assume that you are talking about (at least initially) implementing it as a subclass that can be used as e.g. `tf.EasySession` or `tf.contrib.Session` instead of `tf.Session`?,2
"Sure, even the most (seemingly) trivial assumptions can turn out to be wrong, and especially for essential functionality that is used all the time like `tf.Session` it is a good policy to be extra cautious.",2
"Ah, I assumed it was a GPU issue because I was assigned to this and I'm only responsible for TFLite GPU at best.",2
I had seen flatc building with target's compiler (it must be executable for host I assume) which causes errors in certain environment.,2
"But, If set to ""`local`"", it will assume that the TPU is directly connected to the VM instead of over the network.",2
The error messages indicate node 33 and 28 so i assumed that is the index of the list when you call `get_tensor_details()` but it doesn't seem to be correct in terms of output information.,2
I think I found the problem ... On big-endian system `TF_TString_GetType` is not being calculated correctly for "large" strings. [This ](https://github.com/tensorflow/tensorflow/blob/53b0f6f7a6d25ce858d03b67ab391865d87ac4eb/tensorflow/core/platform/ctstring_internal.h#L184)always gets executed under small string size assumption.,2
I assumed that with this option we can use fixed-point operations on a desktop cpu.,2
I assume you use GCC?,2
"If this works well, I'm assuming we would next have to integrate JavaCPP into the Bazel build, and probably start small and/or somehow modularize the API, something I'm happy to help with!",2
"At this moment though, as far as I know (given that I didn't get any reply from @karllessard or @asimshankar  about this) I am assuming there is no integration with the Java API for the ops with C++ functions like `AddSymbolicGradients()`, so work other than on the build also needs to be done before we can use both APIs together.",2
"I asked about how we could build a graph for training, but I did not get a reply, so I simply assumed it wasn't possible.",2
"For example, assuming we stick with the existing `org.tensorflow.Tensor` API, what does it take to back it with JavaCPP?",2
I assume you have your files located in '/folder/with/images' - Does it behave the same if you put them in '/folder/with/images/foo'?,2
So I'm assuming its another type of error.,2
I assume at some point our nightly builds changed to use cuDNN 6 instead of cuDNN 5.1.,2
"@mathemaphysics having the same issue with 10.2 cublas being installed, I assume it is compatible.",2
My assumption is that they'd be the same?,2
*Assumption: TensorFlow 2.x has been installed via pip*,2
So I do not even know why it assumes it is of dtype tf.sparse.,2
Perhaps I made some fundamentally incorrect assumption about how the async code works?,2
I assume that you're using this on GPU.,2
"According to its docstring `tf.nn.batch_normalization` infers the axes from the input tensors (I assume `x`, `mean`, `variance` etc. and that they're expected to match), so it didn't really need an `axis` parameter, I guess?",2
"Then `axis=None` could assume the user wants means/variances as `[batch_size, frames * height * width * channels]` and not `[batch_size, frames, height, width]` (`axis=-1`).",2
"For the number of nodes difference, it's because we added support for Quantize op recently (i was using HEAD and i assume you were using older branch).",2
"Yes, unfortunately the nb_code_sync tool assumes the same amount of code cells in both source and translation notebook.",2
"The above reduces training logging, but I'm still facing several hundred lines of `tensorflow: Level 1: Registering` logging, which I assume comes when the package is first imported",2
"# If callable, assume same signature and call with tensors and get the types",2
"# If callable, assume same signature and call with tensors and get the shapes",2
"Thinking deeper about this, it seems unreasonable to assume that we can use `model.input` as the object to differentiate against because the same model can be used multiple times within the same `GradientTape` session.",2
"> Thinking deeper about this, it seems unreasonable to assume that we can use `model.input` as the object to differentiate against because the same model can be used multiple times within the same `GradientTape` session.",2
"During training, if you have not provided any batch size, converter will assume batch size as 1 and same has to be provided during inference.",2
"Hello zpcalan@, assuming you were mainly trying to confirm the interactions between workers and ps, can you call `tf.debugging.set_log_device_placement(True)` at the start of the program and see if it provides useful device placement information?",2
"> Hello zpcalan@, assuming you were mainly trying to confirm the interactions between workers and ps, can you call `tf.debugging.set_log_device_placement(True)` at the start of the program and see if it provides useful device placement information?",2
And I assume that's a 3D tensor.,2
"By the way, this collab assumes the blank label is still `num_classes - 1` as per #42993.",2
"> By the way, this collab assumes the blank label is still `num_classes - 1` as per #42993.",2
"We assume that zero-point is representable with integer number, and all optimization / implementation also assume that we have integer zero-point. (e.g. zero-padding is easily possible on quantized domain, some pre-compute optimizations for the symmetric quantized weight assume we have integer zero-point.)",2
"I think the problem is not with splitting the 31 bit shift and 9 bit shift: (a >> 31) >> 9 is the same as a >> 40, assuming there is no overflow.",2
"> I think the problem is not with splitting the 31 bit shift and 9 bit shift: (a >> 31) >> 9 is the same as a >> 40, assuming there is no overflow.",2
"I am assuming you're trying to use the C API and not using the Java AAR, correct ?",2
"> I am assuming you're trying to use the C API and not using the Java AAR, correct ?",2
"Assume if you trained and converted the model correctly, all you need is the metadata writer library above.",2
Then I will assume everything is working as intended and will close this for now.,2
"Assume the bug has already been fixed from my previous observation, closing the bug for now.",2
"Your assumption is correct, you need to instantiate the `tf.keras.model` before inspecting the shapes of the layers.",2
"Also, assuming your hypothesis is correct, it still means that there is a serious bug in tensorflow.",2
"the issue is also present in the gist i linked, which i assume to be a ""clean"" install",2
"I didn't think it would matter much, since I would assume `tf.keras.layers.Conv2D()`'s output would always be of the same type, but that's probably incorrect.",2
I read that part of the documentation but assumed any stateful operations would be called during production.,2
# Mask R-CNN assumes we are running detection on multiple images.,2
"So assuming there is no impact of this problem after the interface got removed in the future, I close this issue.",2
So I assume the problem is indeed not all symbols were exported.,2
- what strategy are you using? (I'm assuming `MirroredStrategy`?),2
Given these results I assume it used the standard (non mkl optimized) version of TF 1.14.,2
I would hope/assume that the function would throw a warning when the input dtype is not int (and is going to be rounded to ints in 0-255 by the function).,2
I checked the tensorflow source code and was surprised to see it always assumes the output depth is at `self.kernel[-1]`.,2
"Though, I did see the Wrapper objects (e.g. WeightNormalization layer), also make this assumption.",2
@karmel The main issue is that the code is assuming output depth at self.kernel[-1] when it is actually [-2] for Conv2DTranspose.,2
The problem here is in an assumption that the placer algorithm makes -- that any tensor can be copied between different devices -- which is generally not true (e.g. for dataset variant tensors).,2
It is not very safe to assume that function is foolproof.,2
"Assuming a multi-GPU node run docker container:
`docker run -it --rm tensorflow/tensorflow:2.3.0-gpu`",2
"I assume NNAPI works only on Android platform, is that correct?",2
I'm assuming your test harness won't be using bazel for execution?,2
What is the error in my assumption?,2
# Assuming converting a tf.Keras model to a TensorFlow Lite model.,2
tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc(148): error C4430: missing type specifier - int assumed.,2
The code in the file assumes TF 1.x,2
"I need to go to bed now and i'll leave this building, I assume it wont be short and report back in the morning.",2
"I tried again against cuda9.2 and it built fine (assuming you have @wdirons patch, of course)",2
I assume the Android environment has V2 APIs enabled and they are not available for other Linux platforms (with OpenGL).,2
"Google Pixel 2 doesn't support OpenCL, so I assume it's OpenGL.",2
"I would assume, in a network where many computations are performed, that all the preceding computations have to be the same.",2
"I'll close it, assuming the previous comment is correct.",2
"Musl follows standards very strictly: if something fails to compile with Musl but works on glibc, then the code is assuming the exception rather than the standard.",2
"@jdduke On side note, as 1.15 is latest release, I assume any changes related to that would be reflected only in 2.x right?",2
3. I assume you're on the TensorFlow Stats page.,2
I assume dtfio should only need to be installed for this to work but I still get the same error message.,2
I assume the use or loading of custom loss/metrics in both of our examples is causing this.,2
"@wuhy08 , `Size` as an op is supported by our [Select TF ops](https://www.tensorflow.org/lite/guide/ops_select) feature - assuming you are okay with a few MBs of increase in binary size.",2
"Assuming you want to apply dilation rate 2 on both the height and width, you can just pass in [2, 2] in this case.",2
"Could you provide with us the .tflite flabuffer or the original GraphDef you are usin(assuming it's not confidential), so that I can give it a try.",2
"> Could you provide with us the .tflite flabuffer or the original GraphDef you are usin(assuming it's not confidential), so that I can give it a try.",2
I did link the related issues as according to the warning message I assumed that somehow through the creation of multiple models in a short time multiple function retracings occured for a single model.,2
At the time it was only a possible assumption that TF tracks function retracings globally.,2
"On mobile (assume you're using c++), the equivalent c++ call is : **ResetVariableTensors**: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/interpreter.h#L624",2
"> On mobile (assume you're using c++), the equivalent c++ call is :
> *ResetVariableTensors*:
> https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/interpreter.h#L624",2
But I assume that my compiled version is bad as tensorflow-gpu installed via pip does not fail but instead continues whithout GPU.,2
"Assuming static shape allows the converter to do extra optimizations, that will be incorrect if you tried doing resize_input_tensor on the interpreter. (You can find many issues already created with old converter about failures during resizing).",2
"I assume the paths in the `BUILD` file come from something like `gcc -v -E - < /dev/null` which includes resolved paths, but the dependency checker does use the unresolved paths.",2
Our code is too complex and building also for 32 bits will require at least 2-3 years of work (since we have so many numerics code assuming 64bits architectures which will result in a lot of security issues due to overflows if not handled properly).,2
"Having said that, we assume (probably not the best assumption) that the left operand is ""bigger"" and the right operand is ""smaller"", and that's not even universally true; I think we support that in ADD but not necessarily in MUL.",2
Now... then comes one of the bad assumptions.,2
"Hi @lihanchen, judging by your filed bug and your example code, I'm assuming you're running `model.predict` inside of a loop?",2
"'If use_side_inputs is True, this explicitly sets '
                    'the names of the side input tensors required by the model '
                    'assuming the names will be a comma-separated list of '
                    'strings.",2
"It obviously still refuses to install on MSYS2, and our first need here is to figure out why that is, and then secondly, assuming that's correct, to figure out how to install it otherwise.",2
"The second link you provided shows how to use the .pb model outside docker, I assume you pointed it because of what I mentioned about using the model on Matlab, which at the moment doesn't support .pb format but ONNX and h5.",2
Am I assuming correctly that this is fused?,2
I am assuming that integer quantization will first be done in tf-nightly.,2
"unfortunately the python program I am using depends on version 1 of tensorflow and assumes unix/linux system behavior, and tensorflow 1.8-1.15 can not be installed under any version of python(cygwin or windows)...",2
"In general you don't need to download the pip from `storage.googleapis.com`, a `pip install tensorflow` should be able to get it, assuming your Python is on 64 bits, your pip is up to date, you have the needed MSVC redistributable installed and that Python is installed from the Python website, not from Microsoft Marketplace (apparently, there is a bug with that)",2
"And, `tf-nightly(-gpu)`, master branch is 1.14.0 in `tensorflow/core/public/version.h`. If I want to compile V1.15(assume related bugs have fixed), should I checkout `r1.15` branch?",2
I assume that I might need to change the calibration code.,2
"So I edited the Interpreter.swift file and commented out lines 54-67 because the problem was occurring inside a section about error logging (nice to have of course, but I assumed not critical) and I am pretty new to Swift so I didn't know the right way to fix this.",2
I assume this error is fine since all I care about is having the files in the local repo.,2
I assume if I change the compiler flags to look at my tensorflow directory for includes that I'll just get the "non-modular header" import problem again.,2
Please always assume good intent as I was basing my question on https://stackoverflow.com/questions/34514324/error-using-tensorflow-with-gpu/34514932#34514932,2
I am assuming it was because of that as I rebuilt everything and it worked and this was the only difference between before and now,2
I assume the delegate didn't build correctly?,2
I believe keras Models assume the user passes one "nest" (see tf.nest) of inputs as the first argument.,2
For now I'm going to assume that possibly I caught the code in a weird state when I built this and will close the report.,2
If you think it's important to keep looking at this I assume you can reopen also?,2
These steps worked for me so I'm assuming that it is only some configuration issue at your end.,2
I haven't tried batch size 4 but I assume there is a deeper issue here,2
I assume we're simply not ready for that yet?,2
"You could also peek inside the Estimator's model_fn, where there should be a training checkpoint just sitting around (assuming `train` was already called).",2
I compiled tf myself so that I can use it with Cuda 10 and Python 3.7 so I assume something goes wrong there.,2
I have been able to quantize completely the Resnet50 model with the same code that I posted so I assume that the problem is with my model...,2
"This may be a duplicate of https://github.com/tensorflow/tensorflow/issues/27472 -- @robieta , assigning this to you as well assuming they have a similar action item.",2
"Hi Saikumarchalla,

The code is running well on Colab on the tutorial website but there are the exception errors when running on Windows 10 with cmd or pycharm. (Assuming that the virtual environment you meant is Colab which I can only test on).",2
"Hi Saikumarchalla,

The code is running well on Colab on the tutorial website but there are the
exception errors when running on Windows 10 with cmd or pycharm. (Assuming
that the virtual environment you meant is Colab which I can only test on).",2
"Assuming one of them is the wrong value, which it is?",2
There is a strong assumption that the precompiled code is invariant to the arguments of the function.,2
"@pedro-r-marques Personally I would prefer the other behaviour, i.e., average across all ""words"" (assuming the batch examples are sequences of words).",2
@omalleyt12 I agree that extending to the 2-d case under the assumption of a single casual/"time" dimension is straight-forward.,2
I find the subclassing API better suited for complex projects (I assume that's also why it's used by all the built-in Keras layers) and this would make it just as easy to use as the functional API.,2
Gradient functions are currently written with the assumption that we don't need to handle integers (e.g. we always return None for the indices param of a gather op).,2
"@skye to understand the problem better and out of curiosity, would you mind pointing to a place where the assumption on returning None is used?",2
"I am in Sofia, Bulgaria time, so I think we have quite a lot of overlap (assuming you are in Shanghai).",2
"@Leslie-Fang 
Yes, this is the original implementation, but it assumes scalar `start` and `stop`.",2
Here's where I start to get into assumptions.,2
"NOTE: this wrapper assumes that no two checkpoints have the same prefix,
        therefore, this function will delete existing checkpoints with the
        same prefix before saving (here prefix acts like a file path).",2
"Note: using `map_flat_values` for this assumes that the innermost dimension of the ragged tensor is not ragged, as is the case in your example.",2
"They do not currently have direct support for `tf.linalg.matmul`; but as noted in the comments above, this operation can be performed (assuming both matrices have a non-ragged inner dimension) using `tf.ragged.map_flat_values(tf.matmul, x, y)`.",2
I assume you would like different elements to be produced.,2
"However, the data adapter used inside `fit` assumes the number of steps is the same across all epochs, which is not true in case of an increasing batch size.",2
"1. The Progbar callback printed the ""output"" as a scalar (same as the loss), I'm assuming via reduce_mean.",2
"2. The Tensorboard callback registered ""output"" and presented it in the report same as the losses, again I assume via reduce_mean.",2
"I did not test if this leads to errors or if it is just an aesthetic issue, but I'm assuming it would also cause performance issues if I tried to extract larger data and Tensorboard kept track of them.",2
"WIth regard to the solution you proposed, I believe it it still has a weak point in that the use of tf.Variable and tf.assign assumes a fixed shape which is not always the case (an epoch's last batch may be smaller).",2
The limitation of the `message` argument is that the base message is worded in a way that assumes the right hand side of the shape check is correct.,2
I'd like to use the function in a way that _doesn't_ assume this.,2
# Assumes the filenames are in the same order,2
"The code assumes 64 bits in several places, so building from source might still lead into errors.",2
@bionicles it is indeed a very reasonable assumption that a framework named TensorFlow should have a tensor factorization.,2
"Since while loops are implemented at the C API level (rather than in the higher level language bindings using primitives), I assume we'd want to implement cond at the C API level too.",2
I was assuming you were looking for an Op to free memory that is more lightweight than configure.,2
@kefirski I'm assuming you are talking about Keras models specifically.,2
We are going to assume that this build is for the rpi,2
-# Assumes the file is in the current working directory.,2
"Assume you have a tensor T with shape (14, 28 ,3), now you want to transpose it to (3, 14, 28).",2
"Yeah, that's what I had assumed, which is why I was so surprised at how different the results were when explicitly passing past characters into the model vs. only passing the last generated character.",2
I feel that the documentation for `plot_model` should mention the fact the `graphviz` needs to be installed separately (especially for inexperienced users who'd simply assume the `pip install graphviz` is enough).,2
> I feel that the documentation for `plot_model` should mention the fact the `graphviz` needs to be installed separately (especially for inexperienced users who'd simply assume the `pip install graphviz` is enough).,2
I assumed it would change the batch_size too.,2
I've assumed TF 2.1 wasn't available for 3.8 as you reported.,2
"Currently, the `KerasTPUModel` implementation of the `validation_split` parameter in the `fit()` method violates the key assumption behind out-of-sample testing (i.e., that your training set and your evaluation set are mutually exclusive).",2
"Note that we only support 1.15 (`r1.15` branch), 2.0, 2.1, 2.2 and master at this point, assuming you already use the corresponding Bazel version.",2
"PS2: If the [build from source on Windows guide](https://www.tensorflow.org/install/source_windows) is wrong, please tell us which steps didn't work, assuming you follow them in sequence",2
"> PS2: If the [build from source on Windows guide](https://www.tensorflow.org/install/source_windows) is wrong, please tell us which steps didn't work, assuming you follow them in sequence",2
"I have models saved as .h5 format, before I go down this road I'm assuming we need to use a model = model.load(""path to model"") and not model.load_weights, is this correct?",2
"I also run win 10 64-bit
python 3.6.2
most recent tensorflow (so I assume 1.3?)
but in the cpu-only version",2
"For my research I need intermediate jacobian values for use in loss calculation, and assume i need a persistent tape for jacobian wrt input columns and loss wrt model trainable variables.",2
"I assume this is because instead of putting the control flow in the graph using `Switch` and `Merge` nodes which must later be converted to constructs using `If` nodes (which is where the error is thrown), `If` nodes are used in the first place so no conversion is necessary.",2
"This assumes that the layer will later be used with inputs that
    match the input shape provided here.",2
"That in turn is because the variables are assigned in a single batch operation with the assumption that their order matches the order of variable values in the serialized file, and that assumption is undoubtedly failing because variables are ordered trainable first, then untrainable, and the `trainable` information is not correctly recorded in the serialized file if the `.trainable` attribute is assigned after layer creation.",2
"This is because the ordering of weights _depends on_ the trainable attribute, and the serialization/deserialization _assumes_ that the ordering is unchanged.",2
"For instance, if it takes 1s to fetch a single output from `ds`, then -- assuming there is not asynchrony and parallelism within `ds` -- fetching a single output from `ds.window(size=10)` would be expected to take 10 seconds and fetching a single output from `ds.window(size=10).batch(batch_size=16)` would be expected to take 160 seconds.",2
I assume you mean control deps _from_ the outer graph _to_ the inner while loop graph?,2
"Maybe a “friend graph” idea like what we discussed with regard to control dependencies earlier would be possible, but from what I saw during my exploration of adding control dependencies, it seems that adding inputs from other graphs is not explicitly disallowed anywhere, so trying to allow it could break things in lots of unexpected places that happen to depend on that assumption.",2
"My working assumption had been that dataflow determines the execution flow of the graph, so an op's control dependencies would only be triggered to run when its inputs flow in.",2
"There, I would have assumed that because the op's inputs never become available, the op's control dependencies would not be triggered.",2
I assume there is no much difference between tf1 and tf2?,2
I assume that you found a solution for the issue.,2
"Given that the two previous blocks of code work, I am tempted to assume that there indeed exists a module named `tensorflow.feature_column`.",2
That assumption is wrong actually.,2
Proving that the assumption is wrong.,2
"Thanks also for the counterexample on my assumption about modules, I have still lot of things to learn about Python.",2
@imarkiew This looks like due to the fact that code in training_utils.py of tf.keras is still wrongly assuming input data to be numpy arrays.,2
a) people would easily assume `Z.assign_add(0.0)` works. (because `Z = Z + 0.0` works. and it's not hard to implement this broadcasting anyway.),2
I assume the former is equivalent in v1.2.1.,2
Otherwise I assume this is the same issue as https://github.com/tensorflow/tensorflow/issues/21460 ?,2
I assume the issue is similar the reset of the distributions calculations.,2
Closing by assuming that previous answer solved the issue.,2
"Given the date of the post, I'm assuming <=0.5.1.",2
@stengoes In your code you've used convolution's associative property by combining the filters of separable convolution and 1x1 convolution assuming that both operation does not use non linearity.,2
"However, this assumption  of linearity does not hold as we do use relu after separable convolution and also the 1x1 convolution in the original MobileNetv1.",2
"2. even assuming that point 1 is not a real problem, could be that layer normalization doesn't fit this particular problem---by the way, note that in the original paper the MNIST problem is not tackled using RNNs but just layer-normalizing a FF network.",2
"Furthermore, some of the suggestions don't directly apply to TF (e.g., `pip` recommendation in 9. is likely something that needs to happen at the level of PyPI, assuming it would be possible).",2
But the code later assumes only None but not -1 means size unknown.,2
This assumes that you put the python script from the bug description next to the Dockerfile in a file called test.py.,2
"I don't think it's feasible to avoid turning Infs into NaNs in some cases, as algorithms may assume multiplying by zero results in zero, and also we don't have any control over cuDNN's algorithms.",2
"My hypothesis from both points is that Tensorflow is parallelizing some computations but the multiprocessing does it aswell and both don't seem to take into account eachother resulting in a deadlock situation (I assume that for the big matrix inverse additional processors are attempted to be used however those are busy in a parallel process, however I'm not very familiar with this topic).",2
"As you mentioned Sage maker as GPU I am assuming you are using AWS Sage maker, and also going through the error log it seems the error might be due to NCCL communication problems.",2
"I am assuming that you have non-GPU pluggable devices which are actually identified as GPU by TF which is the problem,right?",2
"The code that I marked however assumes all PluggableDevices to be GPUs, therefore the `visible_devices` list will be populated with invalid ids, which then later cause errors when being checked internally.",2
"I assume the issue with the lambda layers was that they make the shape of the tensor unusual when they split the outputs, so the metric was averaging along the wrong dimension or something.",2
"I assume the compiler or something else in our setup has something to do with it, but without any debugging information it's hard to understand what.",2
Could I know what error message you want to display?(I assuming you want to display the error regarding the usage of TensorArray w.r.t Gradients).,2
Assume people using remote servers.,2
"I know of no way to construct a class using pure Python that has this behaviour (wrapt achieves this behaviour by using a C extension), and it breaks some fundamental assumptions that the stdlib function inspect.getattr_static makes.",2
I am assuming your question is for `code snippet-2` where True is converted as '1'.Correct me if I am wrong.,2
The code as written assumes there are GPUs available which are not the case on this machine.,2
"the code fail [here](https://github.com/tensorflow/tensorflow/blob/1b3ce795c3b63ac480db585352fd94e52274fd37/tensorflow/core/kernels/mkl/mkl_layer_norm_op.cc#L50)
but I am assuming the source in another place",2
"A simple data type check would help to reject invalid floating `depth_radius`, and no value validity checking is needed (which I assume would be costly).",2
I assume the behaviour mentioned by you is in Local Linux desktop right?,2
I assume this is not really fixed?,2
"I assumed, @mohantym did also get an error in this order of magnitude in TF 2.8.",2
"Thus I assume that @mohantym obtained only the results with (acceptable) numerical deviation, but not the erroneous result",2
"If It is TF 2.10 version in your use case  , I assume that you have installed Cuda 11.2 and Cudnn 8.1 through below command and set path for cuda files.",2
But please note that it is my assumption that it should work with same `dtype` as numpy argument.,2
Until then we shall assume that the `dtype` argument not supported as mentioned in Documentation and also as it is giving inconsistent results.,2
"If set to ""local"", it will assume that the TPU is directly connected to the VM instead of over the network.",2
"Assuming you just copy-pasted the folder into content/sample_data, the path should be         `prediction_head_path = ""/content/sample_data/prediction_head_model""` and not `prediction_head_path = ""/content/sample_data""`as in your code.",2
"So I followed the same tutorial for TensorFlow V2.9.0 and it worked with no issues, I'd think it is safe to assume that the tutorial may not be working with TensorFlow 2.11.0",2
"I think TF is assuming building for IOS need to be TFlite, which is not my case ?",2
Therefore I assume(d) the file in the debug folder is for some kind of debugging.,2
"My initial assumption was the first one, but from the source code it looks like the second one.",2
"Since you are using .tflite model, I assume what you used was the the [tflite label_image](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/examples/label_image) rather than the tf one.",2
"Adding to all convolutions is a whole other beast which requires changing our APIs - our current convolution API doesn't have separate `padding` and `padding_mode` options, it assumes we always pad with zeros and only controls the size.",2
"However, shout if you're already working on it Aryan (its been over a month so I assume not)",2
"In the current implementation, it uses all GPUs in a cluster and it assumes all workers have the same number of GPUs.",2
"Funny thing is the profiler treats the Conv2DTranspose as ""Conv2DBackpropInput"", I assume internally CONV2D, CONV2DT and ""Conv2DBackpropInput"" is very similar.",2
"The lines you added have no effect, I assume you read [this issue](https://stackoverflow.com/questions/34199233/how-to-prevent-tensorflow-from-allocating-the-totality-of-a-gpu-memory), you need to use the instructions related to TensorFlow 2.",2
"I initially thought that the fix in 8.9.1 was motivated by this issue, but it seems it was completely independent ;-) I will report back when I try the full training, but I assume it will work fine given that the forward pass seem to be fixed with 8.9.1.",2
"I would assume TensorFlow would handle numpy inputs by automatically converting it to tensors, instead of requiring the users to explicitly do the conversion.",2
@tiruk007 i assume that you have also uploaded the dataset via the link https://drive.google.com/file/d/1pKAJ-PF42nRB2kw0ZdMAkg1i2fUSvF-y/view?usp=sharing  to your google drive.,2
I assume you're wondering why I (and others) still use tf1.,2
It's as if TensorFlow thinks this memory is available to the CPU somehow (maybe it assumes it's unified memory?).,2
So my assumption is that the building procedure of the C++ API library is at fault.,2
The build just assumes that it is already installed.,2
"Assuming you don't need XLA, can you please try to build with `--define=with_xla_support=false`?",2
"BUT I was able to reproduce the performance problems also with just a blank TF when running our pipeline on CPU, so I assume that the TF threading implementation itself might interfere with other libraries using OpenMP.",2
Note that this is my assumption for not being able to scale up well.,2
"Therefore, I assume that the bottleneck is the number of disk access that costs too much.",2
"I created this ticket deliberately as a ""Support"" ticket and not a ""Bug"" ticket, because I am trying to understand how TensorFlow and MKL work together and wanted to ask: Are my assumptions and conclusions stated above valid?",2
"I would assume that in Tensorflow the state of all things are disabled by default, such as layer regularisation, etc, unless explicitly turned on?",2
We assume None for y and sample_weight.,2
"@nfelt I assume when the job is offloaded to GPU, the underlying algorithm is breaking up the sum into multiple chunks, implicitly achieving a higher precision for this operation, and thus avoiding this issue.",2
"Based on the note for `np.sum` about the partial sum optimization being axis-specific, I'm assuming the rank-1 vs rank-2 difference is actually a memory-aligned-axis difference, since from my testing, in the rank-2 case the effect only happens when reducing along axis 0, which I believe would be the non-memory-aligned direction.",2
"I'm assuming the numpy answer is the closest to the right one by the way, since it has been more tested and implemented.",2
"I have not looked into why the tpu_test.py fails, but I assume it would be for a similar reason.",2
"I assume that you are able to retrieve custom weights, initialized at layer inception, only if the layer is assigned to a model. Correct?",2
"From your error log I could notice that you're creating a `nn` class object by calling NeuralNetwork.py, which I assume the same file [here](https://github.com/MMunibas/PhysNet/blob/master/neural_network/NeuralNetwork.py), in line 53 where it uses `tf.variable_scope` is depreciated in Tensorflow 2.x and instead you need to use `tf.compat.v1.variable_scope`.",2
There is an assumption that the fault may be nvidia drivers for windows.,2
"I assume I can give it a better directory if I change the argument of this method model.export(export_dir='.'), right?",2
"I assume you are persisting the `model` data returned here, until the lifetime of the interpreter:
```
auto model = tflite::FlatBufferModel::BuildFromFile(model_path, &error_reporter);
```",2
"Separate from the seg fault, the frame_length of 2700000000 is just large enough to require a tf.int64 dtype, but windows are assumed to have lengths [representable by tf.int32](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/signal/window_ops.py).",2
"Since I may have made mistakes in my assumptions or the code, I don't think the experiment is conclusive.",2
"This comes from a wrong assumption at early stages of when we thought output tensors are those without any consumers, and this apparently was wrong.",2
I just assumed that you couldn't have polymorphic attributes (the documentation only says that your inputs and outputs can be polymorphic),2
I guess the TFLite converter "assumes" that the `MatMul` is able to handle 3-dim inputs (so we can remove the reshape) but it actually isn't on GPU delegate.,2
Yes (assuming the abs diff threshold is `0.01`).,2
With the dataset stats aggregation an events file is created in `/tmp` and this file slowly (I assume the rate of growth is dependent on on the number of the elements in the dataset and the size of the elements in the dataset) grows in size.,2
# assume padding type 'SAME' and padding value 0,2
"I'm not too familiar with the internals, but I'm assuming proper grpc channels would have to be opened between the machines and that it might be something the AI Platform would have to do.",2
That issue is resolved by telling `tf.function` to assume that the shape is dynamic so it should skip this static verification.,2
"It's unclear what model it is, but given the SUB MUL at the beginning AND your input tensors being pure integers, I assume it's a quantized model.",2
"> It's unclear what model it is, but given the SUB MUL at the beginning AND your input tensors being pure integers, I assume it's a quantized model.",2
"TF 2.4 started enforcing shape assumptions checking, causing layers that were called on incorrectly shaped inputs to fail with a clear error message.",2
"My assumption is that `next()` handles the end of iteration, similar to Python's built-in [`next()`](https://docs.python.org/3.8/library/functions.html#next) and `tf.data.Iterator`'s [`get_next()`](https://www.tensorflow.org/api_docs/python/tf/data/Iterator#get_next).",2
"Ok, from your link I have to assume it's a CUDA version issue.",2
"Assuming the training_data_len is 311, Can you run your code by updating, the range of for loop:

```
for i in range(20, len(test_data)+1):
    x_test.append(test_data[i-20:i, 0])
```",2
That means TPU Pod I assume?,2
"for anyone is interested: my problem was solved by cleaning up the /tmp directory, and my assumption is that the tfrecord file will be temperorily saved there then upload to gcs?",2
"I wasn't aware that GCS artifacts get moved through the VM (I just assumed they would go through the TPU host, which might be wrong).",2
"Also,  I need to work with floating point number, am I right to assume that only `float16` is supported?",2
"Hey @huanyingjun, the output-pointer casting in your MobileNetv2 example (where you use `t->data.uint8`) is the correct, but the SSD one is wrong - I assume you fixed it later.",2
The tool simply assumes the same input tensor order that TFLite interpreter sees.,2
"I'd have assumed you meant `g.gradient(y, [x1, x2]).numpy()`?",2
"I changed code as you suggested, and run 
python distribute_run_tf2.py 0

to only start one worker, I assume in sync-training setup, this worker will wait for another worker(like I did with TF1.0 with SyncReplicasOptimizer + parameter server), but worker 0 just start training, here is the log",2
I get that but can you show me how the derivative work out? (assuming you know how to).,2
During pyhton configure.py I had to set the option /arch:atom otherwise it would assume the AVX capabilities of my buildmachine CPU!,2
1. I assume TensorFlow has some performance testing before releases.,2
"turns out it was a duplicate of https://github.com/tensorflow/tensorflow/issues/20586 but I assumed it was the system, so after installing CentOS 7 CUDA 9.2 and cuDNN 7.3.1 I was able to reproduce the error and then found it was in my code.",2
"Another solution would be to normalize your data around zero, by subtracting the mean and dividing by std of each input channel (assuming image type data).",2
# this assumes K.image_data_format() == 'channels_last',2
"Therefore, I'm assuming the original issue is fixed so I'm closing it.",2
"This would be fine if your data is already
normally distributed in the tfrecord, but let’s assume the first 64 have a
label of 0 and the second 64 have a label of 1.",2
For those of you looking at this --there is no example in the url for saving the tflite file and had assumed would have save() method like the regular tesorflow model.,2
This of course assumes that `vgg_preprocess` is written in a batch compatible manner.,2
"the if statement assumes that if a depth equals to one, it is a depthwise convolution.",2
"I'm not sure if I needed to the ""install NVIDIA driver"", as I'm assuming that was already installed, as I had already been running tensorflow-gpu without issue.",2
I assumed that the Masking layer handled that.,2
"In theory, a NumPy array could be flagged as non-writable (via `a.flags[""WRITABLE""]`), but unfortunately a lot of internal (and I assume external) users already rely on the mutability of `.numpy()`.",2
I assume this is expected behavior.,2
"However, the execution seems stuck with 100% CPU usage and I don't see any GPU activity, so I'm assuming the graph keeps getting built.",2
"I assume I am making something wrong, but sincerely I do not know what.",2
> We will assume that the input dataset is batched by the global batch size.,2
"With this assumption, we will make a best effort to divide each batch across all the replicas (one or more workers).",2
I'm assuming entries like these in the autograph debug output (set to 10) indicate the function is being called with different tensor input shapes and has to be retraced?,2
@aaudiber Thanks for clearing my assumption.,2
"Expectations/My assumption:
- When train dataset reaches its end, the training pauses and evaluation kicks in.
- After evaluation is done, the training starts again",2
"I'd assume that the same is happening due to use of `ds.map(map_fn, AUTOTUNE)` with AUTOTUNE?",2
"To extend a little bit more on what I meant above, let's assume `inputs` is a `batch_size` x `1024` matrix, `nce_weights` is `num_classes` x `1024` and `nce_biases` is `num_classes` x `1`.",2
"If, for example, the first row (example) is comprised of `num_true = 3` labels, which are 1, 4, 6, we will select the 1st, 4th, 6th column from the first row of `all_logits` (we assume here that columns start indexed at zero).",2
"Now, if we used a **sigmoid** function to retrieve predictions later on (and assuming the NCE loss did a good job bringing `out_logits` close to `out_labels`), the result of the prediction might have been deceptive.",2
"Assuming the `serving:0` is accessible to the JVM API (input node of tf.function), what would be the right output node to use?",2
"And given the dimensions, I would *assume* that a pixel at position [1, H, W, C] would indicate the probability of the pixel [H, W] belonging to class C.",2
"Apparently that has been removed, assuming the user would take care of the normalization before running the input.",2
Current code assumes that the grouped_estimator_spec.evaluation_hooks is one PerReplica hook - but it's actually a list.,2
if not then probably something is wrong with TF outputting them (generally) [my assumption here - whatever the case - model is learning or not learning or invalid altogether - the metrics should somehow be relevant - and if they aren't I assume this is a bug].,2
"I understand that `/usr/local/cuda/lib64/stubs` is used to enable the TensorFlow wheel to be built in the absence of a real CUDA driver (and then spat out for use elsewhere), and I assume that the `devel-gpu` container is used for this purpose.",2
Assuming the "fix" is verified and I don't need to do that in the next git download of course you can close it.,2
"Just assumed it was like GPU drivers where they just seem to keep going - will look and report back if its still a problem, sorry for any interruptions! :D",2
"If you want to build from source (assume you have a specific requirement for 1.14 and you cannot wait), check out [this thread](https://devtalk.nvidia.com/default/topic/1055131/jetson-agx-xavier/building-tensorflow-1-13-on-jetson-xavier/).",2
I assume that this was the link:  https://www.tensorflow.org/install/source_windows,2
So i'd assumed the problem was with the linking step of tensorflow and cuda.,2
Current build system assumes that Bazel is running under x86_64.,2
"But if your system has more RAM, I assume it'll be much smoother.",2
It looks like by default the compilation assumes that some of the implementation is already in a system library on device.,2
"I think there were recent changes to attempt dealing with some of this, but in general clang assumes a monolithic CUDA installation (I.e. all CUDA files are under a single directory).",2
So I'm going to assume that the symbols I want are in _libtensor_framework.so_,2
I will assume this issue fixed for now.,2
Tensor RT path search all assume linux as well,2
"Dear @jlebar, I assume the root cause here is the same one as in the equivalent issue for TF2.0 #25773, which is not an inherent problem of protobuf but a name clash of a message field name with a windows header macro (see my comment on the referenced issue), leading to a weird error in the generated header as the compiler sees a ""2 = 14"" entry.",2
"Since Googling the issue doesn't come up with any definitive answers or similar problems, I'm assuming it is likely an issue with my machine.",2
"In general you don't need to download the pip from storage.googleapis.com, a pip install tensorflow should be able to get it, assuming your Python is on 64 bits, your pip is up to date, you have the needed MSVC redistributable installed and that Python is installed from the Python website, not from Microsoft Marketplace (apparently, there is a bug with that).",2
"Specifically, my assumption by follow the instructions: https://www.tensorflow.org/lite/guide/reduce_binary_size#selectively_build_tensorflow_lite_with_docker is that:
The resulted `tensorflow-lite.aar` will replace 'org.tensorflow:tensorflow-lite:x.x.x' dependency in my Android project.",2
"Because of this and the fact that other users don't seem to have this problem, I'm going to assume the problem is in the code I'm using.",2
It looks like `third_party/gpus/find_cuda_config.py` eagerly assumes that having CUDA installed in the system default configuration means that you want to use that CUDA installation.,2
Assume that all roads are laid out in a perfect grid.,2
It is assumed that `sp_weights` is "aligned" with `sp_ids` in the sense that `sp_ids.indices == sp_weights.indices`.,2
"Closing this issue, assuming it is resolved, but feel free to re-open if you have follow up.",2
Seems like I can assume the two ( any exceptions should be caught by pre-built unit tests ). I will go a head with a pull request with in a couple days.,2
"The author has not reverted back on our Stack Overflow suggestion, hence we assume it has been useful to them.",2
"But in the keras version it's doing a bit more (`_keras_shape`, `track_variable`, etc.) which I assume is needed for working with keras models.",2
"I'm just going to assume that `tf.keras.backend.variable` is no longer useful and that the default `tf.Variable` handles any of the keras metadata it needs (`_keras_shape`, `track_variable`, etc.)",2
"That method assumes the graph of the estimator is not being modified (identical graph), right?",2
"I assume you already batched   
your dataset `dataset = dataset.batch(items_per_file)`",2
"@bhack The model attached by @dlaiup has the SpaceToBatch/BatchToSpace, and my reply is about it, i am assuming the conversion is done not using the new converter.",2
This doesn't seem to need an extensive API redesign - although it does assume a lot about  how prefetch works.,2
@achandraa - I assume you saw the code snippet in my original request?,2
Assumptions: You have ssh access without key to workers.,2
Assuming that the Metric class inherits all relevant infrastructure from the Layer class.,2
"I took a look at the code for `Conv1DTranspose`, and it doesn't currently support RaggedTensors -- i.e., the current implementation assumes that the inputs are dense.",2
"> I took a look at the code for `Conv1DTranspose`, and it doesn't currently support RaggedTensors -- i.e., the current implementation assumes that the inputs are dense.",2
# align_corners=True assumes that values are sampled at discrete points,2
# aling_corners=False assumes that values are sampled at centers of discrete blocks,2
There are lot of posts on Stackoverflow where developers assume that this API is only for Single Tensors.,2
We can probably base this off of the amount of GPU memory allocated -- if only a small fraction of the GPU memory is left we can (practically) assume that the GPU is "reserved" by another TF process.,2
"E.g assuming one would be able to select a maximum adaptation length via env variable TENSORFLOW_CONV_MAXADAPLEN and if the variable is set, one would then always run autotuning with min (shape[i],  TENSORFLOW_CONV_MAXADAPLEN).",2
Am I correct in assuming that the gpu-topk function is only different from top_k in that its the hash map implementation vs radix Sort?,2
"@mohantym Thanks I think, I will assume that this is the fastest it can work in eager mode.",2
"Therefore, I assumed `tf.reduce_prod` might not be the culprit for now...",2
"Assuming it has two channels, that gives you a vector of size 131072.",2
"However, I was converting to `Tensor[Long]` previously, because I had assumed shapes are represented as `int64` tensors.",2
"However, I
> was converting to Tensor[Long] previously, because I had assumed shapes
> are represented as int64 tensors.",2
All that is assuming that I am correct about where the problem lies.,2
"Since I assume you're setting the strides correctly (they must be non-zero)
I think we're looking at memory being freed before tensorflow gets to it.",2
"# your input, let's assume each element is (dense, sparse)",2
"OK, I'm assuming that's working as intended, `.ckpt` files are useless on their own, but are intended to be used by a script that builds a model, sets up saver, and loads them.",2
So I can assume that LeakyReLU and the keras experimental preprocessing operations are not supported by tf lite micro?,2
"The strange thing is that if I build in release mode, the final scores for each word are `[64, 64, 64, 64]`, but, if I choose the normal mode the command recognizer returns at line 88 of `recognize_commands.cc` (ie. ""If there are too few results, assume the result will be unreliable and bail."") because the if statement at line 83 is satisfied.",2
"The split operations and reshape are basically memcpy ops so they probably take similar amounts of cycles, but for the mathematical ops consider that while 'sub' for example might take one cycle for fp32 (assuming you have an FPU) when using int8 you have scaling, zero point etc to handle.",2
"I assume you have setup all the things on windows correctly as mentioned [here](https://www.tensorflow.org/install/source_windows#setup_for_windows), If yes and still you have the problem then maybe you could look into [this issue](https://github.com/dariomanesku/cmft/issues/28), I personally do not use windows for development so if that is an issue related with windows I would not be the right person to comment, Maybe looking at other build issues in [tensorflow/issues](https://github.com/tensorflow/tensorflow/issues) might help.",2
"I used the same model.cc file for the three TF Tiny versions ( I am assuming that the model is not the issue, but the missing libraries).",2
It appears that editing tensorflow\lite\micro\kernels\strided_slice.cc to have an extra case that assumes int32 can be treated as int8 can work in at least some cases. (It worked for me; I have trained my model with tf 2.4.2 and built tf-micro with tf 2.4.2 source),2
"2- shield the CPUs that you want to assign (I'm assuming CPUs number 0,1,2,3 (LITTLE cluster)",2
The compiler simply assumed a static pointer is always `nullptr` (`0x0`) right after declaration and skipped the "additional" `nullptr` initialization while it was `0xDEADBEEF` instead.,2
"@angsiokcheng With all these discussions with fixes and code merged, assume this issue can be closed?",2
"I was assuming backward-incompatible changes, but also was confused since I could find there is a similar change on `tf.concat()`: in r0.12 we have both `concat_v2()` and `concat()` (I expect the v2 method will replace the original soon).",2
I assume you're running via bazel?,2
I am assuming now this issue is obsolete.,2
"As described in my comments above, assuming I stay with the contrib Estimator, the problem is now that I need to figure out how to test a trained model without the weight feature being present, and also how to use a trained model for predictions without that weight feature being present.",2
I assumed that meant that `weight_column_name` - `w` in the test - **must** be one of the model features.,2
"Whereas, the test case clearly shows that it absolutely should not be.  (And, when not including it among the model features didn't work the first time, I assumed it was because the feature was broken, rather than what must have been the case: that something else in my code was broken.)",2
"This sort of question is better asked on stackoverflow, assuming that it's user error and not a completely broken model.",2
"Assuming that that
is used and nothing else (hard to tell), the limit shouldn't trigger at 8M
ints.",2
Those can make TF potentially 10x faster on CPUs like Skylake Xeons (c. 2015) assuming `-march=native` is used.,2
I've not personally tried it since rc1 but I assume that hasn't changed as the release notes suggest otherwise.,2
"I've read through the posts from others, the only issue is that this is a direct windows installation and not on AWS as I'm assuming most of the people here have.",2
Assuming @gunan 's instructions worked.,2
"I had actually (obviously, incorrectly) assumed that the type of that Variable would have been some kind of floating point datatype, given that it wasn't specified in the documentation.",2
"The `Tensor` C++ class unconditionally stores the shape on the CPU regardless of where the data is, and essentially everything assumes this (for error detection, branching, etc.).",2
I think I'm implicitly assuming we're talking about the resize_image ops.,2
"Yes, as the @vrv and @martinwicke assumed, I meant the resize_image ops.",2
This assumes that Bazel knows how to extract a tar.xz archive.,2
"I assume you are expecting to get [5,None] from the inference.",2
"# assumption: shadow variable names appear after
    # regular variable names in alphabetical list",2
"I'm assuming here you mean for any distribution with a scalar event shape (i.e., single variate distributions).",2
Here I'm assuming that the underlying infrastructure could take over the `tf.distribution` instance that we have and conduct differentiation etc accordingly.,2
"Bas,

Sorry for the delay, after https://github.com/tensorflow/tensorflow/issues/46419#issuecomment-767343956 I assumed that you're going to look into this further.",2
A quick bump on this - am I making fundamentally incorrect assumptions on how this should work?,2
ResNet (I assume 50) was not a dramatic as I saw ~170ms and then after adding the with CPU and the WINOGRAD NONFUSED flag I was getting 150ms or so.,2
I guess it comes from the fact that the model is not initialized with placeholder weights when creating at https://github.com/tensorflow/tensorflow/blob/r1.9/tensorflow/python/keras/engine/saving.py#L229 so the loader assumes that the layers don't have weights,2
"The link you provided seems the same as the invalid one I listed, I assume you were meaning to link to an older build?",2
"I assume that I could structure it in a similar way to [`TensorReduction.h`](https://bitbucket.org/eigen/eigen/src/59859fde3bc7173175087ed5d002389b4e76876f/unsupported/Eigen/CXX11/src/Tensor/TensorReduction.h?at=default&fileviewer=file-view-default), except that `accumulate` would preserve the original shape of the tensor.",2
I assume `#undef` after the tensorflow include is a workaround?,2
I built my code upon the VAE tutorial assuming that it shows the best possible way to start and will work with the default tf and keras methods such as saving.,2
I assume I'd need to set the GPU memory allocation to be <50% for this to work.,2
"I'm not sure what this request was for, but #26 is closed so I assume this one is too.",2
"Assuming you restructure a lot anyway internally about the variables, I'll look at them again once it's stabilized.",2
I think the existing reader ops basically all assume that data eventually comes from file system - please correct me if I'm wrong about this.,2
"Dropping down a level (if the above response is focused on the larger discussion, this is on a more detailed technical level), the cost of creating a new session is typically pretty cheap (assuming the graph is not gigantic).",2
"I think a good solution to this family of problems should not make
assumptions about layers or primitives ""above"" the abstractions that are
part of the TF distributed abstractions.",2
"> Dropping down a level (if the above response is focused on the larger
> discussion, this is on a more detailed technical level), the cost of
> creating a new session is typically pretty cheap (assuming the graph is not
> gigantic).",2
"(2) Assuming we've solved (1), we now have an op (which runs on a worker) that knows a failure has occurred.",2
"Let us assume for now that upon ""failure"" a worker cleanly shuts
down its TCP connections and rejects any future connection attempts.",2
I assume that any waiting receive will raise an error of some kind.,2
"> (2) Assuming we've solved (1), we now have an op (which runs on a worker)
> that knows a failure has occurred.",2
"Otherwise, assume I haven't started working on it yet.",2
I'm assuming you mean the [cudnn_rnn.py](https://github.com/tensorflow/tensorflow/blob/a6a6188/tensorflow/contrib/cudnn_rnn/python/layers/cudnn_rnn.py) file that @protoget has been working on?,2
"@cancan101 Assuming the crop region should be at the same location in each image, you would just take `images[:, y_start:y_end, x_start:x_end, :]` where `x_start`, `x_end`, `y_start`, and `y_end` define the corners of the crop region.",2
I'm assuming you are referring to smart_initialize from the gist: https://gist.github.com/yaroslavvb/d592394c0cedd32513f8fbb87ca05938,2
I like this approach (assuming it works) as it uses a single sess.run call.,2
"exp(0) == 1, so that densifies the SparseTensor (therefore it's not very useful)
log(0) = -inf, and i see you just pushed that; we will have to revert it because the correct version densifies the sparse tensor (and is not very useful) while the pushed version assumes log(0) == 0.",2
"Assuming the above list is correct, only `tf.erf()` remains to be done.",2
@ToxidoLiu based on #4832 I'm assuming you're running TensorFlow version 0.8.,2
@caisq assume this was intentional?,2
"My thinking was in case the assumption is correct, the docs can be modified to assert that as I see so many posts about this very confusion.",2
Duplicate of #44485 (assuming you meant/use Python 3.9),2
I note however that micro_speech assumes an input inference type of int8 and an output inference type of uint8.,2
"Assuming the developer is responsible for input quantization and output dequantization, has this policy changed since TFLite 1.x?",2
The error is no longer reproducible with a recent version of TF (e.g. a nightly from the past month) - so I'm assuming the bug has been fixed.,2
"Assume the input vector `x` and the upstream gradient `g` has the form:
```
x = [x1 x2 x3 ... xn, 0, -, -, ...]
g = [g1 g2 g3 ... gn, gnp1, -, -, ...]
```",2
"@danijar Assuming `training_batch` and `testing_batch` are the results of calls to `tf.train.batch()` that occur before the `tf.cond()`, it will always dequeue both batches.",2
"One dimension for the samples, a second dimension for the amount of classes (let's assume just one output neuron for simplicity), and a third dimension that differentiates between correct and incorrect match for that one binary output neuron.",2
"@xlambein you are assuming that all datapoints from the same class should be weighted the same, which is not true in the most general case.",2
"I am assuming cmake builds everything, hence, no need to use bazel, am I right?",2
"tf.nn.sparse_softmax_cross_entropy_with_logits is the equivalent function here -- the ""sparse_"" means that the distribution is hard, i.e. (0, 1, 0, ..., 0) not (0.5, 0.25, 0.25, 0, ... 0), which is what SpatialClassNLLCriterion is also assumes",2
@mcjjin I am assuming you are using a 64-bit python distribution.,2
I don't know why for some reason I would assume PYPI whl is a different build from the provided on tensorflow.org.,2
"For better or worse, TensorFlow assumes it owns the whole GPU, so other libraries trying to use the GPU at the same time will cause issues.",2
"I was applying the `repeat()` before caching (both in the example and in my real data loader), so I assume the cache releases the lock and produces the index file on `tf.errors.OutOfRangeError`",2
The python 3 installation instructions are already published in the docs so I assumed it was official.,2
So I would assume there is something to do with using the TensorArray's inside the while loop that is causing issues.,2
"Also, the docs on the tensorflow seem to assume I already know what everything does.",2
"So I would assume there is
> something to do with using the TensorArray's inside the while loop that is
> causing issues.",2
"Assuming the toolkit is installed in /usr/local/cuda, run the following commands (**edited to reflect the cuDNN version you downloaded**):
> 
> tar xvzf cudnn-6.5-linux-x64-v2.tgz
> sudo cp cudnn-6.5-linux-x64-v2/cudnn.h /usr/local/cuda/include
> sudo cp cudnn-6.5-linux-x64-v2/libcudnn\* /usr/local/cuda/lib64
> sudo chmod a+r /usr/local/cuda/lib64/libcudnn*",2
"```sh
(Assume MNIST_CNN model costs only 400MB GPU memory)
config.gpu_options.per_process_gpu_memory_quota_mb=400
```",2
"Assume we have a GPU memory of 2GB, and a host memory of 16GB.",2
"@danmane, @martinwicke: I assume this is just a css style change?",2
"> @danmane https://github.com/danmane, @martinwicke
> https://github.com/martinwicke: I assume this is just a css style
> change?",2
"And maybe in the case of HMC and BBVI, it's easy to assume the user passes in a function or class that implements a model's `log_joint(x, z)` density.",2
"It would be easy to add python wrappers around these for specific formats, assuming the image format encodes exactly as a raw byte grid.",2
"Tensors are always assumed dense, row-major, and memory-aligned; for example, [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/framework/tensor_types.h#L80) is the definition of a Matrix.",2
"So in case, I use Bazel as you indicated how can I specify the target ARM platform and I assume the cross-compilation?",2
My assumption is you don't have enough memory to run the build.,2
"The whole link seems like a mix of different issues but I assume you're referring to the answer that advices converting with an itermediate step, ie .h5 to .pb.",2
providing labels to the `model_fn` in predict mode seems breaking the assumptions.,2
"@rmlarsen 

The simple answer is likely that LinearOperators predate eager mode and therefore assume deferred computation anyway.",2
"I
think Martin just assumed it was nicer than it is.",2
"You'll have more luck making Java issues on [tensorflow/java](https://github.com/tensorflow/java) directly, assuming you're using the new bindings.",2
"The nodes I am using have 16 CPUs for 8 GPUs, so I assume this problem will not completely go away but will most likely be minimized for now.",2
"> The nodes I am using have 16 CPUs for 8 GPUs, so I assume this problem will not completely go away but will most likely be minimized for now.",2
"Assuming there is no further follow-up needed on the tensorflow team's end, I would be fine with closing this issue for now.",2
"Assuming there is no further
> follow-up needed on the tensorflow team's end, I would be fine with closing
> this issue for now.",2
"Assuming you're using a VPN to access tensorflow.org or using tensorflow.google.cn, these resources should be available.",2
I assume that's fixed internally and just needs to be pushed?,2
"I assume need to do some modification in this file to get location and number of detected objects.
https://github.com/tensorflow/examples/blob/master/lite/examples/object_detection/android/app/src/main/java/org/tensorflow/lite/examples/objectdetection/ObjectDetectorHelper.kt",2
I just assumed that maybe TF's build files haven't been updated to cater to Bazel >0.18.0 and so I just pinned to Bazel 15 for now,2
"Assuming this is the iris tutorial take a look at 

``classifier = tf.contrib.learn.DNNClassifier(feature_columns=feature_columns,
                                            hidden_units=[10, 20, 10],
                                            n_classes=3,
                                            model_dir=""/tmp/iris_model"")
``",2
"I was under the assumption that the model was _only_ looking at the same CSV data every time, which means it should have arrived to `[1,2]` every time.",2
"I'm assuming this works by now, please let me know if I'm mistaken.",2
"In theory you should be able to swap out your use of `TensorFlowInferenceInterface` with the standard TensorFlow Lite `Interpreter`, assuming you have the .tflite model available.",2
"You could try adding prefetching threads to the input pipeline to see if that improves things. (I'm assuming you're using a version of [`cifar10_multi_gpu_train.py`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/image/cifar10/cifar10_multi_gpu_train.py), so no data is being fed or fetched in each training step.)",2
"The issue tracker is for bug reports, and I assume your post will not be widely read here.",2
So i assumed the framework transfered the tensor to GPU automatically.,2
This assumes you have enough model capacity and the architecture of the underlying RNN has enough capacity to do so.,2
"FYI, @danmane, I assume documentation contributions are welcome.",2
I assumed Tensorflow had a way of handling overflow memory.,2
Does this started QueueRunner then violate the assumption that the cond() branch is only a function?,2
"However, by looking at the location you executed `tensorboard`, I would assume you do not have `C:\Python36\Scripts\` added to your path.",2
"(2) I am assuming there's not a memory problem since on cpu it runs fine and starts training rather quickly, so I can see the progress plus when running on cpu the allocated RAM doesn't go beyond 3GB.",2
Assume you create an SSBO with ID 42 and you tell an input / output tensor that ID 42 is used for that tensor.,2
"Assume you have to do this for both of them:

df['label']=df['label'].astype(int)",2
I'm also assuming you're also familiar with `tf.cond` which has been traditionally used to implement skipping type logic.,2
"I assume they are Android or some other operating system what is bleeding through on the configuration:

Linux: Ubuntu 16.04
Compiling with GPU support
Commit: 91a70cbf1c627117b70a3d2dd4c612779369e293",2
I'm assuming you're talking about Android?,2
"Assuming you have the following code (or something like it):

...
estimator = DNNClassifier(model_dir=/path/to/files, ...)
tf.train_and_evaluate(estimator, ...)",2
"However, you could also use other tools to monitor memory use (is anything about your setup causing swapping), hack the code to time individual RPCs and operations at the PS server, and other techniques to look for operations that violate your assumptions about how they should be behaving.",2
Something wrong with the dependencies I assume.,2
"However, in the case of `--config=cuda`, it seems that `nvcc` doesn't recognize `__builtin_expect` as a compiler builtin, and simply assumes it's some function defined for the host, leading to the compilation error [above](https://github.com/tensorflow/tensorflow/issues/19203#issue-321998060).",2
"f! That's cool, I'm just trying to verify my assumption before diving into the details for working on the related project.",2
"@alanchiao , As of now we don't have any speech models which are in LSTM Quant and available in TFLite, I assume some of the below tflite models may be quant lstm model and we like to run this model as part of TFLite Speech apk and run its full network to understand further.",2
@niruyadla : I'm assuming float models wouldn't serve your need.,2
"Given the lack of recent activity, I assume the question has been answered sufficiently.",2
"However, I would assume this is because the input tensor images from the rep dataset maybe need to be in uint8.",2
"While I installed v1.0.1 from 
`https://storage.googleapis.com/tensorflow/windows/gpu/tensorflow_gpu-1.0.1-cp35-cp35m-win_amd64.whl` as per tensorflow installation guide, I am assuming that it should correspond to build 108 given the patch version numbers.",2
"I assumed, the semantic version releases were also cut from `master` whenever one was ready to ship.",2
I assume the nightly have moved on to the version that does not have the patch that suppresses the warning messages.,2
@gunan I'm assuming this has been cherry-picked into a release.,2
I assume specifying activation =None means that it uses no activation function and is therefore linear model?,2
Am I correct in this assumption?,2
An example of feeding RGB inputs with fewer intermediate steps than the examples that assume FP32 inputs would also be helpful for demo code (if that's possible.),2
I started out with the assumption that running the same operation on data of the same shape should take approximately the same amount of time.,2
Assuming that NumPy arrays can be marshaled to from R arrays with no copying I'm assuming this would have no performance problems since the python code is just defining a graph.,2
">    Assuming that NumPy arrays can be marshaled to from R arrays with no
>    copying I'm assuming this would have no performance problems since the
>    python code is just defining a graph.",2
Closing because I assume this is fixed by a change Yangzihao made.,2
"I assume `tf.nn.depthwise_conv2d` is a wrapper for `tensorflow::ops::DepthwiseConv2dNative`, and I will share my experiments in hope it is useful for someone.",2
"int32 tensors were usually used to represent the shape information, thus many operators assume it's a cpu tensor.",2
"As far as I understand the whole process, the necessary steps to have bazel run with Python2, you have to follow these steps (assuming Anaconda):",2
"This also appeared in your gist, though, so I assume you're aware of it.",2
I assume you used a different installation method.,2
I had been using tf.trainLoggingTensorHook which I am assuming uses the lower level summary writers under the hood.,2
"I was assuming that the [r0.10](https://github.com/tensorflow/tensorflow/commits/r0.10) branch was representing to what would go into the 0.10 release, and that branch no longer contain the changes.",2
"@mrry I assume this is fixed now, in that we don't do improper placement, but I'm not sure all sparse optimizers are supported on GPU, which is perhaps another bug which I believe we already have an issue for.",2
"Assuming the network architecture can really handle arbitrary input size (I skimmed over the paper and I think it does), could you try this and let us know if it works: 

* When converting, use an arbitrary input size like (1, 512, 512, 3). 
* When using the interpreter, call `interpreter->ResizeInputTensor` to resize the input tensor before calling `interpreter->Invoke`.",2
"Indeed it's a fair assumption that we could ""lazily"" freeze the graph just before building the engine, which absolutely would solve the problem (only for TF-TRT) in the graph is saved ""unfrozen"".",2
"In the meantime, please try one of the following:
(Assuming CPU)

**Python 3.5**
`pip install https://ci.tensorflow.org/view/Release/job/release-win/lastStableBuild/M=windows,PY=35/artifact/cmake_build/tf_python/dist/tensorflow-1.2.1-cp35-cp35m-win_amd64.whl`

**Python 3.6**
`pip install https://ci.tensorflow.org/view/Release/job/release-win/lastStableBuild/M=windows,PY=36/artifact/cmake_build/tf_python/dist/tensorflow-1.2.1-cp36-cp36m-win_amd64.whl`",2
"I am assuming you will be running and debugging it on iOS, so both build and host are the same",2
"Right, I think `tf.assign(..., validate_shape=False)` is unsafe wrt shape inference (which, for sanity's sake, assume that, once inferred, shape information is never invalidated).",2
"I'm not sure what your code looks like, but I'd suggest that you construct the `Exporter` object before starting training (which I assume is using a `Supervisor` and therefore calling `Graph.finalize()`...) to avoid this error.",2
"However, I think the 1.0 failure mode is a little more subtle: it is possible that TF worked fine assuming you never placed an op on the GPU.",2
"Based on your reply, I assume you did not set it.",2
"> Based on your reply, I assume you did not set it.",2
I assume that this made [this line](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/c/c_api.cc#L1108) in the C API fail silently.,2
I assume `*.grpc.pb.h` might be generated with grpc plugins though I am not familiar with cmake so not sure how to fix it.,2
I would assume that something happened in between.,2
"# in samples, assumes 25ms of 16khz audio",2
We now assume your model has a network which maps the `input`s into fixed-length `dim`-dimensional vectors.,2
"Thanks for the suggestion - assuming there are no knock-on effects to the full softmax case, we should fix the sample code to avoid the performance pitfall on sampled softmax.",2
"2. Assuming by ""close"" you mean calling TF_DeleteFunction, yes.",2
Are you using the CPU version of TensorFlow? (I'd assume so because you don't have a CUDA-capable GPU.),2
"I assume you'd edit the occurrences here: https://github.com/miyosuda/TensorFlowAndroidDemo/search?utf8=%E2%9C%93&q=armeabi-v7a
and add x86 and x86_64 to each.",2
"By default the `tf.data.experimental.AutoShardPolicy` is set to `AUTO`, which will  first attempt to shard by `FILE` (the assumption here is that if you're doing multi worker training, you probably have a large dataset spread across a number of files, and not something you can easily load into memory).",2
The assumption is that any use of `b` will be ordered after `do_work(a)` so all is well.,2
I am assuming it's not for testing as you mentioned DMA and thus only a performance-wise matter.,2
"I'm getting this error (which I assume is from libtensorflow, the C++ binary) when using Tensorflow.js in a Node.js environment:

```
2020-06-16 15:46:14.057597: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 8998027264 exceeds 10% of system memory.
terminate called after throwing an instance of 'std::bad_alloc'
  what():  std::bad_alloc
Aborted (core dumped)
```",2
That may also generate more attention I assume.,2
"Since I can't access your data file, I can't tell whether you logic in inception_preprocess is correct (it seems to make the data ranged from [-255, 255], assuming the original data is from [0, 255]).",2
"My assumption is that you have a different version of tf installed that Python is finding when you import tf elsewhere, so that is probably misleading.",2
"Assuming you have specific versions of these dependencies that are supported, **is there a foolproof way of installing packages that will work reliably?**",2
"@namitajadhav : I assume the limitation on Tensorflow 1.14 is for training and converting the model to tflite - if that is the case you can still deploy the tflite/flatbuffer on current (top of tree) tensorflow master,

@PeteBlackerThe3rd 's   tflite analyzer may help you to analyze your tflite file: https://github.com/PeteBlackerThe3rd/tflite_analyser",2
"Assuming:
w_gradient is the matrix representing the gradients of shape [m, n]
w_gradient_column is whatever reduction function along the column dimension (shape [1, n])
w_tensor is the original weight matrix
w_scaled_tensor is w_tensor with the normalization applied for all columns",2
Thinking it was related to the single lookup issue @vincentvanhoucke mentioned and assumed it was expected behaviour.,2
"I assume you do that [here](https://github.com/tensorflow/tensorflow/blob/97c6203bb3f3978ac67920c66b6234ef82051c57/tensorflow/python/client/tf_session_helper.cc#L546), where you create a tensor by providing a pointer to the numpy array data.",2
I currently use SBT as my build tool and I assume that libtensorflow.so is in "LD_LIBRARY_PATH".,2
"I made this function to calculate output shape of deconv2d, assuming stride==1.",2
Always assumes stride=1,2
# assumes in_shape[0] = None or batch_size,2
"If you ask for the gradient of something (`z` in this case) that isn't already scalar real, it assumes the gradients `dL/dz` are 1.",2
"As no errors were returned and the .so-file was generated, I assume it was done correctly.",2
"If they are the same
  # length, we assume the characters are one-to-one aligned.",2
So I assume parts of the TensorFlow API I am using are only compatible with version 2.,2
Since the `einsum`is syntactic sugar for `matmul` I assumed there should be no problems with back propagation.,2
E.g. I can only assume that a problem arises from Keras only having one session while `train_and_evaluate` (as far as I know) creates a training session in the beginning and a new evaluation session on each evaluation.,2
"So without wanting to hijack this issue, I would assume that this might be a similiar problem.",2
"assuming you can still repro the confusing error message yourself, it would be useful even if you can just understand and explain how the error arises (this is always a great way to learn about a new codebase too).",2
"That said, the short answer is that the two should be the same, assuming that in the course of computing `accuracy` and/or `cost`, the model weights are not modified.",2
I'm assuming this is training?,2
I would start with nothing distributed and assuming the code is fully optimized and I thought the server was not fully utilized I would try a distributed setup.,2
@zheng-xq I assume you want to use event polling to enable the CPU operations?,2
"I assume tensorflow/models #824 will fix this but please respond to this issue once that PR lands, if it doesn't.",2
"Assuming your Python 3.5 distribution is 64-bit and not 32-bit, could you try `conda install tensorflow` rather than using `pip`?",2
I'll assume you do.,2
"The error I described above was probably because I had exported the SavedModel with tensorflow 1.4.1 and it has some incompatibilities with tf1.5, which I assume is used by the most recent version of tensorflow/serving.",2
"I am assuming there is an incorrect definition of input_shape = (242,4,1) but correct input_shape = (4, 252, 1) should be in my view because the First dimension represents the number of channels, and channels should be 4 instead of 252.",2
Assuming my solution is sufficient.,2
I assume this is a memory issue in a similar vein.,2
"Yup, that generate script does assume a single directory in GOPATH.",2
"I'm assuming you're using Ubuntu or Debian, and that you've installed CUDA at its default location.",2
"Assuming that they indeed are proper numpy arrays, you should use `np.concatenate` and not `[data_cnn, data_mw]` if you are trying to concatenate them.",2
"@reedwm the reason I asked you was the recent refactoring of dtypes in keras, though it seems the issue here is more around keras assuming all items returned by a layer are tensors or ops, whereas the distribution layers return subtypes of this class: https://github.com/tensorflow/probability/blob/master/tensorflow_probability/python/layers/internal/distribution_tensor_coercible.py#L41
(note that keras is checking op.type in the stacktrace via lift_to_graph->op_selector).",2
"With my refactor, I was careful not to assume anything was a tensor.",2
I assume the model creation needs  to be modified to reshape the labels as 2d-tensors - or am I wrong?,2
Some of us have invested time coding for using this assuming that it was production ready/tested and provided performance gains.,2
Since you mul and add epsilon it assumes the two have the same shape.,2
I am assuming you are providing your own implementation of cblas_gemm.,2
I think it's safer to assume that it won't be there in the next few months.,2
This is fine assuming org/tensorflow/native/windows-x86_64/tensorflow_jni.dll is not built to depend on it.,2
"It seems that constant_folding.cc, ReplaceTensorWithConstant, assumes that the node that will be replaced will have multiple outputs, and only replaces those edges that are fed by the one replaced output.",2
I assumed you already verified before merging :(.,2
"With GPU support, I assume?",2
"Assuming you always pass tensors with one component in their shape, I think the two forms have no practical difference, although `shape=[None]` may have a performance benefit.",2
"@wenmin-wu Please take a look at this [comment](https://github.com/tensorflow/tensorflow/pull/21757#issuecomment-416835941) i.e.,
in the documentation of `tf.nn.embedding_lookup_sparse` its mentioned that **This op assumes that there is at least one id for each row in the dense tensor represented by sp_ids**",2
"@limdlh Assuming all the nodes in you quantized models could be delegated to GPU, then you are comparing CPU int speed and GPU fp16 speed (because GPU delegate has to dequantized your model to floating point).",2
I assume those extra memory transfers are related to JIT optimization and they would only run once during the first warmup run.,2
> can't determine number of CPU cores: assuming 4,2
"actually the lib link points to the site-package, which I assume will resolve numpy errors.",2
But I assume it is okay...?,2
> But I assume it is okay...?,2
I assume you are following https://www.tensorflow.org/install/install_sources#prepare_environment_for_mac_os ?,2
@gunan I assume we're still not doing a 1.0.2?,2
I assume you are trying to pass input as Sparse tensor and padding it with some default value(`"-1"` here).,2
So I am assuming all cores are used.,2
Assuming issue has been addressed.,2
"I assume this problem may be related to running out of memory, so I set the batch size to 1.",2
I assume you missed out my other question - Could you please clarify if OpenCL is giving optimum performance for TF lite in comparison with other delegates (OpenGL/Vulkan) as suggested by https://blog.tensorflow.org/2020/08/faster-mobile-gpu-inference-with-opencl.html ?,2
I only compiled armeabi-v7a version assuming that they will work properly on arm64 (on S6) as well.,2
My assumption is that the sigsegv happens because a bug in the camera code is causing it to provide a preview frame that is not the resolution it claimed.,2
"Indeed, the GDR plugin is developed under RDMA over Converged Ethernet (RoCE) environment, and it assumes the IP address user passes to the GRPC server could also be used for RDMA.",2
"> I'm assuming that it is the case that there is a discrepancy between the version of tensorflow used by bazel to build the inception graph for retraining, and my (likely slightly more recent) build that I am using to classify?",2
"I'm assuming this is the retraining tutorial, the grammar seems to be fixed at head -- https://github.com/tensorflow/tensorflow/blob/4172ca2cd7ac34be67bda2600944d284e8907b95/tensorflow/g3doc/how_tos/image_retraining/index.md",2
"I don't believe that behavior is defined for RankNet or LambdaRank, where the assumption is that you are dealing with labeled pairs.",2
Currently TensorFlow assumes NCHW as the better data format to present tensors for convolution on the GPU.,2
"From the documentation at [1] and from most iterator interfaces (java, c++), the convention assumes that you would have to call `get_next` to fetch a new batch.",2
The reason why not using 2.x is simply because my code base is in 1.14 so I assume I need a 1.14 library file to run it.,2
"We are unable to write a unit test for this
      # because TensorBoard dependency assumes TensorFlow package is installed.",2
"So to convert the weights, assume each gates has size U, it will be:

i, f, c, o = np.split(tf_weights, 4, axis=1)
keras_weights = np.concatenate([i, c, f, o], axis=1)",2
"That causes people first to assume a breaking API-change, then to look for problems in their own model definition, when finding out that model-saves cause this, and finally to start digging in tf's code for the reason of this message, which by it self sounds like the model-save did _not_ work.",2
"> That causes people first to assume a breaking API-change, then to look for
> problems in their own model definition, when finding out that model-saves
> cause this, and finally to start digging in tf's code for the reason of
> this message, which by it self sounds like the model-save did *not* work.",2
# assume every pic is rgb,2
"As Derek mentioned, currently we don't have a mechanism for specifying if some outputs should be in host memory and we assume (to a large extent) that they'd be in device memory.",2
"Assuming the example is minimal, it looks like the failing code is (probably) in one of these files:

https://github.com/tensorflow/tensorflow/blob/60a21e25b0261369a15ca1d17505d7c3c82be967/tensorflow/contrib/image/kernels/image_ops.h
https://github.com/tensorflow/tensorflow/blob/60a21e25b0261369a15ca1d17505d7c3c82be967/tensorflow/contrib/image/kernels/image_ops.cc
https://github.com/tensorflow/tensorflow/blob/60a21e25b0261369a15ca1d17505d7c3c82be967/tensorflow/contrib/image/kernels/image_ops_gpu.cu.cc",2
"I'm going to assume the issue is fixed since that was the only known padding bug; @amnonh-uw, please reopen if that's not the case in 1.7.",2
I'm not sure how likely the label is to be the same on multiple entries of the batch (which I assume that is the broadcast dimension you are thinking about).,2
"@ChesterWQC I don't know enough about the release schedule, though I assume the changes will show up in 1.13 (not knowing the date yet).",2
"Since I haven't heard back from @anilsathyan7 , I assume he's good.",2
"When it comes to fusing `B`, `C`, and `D` into a fused `D`, the rule assumes that the inputs of `B` and `C` are different tensors, but in this case, they are the same (`A`) and the fusion fails.",2
"I get no parallelism using TF.dataset I assume b/c I am using a pyfunc, b/c I couldn't figure out how to put all my work into TF.",2
"In this case, assuming your generator produces an (image, label) tuple, you probably want to rewrite your `distort_simclr` function to take two arguments (`def distort_simclr(image, label): ...`).",2
I assume that you are referring to `petastorm.reader.make_batch_reader` ([documentation](https://petastorm.readthedocs.io/en/latest/api.html#module-petastorm.reader)) and `petastorm.tf_utils.make_petastorm_dataset` ([use example](https://petastorm.readthedocs.io/en/latest/readme_include.html#tensorflow-api)).,2
"Until it's ruled out, we should assume that the observed/reported nondeterminism is coming from the upstream [Petastorm](https://petastorm.readthedocs.io/en/latest/index.html) section of the input pipeline.",2
Because ResNet50 also has a loss of ~1.6 and spread out probabilities of ~20% for each class in the new version I assume that the old version (TF 1.13.1) has the bug and the saved (faulty?) model of that version can't be loaded into newer versions (?).,2
"we just imported the regular artifact using gradle, so i assume it's GL backend.",2
"It's true that these do not have read permissions, as assumed by the `cuda-bin` rule.",2
"Assuming this is a nightly build error, but will wait for feedback.",2
"https://www.tensorflow.org/install/source_windows doesn't mention installing protobuf, so assumed it came with the distribution.",2
I assume that this is the fix: https://github.com/tensorflow/tensorflow/commit/69da929ad4d5ba605507efa1f52b382a55b6a969,2
"Assuming you're using `tf.train.Saver`, this is the `save_relative_paths` argument to `__init__`.",2
I assume if I ignore the warning I will be safe.,2
"The difference at the first step (step1) of decoding is between:
```
state1 = cell((context1=attn(state0)), state0) # RNNSearch
context1 = attn((state1 = cell(context0, state0))) # AttentionWrapper
```
(assuming, as in GRU cells, that states and outputs are the same)",2
"Let's assume `feature_spec` and `features` is something like:

```
feature_spec = {
'feature1': FixedLenFeature(shape=(1,), dtype=tf.float32, default_value=None)
'feature2': FixedLenFeature(shape=(1,), dtype=tf.float32, default_value=None),
'feature3': VarLenFeature(dtype=tf.string)}


features = {
'feature1': <tf.Tensor 'ParseExample_15/ParseExample:15' shape=(?, 1) dtype=float32>,
'feature2': <tf.Tensor 'ParseExample_15/ParseExample:15' shape=(?, 1) dtype=float32>,
'feature3': <tensorflow.python.framework.sparse_tensor.SparseTensor at 0x7f0ea4626a20>}
```",2
I am assuming you are using TF2.0.,2
I assume "cp36" refers to "python 3.6".,2
"I'm not 100% sure, but I assume this depends on how you're _using_ TensorFlow.",2
"I assume that the first 8 tensors are for layer-0, and the last 8 tensors are for layer-1.",2
"By convention, dataflow edges are directed upwards, so that is why the ""dataflow edges"" lack arrowheads - we assume the reader understands the convention.",2
I assume that was a typo?,2
You can't just assume memory usage is going to be the total memory usage of the variables.,2
"I assume just install cudnn v4 without changing anything ,right?",2
"The notebook was running on a GPU with small batch sizes of `32` to keep resource usage low, so when the number of stacked layers increases, there are free resources available to allocate, assuming a quasi-parallel execution.",2
Assuming this was fixed in later versions.,2
Assuming no news is good news.,2
"Since my MWE is reduced to only pandas code without tf dependencies, I assumed an issue in pandas:

* colab uses pandas `0.22.0`
* tf docker container (v1.11.0) uses pandas ``0.23.4``
* my local python installation uses pandas ``0.23.4``",2
I assume it is the same problem.,2
"@jkschin Assuming that `tf.reduce_sum` and `tf.reduce_mean` are now deterministic, are all gradient based operations deterministic too (assuming the same data is passed to the neural network).",2
I assume that you are using a nightly build of TensorFlow?,2
"For example, assume 2 GPUs (GPU0 and GPU1), 100 global batch size, 50 samples in the last batch.",2
"I'm therefore, for now, going to assume that it also works correctly.",2
"If `True`, the method
                assumes that `a` is the second argument in the contraction operation.",2
"Also, we should document that `x` and `y` are assumed to be in standard lexicographic order (and tf.sparse.reorder needs to be used if they are not).",2
"5. 

Finally, the rgb_to_yuv and yuv_to_rgb functions are problematic because they assume a linear, non-gamma corrected RGB color values.",2
"@fchollet, the main author of Keras, decided to remove the lines, I assume he knows what he is doing there.",2
"Assumes we've defined:

- A directory for our working files to live in, CONTAINER_DIR
- an arbitrary integer VERSION_INT
- We have established local and S3 paths for our model and their labels as variables",2
"But I already wrote all that in the initial issue, so I would ask you to please read it again, especially the **Clear description** part where you can see the current code and what I would assume to be the correct demonstration code.",2
"Since the new module is not called ""tensorflow2"", anyone looking at the Beginner's Tutorial might assume that we need to ""pip3 install tensorflow"", which is a good and valid assumption normally for python when trying to figure out modules you need, but that assumption is wrong in this case.",2
"2. I was interested in minimizing memory consumption, and I was under the (potentially flawed) assumption that accessing TF Lite as part of the full package would incur higher memory usage than using the stripped down runtime package.",2
"To be honest I simply went for a large memory size for testing, like 500*1024, assuming this would cover all my needs and worry about getting it smaller at a latter point.",2
"I assume you would need the mean, std, and labels to debug in a way for a more typical trained model?",2
I assume this is part of the problem?,2
"Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089",2
"Hi, the reason why this happens is because tflite assumes that min/max ranges have been calculated correctly.",2
"In TFLite's reduce sum kernel, there is a cast from float->int for latency reasons (assuming that the scales are correct) vs rounding.",2
Could you please refer me to where this casting/assumption on correct min/max ranges is in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/kernels/reduce.cc?,2
Does the assumption on correct min/max ranges hold for all fake-quant layers in the model or just the one that quantizes the input?,2
"Currently TFLite doesn't support any quantized data type with bitwidth less than 8, so even though the fake quant op seems to be working in TF, when converted to TFLite, (with default optimization) it will assume that the requested behavior is to produce an 8bit operation (quantize to 8 bits).",2
"the element_shape is [-1, 4], and this piece of code changes it to [1, 4], which assumes the batch dim is 1.",2
I assume TensorFlow recognizes the used objects in RAM and it prevents further errors.,2
I assume 3 months waiting period for a help is fair :),2
"Assuming you are not exporting the CenterNet model with keypoint output (since you only need bounding boxes), you simply need to disable input preprocessing that happens in the inference code.",2
"Since this input is not a constant, I assume that the Reshape output is marked dynamic in the runtime.",2
My bad - I assumed the same tensor shape is it was for mobile net.,2
I'm assuming this is fixed since @bnoreus stated he would send a PR.,2
I'll give Pete the benefit of the doubt and assume that by xor he meant AES-GCM.,2
My assumption was to create one hot labels based on the id of the row and use that as the label.,2
"In other words, if Slurm already handled port management at the host level, then with `--net=host` it will ""just work"" I assume.",2
I assume it had something to do with the issue I had when I installed normally without Virtualenv.,2
"The current code assumes that you have a shared filesystem between the client and the servers, such as a shared NFS mount (or gcsfuse, if you're running on GCE).",2
"Assuming you have device connected with adb debugging enabled (run `adb devices` to check), you can install it via `adb install -r bazel-bin/tensorflow/examples/android/tensorflow_demo.apk`.",2
"Ah OK, I assumed it was hanging but perhaps this graph just runs really slowly on CPU!",2
"For example, CUDA_VISIBLE_DEVICES=GPU-8932f937 may be a valid way to refer to the above GPU UUID, assuming no other GPU in the system shares this prefix.",2
Closing as (assumed) fixed.,2
This is how I configured the source (I'm assuming you're asking for ./configure options in tf?,2
"As things are today, _any_ op that converts image dtype without range rescaling will _silently_ mess up the assumption that convert_image_dtype() will do your rescaling for you.",2
"Integer types are assumed to be fixed point numbers, so (int8)(255) == (float)(1.0).",2
"So, assuming I decode a jpeg image from the raw file stream, the first function I can think of about image type conversion is `convert_image_dtype`.",2
But I don't think it's a good idea to assume everyone agrees on that.,2
"We've set up TensorForest with the assumption that x,y is used for smaller data sets that fit in memory, and input_fn is used for batched large data sets.",2
"Maybe that's not a good assumption, but in any case this should at least be documented better.",2
"With regards to 3, none of the tensors I was using were empty to I'm assuming there is a discrepancy between the shapes of the inputs used for the non-tensorforest Estimators.",2
"I don't think that's a good assumption for `input_fn`, although that's what I would like to use it for but having issues (see #4026), because it's currently the only method of being able to input tensors to the model.",2
"1. The ""typical"" meaning of sparse, where each example has a few columns out of many that are present and rest are assumed zero or """".",2
The values chosen for candidate_split_features are sampled from a uniform distribution with a max value of num_features as inferred from the second dimension of the input data (assuming we're talking about dense data).,2
"As to `candidate_split_features`, I made the assumption that the parameter I set would be used as the max features; counting the degrees of freedom (embeddings) for each categorical feature gave me 87 inputs, which is correct.",2
"I'm, um, just going to use the existing flag and assume it's someone else's responsibility to make the flag work. :)
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/platform/host_info.h#L25

(static const bool kLittleEndian = true; )",2
"The script assumes that you have cloned and built tensorflow at `/tensorflow`, and can be run like this to copy the headers to `/tf_headers`:

`sh bundle_tf_headers.sh /tf_headers`",2
Interesting -- we should support r3 just fine (assuming you installed it from sources and said cudnn r3 during ./configure).,2
"The Split kernel assumes its inputs are nonempty, and `TensorArrayUnpackOp` doesn't check this.",2
I assume that the model is just too big and random fluctuations in memory use push it over the edge.,2
"However, this assumption fails for graphs, where NaN's and Infs a are expected and later explicitly handled, such as in the implementation of `tf.pow`.",2
I assume this has been fixed in the meanwhile.,2
"The shape inference for SplitV is in [array_ops.cc](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/ops/array_ops.cc#L421) and according to the comment it assumes that the value of size_splits is not known at shape inference time, and hence returns unknown shape as you report.",2
"Note that the code in question does not just _assume_ the value is not known at shape inference time, it is in fact impossible for the C++ shape inference code to inspect the contents of Tensors during shape inference.",2
"Current sanity check assumes that quantized Tensor has same sanity checks as non-quantized Tensor:

```
 dtypes.qint16: _FilterInt,
 dtypes.qint32: _FilterInt,
 dtypes.qint8: _FilterInt,
 dtypes.quint16: _FilterInt,
```",2
From the instructions 'row is the label of the embedding' so I assume my metadata file is correct.,2
"It is possible that having varying-shape variables will lead to e.g. more unknowns in shape inference, which could inhibit some nice optimizations that are possible when the shape of a tensor is static, but I assume you have a reason for wanting to change the shape of a variable, so some amount of dynamism is probably necessary.",2
That seems like intended behavior? (assuming your graph `init` has a dependency on `mode),2
After reading the line number 34 I assume that it's somehow related to the CPU as it states _device="/job:localhost/replica:0/task:0/cpu:0".,2
"@MarkDaoust good to know bazel is not necessary that simplifies a lot, I assumed according to the [code documentation](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/image_retraining/retrain.py#L38) it was though.",2
"@jsimsa I also assume that some serialization happens when you cache a dataset to file:
```python
dataset = dataset.cache(filename='somecachefile')
```",2
Iam assuming that in TF2.11v you want the file `xplane.proto` to be at `tensorflow/tsl/profiler/protobuf/xplane.proto` whereas currently it is at `tensorflow/core/profiler/protobuf/xplane.proto`.,2
Only with these assumptions everything will be okay.,2
"Yep, assuming that's correct, onwards to optimization.",2
"I would assume that once the batch size is determined, the shape won't change throughout graph of BERT.",2
@mihaimaruseac As the patch releases are now out (:rocket:) (e.g. [`v2.9.1`](https://github.com/tensorflow/tensorflow/releases/tag/v2.9.1)) so that there is no breaking with `python -m pip install --pre` and I assume that updates for protobuf are now on some TODO board connected somewhere to Piper,2
I'm going to close this Issue as I assume that in the future sometime we'll be seeing the lower bond on `protobuf` get switched to `>=3.20`.,2
`regression=True` needed to be specified in the `ForestHParams` because `TensorForestEstimator` by default assumes a classification problem.,2
I'm assuming this is resolved now.,2
I assume overhead is somehow associated with putting data on the GPU.,2
"By default, TF assumes it can take over all CPUs.",2
"Sure, I don't see any reason it shouldn't be included, just assumed it was left out on purpose.",2
As the DecodeJpeg Node assumes to be passed as unit8 we cannot simply add the DecodeJpeg as additional input_node_names,2
"In case it's working though, it'd probably be a good idea to include this additional file into the main repo (assuming @guschmue won't mind)",2
I assumed it would work since I thought it was the same compiler as before the upgrade. Also apologies for the slow follow up.,2
Do you have one ? ( I assume you should as you are support person and work with all that stuff day to day),2
"For your specific question in the above comment, in general you __cannot__ make that assumption _if you want to have no false positives_.",2
"If these false positives are something that are not an issue, then please assume `< x.y.0`",2
I assume that `os.environ` is the TF1-style way to do this.,2
"@sayakpaul It looks to me like the keras code would need some refactoring to be able to deal with variable-length labels -- right now, it's assuming a specific rank for its input.",2
"Well, I had thought so, the only major difference was using TFDS, which I had assumed set the label_name field to inform the model of what the labels are.",2
The relevent code is not changed very much so I assume we are having the same problem.,2
"// Let us guard our assumption that only Merge nodes consume the outputs
        // of Switch nodes:",2
"It looks TOCO assumes that merge node is immediately after switch node, but in our models, there are several nodes between switch and merge.",2
"This is rarely what a TensorFlow user would want, but conversely it's dangerous to assume that every int32 would fit in float32.",2
"I'm assume this should be a bug or lack of design in Tensorflow, who   try to run [tensorflow/models](https://github.com/tensorflow/models) on CPU may meet this issue, and I also think this is the reason of #14900.",2
Assuming that goes fine I'll close the issue.,2
"Assuming
> that goes fine I'll close the issue.",2
"A better solution might be to clamp to `[-1, 1]` (assuming `clamp(NaN, [-1, 1])` is still `NaN`), then round (away from zero).",2
This is actually by design; TFP tries to incur as little overhead as possible by assuming the input is "correct.",2
Looks like in that comment they already assumed that TensorFlowLiteC_framework.zip exists and talked about how to get it working with CocoaPods.,2
... I suppose it'd be ok to assume 90 in general if the value returned % 90 != 0.,2
"The new transformations are:
`window` -- which combines elements of the input dataset into windows of (nested) datasets
`count` -- which assumes the input is a dataset and counts the number of elements of its elements",2
@akashjobanputra  Could you share your CMAKE comand .bat file (assume your env is same as above and GPU version)?,2
"But as assumed, `tf.Print()` should do nothing but a `print` operation?",2
# assuming an int32 vector,2
"Toco tries its best to remove what it thinks aren't used in inference, so working with the assumption that only your inference will remain is fair.",2
@LordPython The check is in-place because it was assumed you'd always want to have an input.,2
"Feel free to re-open if it's still an issue when synced after https://github.com/tensorflow/tensorflow/commit/70674b950ab48f913ed1c99e48c4162287595d46

(FWIW I tried in a nightly, and memory usage does fluctuate a bit which I assume is due to buffering, but it doesn't seem to grow over a few minutes)",2
Assuming NCCL header path is /usr/local/cuda-10.0/lib/../include/nccl.h,2
I'm assuming that there is something that prevents you from using `with tf.device`?,2
"I assume that you distilled the repro from a more interesting use case, maybe you can tell us a bit more about the context?",2
"I may be wrong about what this option is meant to do, but I assume it's meant to make `grads = tf.gradients(..)` faster.",2
"@andrewharp Overriding useCamera2API works for TF Classify, sadly it doesn't for TF Detect or TF Stylize, at least the errors are different, I'm assuming they are related to the 'nativeBuildSystem' as well as I get an error log about before the problem, maybe @ArtsiomCh can confirm that.",2
"I dont see the test failure anymore, so I assumed that the fix went in.",2
I assume that is my problem here.,2
"However, this assumes that the sequence_lengths of each example are all the same.",2
"In this case, I assume that the logit for class 0 is 0 and the logit for class 1 is the logit itself.",2
"And the weight need to be reordered before tf.flatten step, assuming from 2D conv layers to fc layers.",2
"@jheymann85, I can reproduce this issue on TensorFlow 1.3 but not TensorFlow 1.4, so I am going to assume it's fixed (although I'm curious what the issue was).",2
"This has always been the assumption in the `SparseTensorDenseAddOp`, but was [not enforced](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/sparse_tensor_dense_add_op.cc#L56).",2
But generating  error: explicit type is missing ("int" assumed).,2
"I do not know if a `shared_name` was intentionally abandoned, but I can submit a PR, assuming that adding a `shared_name` argument to `lookup_ops` is an acceptable workaround.",2
# I assume that keras makes this work properly on evaluation..,2
I have not addressed usage itself yet because I assumed it was due to the balance of loading data.,2
"From the thread above, I assume there is already a solution, wonder when will it be published?",2
@XeMinZa I'm assuming you're on Windows?,2
"The behaviour of GFile is different from Python (on all platforms, I assume).",2
I assume something is going wrong with the path..,2
Normally I would assume that this is a setup issue with my Python installation.,2
"Will try to run some optimizations, assuming I/O is float32.",2
I assume it’s some difference between in the rounding behavior for `np.float32` and `np.float64` on zSystems.,2
"- In pid: ""5"" named ""/device:GPU:0/memcpy Compute"", I assumed that it will only contain memcpy nvidia cuda operations.",2
"However, looping over `[np.float32, np.float64]` might make sense for these tests (assuming the tolerance can be set appropriately).",2
I assume having a token as the return value of the entry computation should be illegal. (Interestingly this doesn't crash the CPU backend).,2
"I'm assuming not, but I want to check.",2
In Python 3 the unicode is considered as UTF8 while in Python 2 a default (ascii) encoding is assumed.,2
"I previously checked out the `v1.5.0` tag, in the assumptions that both point to the same commit.",2
"The benchmark script assumes a batch of images not data streaming in, which is a scenario I hope to have a better example for in the near future as I think it is common.",2
"Because this compilation error happens while compiling a CUDA file, maybe there's a problem with the nvcc version you're using (assuming you're using nvcc).",2
I'm assuming the issue is that TensorFlow does not compile on a 32-bit platform.,2
"Since the 1.5.0 rc page* didn't specify anything about minor versions, I assumed 9.1 was okay.",2
Closer to cutting edge are (assuming you have a GPU): https://ci.tensorflow.org/view/Nightly/job/nightly-matrix-linux-gpu/,2
I assume it shares code with scipy.stats.gamma.ppf().,2
"I think it is important to add to the manual that the fetches are run in ""unspecified order which may change from one run to another, possibly in parallel"" to dispel the natural assumption that they are run in the order they appear in the list.",2
"They're still correct (assuming the original registrations are correct), but there are cases where we could/should do extra pruning or avoid building some extra graphs in the first place.",2
"Assuming we were processing 4.1 inputs per sec now, we can infer that each run increased memory by ~0.17mb.",2
I was assuming it was thread safe.,2
@mingxingtan I assume you mean you weren't able to reproduce the issue?,2
"However, if you create a graph and enter its context we assume that you mean to be adding ops to that graph instead, and we'll do that.",2
"For the method that you iterate through all the layers, you assume the model structure passes data through layer by layer.",2
"I assume `ProcessPoolExecutor` uses `fork()` internally, and forking after the TensorFlow runtime creates internal threads is unsafe.",2
"Once that drops, we'll open up access (assuming there's no other underlying issues still to be discovered).",2
"This would have the advantage that it could in turn be differentiated (assuming you use ops that have gradients defined), and might be easier to implement.",2
"As a side note, since you seem to care about performance, I recommend you build TensorFlow from source with AVX, AVX2, or FMA enabled (assuming your CPU supports these).",2
"Yeah, I assumed the lack of movement here meant it was probably not a trivial fix :/",2
"This is because tfcompile assumes that the data for Eigen is not properly aligned, even though they are.",2
"I assume you'd need more information about the project to help diagnose what the issue is (threading related perhaps?), but I'm not sure what's most helpful to provide.",2
"So, you assume the `malloc` from libsystem_malloc overwrites the `malloc` from libtensorflow_framework?",2
I built tensorflow from master so I assumed I had the latest.,2
I assume this is something for @allenlavoie ?,2
I think it may be because tf.Print somehow forces tensor to load quickly but that's just my assumption.,2
"I can reproduce this on 1.3, but not on master, so I'm assuming its fixed and closing the issue.",2
@bignamehyp I had assumed this was a bug as it seems to be occurring with variables setup inside ‘tf.keras.applications.VGG16’ rather than any I had setup.,2
"@ClaCec The tfdbg tutorial ([here](https://www.tensorflow.org/programmers_guide/debugger) for posterity) doesn't use gRPC, but there's a flag in `debug_mnist.py` for using TensorBoard, so I'll assume that's what you're referring to.",2
I assume we make a bad call to `ShapeUtil::Rank()` on a tuple somewhere.,2
So I assume that either another allocator is used by default now or that the allocation pattern with my test case changed.,2
"So I assume that either another allocator is used by default now
> or that the allocation pattern with my test case changed.",2
"Also, the same issue happens with `tensorflow::ops::Add` (and I assume more ops, these are just those I tested)",2
"Furthermore, after a variable is ""initialized"", it seems reasonable for a user to assume that they can read from and update the variable.",2
"I assume 986591585 is NameHash('rx_ack_buffer'), can you confirm?",2
Since that assumption can explain the strange log events.,2
"Maybe I have some fundamentally wrong assumptions about how memory registration works in verbs, but shouldn't the IB driver pin the memory pages in kernel space, as verbs user space library will send a command in ibv_cmd_reg_mr?",2
"@on-the-run @bobzhuyb, the assumption doesn't make sense to me.",2
@fchollet I assume you are referring to the fixes contained in this pr: https://github.com/tensorflow/tensorflow/pull/13934,2
This is because this function only checks if the command is running on macOS and then assumes the sed that it is running is BSD sed.,2
"If the allocator doesn't release the memory, I assume the new session created when running evaluation won't have access to it (at least that's what I infer from the log messages).",2
"@jsimsa I think this regression crept in at 82fa1e1ae5b2f8af642979fafb1cab455db1882f, which added SparseTensor support, because the new logic assumes that all return values from a map function are either `tf.Tensor` or `tf.SparseTensor`, whereas the old logic had a conversion pass.",2
"Of course, this assumes that `impute_finished` and `sample_id` are not necessary to your task.",2
I'm assuming there's an amount of data where using iterators becomes better but I've not hit it yet.,2
"# NOTE(mrry): I assume you didn't really intend to reinitialize the
  # variable in each call to `mapf()`, and were instead trying to
  # increment it with the `temp = temp + 1` in the original code.",2
I assume the above warning is just a normal warning because I tried in a diffrent ubuntu machine where it installed properly.,2
"I will close for now assuming you were able to build, but please reopen if I have misunderstood.",2
Assuming this worked for you.,2
It is a feature/enhancement not a critical bug so I assume it make take time.,2
I'm assuming this is a Feature Request for float16 in slim.separable_conv2d.,2
Assuming that the answer is yes; please open a new issue if you encounter any trouble.,2
I'm assuming that you are seeing this only on GPUs?,2
"Also of note, this is a really low mem GPU machine, before I found this issue, I assumed memory limits had been reached.",2
@janstrelka : Assuming your issue is the same as what was talked about in #18530 then this means that the CPU you're running on does not support AVX instructions.,2
The existing verbs implementation assumes GPU usage.,2
I'm assuming you built with XLA support enabled?,2
"I assume it's still a problem for the corresponding Pandas input_fn though, right?",2
And similarly throughout the docs there is a very strong assumption that the output of an estimator will always be a single tensor of labels (which is not the case for a multitude of common models).,2
"However, I tend to assume that handling Unicode properly is ""more complicated than you'd think"", so it would be great to get a second opinion!",2
"Asim, I assume you know how the JNI library is built, so can you suggest a solution here?",2
"So I assume it's not there anymore, sorry :(",2
I assume you're trying to use the contrib/mpi extension to TF.,2
In this case it looks like the configuration script can not find the 'mpi_portable_platform.h' file and incorrectly assumes you are using MVAPICH.,2
"Basically it seems to assume everything would be in:
```
/path/to/mpi/include/
/path/to/mpi/lib/
```",2
"I'm going to assume this is the issue and close this, because you said this is only affecting the gradients, which often involve doing convolutions.",2
"Not sure if the `segmented` keyword really matters, but I assumed this refers to the same issue.",2
So I assumed that y=x in the loop_body.,2
This issue is assumed to be fixed by #17455,2
"Got it and it was a bad assumption on my part, tf.TFRecordReader.read(queue, name=None) returns a tuple when I assumed it would have returned just the value not (key,value) which I was directly passing into the example parser. :P",2
"Only suggestion I can think of is to try again with Anaconda 3.5, which is the only Python distribution that I've successfully used to build on Windows. (I'm assuming from the paths in your log that you're not using Anaconda.)",2
"Is there currently a release with this change and if not, which release is planned to contain the change? (I assume the next one but it's nice to have the number for folks who might come across this issue in the future and don't want to cross-ref release dates with comment dates.)",2
@andrewharp Gradle Version 3.3 but Android Plug-In version 2.3.0 (which I assume is what you meant).,2
"Our source code assumes what @prb12 described, so `/usr/lib/x86_64-linux-gnu/include/cudnn.h` is probably constructed by our code.",2
We will need to update our configure script to avoid this assumption.,2
"In basic_saver_restore, I put a module level variable server equal to create_local_server (which I assume creates a child process to run the session right?).",2
So for instance the flowers dataset assumes that the images are [jpg](https://github.com/tensorflow/models/blob/master/slim/datasets/download_and_convert_flowers.py#L145),2
I assume you are asking us to update our binaries uploaded to pypi.,2
"At best, I'm sure Keras is assuming the `axis` to be an integer (i.e. not `floatx`), and from my reading of the source, I'm not sure if it supports an integer `Tensor` there at all.",2
"I'm closing for now on that assumption, but please re-open and let me know if I'm incorrect!",2
"// NOTE: Does not affect the Makefile build target API (yet), which currently
// assumes armeabi-v7a.",2
"As you have them now it seems to be pointing to tensorflow/examples/libs, which is incorrect both because that path doesn't exist (note the ..), and because I assume you meant tensorflow/examples/_android_/libs, which is actually the destination, not the source (which would be wherever bazel/make create them).",2
@jubjamie Ok -- I assume this sort of thing can be cleared up in Android Studio by just clicking to install/upgrade whatever Gradle-related thing it asks you to?,2
Regardless of the `tf.version.GIT_VERSION` I assume that the version number (being .0 not .0.foo) is the stable version?,2
"I assume that you can still see it, even though it was closed?",2
Assume a row-major format.,2
"One potentially simple error msg would be to do a type check within tf.Print itself and echo out a warning msgif instance(list, tuple)...or perhaps if not instance(tensor) (away from command line, can't check if this isinstance(tensor) is supported...I assume it is?).",2
"I'm not exactly sure what you mean by ""standalone c++"" build, but I assume independent of TensorFlow tooling is wha tyou mean.",2
"But these typically assume the inputs have a small mean and variance, typically like `mean=0, var=1` or a uniform distribution on [-1,1] or [0,1].",2
"For example, assuming you're using `tf.keras`, specify the `activation` on the final `Dense` layer to be 'softmax' and then select `tf.keras.losses.categorical_crossentropy` for the loss function.",2
"Checking some assumptions before jumping out there and starting to work on this:
* would you be fine with me taking this on?
* this would essentially be a special case in the body of `tf.nn.softmax_cross_entropy_with_logits` and `tf.nn.sparse_softmax_cross_entropy_with_logits` that is active if and only if `TF_DETERMINISTIC_OPS` environment variable is set?
* to work around this, it should be possible to follow what `tf.keras` does in the non-fused case you mention as workaround above. Seems to come down to computing `tf.nn.softmax` and then following implementation of `tf.keras.backend.categorical_crossentropy(from_logits=False)` ([lines 4636 - 4641](https://github.com/tensorflow/tensorflow/blob/d5b3ec27d1d6bb157588ff3033a3d9bd2e46711f/tensorflow/python/keras/backend.py#L4636)) Does that sound correct? I'll make sure functionality is retained as per the unit tests.",2
I assume the tf.contrib.summary.image does the same.,2
This specific bug seems to be caused by an assumption that only readable files can be seeked.,2
"I do not see any documentation of the `mode` parameter for `tf.io.gfile.GFile` in the [TF docs](https://www.tensorflow.org/api_docs/python/tf/io/gfile/GFile), so I can only assume that the semantics are supposed to be the same as the `mode` parameter for the built in `open()`.",2
"Indeed it was surprising -- Tensorflow'ers probably shouldn't have assumed __doc__ is not None when the codebase was written years ago, but who would have known..",2
"I've tried playing around with these flags - this still doesn't explain how the Java API performs much faster comparing to the C++ API, when Java is just a wrapper for the same C++ code (which I assume initializes the GPU delegate with default settings).",2
I think this behaviour is quite confusing for users since I don't think it is documented anywhere in the Keras to TFLite conversion docs and breaks with the assumption that Keras model outputs are ordered which as far as I know holds true anywhere else in the code.,2
"I would assume other types of remote file system such as s3 (AWS) or azfs (Azure) should work as well, as long as the TF version you use support the scheme (e.g, `s3://bucket/object`, `azfs://...`).",2
I assume this is for TFLite module and not GPU Delegate.,2
"and due to a bug in the GPU IR, it is not possible to declare an intermediate tensor as a graph output for GPU delegates (it was a bad assumption, but it's not trivial to fix).",2
"> and due to a bug in the GPU IR, it is not possible to declare an intermediate tensor as a graph output for GPU delegates (it was a bad assumption, but it's not trivial to fix).",2
I'll just assume that TF 2.3.1 has some strange warning message and that there is nothing to worry about.,2
"Can i use the Coral Edge TPU on a custom imx8 based board by Toradex, assuming i can build yocto linux (with tensorflow and Edge TPU driver support) for this platform ?",2
"If we clock at half the maximum speed, i am assuming the inferencing delays will be doubled.",2
# Assuming we named it in the original model as 'result' we can then pass it here.,2
Neither of the linked issues seem related to this which seems to happen due to some assumptions that Keras makes when compiling a static graph,2
3. Assuming I was able to keep control of the IPython session.,2
"- https://www.tensorflow.org/alpha/guide/autograph doesn't have a mention of this (and has a nice ""Use Python control flow"" section, but lacks a ""BUT DON'T USE PYTHON VALUES"" section;
- https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/LIMITATIONS.md doesn't mention this either, and yes I can see it contains a different kind of table, but it is linked to by the tf.function tutorial as ""Capabilities and Limitations"" of tf.function and AutoGraph, and one could assume it is a fair summary of gotchas -- it isn't;
- The RFC https://github.com/tensorflow/community/blob/master/rfcs/20180918-functions-not-sessions-20.md mentions the idea of a warning when too many traces are created, but I don't think the warning exists yet.",2
"I mean, C eventually adopted ""restrict"" as an explicit keyword, after three decades of ""we'll just make silent and subtle assumptions about memory aliasing and break shit – developers will just get it right, after all we have a footnote about this"".",2
"However, the check of the initializer always assumes the initializer is 1.x:
https://github.com/tensorflow/tensorflow/blob/a2f7f39d982682fa8de050e001522581570c510f/tensorflow/python/keras/engine/base_layer_utils.py#L124-L128",2
I assume you want to create metric object and use it with add_metric API?,2
"When the addition is inside the `res_net_block`, the `encoder` simply stacks one layer on top of another and is essentially a sequential like model where we can safely assume that each layer in `model.summary()` is connected to its previous layer, hence `Connected to` column would be redundant, whereas if addition is inside `encoder` it deviates from simple sequential like structure and `Connected to` column is necessary to know inter-layer connectivity.",2
"I had assumed that once initialized, its value would not change when the graph is reevaluated.",2
"From this I assume that the bug is not in `network._map_graph_network` function, but somewhere in the construction of the graph.",2
"* I'm passing `step=0` to avoid modification to the signature of `train_step()` as in your example, which I assume involved other modifications to the callsite",2
I assumed setting the data format explicitly would force TF to use it with cuDNN.,2
Am I right making that assumption?,2
"I assume it would make sense to test specifically for IndexedSlices only, and perform the same shape check as in the case of tf.Tensor?",2
The current Tensorflow implementation assumes `gast==0.2.2` but doesn't lock in the version.,2
I only use one Session created with TF.NET and I run it once so I'm assuming I only have one TF runtime.,2
"I only use one Session
> created with TF.NET and I run it once so I'm assuming I only have one TF
> runtime.",2
"- My operating assumption is that the GPU kernel for summation doesn't have the same numerical instability issues due to a different implementation, and thus didn't result in truncation (or perhaps only did so at much higher counts)",2
"So if you have a machine that has 4 GPUs, it's going to complete the forward/backwards passes on the data in a particular step faster than the machine with 2 GPUs (assuming your data is evenly distributed across the machines).",2
"All of the casting / pre-processing (I assume) is done via the DataLoader class, and it seems it is casting audio data to int32 instead of float32.",2
~i assume this will not require much disk space to write to the log for tolerance?,2
So I assume the problem is in the code.,2
I assume the issue could be fixed with PR #29017,2
So I'd assume that this is not related to the version.,2
"To be more specific: I expect a dataset to know its size and provide random access to its elements where this is possible (and I assume for most datasets it is possible as they use images, videos or whatever files or lines which can be counted and ordered first, I even thought TFRecord files were made for that).",2
@grofte am I correct to assume that you would want the functionality of `return_shuffled` to be equivalent to `cache().shuffle(buffer_size=NUM_ELEMENTS)` while avoiding the extra buffer that `shuffle` introduces?,2
"I would assume that if the first three indices were 100, 3, and 2000, then you would need to read 100 elements to get the first results, and then either 0 (if the read elements are cached) or 3, and then either 1900 (if the read elements are cached) or 2000.",2
This is based on the assumption that all operations in keras.model or keras.layer should not touch the batch axis.,2
"3. Note, the above build generated `icudt64b.dat` for me( **single letter following the version number in the file name was **b****) so assuming it generated correct format data, I tried using this data file directly in TensorFlow, however test failed with `InvalidArgumentError: Could not create converter for input encoding: shift_jis`",2
">    3. Note, the above build generated icudt64b.dat for me( *single letter
>    following the version number in the file name was b*) so assuming it
>    generated correct format data, I tried using this data file directly in
>    TensorFlow, however test failed with InvalidArgumentError: Could not
>    create converter for input encoding: shift_jis",2
I assume you're not using it on a mobile device.,2
"This is very relevant for our security posture, and for other security-conscious TF users as well, I'd assume...",2
# meta file from main net (assuming all nets have exactly same architecture),2
"It seems that these tests require `bias_data` to be in Little Endian format and is handling data accordingly while for `hello_world_test` and micro_speech_tests, `bias_data` is being used in calculation assuming that it's in BE format and hence, it's messing up the calculation of `acc`.",2
"I assume this because we also have an own native LSTM implementation in our framework, which does exactly the same matmul call as LSTMBlockCell, and we see the same problem with that.)",2
Note that I am assuming that the problem is not related with the library version.,2
"If my configuration all exceeds the minimum, I have to assume that the problem is related to GPU driver version and CUDA version.",2
"I assume you meant ""upgrade to a stable version of python"", and it does ondeed only seem to be a problem in python 3.8.0b4.",2
> I assume you meant "upgrade to a stable version of python",2
Could you explain what that file edit does / why that patch works (I'm assuming somehow tricks auditwheel to thinking the sharedlib is a common one on all systems)?,2
I assumed that we were expecting a *multiplication in double precision* - as the quantized multiplier is essential.,2
I assume is there a flag I am missing when I am building from source?,2
Otherwise Keras assumes that your model is able to take symbolic tensors (and uses this for shape inference) even if you've asked it to compile in eager mode.,2
I assume you did more than just simply subclassing because propagating the init via a super-call shouldn't make any difference.,2
"It is assumed that `fn` has at least
        one concrete function and that the inputs are in the first argument.",2
"Given that `get_concrete_function` joins the Python variable name (`inputs` in this case) with the name of the input (`first_feature` or `second_feature`), I wonder if there is a way to mark the correct concrete function from which to infer the inputs when saving the Keras model instead of just assuming the first one or otherwise remove the Python variable name.",2
"The following loop assumes the dimension of `begin`, `end` and `strides` are same, but in my case, dimension of `begin` and `strides` was `3` while dimension of `end` was `1`.",2
"I assume you mean me, as @TuringEmmy is not the original author of the issue.",2
If the  sparsetensor is created before the dataset.map I hit the limit (I assume the map traces the function and injects the eager sparse tensor into the graph.),2
"@sachinprasadhs Yes, that is true -- the warning is caused by the source snippets above, which are marked with `TODO(b/156447398)`, which I assume is some internal bug tracking number.",2
"That's helpful, but still doesn't solve this issue - am I right to assume then that `MirroredStrategy` cannot be expected to work correctly with eager execution disabled, and that the `InvalidArgumentError` is to be expected?",2
I (incorrectly) assumed that `losses.softmax_cross_entropy` may have moved to some other location in the tf2.0 api.,2
"If left unconfigured, each worker assumes it is the leader and waits for a message from other workers in the group.",2
"Also I assume you are doing `interpreter->AllocateTensors()` when using C++, before any invoke?",2
"I would have thought that `st.dense_shape` should be something like `(input_shape[0], input_shape[1]` where `input_shape = tf.keras.backend.shape(y_pred)` (assuming you add this line before the transpose at the top of the function).",2
"But this causes the first assertion in the associated test (see below) to fail because it assumes that the output has not been padded with -1 values, which seems incorrect to me but I'm really not sure.",2
"Assuming Grappler doesn't just prune this operation out, it should theoretically force an ordering on both the forward and backward pass, because `x` actually depends on `y` numerically and therefore the gradient of `y` should wait for the gradient of `x` to be calculated.",2
You are doing text classification with a 2D input tensor (that's what I assume from the error message; I haven't generated or taken a look at the .tflite model).,2
"If you guys are interested in the fate of these metrics, please join addons@tensorflow.org for the Addons SIG, where metrics like this may end up (assuming there is someone who wants to migrate and maintain them).",2
":param is_time_consistent: bool, if true it is assumed that the graph does
                not change over time",2
"I'm assuming this has been resolved by the same answer as for 
https://github.com/tensorflow/tensorflow/issues/35107",2
Due to `gradient_tape` and `Conv2DBackpropFilter` I assume that this should be related to the gradiet computation and the backward pass.,2
"If False, we assume that the layer can safely be used to generate a static computation graph.",2
"Assuming this is a quirk of the Keras specification, it is probably also not realistic to tighten up the requirements for array input to match that of dataset.",2
I assume this is a parser or quantization bug.,2
Is it safe for me to assume that Option 1 works just as Option 2 provided the inputs are same?,2
# Assuming we have a single output,2
"Given the TFLite GPU's background of running things as efficient and as fast as possible, it didn't consider batch sizes, or rather, was assuming everything would be running on batch size 1.",2
"Looks like something to do with the optimizer, but it should tell me when this happens, because otherwise (until this experience) I would have just kept assuming it was working.",2
Assuming that has made it to the nightly - could @lgeiger could you try the nightly and see if this has been fixed for your use case?,2
That should have minimial overhead assuming epochs take at least a few minutes.,2
"So, assuming the model is dequantised correctly, shouldn't it work the same way as a ""pure"" floating point model works, with respect to delegates?",2
I assume that's the only reason they're giving different results.,2
"Logic in `to_tfrecord` (below) assumes it's a dataset yielding `dict`s, but can be modified to suit tuples as well.",2
Logic in `to_tfrecord` assumes it's a dataset yielding `dict`s.,2
I had just assumed that `Saver` would be present in 2.x.,2
"Yes, I assumed that it is not a bug, but rather more unexpected behavior/missing documentation.",2
Assuming that the normalization is in the range of 0.0-1.0 as,2
The easiest way to understand why is to assume that dataset construction is "by value".,2
"Assuming y_true is 0 or 1 (reject or accept) and score is the cosine similarity in the range [-1,1]
`-( y_true*log(sigmoid(w*score-b)) + (1-y_true)*log(1-sigmoid(w*score-b)) ) `",2
"I would assume training=True will always consume more memory, due to dropout (unless XLA optimize away the dropout mask)",2
"However, the lazy loading approach we're using assumes read only modules, we cannot add new attributes.",2
"- Finally, if `Model.fit` is just given a bunch of examples without any other clear signal, the optimizer has to assume that this is a fresh model starting from step 1.",2
"I assume Tensorflow has some sort of global thread pool, but a) it does not handle `DllMain` events or any other resource management mechanism to automatically close the thread pool when no external reference to Tensorflow exists, and b) it offers no way to manually close the thread pool from the public C API either.",2
Maybe we can extract out a test case for cuDNN that demonstrates this issue (assuming TF is using cuDNN correctly)?,2
"I assume I'll have to port forwards again then, hoping that this is fixed by then.",2
"Moreover, I found that in tf.function mode, as long as len(axis) = len(input_tensor.shape), tf.math.reduce_sum, tf.math.reduce_mean will ignore the actual value of the axis argument and reduce all dimensions of the input_tensor, which is a wrong assumption without checking duplicate dimensions in axis.",2
I am assuming the input to the graph has a valid shape.,2
"It failed two times in a row at about the time evaluation must have started, after which I have switched to training without evaluation, so I assume it is reproducible.",2
"I install all dependencies using conda, assuming it will figure out correct versions of packages.",2
"Also, I'm assuming [you followed the instructions here](https://github.com/ethanyanjiali/deep-vision/tree/master/YOLO/tensorflow) to download the data and run the training script?",2
"The ticket is about what happens when an error (violated assertion and I assume it happens for other errors as well) happens in a pipeline that specifies `tf.data.experimental.ignore_errors()`, which is about ignoring exactly those errors.",2
The script currently assumes that import has the form "import tensorflow as tf".,2
"I think the only outstanding task was adding a note to documentation. Just checked our documentation here: https://www.tensorflow.org/guide/upgrade has this sentence:
""The script assumes that tensorflow is imported using `import tensorflow as tf.`""",2
"I tend to disable eager execution under the assumption that this improves performance, but perhaps that isn't the case anymore?",2
This assumes that your machine has 2 available GPUs.,2
"After digging into the code 
https://github.com/tensorflow/tensorflow/blob/14246bd0280d1c5e5564eedd4927bf9af9339967/tensorflow/python/ops/image_ops_impl.py#L4307
, it turns out that the implementation assumes the input data has a shape of `(batch size, h, w, channel)`.",2
"It simply assume the input data has only 1 batch with a shape of `(h, w, channel)` and continue with the calculation.",2
"@zachmayer

Shoot, when I fixed it for predict, I added tests for predict assuming that there were tests for fit __somewhere__...",2
There's still some kind of interface between that library and TF I assume.,2
This assumes that the layer will later be used with inputs that match the input shape provided here.,2
"In some cases, .fit is more restrictive, as we can't make assumptions about incoming data.",2
"edit: I should add that this isn't a problem for me (it was easy enough simply to rework the code to build the entire graph before using the `Session`), but I filed in the issue because I assumed that the error indicated some underlying issue that needs to be fixed.",2
There was a bug in my test that made me assume it was.,2
"So I assume this image is using the `Dockerfile` [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/dockerfiles/dockerfiles/devel-gpu.Dockerfile) in the tensorflow repo, so it uses the master if I'm not wrong looking at the contents of the Docker file [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/dockerfiles/dockerfiles/devel-gpu.Dockerfile#L87):

```
# Check out TensorFlow source code if --build-arg CHECKOUT_TF_SRC=1
ARG CHECKOUT_TF_SRC=0
RUN test ""${CHECKOUT_TF_SRC}"" -eq 1 && git clone https://github.com/tensorflow/tensorflow.git /tensorflow_src || true
```",2
Yes I assumed that the bazel config would do this automatically when using the bazel wizard.,2
"Hi @impjdi,
The two pre trained models (512x512, and 640x640) in the first device (RK chip) worked on GPU, I am assuming this because the interpreter time dropped almost by 50% (from 1.2 seconds/frame to 0.6 seconds/frame) and the output was correct.",2
"The build.gradle file should handle all of the building for you, assuming you're running on Linux.",2
You should just need to update the values in ClassifierActivity.java to point to your retrained graph assuming you have Bazel installed correctly etc.,2
I'm assuming that the C++ API is the most commonly used one internally at Google (ignoring Python for a second) and maybe the C API was developed mainly for porting purposes (eg. more support with a variety of compilers and easier integration across more languages and platforms)?,2
"I am assuming a default tensorflow install, if you are custom compiling please let me know.",2
The underlying assumption in TensorFlow is (approximately) that you'll build a graph once and then call `sess.run()` on (various parts of) it multiple times.,2
I feel this is related to this line in TensorImage.class by assuming the channel size is 3,2
"Regarding `ImageConversions.java`, I see I have to modify this method https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/experimental/support/java/src/java/org/tensorflow/lite/support/image/ImageConversions.java#L90 regarding couple place assuming that size is (w, h, 3).",2
"I believe there is now the ability to read batches from a reader that can reduce overhead, assuming there is no problem with the examples having different dimensions.",2
"> I believe there is now the ability to read batches from a reader that can
> reduce overhead, assuming there is no problem with the examples having
> different dimensions.",2
I'm assuming that this is checked in.,2
"# Assuming model_checkpoint_path looks something like:
        #   /my-favorite-path/cifar10_train/model.ckpt-0,
        # extract global_step from it.",2
"# The global step variable used by the optimizer (in cifar10.train()) 
# and I assume by whatever is using the Saver object (and more?).",2
"# Assuming model_checkpoint_path looks something like:
>         #   /my-favorite-path/cifar10_train/model.ckpt-0,
>         # extract global_step from it.",2
"Currently tensorboard still requires tensorflow to be importable, and if you want to generate a file yourself I assume you also need to use tf.summary?",2
"TensorFlow doesn't do dropout inplace to my understanding, so in the worse case scenario, it can use double the memory (assuming you place dropout everywhere in your graph).",2
"In my case, using :

`Keras.backend.clear_session() `

right after I am done with a model and before calling or instantiating a new one solves the problem (assuming a single model runs well without issues).",2
"> In my case, using :
> 
> `Keras.backend.clear_session() `
> 
> right after I am done with a model and before calling or instantiating a new one solves the problem (assuming a single model runs well without issues).",2
Actually I compiled the source code from master branch and assume it should be the latest version of 0.11.,2
"For complex number applications, I assume we have to explicitly declare the `dtype` of the input so that we don't run into this problem?",2
"I assume the CVNN library might be using floats to construct complex numbers, in which case you will need to deconstruct the complex number and call `tf.complex`.",2
# Assuming data has is the parent directory of images,2
"Assuming from your :+1: that the upgrade solved your problem; if not,
please let us know and we can reopen.",2
"Assuming you are using the Android demo code [here](https://github.com/tensorflow/tensorflow/tree/e39d8feebb9666a331345cd8d960f5ade4652bba/tensorflow/examples/android/src/org/tensorflow/demo), yes, that looks approximately right.",2
"I'll close this, assuming this is a problem with your installation.",2
I assume you are storing interpreter in a std::unique_ptr so that interpreter=nullptr doesn't leak.,2
"Given that this bug is quite old without updates, I assume the OP solved the issue by him/herself and will close the bug.",2
"Assume have a savedmodel format model,how to know if the savedmodel supports batch input and dynamci length input?",2
I'm assuming that [this question on Stack Overflow](http://stackoverflow.com/questions/36055090/zlib-error-error-3-while-decompressing-invalid-distance-code) is related.,2
I assume the generate function can generate data now but the datatype may be wrong.,2
rnn() assumes your cell is not stateful.,2
"Assume that `y=tf.matmul(input,W)`; if `W` is a dense matrix, then `tf.gradients(y,W)` returns a dense matrix.",2
I assume this happens because `sparse_W` is not considered as part of the graph and the gradients of `y` with respect to  `sparse_W` become `None`.,2
The doc is assuming you're using "strategy.experimental_distribute_dataset" which does the batch splitting for you.,2
"Using TensorFlow with other frameworks is a bit tricky, since there are many places assuming it has exclusive access to the GPU.",2
So I wrongly assumed that loading worked.,2
"I suppose the assumption was that proto->ParseFromCodedStream would return false if the file wasn't found, and then the CHECK on ReadFileToProtoOrDie would catch that.",2
You're also getting a suspiciously fast 7ms initialization time so I'm assuming it was a problem loading the graph.,2
Therefore I assumed that `fit()` as well was able to infer the `steps_per_epochs` from a `Sequence` and indeed until TF v2.1 it did!,2
"I assume when I went back to the CPU only without a fresh install, some of the old GPU code was not erased but found when the experiment ran.",2
I noticed the RunMetadata has format changes that break tfprof's assumptions.,2
"However, if some of the inlined functions are not inlined and instead turned into exported symbols implicitly, the dso loader will attempt to share one symbol with both libraries which will not work (it will assume the wrong structure layout).",2
@xuehanxiongsc I'm assuming that's when run on your Mac?,2
"Assuming a CUDA 7.0 device, how we can tell bazel to build the android demo with GPU support?",2
"If you just want to get on with your other task, override the kUnknownNumaNode value (-1) being returned with 0, and the rest of the system should work ok...assuming that TF is actually accessing the correct GPU.  (Notice that for OS/X that's exactly what happens in TryToReadNumaNode().)",2
"Everything down to cuDNN assumes rectangular tensors, and uses this assumption to arrange for high arithmetic intensity.",2
"@nbro You can follow the steps I described above to use `tf_upgrade.py`, assuming you already have TensorFlow installed on your system.",2
"@vanpersie32 calling `your_tensor.set_shape(...)` should do it, assuming you know the expected shape of the tensor.",2
"In any case, the current behavior allows both python objects and tensors, just not mixed - I assume this is done with an implicit call to `convert_to_tensor`, so any improvements to `convert_to_tensor` should carry over to all its use-sites.",2
">  In any case, the current behavior allows both python objects and tensors, just not mixed - I assume this is done with an implicit call to convert_to_tensor, so any improvements to convert_to_tensor should carry over to all its use-sites.",2
"So this implementation assumes that the tree is known a-priori, doesn't it?",2
"You're right, this example does assume that the tree structure is part of the input.",2
"The particular model in the Socher paper that generates trees can be implemented with Fold, because the shape of the computation graph is a function of the input data (I'm assuming here that the terminals and adjacency matrix are provided as inputs to the model).",2
"Our policy is that until it is documented, assume it is private and not ready to be used.",2
I think for now it is safe to assume that there's no way to create `Variable`s in a `function` (I'm also confused by the test-case you sent),2
"Let's assume that the output of 'conv_3x3a' is `[a, x, b, x, c]` then 'conv_1x1a' is going to skip all the 'x' due to stride=2 and going to produce `[a2, b2, c2]`.",2
I assume you're following the instructions here: https://www.tensorflow.org/versions/master/experimental/xla/jit ?,2
"3. As the stewards of tensorflow, I assume google has, and they may want to use their own googley options and may want to use them. :-)",2
The Dockerfile will assume those files are available locally (which is the missing `cuda/` path you spotted).,2
"For the lost souls that end up here, the reason why this was happening is that I (wrongly) assumed that the Bazel repo for `apt` would work just fine for Ubuntu 18.04, but it did not (and severly, too).",2
These instructions assume that cuda libraries are available in `/usr/local/lib64` which is typical if you install cuda with the default options.,2
"I assume when you take the SVD you're not sending the
full U, S, and V matrices back but something smaller.",2
"looks like I have a cuDNN problem too, but that was present already and I assume it is unrelated.",2
"Considering how one of the frequently mentioned advantages of TensorFlow Lite (interpreter) over XLA (compiler) is that you can update models without changing app code, I assume the intention is to require a file system.",2
I'm assuming this can be closed since #1691 is merged now.,2
"Apologies, I (wrongly) thought I knew more about C++ than I actually do, and assumed this was indeed a typo.",2
"Assuming the `sess.run([key, image])` does not run in a distributed setting, tfdbg (TensorFlow Debugger) should be able to help here. (tfdbg supports only `DirectSessions` right now; support for distributed session is in the works.)",2
"Given the information in the commit and the related internal bug report that this fixes, I'm going to assume this is now fixed.  Please reopen if this is not true and you are running a recent version of TF.",2
So I assumed is on his side.,2
"Assuming for a moment that we wanted to make this change, there are two things that worry me.",2
"> (Sorry for my English.) I have another problem with random initializers,
> but don't want to create a separate issue yet: Until now I assumed that
> tf.get_variable() by default initializes with zeros (
> tf.zeros_initializer()) and just now was really shocked that it seems to
> use tf.glorot_uniform_initializer(), which is not documented in the
> section for tf.get_variable().",2
"But tf.glorot_uniform_initializer() seems to make
> assumptions just based on the shape.",2
We disable fail_fast on the RPCs so gRPC will retry until it gets a response... this means that if a process fails we assume something (e.g. a cluster manager like Kubernetes) will restart the process for us.,2
"I also made a mistake in the documents and when you start the PS server you want to do this, which I assume you likely already know.",2
I'm assuming this is fixed. Please reopen if this isn't the case.,2
"I'm no expert on Bazel, but I assume it's because that it is using an android toolchain when the root target is an android_binary target.",2
I will assume in_channel = out_channel since many modules (layers) in deep architecture has such config.,2
I believe this is correct and I will continue to work under that assumption.,2
"I believe this is correct and I will
> continue to work under that assumption.",2
"@HggsHntr Please do let me see the error log as if no autotune is involved, there shouldn't be any profiling so I assume the error must came from a different place instead of cuda_timer.cc.",2
"Closing due to lack of activity, assuming this has been fixed by installing the correct cudnn.",2
"On a Titan V, I get 16.7 seconds with float16 and 43.2 seconds with float32, so I'm assuming this has been fixed.",2
"On further reading I probably could have assumed this from reading the tutorial, but maybe worth clarifying in the paragraph on ""Custom Training Data."" (Here's the tutorial I'm referring to: https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/audio_recognition.md).",2
# assuming we want to be working within ~/tensorflow,2
I assume you're referring to the tutorial [here](https://www.tensorflow.org/get_started/estimator#load_the_iris_csv_data_to_tensorflow).,2
"I assume that some of this (especially the second one) is part of XLA, but in general, many of this is part of the graph optimizations.",2
"I assume the concatenation in `predict()` will not go away anytime soon, because it's what's sensible in 99.9% of cases.",2
"2. **Stateful** is mainly for fitting a _single sequence_ in separate consecutive fits; that is, inputs are assumed to _causally continue_ from their predecessors.",2
"2. **Improved inference-time performance**; for `t` timesteps, assuming a favorable case of all gates being equal to 1 to preserve the hidden state, the hidden state vector at time t, `h_t`, under paper 2's recurrent transformation, is 

![image](https://user-images.githubusercontent.com/16495490/72905379-e4dfca80-3d49-11ea-9c68-8b0af3caacbe.png)",2
"Hi @zampnrs  in your code

""getBuffer: 
let status = CVPixelBufferCreate(kCFAllocatorDefault, Int(image.size.width), Int(image.size.height), kCVPixelFormatType_32BGRA, attrs, &pixelBuffer)""

you're assuming input image is kCVPixelFormatType_32BGRA, which is not always true, sometimes you may got a kCVPixelFormatType_32ARGB image, suggest to debug from here.",2
"I was assuming that I could do that with the existing graph easily, but it looks like you currently need to create an alternate graph to do that.",2
TensorFlow design today is fairly tied to the "there is a single compute stream" assumption.,2
"Assuming you create the graph yourself, calling `as_graph_def(add_shapes=True)` will add that information to the `GraphDef` so that you can restore it when it is imported.",2
I assume its not a CNN :),2
On K80 and I would assume this is also true for K40 even if peering is turned on nccl is often slower due to the sync calls ending up being other work in the thread.,2
`tf.data.Dataset`s don't use this argument bc they are assumed to be batched already.,2
"> But assume I'm getting the derivatives of the loss w.r.t. final_layer from
> an external source (e.g. a tf.placeholder named _deriv).",2
Though I assume it will be in the future to have consistent behavior with other initializers.,2
"I'd probably stick with tf.float32 [here](https://github.com/tensorflow/tensorflow/pull/17652/files#diff-85e323da48079f7831b7e9f6ec24cda2R655) for consistency, despite not matching NumPy, especially considering how the vast majority of TensorFlow users assume single precision floats (e.g. for GPU model training).",2
Actually it may not be a bug because TF is somewhat forced to assume first dimension of predictions is batch dimension.,2
"The documentation for the function calls out that if the `memory_layer` is None, the memory should assume the shape of the `query_layer` and vice-versa.",2
"Ah, the ""epsilon hat"" vs the regular epsilon is what I was missing (though ""epsilon hat"" is never defined that I can see, I assume it is a scaled version).",2
"I'm going to assume this is fixed now, and close the issue.",2
"Also, the error message suggests you should report a gcc bug, so I am assuming this is a gcc bug.",2
"I suspect this may have to do with code in Keras that assumes keras objects are created in the main thread, which is not the case when running in spark udfs.",2
We assume that prediction is a value between 0 and 1 and labels are binary ie. 0 or 1.,2
"With these assumptions cosine similarity will be in positive space - [0, 1] and the loss function will be in [-1, 0].",2
"If it's not causing you an immediate problem, then I assume there's no great urgency here?",2
"I see, you're assuming your targets to be 0/1, where as usually, people are using -1/+1 labels when speaking of the logistic loss.",2
"Assuming the toolkit is installed in /usr/local/cuda, run the following commands (edited to reflect the cuDNN version you downloaded):""

which should illustrate that you might need to edit the version.",2
There's no built-in API for shutting down a TensorFlow server remotely; the assumption is that whatever mechanism (e.g. a cluster manager) you used to start the processes would also kill them after the job completes.,2
"I might be doing something wrong, but since the documentation suggests 'tf.contrib.keras.datasets.mnist' as the module name, I assumed that I import it by 
```python
import tensorflow.contrib.keras.datasets
```
but that didn't work.",2
"Hi @bjourne, as @ymodak mentioned, when using TPUStrategy with keras, the input dataset is assumed to be batched by the global batch size, and each batch will get divided across all the replicas.",2
"Assuming the above addresses your problem, I will close this issue - feel free to reopen if you encounter problems further.",2
I assume you mean L132?,2
So assume the above function is defined in a library.,2
"I completely misunderstood your point, for some reason I assumed you meant checkpoints.",2
From your comment I assume that I need to add a build target with both `android_tensorflow_lib` and `c_api` to build those?,2
"Since I assume you want the same behavior in both, could this be changed to use \copydoc from doxygen to avoid having to put the docs in two places?",2
The proposed changes relies completely on input_shape which we are assuming that output_shape also being same as input_shape.,2
"In the meantime, let's assume that it is **not** the issue and i'll give you my answer for users of cuDNN 5.1:",2
"Consider the following 3 operations in sequence:
   x = add(a, b)
   y = add(x, c)
   z = add(y, d)
assuming, a, b, c, d, x, y, and z are of the same shape, and x and y are
not used before the 3rd operation.",2
I asked this question here assuming that if it is not possible to simply convert MobileNet to tflite (which which is designed for it I believe) this might be a bug.,2
"When running `dynamic_rnn`, it is assumed that the inputs' max_time dimension is the **maximum number of frames in your minibatch**, and can vary from step to step.",2
"For anyone else who runs into this problem, using the example above with the assumption of 3 Dims:
```
decoded_image = tf.image.decode_image(encoded_image_data, channels=3)
decoded_image.set_shape([None, None, None])
resized_image = tf.image.resize_images(decode_image, (800, 600))
```",2
I couldn't find format of colocation groups documented so just assumed they are in the form `_class: loc:@opname` and it seemed to work,2
"I try replace *tf.train.batch* with *tf.train.shuffle_batch* and set *min_after_dequeue=10000*  to avoid queue starvation (I assume this parameter help fix it, right ?), but my program as slow as before.",2
"First I tried using `convert_to_tensor` but I assume this would not work well with sparse arrays so I started exploring using the SparseTensor, however looks like transforming the data into a SparseTensor won't help much since it cannot be fead to the RandomShuffleQueue.",2
I assume that `b/31222613` is a reference to some internal Google bug tracking system?,2
Assuming it doesn't break any exisiting tests.,2
"We use environment modules and apparently that doesn't fit seamlessly with bazel's assumptions about its environment, necessitating a special bazelrc on every run, which I had left out.",2
"I just saw a Kaggle competition for TensorFlow 2.0 so I'm assuming they'll either see this performance issue there or if not, there's something we're doing wrong..",2
"It assumes that you have basic familiarity
with TensorFlow programming concepts such as the computation graph, operations,
and sessions.",2
Closing this on the assumption that @xiejw's answer solves the original problem.,2
If I don't hear back I'll assume this was resolved.,2
"I didn't use any deprecated APIs, so I'd assume that that's the problem, if it is indeed incompatiblity.",2
I assume my errors are related with CUDA configuration.,2
I am assuming that either gcc-5.4 or Xcode 8.2 bundled version as this is what CUDA 8.0 supports.,2
I'm assuming this is what will be updated?,2
"Since the code is there, I assume it's supposed to work.",2
"I had assumed the goal of SKCompat was to be compatible with scikit-learn, but I can see that is not the case.",2
"I assume it's getting called either from tensorflow or cv_bridge, so would the best way be to find the actual `tcmalloc` function call and change it to `malloc`?",2
I'm assuming this is a duplicate of #3603,2
"I assume this problem might be related to enviroment , for in another machine (centos 7)  and training from scratch(step 0) I never face this nan issue.",2
"If I explicitly assign the GPU, I get the ""no kernel found"" error, but I'm seeing posts on this thread discussing the speed of GPU calculations, so I have to assume some release of tensorflow has SVD GPU support?",2
Your benchmark assumes a single large SVD operation as a use case.,2
"I assume, fold_constants can be a safe bet to get graph working on hexagon once after fixing the instantiate graph part.(Comment? if you have anything to say)",2
I assume it is reducing the order of matrix from 3 to (3-2),2
It is an assumption that it is fixed there as well,2
Did the XNNPACK version worked fine for you? (i assume so from your previous comment),2
"If I am interpreting your issue correctly, I assume you mean the [howto].",2
"In general, the `tf.train.Saver` code assumes that the worker and parameter server jobs share the same filesystem.",2
"In general, the tf.train.Saver code assumes that the worker and parameter server jobs share the same filesystem.",2
I'm not fully convinced we have enough information to assume this isn't a bug...,2
"It's just that protobuf assumes it will be there, so I had to add a workaround to tensorflow/examples/android/BUILD.",2
Assuming it was fixed :),2
The pip package at 0.7.1 is built assuming you have cudnn r4.,2
channels (int): how many channels the image is assumed to have.,2
"The author of that post also posted here: https://github.com/tensorflow/tensorflow/issues/1511 but she received instructions to go to stackoverflow, which I assume resulted in the first link.",2
"FYI I'm pretty sure this is achievable with https://github.com/uber/horovod in combination with a standard SLURM launch shell script, assuming all the proper software is installed.",2
As far I understand for **x64** - msvc assumes SSE and SSE2 for its own optimizer but does not set `__SSE__` or `__SSE2__`.,2
For SSE4 it should be save to assume to be there if AVX is there.,2
sse and sse2 are 'implicit' set for x64 and tensorflow (eigen) assumes sse2 for x64 on msvc.,2
"Not sure how to fix this the correct way, maybe setting   `__SSE2__ , __SSE__ `  in cmake would be ok since everybody is assuming SSE2 is set for x64.",2
Fort 08 assumed shape: yes,2
"Let's assume that, someone saved the model, for me, I don't know what's the exactly input or output segment is, in this condition, how can I get the result?",2
"Btw, I assume it is feasible that I load the graph & weights for continuing training on a Android device?",2
"Ah, I assume you are running on Windows?",2
"i assume that my input has shape 3d (1,13,4) but i feed input with 1d array.",2
I'm assuming you are trying to uninstall everything from your `pip` environment.,2
I assume there is a better way to do it in Keras though.,2
"If I understand it correctly, since [`space_to_batch_nd`](https://www.tensorflow.org/versions/master/api_docs/python/tf/space_to_batch_nd) assumes that `input_shape = [batch] + spatial_shape + remaining_shape`, hence `paddings` is hacked as the tensor `[zeros, paddings]` to handle NC format.",2
So if I understand correctly what's happened here...model.call was supposed to do things in eager mode; that's what I initially assumed would be the case in 2.0.,2
i assumed that it was ok to install futures 3.1.1 for python 3 but seems like they just forgot to check the version.,2
I assume this error somehow made it back into the master branch.,2
"Your printout is on line 117, while I would assume it should be on line 97 given the current state of `jni_utils.cc`.",2
@renxida I assume you are using different model directories for every Estimator?,2
"Using the underlying ops of `index_to_string_table_from_file` (`tf.contrib.lookup.HashTable ` with `tf.contrib.lookup.TextFileStringTableInitializer`) which can take the file path as a tf.tensor seems to solve the issue of loading the file from the saved_model assets folder, so I assume the proposed patch from @facaiy for input validation will work for my issue.",2
I think you're assuming that this step is sufficient to rename the `old/w` variable to `new/w`.,2
I assume by doing this I save variable using new name.,2
"It only happens if you configure for python3, on a Mac, so I'm assuming it's a swig issue, but it's deep inside Eigen, so maybe you have an idea?",2
"The ""slightly unusual"" part is this line:

```python
            print 'building local params'
            with tf.device(worker_device):
                worker_tparams = init_tparams(is_local=True)  # define variable in collection tf.GraphKeys.LOCAL_VARIABLES
```

...which *should* work, but it might conflict with some of the assumptions in the `tf.train.SyncReplicasOptimizer` code.",2
I guess TF assumes you will be minimizing a loss function.,2
Close for now since I assume this has already been fixed.,2
I see you're using MirroredStrategy so I assume you want to distribute the training on multiple GPU.,2
"For example [`LogMessageFatal::~LogMessageFatal()`](https://github.com/tensorflow/tensorflow/blob/d42facc3cc9611f0c9722c81551a7404a0bd3f6b/tensorflow/core/platform/default/logging.h#L54) has the `TF_ATTRIBUTE_NORETURN` annotation, so I'm not sure why that's not enough to inhibit the warning (assuming the compiler constant-folds the `false`).",2
"But at the end of the day, `tensorboard` is still a command line program, so it's assumed that the user will feel comfortable with the fact that little command-line-fu is required to use this fabulous GUI.",2
"The Faster RCNN model is also not trained with quantization enabled, so it might become inaccurate when deployed, assuming you can convert it to TFLite.",2
It's just assumed that I know loads of stuff.,2
"I know it can be very tempting to just quickly include another minor change and replacing the tag (probably assuming that nobody will notice), but it's really bad practice, especially for a popular project like TensorFlow (where you can be damned sure *somebody* will suffer from doing this).",2
"# Assume features is of size [N, H, W, C] (batch_size, height, width, channels).",2
"# Assume that image_coords is a tensor of size [H, W, 2] representing the image
# coordinates of each pixel.",2
"TensorFlow is not really designed for this use case, it suits designs using containerization where you can assume (almost) infinite computation power and resources.",2
"@shoeffner Your scripts assume that there are enough available nodes in the SGE cluster, right?",2
"If we can know this size, and you pass the exact size in `steps_per_epoch`, then we will assume that you meant for us to recreate the `Iterator` each epoch.",2
"You can use `tf.trainable_variables()` to get all the trainable variables in your graph, assuming that what you want.",2
assume `/tmp/distilgpt2_tflite/1/model.tflite` is where the model is.,2
"The build has been working in our internal Bazel tests, so my initial assumption is that this is an environmental configuration issue of some kind.",2
"I assume you are setting the bagged_features
parameter to true, and that you are seeing a crash or something inside the
_bag_features function?",2
"@jhseu Also, many Linux distros already come with libjpeg-turbo (as libjpeg.so for compatibility with libjpeg), but I assume that relying on the uncertainty of whether a shared lib is there is complicated if one is to support platforms other than popular Linux distros such as Ubuntu.",2
I don't know because it's not clear from the doc-strings what the functions assume of the input.,2
A paint program turns contrast into a pointwise operation typically by assuming a 0.5 mean on every channel.,2
"Assuming you don't want to run the cuda binaries on the non-GPU server, would it be ok for you if the build didn't require libcuda.so.1?",2
Currently TensorFlow assumes a cluster is a fixed size and shape.,2
"For example: Assume that you have 12GB of GPU memory and want to allocate ~4GB:

gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)

sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))",2
"But you can build them locally and use them, assuming you are using compatible versions of the dependencies.",2
"If we take above assumption, then TensorFlow will train your data starting from `dandellions`, `lilies`, `roses`, and then finally the `tulips`.",2
My base assumption is that there is a known way to do what I need want with needing to modify source code or create new TF source code.,2
one would assume that one of the most common things people did once they imported files into a TF was to split them into training and validation....but this is not clear in the documentation as to how to do it.,2
This is based on my assumption that `Dataset.shuffle` should reshuffle between epochs.,2
"@gowthamkpr assuming that your explanation is correct, why do I see *different* random numbers in `map()` in each epoch without a graph-level seed?",2
"That is, assuming a deterministic order of fixed input elements, this will yield a deterministic sequence of random numbers for each epoch - I get as much.",2
"Assuming you get the same results in about the same time, then this can be closed.",2
"@jhseu, I'm marking this contributions welcome, assuming you agree with that change.",2
"I'm
assuming the pip package was built with -c opt?",2
@petewarden Assume you're new to TensorFlow.,2
"Assume the training loop looks like this:

```python
image_batch, label_batch = sess.run(t_example)
_, summary = sess.run([train_op, summary_op], 
                      feed_dict={image: image_batch, label: label_batch})
```",2
# Assume you've downloaded both tensorflow/docs and tensorflow/docs-l10n repos,2
This script assumes that the number of code cells matches between the two notebooks to properly sync.,2
I'm assuming you mean the jniLibs directory?,2
"@domluna: Assuming the meta file is a MetaGraphDef, can you check whether it's the `GraphDef` part that's growing?",2
"Assuming I've done this right, using https://gist.github.com/domluna/f06921196b539a397a6a24ae7f571276 to check the ByteSize.",2
"From this point of view, it should be safe to assume that ""ldconfig"" is always in /sbin (if it is installed at all -- the FHS says it's optional).",2
"Since your backtrace into [translate.translate](https://github.com/tensorflow/models/blob/86ecc9730d751c1f72e3bfecac958166390f4125/tutorials/rnn/translate/translate.py) is on a line that exceeds the number of lines in the file, I'm assuming you made modifications to this file.",2
"We are aware of a bug with XSRF and multi-login, and I assume this is was what happened here.",2
"Thus, I assume it failed.",2
"The problem seems to be that in the DirectoryWatcherTest, the ByteLoader implementation assumes that you can read EOF from a file, have another thread append to the file, and then continue reading from the last known seek position.",2
I assume you are using a cpu build.,2
"As this was [indicated to be a bug](https://github.com/tensorflow/tensorflow/issues/42045#issuecomment-674232499), I assume the old behavior of `accuracy` will return in TF 2.4.",2
I assumed DefaultStack was to blame by looking at `gc.get_referrers(sess)`,2
"Building from source without using Bazel is not fully supported right now, but you could try adding `-I/home/sander/tensorflow/bazel-genfiles` to your `g++` arguments (assuming you have previously build TF from source).",2
"I assume it's fine to add a route to handler.py, and the modify the js behaviors in the tf-tensorboard and tf-backend folders?",2
"I assume we see an artifact of optimization, trading accuracy for speed.",2
"The fast_tensor_util warning is because we only build for 3.5, then copy the pip package to a 3.6 name assuming they will be compatible (I think).",2
"Users should still git clone the source repo to get access to examples, tutorials, etc, and should write their code assuming they are using the public API, where the public TensorFlow API is defined as what is documented at http://www.tensorflow.org/versions/master/api_docs/index.html",2
"We have lots of internal uses for that, so I'm assuming that all commits on master work, but there might be some cherry-picks in 0.11 that don't work.",2
"Assuming the `\r` is part of the intended target path, it looks like there is a stray line break in some part of the configuration.",2
"Some of these are missing for earlier release candidates, but I assume people don't care about that.",2
Assigning to @andrewharp assuming he wants to add `Fixed #6738` to the commit message which adds that walkthrough.,2
"Closing, assuming that the fix was committed.",2
"Yes, I understand that implementing a context manager is more tricky, considering that also tracing should work nicely (currently I would assume the `{get,set}_step` is converted to reading/writing `global_step`).",2
"The logic for this would be comparatively complicated, since I assume you'd definitely want to include ties if the set of tied values fits in k (i.e. for top 5, if places 1 and 2 are tied, you still want them in the set).",2
"Here, I'm assuming your `sample` means random.",2
`initialize_or_restore()` on the status object returned by `restore()` will initialize anything that wasn't restored (assuming it's in the dependency graph).,2
Your example works for me assuming I build/use `checkpoint.TEST`.,2
"Again, this warning changes as training progress (assuming not all the samples in your training set raise this problem), since the network activations change.",2
I assume your current GPU implementation actually is already like that.,2
"I used your nvprof - o method and waited until the cursor returned, which was a multisecond delay after the training finished which I assume was file IO.",2
One more question: Assume that we have a GPUDeviceContext assigned to TRTEngineOp.,2
"Assuming no one has overwritten the default behavior in GPUDeviceBase which ensures a single stream,  we should be all good.",2
There is also an assumption that the other inputs (t and e in the op def) are rank 4.,2
"Assuming my understanding is correct, we could envision letting you do something in these lines:

```
def insert(buffer, buffer_head, element):
  magic_list = autograph.util.variable_backed_list(buffer, buffer_head)
  # AutoGraph would generate all the necessary variable assigns and scatter updates.
  magic_list.append(element)
```",2
There's considerable complexity in the module and nobody in the core team feels comfortable enough to assume ownership of it.,2
Note that there are some places in the existing codebase (and tests) that assume this behavior.,2
I'm working under the assumption that we can't just remove this transformation since there will already be a significant number of graphs which depend on it.,2
What we want for an ML compiler is different from traditional compiler "fastmath" assumptions.,2
Instead (I think) we want the freedom that comes from the assumption that the floating-point inputs to a program are effectively random numbers.,2
This is useful on the assumption -- now questioned! -- that computing div.approx is significantly more expensive than computing multiply.,2
After that I assume it forced Pycharm to do something because it then worked.,2
"@gunan, I assume this is a duplicate of #12979.",2
I ended up installing a real version of linux but i assume memory allocation was the reason!,2
There also likely needs to be a unit test assuming something is broken so we catch this in the future.,2
Assume N = output size of each perceptron,2
I assume you are referring to `inter_op_parallelism_threads` and `intra_op_parallelism_threads`.,2
"> I assume you are referring to inter_op_parallelism_threads and
> intra_op_parallelism_threads.",2
This assumes the terminal server has python installed.,2
I think you want `pip install --no-deps {tensorflow or tensorflow-gpu}` (assuming you're using pip).,2
I assumed it is `6/sqrt(n_in + n_out)`.,2
After restarting from a checkpoint I assumed I could make Tensorboard show new values starting from the training step it left off before the training restart.,2
"You can locate the file (i.e. `tensorflow/lite/toco/tooling_util.cc`) and the line number (`644`) and from there go to the check (I'm linking to code on `r1.14` branch, assuming you got the error from 1.14 release; please use the corresponding branch when searching):

https://github.com/tensorflow/tensorflow/blob/00fad90125b18b80fe054de1055770cfb8fe4ba3/tensorflow/lite/toco/tooling_util.cc#L644",2
"Assuming you're using CUDART, it should _silently_ try and create the context on the next GPUs and fail if all GPUs are busy.",2
"But we shouldn't, IMO, assume all users are so sophisticated.",2
Assuming we use a Sequence with multiprocessing (and TF 2.3).,2
"odd.. anyways the performance seems to be about the same as with commenting out the assert, so I'm assuming the solution for this is to just use soft device placement and that there is no big issue with using RNN on GPU",2
"I read that these files are generated (and then placed in tensorflow/core/framework, i assume), but apparently that didn't happen while building TF.",2
"Currently, the tensor size is assumed to be fixed except for string tensor.",2
"But, I get a weird runtime error now when I try to run the benchmark or the simple app in the simulator (I'm assuming the camera app is failing because it can't get camera input in the simulator).",2
"@liangwang the reason is simply that, the design of `SparseTensor` already hardcodes the associated shape as `tf.int64` [1], so any downstream ops that consume these objects assume likewise as well.",2
"On the docs, we could just assume all ops are gpu compatible, but if they are marked as ""CPU only"", it would help!!!",2
"GPU version of TensorFlow always assume the ""mixed environment of CPUs and GPUs"", and it is very natural because GPU-only environment doesn't exist.",2
"GPU version of TensorFlow always assume the 
> ""mixed environment of CPU and GPUs"", and it is very natural because 
> GPU-only environment doesn't exists.",2
Assuming this is fixed.,2
This solution assumes that you don't want to debug the data queue threads.,2
"@Bonnevie I assume that your logdet_chol is something like this:

https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/distributions/python/ops/operator_pd_cholesky.py#L101",2
Due to the nature of the errors people are seeing (like missing RELEASE.TXT files) I'm assuming Bazel.,2
"I assume you've seen the following documentation, since you understand how SAME padding works:
https://www.tensorflow.org/api_guides/python/nn#Convolution",2
I'm assuming there's some process to generate it but I couldn't figure out how.,2
"Besides, I assume running  `tf.data.experimental.make_csv_dataset` without `ignore_errors` on the very same labels, should give an error if something somewhere is wrong, which didn't happen when I tried shortly after your comment.",2
"The instructions assume you install from the tensorflow official pip by pypi or our website, e.g.  `pip install tensorflow-gpu`",2
It's possible you might have read the documentation for `fully_connected` assuming it would reshape the output.,2
I am assuming that I can use any number of workers to run this example.,2
"I'm not familiar with this code, but I'm assuming that check is because it's inefficient to use more workers than GPUs, because each worker uses one GPU for compute.",2
It might be possible to add a dtype in tf.reduce_mean though a type cast is always needed I assume.,2
What I ended up doing was collecting the variables of the two models separately and computing separate gradients/minimizing ops for each (after debugging as I had assumed that gradients would stop at fed nodes).,2
This is indeed the assumption.,2
For instance let us assume we have a sequence with length 256.,2
"Let us assume we have a masking:

0 0 0 1 1 0 0 0",2
You made too many assumptions.,2
"However, unless I'm missing something it looks like the implementation of the OpKernel assumes that the `sizes` are `int32`:
https://github.com/tensorflow/tensorflow/blob/r0.11/tensorflow/core/kernels/reshape_op.h#L48",2
"The best thing to do is add a 
```
TypeConstraint<int32>(""Tshape"")
```
 to all of the kernel regisgtrations here: https://github.com/tensorflow/tensorflow/blob/r0.11/tensorflow/core/kernels/reshape_op.cc#L21

since right now the implementation assumes int32 for the Tshape input.",2
"Regardless, below implements arbitrary indexing and more efficiently, assuming `x_slc` has no NaNs.",2
"@aselle That what the original script was doing -- I assumed it was on purpose -- the only reason it would be required is if there are two different locations that the script would have to work with: one where `SOURCE_BASE_DIR` is, and another where the `configure` is located.",2
"Assuming TF allows them to be in different locations, it makes sense to keep one of them on a stack, while working in the other.",2
"By not running the train_op, I assume that the network weights remain constant.",2
"We intentionally oversimplified the solution to assume the original caller of `super()` is exactly one frame up the call stack in the converted code, and we're working on a follow-up improvement that removes that incorrect assumption and instead walks the call stack to find the caller, which can be any number of levels above.",2
"So that looks good, except that I assume you don't mean to templatize your new `operator()` over `NDIM`?",2
"@naniqingkuang Works fine for me, assuming you're defining `relu_feature_maps1`, `conv_filter_w2`, and `conv_filter_b2` like in [this](https://www.kaggle.com/zbasper/test-for-cnn).",2
Is this sufficient to assume the ops are running on the GPU?,2
I do know that every time I see it I assume it is a problem and it is good practice to just not use the `feed_dict` approach.,2
"Assuming these are float32, that's about 9GB which is quite large.",2
"i assume that it's a runtime error of protobuf , 
say , protobuf can be loaded normally on the test phone, 
but when u try to call interface of protobuf, it crashes.",2
"Also, you may see substantial speedup if you use a GPU, assuming you are running many images through the classifier.",2
Closing as duplicate of #2883  (@petewarden - I'm assuming that workaround is still necessary?),2
"We rolled back the ""safe rewrite"" because, as @alextp mentioned, the assumption doesn't always hold.",2
"Hey, I'm assuming you got to that page through a Google search, or a link from elsewhere, not through navigation on the Tensorflow site itself, right?",2
"> Hey, I'm assuming you got to that page through a Google search, or a link
> from elsewhere, not through navigation on the Tensorflow site itself, right?",2
"I assume there must be a reason it's there, but I haven't figured out what it might be (assuming that bazel can correctly pick up the changes in all files touched by `configure`).",2
Closing assuming there is no real action item here.,2
All the sequences would roughly be within 5 or 7 timesteps (assuming you're doing NLP seq2seq).,2
"Since TF doesn't have batch dimension concept and TRT requires a batch dimension, our assumption of Rank0 being the batch dimension is failing in FasterRCNN.",2
"For compressed file, it assumes that the file will be read sequentially and it will ignore the offset parameter in 
```
class RecordReader{
  //...
  Status ReadRecord(uint64* offset, string* record);
}
```",2
Note that this function assumes that the size of the tensor is known and that the offset is the same for each batch.,2
Seems to be a bug in the checkpoint reading code: it assumes end of path is a glob but doesn't check that no globbing characters are used in the path before that.,2
I was just assuming that the byte data displayed was the uint8 quantized values.,2
"I just assumed it would be there as 32 bit signed data, in the same form as in the Netron viewer.",2
"So, I guess I can close this, assuming that someone intended the int32 data to be represented by bytes in the json file.",2
"Assume, model A predicts {bike: 0.9, car: 0.1} and model B predicts {bike: 0.6, car: 0.4}.",2
I assume its supposed to be.,2
@zheng-xq I'm assuming this will happen at some point? ;-),2
"It looks like @thomascolthurst has added a reshape to TensorForest input, which I assume just hasn't made it into a TensorFlow release yet.",2
"Assuming the causes of the error being the same is easy to do, but often not true.",2
@Goofy-G I assume original issue was resolved.,2
But I think en_us.UTF-8 should not be assumed by default on installation,2
"This is an issue with `Sequential` models, where they will essentially assume that any layer can be traced with a an input matching the layer's dtype",2
"Anyway, the end goal here should be to fix tracing inside the `Sequential` model so it does not make invalid assumptions about input types.",2
tf.image.flip_left_right and tf.image.flip_up_down incorrectly assumes rank-3 image and flips along the wrong axis,2
TF 2.4.0 crashes on startup with IndexError assuming that sys.argv[0] exists when it may be hosted by C++ (regression from 2.3.1),2
lite/micro: micro_speech example:  input tensor lifetime assumption invalid,2
OSX Yosemite "can't determine number of CPU cores: assuming 4",2
Keras Docs Examples silently assume categorical tasks,2
"ImageDataGenerator inherits wrong class from TF 1.11, causing fit_generator to assume it isn't a Sequence",2
I'm assuming this is meant to implement the novel initialization proposed in this paper: http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf,2
Assume we are trying to learn a sequence to sequence map.,2
Now assume that the sequences have different lengths.,2
"I'm assuming that model.to_yaml() -> model_from_yaml() and model.get_weights() -> model.set_weights() should do that, but either I'm missing something or there's a bug in one of those two functions.",2
I assume for this example that `nb_samples=1000` and `input_dim=2`.,2
It currently assumes that "prev=" has not been used - it assumes all layers are sequential.,2
I am making an assumption that each image has atmost 3 components.,2
"- Thorough checking of assumptions made about user-provided constructor arguments throughout the codebase, and raising helpful and clear error messages when some assumptions aren't respected.",2
"I see this pattern appear elsewhere with accumulators as well, so I assume I'm just misunderstanding something fundamental about how theano works - but if so I'd really like to know what.",2
- Stricter checks of assumptions throughout the codebase.,2
now assume that to spot Keras we need at least one word on the left and one word on the right of the target word.,2
Now assume that we have this new kind of model lets call it TimeDistributedModel and that the API modification in point 1 is implemented.,2
"I would have assumed that the convolutive layer parameters wouldn't be updated, but they clearly are.",2
"Let's assume that we want to create a model accepting two sentence or two images, creates a representation of the two and computes a similarity function between the two representation",2
#Assume x = inp1repr and z= inp2repr so the similarity function can be computed as follows y =  xWz where W is similarity matrix and y is the similarity score.,2
"> Thorough checking of assumptions made about user-provided constructor arguments throughout the codebase, and raising helpful and clear error messages when some assumptions aren't respected.",2
This assumes that `len(self.layers[i].params) == len(self.layers[i].get_weights())`.,2
"Because each prediction _should_ act on long term dependencies, and there are no long term dependencies at the first timestep, the output for the first ~20 timesteps may be assumed to be garbage.",2
"- exponential activation for the variances (M outputs, assuming radial covariance matrix)",2
"Now let's assume i have a masked Input (embedding layer with mask zeros) If i want to concatenate over the embedding dimension that layer with another embedding layer (to represent another feature of the word (pos tag?, capitalisation?, ner tag?) with the same mask all the mask information are lost?",2
"Assuming an input of size (1000, 25, 15) where 1000 is the samples, 25 is the sequences per sample and 15 are the features per sequence.",2
"- strict enforcement of user input assumptions, and raising of helpful error messages.",2
"Here is one thing about Keras, it always assume that output dimensions are `(samples, dim)` or `(samples, time, dim)`.",2
"So I assume I would need to use the same embedding size of 300 to obtain a merged output shape of `(None, 101, 300)`, but I haven't been able to do this successfully.",2
"I assume that this performs word encodings, but I'm interested in how it is done.",2
"With this setup, I assumed the X_train vector should look like [total_time_steps x 2].",2
I assume that this is interesting to others as well.,2
Because there's no imports included I'm assuming: keras.layers.core.Merge and I get the following error: AttributeError: 'Merge' object has no attribute 'add',2
"assuming I have a mini-batch size of 1600, and my `y.shape == (1600, 20, 1000)`, and my `weights.shape == (1600, 20, 1)` if I call `standardize_weights(y, None, None)` I get weights with shape `(1600,)`, but If I call  `standardize_weights(y, weights, None)` I get weights with shape `(32000,)`, e.g. my weights are just flattened and returned.",2
"Assume that our model takes two inputs, transforms these through a set of shared layers, and finally outputs the distance/similarity for the representations obtained in both subnets.",2
Now one may assume by reading the `ImageDataGenerator` documentation that the images will be shifted by `0.5*image_width` from left to right (or from right to left).,2
"So, the thing I want to do is basically (assuming that I have padded sequences of length maxlen, and I have max_features tokens).",2
"I am assuming I will perform the first step with one graph, save the weights, and attempt to initialize a new graph with the weights learned in the first step.",2
"I assume that if it was this easy, someone would have done it already, though.",2
The RNN assumes size (nb x 1 x 1).,2
"For some strange reason, it seems to assume testing is done over 5 samples.",2
ImageDataGenerator should apply standartize() on validation_data parameter or at least the docs should mention the the validation data is assumed to already be standartized,2
Here I assume the whole input as a continuous sequence.,2
"Assuming that I have 500 sentences,
and maximum seen length of a sentence is 52, then I will have a 500x**52** input matrix.",2
"I am assuming that, when enabling GPU, even the model building is done on GPU, which may have less parallel requirements and CPU would be faster on building it.",2
3. It assumes that the position of the sentiment rich contexts into the sentence matter.,2
In many works the used max pooling assumes you take the maximum value along the second axis (the time axis) after the convolution.,2
"Assuming the generator for `model.predict_generator()` should behave just like `model.fit_generator()`, how come returned predictions are only for the first frame for every sequence? Shouldn't entire sequences be predicted over all their minibatches?",2
Let assume that I want to have a matrix W which is learned and is used _differently_ in different type of layers.,2
"I assume the callbacks follow the input list's ordering, but what about the defaults.",2
"The format of `inputs` and `targets` is not properly documented, but some assumptions are made in the code.",2
"2. Later on, more undocumented assumptions on the data format are made.",2
"every variation on that idea (altering parts of Node, altering the variable in various places during runtime) always fails because there's some other part that assumes data can only be passed in at every iteration.",2
"I'm assuming that it can be done with proper use of masking, but I'm not exactly sure how.",2
"Assume  input ""processed_a"" and processed_b have  shapes with (nsamples,dim)., then the input shape will be like [(nsamples,dim),(nsamples,dim)]",2
"For example, can we display the accuracy every N batches (lets assume N=100).",2
"Assuming I have only one filter, is there a way to configure the layer so that I get as an output the convolution of the input with 4 versions of the filter each rotated 90 degrees with respect to the prev. one?",2
Assume each word is a vector of size 2 and a sentence has 3 words:,2
"I accept the possibility there is a bug in my code, but assuming there isn't, I can't figure out the order of the weights / gates in the LSTM layer.",2
"Assume x = [[1, 2] and y = [[5, 6] [3, 4]] [7, 8]] batch_dot(x, y, axes=1) = [[17, 53]] ...",2
"Assume x = [[1, 2]   and y = [[5, 6]
            [3, 4]]          [7, 8]]",2
Assuming that I have 3 models.,2
I want to train a model to identify the keyword of a sentences (assumpt just one keyword in a sentence).,2
This token is assigned the index 0 in the corpus and I assume that this index has special meaning in the lookup.,2
"My assumption was an operation level parallelism 
and seeing as all I'm doing here is summation it feels like that should parallise efficiently, 
is this not correct?",2
"For example, assume we want to make a character-rnn model with Keras.",2
"In the metrics module, the way binary accuracy is calculated assumes your predictions and labels are 0/1.",2
"It's easy to work around (define a custom metric to use), but it is slightly inconvenient to the user who assumes that binary accuracy will automatically do the right thing.",2
"Now, assume that I want to train/evaluate a neural network with different initial random states, 
for 10 times, and take average of f-scores.",2
"I am assuming I need to insert another layer of convolutions to get it down to (1, 512, 8, 8), so I can keep the number of parameters under control.",2
"As we know, the phoneme sequence in a fragment of speech varies a lot, but the example code assumes that all sequences are of the same length, and passes the length as parameter to CTC cost function.",2
"I'm just wondering if anyone can see any obvious reason, why, when porting a CNN model from 
TFLearn to Keras, I would get a ~8% reduction in accuracy (I'm assuming I'm making a mistake somewhere in the ported code).",2
"I realized that there wasn't a Conv1D and instead it was Convolution1D, so I am correct in assuming that it should be ""from keras.layers import Convolution1D""",2
"Question 1: I use `axis=1` because I assumer the lambda layer gets applied to a whole batch of inputs at a time, meaning axis 0 is the sample index, while axis 1 indexes the words (i.e. word vectors after embedding) in each sample. Is this correct?",2
Let's assume that generator return batch of 5 single samples and we want to train model on 10 batches per epoch so we have training on 50 single samples per epoch.,2
for example i assume 4 memory blocks and 2 cells.,2
"Assume x = [[1, 2], [3, 4]]   and y = [[5, 6], [7, 8]], _with shapes (2, 2)_
    batch_dot(x, y, axes=1) = [[17], [53]] with shape (2, 1).",2
"Assume x = [[1, 2], [3, 4]]   and y = [[5, 6], [7, 8]]
    batch_dot(x, y, axes=1) = [[17, 53]] which is the main diagonal
    of x.dot(y.T), although we never have to calculate the off-diagonal
    elements.",2
"That is, assume the seed is ""x"" , I get some result for the first sequence , but I get a different result for the second sequence for the same seed ""x"".",2
"The issue is that since original inputs to the SR-ResNet have a batch size of 8, Keras assumes that output batch size should also be 8.",2
"Assuming the above code is correct, I have a question about the loss function.",2
"Assuming it's not too invasive, would there be any chance of getting such functionality merged into the official repo?",2
I assume this is related to having convolution operations inside a scan.,2
"After training, each sample in X1 is assumed similar to sample in X2.",2
"Assuming the MNIST images data of the size 28*28, how to define the input_shape to accommodate the two types of image inputs.",2
Assume one have 10 inputs and 10 outputs in one sample and a single prediction model could generate 1 output from 10 inputs at each time.,2
# this assumes K.image_dim_ordering() == 'tf',2
"This is the main point of this issue - I assumed that cos and dot should be interchangable and handle the same input dims, but that seems not to be the case.",2
Let's assume we have just 4 samples: two negatives and two positives.,2
It should assume default using GPU.,2
"I went ahead and ran the code, using the Theano backend, and saw no learning past a Normalized Edit Distance of .85 - this value for an edit distance means the output is essentially random, with the model just having learned the distribution of letters; this was backed up by the visual validation examples, where the model generally output a string of 'a's, 'e's,  and 's's, which I assume are the most commonly used letters.",2
"Assume our model have two outputs : 
output 1   'class'    for  classification
output 2   'location'  for regression",2
"I mean, let's assume I have only a training data set consisting of 100 records and want to build the model 100 times based on 99 records and validating it on the remaining one.",2
I have thus far been working under the assumption that a network with an LSTM layer is the way to go in order to achieve this.,2
Assume I have a large set of screen -> action values.,2
Assume that there are 6 classes.,2
"# 32 floats -> compression of factor 24.5, assuming the input is 784 floats",2
"My goal is to implement a custom regularizer, if I could use L2 regularizer, is it straightforward to switch from L2 to my custom regularizer (assuming that the implementation is completed)?",2
I'm learning how Keras/Theano compile an actual execution graph of the operations necessary to perform the calculation of the gradients and I'm trying to better understand the special conventions / assumptions that are made about the lazily-evaluated functions so that I don't hinder the proper calculation of the gradients.,2
"Also, I'm assuming W_regularizer refers to weights and b_regularizer refers to bias?",2
"For example if customer #1 has 300 time steps and customer #2 has 400 time steps, I would reset the state of the model after 300 batches and then after 400 batches, assuming that each batch = 1 time step only.",2
I am assuming that this `` is a special formatting character used to reprint on the same line in console and on ipython notebooks.,2
'''Assume that you have 6GB of GPU memory and want to allocate ~2GB''',2
"For example, let assume here I have 14 frames data, so I tried like this:
`model = Sequential()`
`model.add(LSTM(1, batch_input_shape=(14, 10, 68), stateful=True, return_sequences=True))`
`model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])`
` model.summary()`",2
"I'm assuming it's `bool`, because that's what gets returned by the [`Embedding`](https://github.com/fchollet/keras/blob/master/keras/layers/embeddings.py#L107) and [`Masking`](https://github.com/fchollet/keras/blob/10399242459eb222afece5edc5645ad458ea43c7/keras/layers/core.py#L59) layers.",2
My assumption is this is not supported/implemented.,2
# this assumes K.image_data_format() == 'channels_first',2
"But now assume we have data that looks like this:
dataX or input: `(nb_samples, nb_timesteps, nb_features) -> (1000, 50, 1)`
dataY or output: `(nb_samples,  nb_timesteps, nb_features) -> (1000, 10, 1)`",2
"I'm currently getting 0.50000 for the accuracy all the time, i assume it might be something to do with the pair/data preparation.",2
"There are some hard-coded assumptions in the current 1D global pooling implementations that I'd propose fixing, being: dimensionality ([ndim=3](https://github.com/fchollet/keras/blob/master/keras/layers/pooling.py#L442)) and the axis to pool over ([axis=1](https://github.com/fchollet/keras/blob/master/keras/layers/pooling.py#L463)).",2
"Assume, there is a general function ""func"" with n parameters and it should be evaluated on (W %*% Input).",2
I have what I assume is an installation issue.,2
Based on this [line](https://github.com/fchollet/keras/blob/97174dd298cf4b5be459e79b0181a124650d9148/keras/layers/normalization.py#L83) in `normalization.py` it seems that library makes this assumption.,2
"We assume this was done on purpose, and we will not be expecting any data to be passed to ""custom_variational_layer_20"" during training.",2
"It looks like it assumes all inputs for a layer will have been created before it, but I couldn't sort the layers to manage the actual dependencies.",2
This change may break code that assumes the current behavior but as far as I know there's no work that explicitly relies on this behavior.,2
"Let us assume two small matrices with `batch_size = 1, height = width = 2, feature_dim = 1`",2
# assumed already an op,2
"The cosine similarity between two normalized vectors u,v (let's assume of length 3) is usually computed as 

sim = u * v = u[0] * v[0] + u[1] * v[1] + u[2] * v[2]",2
"So I assume that fbeta_score function is not implemented, as it says in the documentation.",2
"This is due to the fact that 

`avg = self.sum_values[k][0] / max(1, self.sum_values[k][1])` in `generic_utils.py`

is assumed to be a single value, while in this case it contains all values for all time steps.",2
"Since I can run any of these two program on a 4g GPU, I assume that there probably exist ways to limit the memory use of the first program.",2
"If true, assume the variable is 0-intialized and
      unbias it, as in https://arxiv.org/abs/1412.6980.",2
"However, this is a very hacky solution as it assumes that all validation metrics are prefixed with `val_`",2
"I could change the code like this (always assuming that we're running on a tf backend):

```
check_op = tf.add_check_numerics_ops()

self.train_function = K.function(inputs, 
    [self.total_loss] + self.metrics_tensors + [check_op],
    updates=updates, name='train_function', **self._function_kwargs)
```",2
"We assume this was done on purpose, and we will not be expecting any data to be passed to ""custom_variational_layer_1"" during training.",2
I assume that there is some bug somewhere here https://github.com/fchollet/keras/blob/master/keras/backend/tensorflow_backend.py#L2745,2
"I assumed the integers in the IMDB training/testing dataset were just indexes from the IMDB vocabulary, 
so I wrote some code to make sentiment prediction for some new texts using the steps below.",2
"I assume that I get a sequence of separate, independent label predictions from the model (like ""2"", ""2"", ""3"", ""1"", ""1"", ""0"") without any further hint what is the sequential order of these for my whole input number.",2
So I assume that's not the correct way to build a seq2seq autoencoder.,2
Also it was coded for 1.2.2 but I assume that part of the lib didn't change that much.,2
So i assume here should be an element-wise multiplication between 'match' and 'input_encoded_c'.,2
I assume the current issue is that that limit has been exceeded and it has resorted to the 'valid' type,2
"It's not clear to me how to make this method trains on batches, so I assumed that the generator has to return batches to fit_generator().",2
"For what I understand from the [Keras implementation of ZCA whitening](https://github.com/fchollet/keras/blob/master/keras/preprocessing/image.py#L680-L684), the assumption of zero mean data is not met when `featurewise_center=False`, which is the default.",2
"*For 2D data (e.g. image), ""channels_last"" assumes (rows, cols, channels) while ""channels_first"" assumes (channels, rows, cols).*",2
"Assume first element is an action tensor with shape 
                    [Bacthsize, timeStep, #. of controll vars] and the second element is a stateTensor
                    with shape of [Batchsize, Dim of states].",2
Assuming that words in the beginning of a sentence contain "more signal" / "more meaning" than the words in the end.,2
"But in reality is it `(height, width)` and not `(width, height)` if I understand correctly, since this is the same order of these two values as in shapes of images, which is
`For 2D data (e.g. image), ""channels_last"" assumes (rows, cols, channels) while ""channels_first"" assumes (channels, rows, cols).` with `rows` == `height` and `cols` == `width`.",2
"This is making the code assume (in the if statement) that the default value is `channels_first`, which is not right.",2
I have set shuffle to false so I assumed that predict_generator and predict are reading images in the same order.,2
So that leads me to the assumption that the bug is probably in the `keras.model.load_model` function.,2
Assume that you have 6GB of GPU memory and want to allocate ~2GB,2
# We assume data format "channels_last".,2
"We assume this was done on purpose, and 
    we will not be expecting any data to be passed to ""custom_variational_layer_1"" during training.",2
I assume then that there is a bug and post here.,2
I would assume that the margin would be the same parameter as the threshold for the accuracy of the model. (here 0.5 in the compute_acc function).,2
I am assuming the correct size of y_trn should be: `(160 x 128 x 128 x 7)`.,2
e.g. (Assume I properly padded).,2
# Assumed to be 1730 grayscale video frames,2
"# assume, utils.to_categorical() like sample",2
"# assume, numpy array type sample",2
"For example, when using `sparse_categorical_crossentropy`, [this code](https://github.com/keras-team/keras/blob/068a680480ebf27ecbe57f1406d60157b7d2df38/keras/engine/training.py#L1460) assumes `'channels_last'` format.",2
"If converting to one-hot encoding instead of using `sparse_categorical_crossentropy`, the function [`to_categorical`](https://github.com/keras-team/keras/blob/068a680480ebf27ecbe57f1406d60157b7d2df38/keras/utils/np_utils.py#L32) also assumes `'channels_last'` format, and puts the classes last.",2
"In short, `'channels_first'` image data format seems not to be fully supported, and many places in the codebase seem to assume `'channels_last'` format.",2
I assume the same is true for a direct call to `model.save(...)`.,2
"Correct me if I'm wrong here, but I assume when model.fit() is called the optimizer's parameters (the learning rate, decay...) are restarted.",2
I am assuming it will however this code was posted as a solution so I'm confused.__,2
"We assume this was done on purpose, and we will not be expecting any data to be passed to ""decoder"" during training.",2
"#We assume this was done on purpose, and we will not be expecting any data to be passed to ""decoder""
    #during training.",2
I assume these parameters are named for consistency with the convolutional kernels and changing them might be tricky (though I'm not sure if consistency with the convolutional layers is really a good criterion here).,2
"Right now it assumes all
#       images in a batch have the same active_class_ids",2
"This is already problematic because the CNN now assumes I'm putting in an all-black image (disregard preprocessing here, and this should explain why I chose negative pixel values for the mask).",2
"I assume this corresponds to (N,H,W,C) .",2
"We assume this was done on purpose, and we will not be expecting any data to be passed to ""conv2d_186"" during training.",2
"Lets assume, `Dense Output_0 is [0.9, 0.9, 0.1]`, so here `Hidden 1` & `Hidden 2` sub-model parts will be triggered and model predicts labels from `Dense Output_1` & `Dense Output_2`.",2
"Question 2: In a stateful lstm and assuming we have one long sequence that is subdivided into multiple samples that are passed in one by one with a batch_input_shape=(1, 200, features).",2
"Assuming many batches have already been passed in (meaning there's state from previous batches), does the time distributed prediction of timesteps depend on where in the sample a timestep is located?",2
I'm assuming this is where I'm going wrong and not properly feeding the output of this intermediate layer to the `model.fit()` method.,2
"Though, I also assume weighted accuracy is not necessary when `mask_zero=True`, so this might not be a very important issue.",2
The following code lines (taken from [callbacks.py](https://github.com/keras-team/keras/blob/master/keras/callbacks.py)) are wrong since they are assuming that the denominator in metric formula is the number of samples in a batch (i.e. batch_size).,2
3068     # else: assume learning phase is a placeholder tensor.,2
I was assuming that both approaches produce similar results in terms of accuracy and loss.,2
"If environment variable KERAS_BACKEND is set, but empty, keras assumes that it has a valid value and tries to load undefined backend.",2
# assume our data belongs to 3 classes,2
"# I assume these will yield the last two output of the whole convolutional lstm process instead of the output 
    # at time step t-1 and t-2",2
"However, for layer f_t, I assume these will yield the last two output of the whole convolutional lstm process instead of the output at time step t-1 and t-2.",2
"But this solution (assuming it works) seems to be used to train the newly added top layers only (step 1 above), how to fine-tune the convolutional layers in InceptionV3/Resnet50 (step 2 above) is still unknown to me.",2
"The even distribution of categories across batches cannot be assumed, i.e. it may happen that when I split my data into, say, two equal parts, first part will contain a subset of all available categories, and the second part - different subset.",2
"I notice that the input shape 66=192-126, so I assume that the fit() function takes the same batch_size for training and validation data.",2
"I would rather not try to accumulate across time if at all possible -- as I understand it by default, with return_sequences set to True my model learns as it goes rather than all at once at the end, though it occurs to me that this assumption is unfounded.",2
I assume that the problem lies with pytest.,2
"But `fit_generator()` checks if the generator is a subclass of `<class 'keras.utils.data_utils.Sequence'>`, so it seems to assume that the ImageDataGenerator instance is not of type Sequence, causing above problems.",2
The issue is that `states[0]` is assumed to be equal to the `output` of the `step_function` in this [line](https://github.com/keras-team/keras/blob/master/keras/backend/tensorflow_backend.py#L2976) (not so in other backends or with `unroll=True`).,2
Especially since the [introduction of `output_size` in the RNNCell](https://github.com/keras-team/keras/commit/66f8cc7ac4942f7f9fe0164a2a854a6264b87735) it is clear that this should not generally be assumed.,2
I assume If I could transfer all my data to GPU memory at once it will improve the performance dramatically  ( similar to PyTorch) .,2
:param input: An input Tensor assumed to be coming from a capsule layer.,2
"I can't run my model now, it would output some error about mismatching shapes later down the line in some operations and I assume this is causing that",2
"Additionally (I am not sure if this is a plotting bug, but I assume so), the lstm_backward layer seems to not be connected with it's input.",2
# Same labels assumed.,2
So I assume that it's just something with saving.,2
It will not work in some earlier versions of TensorFlow (but I assume they're not supported).,2
My assumption is that `y_true ` only contains the labels values.,2
"according to the [tensorflow documentation](https://www.tensorflow.org/api_docs/python/tf/keras/backend/categorical_crossentropy), it seems y_preds are assumed to come from softmax when from_logits=False, yet how about keras?",2
"# initialize the input shape and channel dimension, assuming
    # TensorFlow/channels-last ordering",2
"Where the assumption is that unless `steps_per_batch` is specified, we are counting samples, rather than steps (i.e. batches).",2
"This assumption is transferred to the `__init__` method of `ProgbarLogger`, which then transfers it to `Progbar`.",2
"My assumption is that if the creation of `Progbar` is prone to this error, then the actual training might be too, but I haven't verified that.",2
I'd assume that the fix would be to find all the places where `steps_per_epoch` is used to see if mini-batches are being used in training.,2
"I will say that for the most part, even though the values are low, the highest value is normally assigned to what I would assume is the correct class... so another question would then be, why is the value so low?",2
I cannot find how the initializer works for the moving_average but I assume this behavior is not intended as otherwise there'd be no need for the initializer at all.,2
"I'm using tensorflow backend and my data is of size (samples, width, height, channel), so I assume I should use `x = BatchNormalization(axis=3)(x)` but this does not work and produces the error as shown above.",2
"The same tests run ok on my local machine, so I'm assuming something to do with the latest changes to Keras.",2
"I assume that this should be something like https://github.com/tensorflow/tensorflow/blob/e2a6861c2be77412d86bdf433b640ed7dd1de32c/tensorflow/python/keras/utils/tf_utils.py#L384, to act accordingly.",2
I am assuming it takes care of handling the training/test state internally.,2
"In the Simplest form, assume that we have a bunch of layers stacked together.",2
"# if augmentation is defined, we assume its a train set",2
"# if augmentation isnt defined, we assume its a test set.",2
# assumption in initializers.VarianceScaling,2
"So, we can assume that the loaded weight model should give the last performance output.",2
"Assume that df is a Pandas DataFrame consisting of valid filepaths and classes, and model is a pre-compiled CNN with rmsprop as an optimizer.",2
"I assume this should be among the most basic tools any deep learning package could provide, it is strange why there seems no easy way to do so in Keras2.",2
"encoding_dim = 32  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats",2
I assume mistake should be with preprocessing the test image.,2
"I think the shape (None, 20, 512, 512, 3) make sense, but I assume, that the function wants a shape like **(20,None,512,512,3)**.",2
I assume I'm doing smething wrong while preprocessing the image.,2
# Here I'm assuming some dummy data,2
"It's somewhat of an assumption not knowing the inner workings Keras / Tensorflow in great detail, but I saw the LOSS jump up a bit (well more than a typical epoch at that stage of training) which made me think a node probably dropped out to make that happen.",2
This is assuming that once a node is dropped it stays dropped (which from my understanding is the case).,2
"This code was working well on my current python installation and in google colaboratory up to a few moths ago, it has stopped working with google colaborator but still works on my desktop python version, so I'm assuming it has something to do with a new TF version or some other update.",2
"I assume, a reason for this issue is line 933, 934 in function `reset_states` in class `RNN` in file keras/layers/recurrent.py",2
"I ran 5 models successfully in Google Colab (where I assume they use TF 2.5), but when I try and run on my local CPU in VS code in a conda env (where I can't seem to get the TF version to be above 2.0?) a ValueError is raised (in the title of this issue).",2
"`image_dataset_from_directory` currently assumes that the dataset will be used in classification tasks, so the labels take some form of categorical values (integers, binary, etc).",2
"It also make strong assumptions on the directory structure in which the images are located: if a list of labels is passed, the images should be placed on subdirs named the same as the labels (even if the documentations says that the structure is ignored).",2
# because TensorBoard dependency assumes TensorFlow package is installed.,2
Item #2 -- Review and likely re-branch  "origin/r2.6.1" from the correct change-list --  I assume branched from  the TAG "v2.6.0",2
"The documentation only shows `Sets the default float type.`, so I assume that the floatx is supposed to affect both keras and tensorflow.",2
"1. anchor box: It uses an anchor box by assuming the target shape **(xmin, ymin, width, height)**.",2
It's trying to decode one of the strings using the default encoding (which I'm assuming is UTF-8).,2
"**Standalone code to reproduce the issue**

(Here, we assume all necessary libraries (including Tensorflow) are imported)",2
I assume that this operation is simply moving tensors around (should be only on GPU) and thus should not take time comparable to the large matrix multiplications occurring during the batch iteration.,2
"Since the latter one is **deprecated**, we assume that the ``image_dataset_from_directory`` api is the only viable option moving forward.",2
"Assuming that nobody has used the `rate` variable in the constructor of image augmentation layers, this should avoid reproducibility issues.",2
"However, I assume they should support ""half"" datatype.",2
"Right now the Keras assumes TensorFlow is installed by pip, and it has no Bazel dependencies on TensorFlow.",2
# assume we have 2 GPUs,2
"However, given the current design decision to declare a separate class KerasTensor and _then_ overload all methods to it, I am assuming that simply inheriting KerasTensor from the public tf.Tensor is not a solution.",2
"Hence, my assumption is that a refactor or revamp of KerasTensor is a plausible, albeit difficult solution.",2
"Now, let's assume I've more than one output from model and want to weighted them towards the final loss.",2
# assuming predictions of some model (10 examples),2
"When I print the model summary with `expand_nested=True`, I see the sublayers with param count and I assumed I should get a similar result with tf.keras.utils.plot_model(model, expand_nested=True)`.",2
Nevertheless it may be worthwhile to consider dropping the unsupported forks assuming there are no backcompat issues - I didn't see anything explicit in the test suite to suggest that was the case.,2
"2. To me it seems it's not possible to give `tf.Variable` a unique id, so I assume the naming would need to be done manually with something like `lambda x: backend.varaible(x, name=f'state_{unique_id}'`.",2
So I assume it's a Keras problem.,2
"I have not looked into details yet, but I assume that there is something wrong with the conditions within the `go_backwards=True` path.",2
This assumption is certainly violated for RNN that use dropout/recurrent_dropout as the state cannot be independently computed.,2
"I did not try but I assume that this would have not been an issue if the model was saved as an h5 or keras instead of plain text, however, for my use case, I really prefer having weights as plain text as I intend to use this model on its own later in C instead of Python without using Keras/TensorFlow.",2
"However, if I don't specify it, the method assumes that the validation batch size is the same with the training batch size.",2
"My first few hours with Keras were needlessly a lot more painful than needed, because I didn't realize most of the examples at http://keras.io/examples/ and elsewhere were geared at categorical, not binary classification (which is what I personally assumed by default) - and when I realized, I didn't realize how important that was.",2
# Assume total data's sequence length is larger and evenly divisible by this number.,2
This breaks the assumption of `standardize_user_data` and makes it impossible to use Keras for this kind of data AFAIK.,2
"""you love me""(assume lemmatization which changes me to I) is
[3,6,9]
[2,5,8]
[1,4,3]",2
"The third set of weights have biases initialized to 1.0, so I'm assuming that's the forget gates.",2
"For matrices U = {u1, u2} and V = {v1, v2} with u1, u2, v1, v2 being normalized vectors (let's assume length 3), this can be computed as

U * V = { (u1[0] * v1[0], u1[1] * v1[1], u1[2] * v1[2]),
               (u2[0] * v2[0], u2[1] * v2[1], u2[2] * v2[2]) }",2
"get_file has some serious limitations, even with untar=true it can't unzip `file.tar` it assumes it is a `.tar.gz` file.",2
"Yes, could you post a script to repro this (I assume you used the Kaggle Otto challenge data).",2
"We probably want to make it open to all, as manually approving memberships seems like a pain, and we don't have any reasons to ever reject one (I would assume Google is pretty good at spam filtering?).",2
But im under the assumption that in the theano function "get_activations" there is nothing to restrict the input shape and so I should be able to give it a larger image size and the output would scale accordingly.,2
The main assumption behind the Glorot initialization is that the variance of the gradients should be the same in each layer.,2
"> The main assumption behind the Glorot initialization is that the variance
> of the gradients should be the same in each layer.",2
My code assumed the rows/columns of the embeddings were flipped from how keras stores them.,2
"Batch size during training is assumed to not be fixed, and may vary when iterating over the data (in particular, if you use the fit() method of models.Sequential, the last batch will generally be smaller).",2
"The input_shape parameter is assumed to be the shape of a **single** sample, not of a batch.",2
"The basic Rule for Merge is that the outputs of the layers you want to
merge should be of same dimensions( assuming you already know it)And then
you specify the mode(https://keras.io/layers/merge/) based on the mode you
set the axis.",2
"> The basic Rule for Merge is that the outputs of the layers you want to
> merge should be of same dimensions( assuming you already know it)And then
> you specify the mode(https://keras.io/layers/merge/) based on the mode you
> set the axis.",2
"Let's assume you are given this simple string: 

""Bob moved to the bedroom. Where is bob? Bedroom. Bob moved to the Garden. Where is Bob? Garden""",2
"> Let's assume you are given this simple string:
> 
> ""Bob moved to the bedroom. Where is bob? Bedroom. Bob moved to the Garden.
> Where is Bob? Garden""",2
Just a clarification - I assume the batches are user controlled  - the networks is going to save state after x `timesteps` and the next batch will have to come from the user?,2
I'm assuming the batches are also in chronological order(?),2
"I'm assuming TensorFlow + ""stateful=True"" has a bug that's not getting
caught by current unit tests, so I'd like to hear others' experiences.",2
"> I'm assuming TensorFlow + ""stateful=True"" has a bug that's not getting
> caught by current unit tests, so I'd like to hear others' experiences.",2
"> > I'm assuming TensorFlow + ""stateful=True"" has a bug that's not getting
> > caught by current unit tests, so I'd like to hear others' experiences.",2
The sklearn API is based entirely on these assumptions.,2
But it would definitely be possible to develop a sklearn-compatible wrapper that would give the user access to a subset of the functionality of the model class (under additional assumptions).,2
"You can implement a new loss function, assuming binary classes `{0, 1}`, such as:

``` python
def max_margin(y_true, y_pred):
    return T.sum(T.maximum(0., 1. - y_pred*y_true + y_pred*(1. - y_true)))
```

Which returns the max margin loss on the current batch.",2
"I don't know what you are trying to do, but I would assume that Reshape layer is probably useless.",2
"This would be compatible with our text preprocessing utils, which assume that 0 is a non-character.",2
I can look into this (I assume this can be solved with a fuzz factor).,2
"Yes, assuming the problem is tractable.",2
I assume we'd also need to change the compilation loss argument to a list?,2
"Assuming I only have one objective function, is there no simple way to zero out the gradients for missing outputs before backprop?",2
"> Assuming I only have one objective function, is there no simple way to
> zero out the gradients for missing outputs before backprop?",2
"if X_train = numpy.array([[1,3,4],[2,5,6]]) then model.fit(X_train, y_train, nb_epoch=200,validation_split=0.03, batch_size=50) works fine, because after standardize_X((X_train) it will become [array([[1,3,4],[2,5,6]]) ] , so slice_X works fine. But if X_train = [[1,3,4],[2,5,6]], then after standardize_X((X_train) it is still [[1,3,4],[2,5,6]], then there is a error in slice_X for it assumes X is a 3 rank tensor.",2
2D convolution only really makes sense under the assumption that the input is spatially continuous over both dimensions (like pictures).,2
"I think my settings would be:
    *nb_filter = 25 (see 1d above)
    *stack_size = 1 (i've seen 3 in some of your examples and i assume that its 3 because the pictures have a red, green and blue color channel, my input is text so i think it has only 1 channel??)
    *nb_row = 1 (my data doesn't have multiple rows, its just one row with 100 columns)
    *nb_col = 100 (i have a 100 characters, so i guess thats 100 rows)",2
"To a large degree, I assume that comes from the performance
of Theano, but there will presumably be parts of Keras which could be
faster.",2
"Assumes weights are distributed independently of the dimensions of the weight tensors
      (i.e., the weights have the same distribution along each dimension).",2
"What I was thinking about, is that you pad your data before actually providing it to the model, then if a timestep is all-zeores then it is assumed to be padding.",2
"1) I assumed the inputs (X, y) are two matrices, and their timesteps axis (1) should be padded with zeroes (in X) and any value (in y, because we understand it's padding from X).",2
"I assumed X and y must be matrices, hence muse be padded before the model",2
"My patch made the first assumption, and I haven't tried the second.",2
"Assuming the weights are initialised the same, updates will be the same and weights are tied.",2
Let's assume you're missing (and thus masking to 0) all datapoints.,2
"For simplicity sake, assume the maxpool layer gets (2x2) as an input: `[[a,b],[j,k]]`.",2
Lets assume that `j>k>b>a`.,2
I assumed you were using an embedding layer.,2
"Assume I have a vocabulary of size nvocab, and all my sequences have length nseq.",2
Assume I have only one sample for simplicity.,2
"RMSE is a popular error metric as errors in the training data is assumed to be normally distributed according to the CLT, and so RMSE is the 'best' metric to minimize under those assumptions when you have real numbers not ordinals - at least in theory.",2
I am assuming you just have a lot of data.,2
"Of course, y1, y2, and y3, are a distribution of percentages (assuming your using a softmax).",2
"Though a standard encoder produces a single output, so connecting it to a time-distributed layer without a repeatVector should break your code (which I assume it doesn't, so something else must be going on)",2
Q. I assume the get_outputs function that (returns the outputs) feeds them to a dense (softmax) layer that makes the prediction ?,2
"Somewhere the length is being shortened, so I'm assuming my decoder has to take this into account....",2
- We got the thing running in our own framework at: https://github.com/RobGrimm/benchmark_hierarchical_softmax/blob/master/HierarchicalSoftmax.py but when we try to integrate it into keras we get indexing errors that suggest that we are making wrong assumptions about the format of the input batches.,2
I assume it is smaller because the model.predict is being used.,2
"Assume that we have a array x, and we choose k
 to be time step 0.",2
"If an output is not wrapped in a dictionary, scan will wrap it in one assuming that you use only the last step of the output (i.e. it makes your tap value list equal to [-1]).",2
"If not provided, uniform weights are assumed.",2
"Dimensions of input are assumed to be (nb_samples, dim).",2
"Convolution1D is usually applied to temporal data, like yours (assuming that you ""samples"" are in the temporal space, not the frequency space).",2
But I assume @jdwittenauer wrote those as temporary placeholders.,2
"# no inputs or outputs for this theano function, only updates, I'm assuming the whitening won't depend on the input, if it does just pass it in here",2
It seems to me that the positivity assumption is a reasonable thing to enforce here.,2
"I'm assuming you are familiar with Theano and Keras internals, if not, let know which part was not clear.",2
"So no, the validation data is not necessarily taken from every class and it is just the last 10% (assuming that you ask for 10%) of the data.",2
Also I don't really like it because it breaks the general assumption that layers are independent entities.,2
"EDIT: sorry re-read your post, assuming you mean that the issue is between this commit and master?",2
"Keras is not doing anything particularly fancy with Theano, so if Keras is broken I assume a lot of other Theano-code must be broken as well.",2
"It has no reason to assume that you want to reuse the same samples in separately generated sub-expressions, unless you explicitly tell it to.",2
This implementation assumes thread-safeness.,2
Hopefully that's a reasonable assumption?,2
So this seem a resonable assumption.,2
> This implementation assumes thread-safeness.,2
"Hopefully that's a reasonable
> assumption?",2
"Assuming that your power layer and addition layer implement the multi-io API (which is the Graph API, basically, because models/containers should have the same topological API as layers, for total compositionality), then the above will work fine.",2
"Suppose I want to identify a house no 5436 from an image and I assume every image will have max 4 digits, so one image will be tagged with 4 one hot vectors like 

[(0000010000), (0000100000), (0001000000), (0000001000)] and I pass this as a 2D matrix then will it give me probabilities for each element?",2
"Assuming there are two target labels out of seven for example, the neural network tries to predict top two posterior probabilities in the specific nodes, and the two probs are definitely the same.",2
"- use label vectors that are mostly zeros, with ones at the index of each class present in the input (default assumption is 0 == class is absent).",2
"Right now, Keras implicitly assumes the desired is either a matrix (samples x dim) or a tensor3 (samples x time x dim)",2
"Like, for example, lets assume the Dense layer",2
"Right now, Keras implicitly assumes the desired is either a matrix (samples x dim) or a tensor3 (samples x time x dim).",2
"Yes, that's true but assume training and prediction take place in different sessions.",2
"When no `inputs` argument is provided, the layer is assumed to be an input layer.",2
"I assume that if they were to be implemented in Keras, they would have an `outputs` property (being a `list` of `Layers`) just as `Graph` does?",2
I would assume that this is automatically inferred?,2
Assumedly you have more than a single MIDI file (otherwise you won't be learning much).,2
Thanks for giving proof to my assumption :),2
"There are assumptions in Keras that make it unsuitable for _certain_ types of research, and multi-dimensional RNNs in one of these cases.",2
"There are assumptions in Keras that make it unsuitable for certain types of research, and multi-dimensional RNNs in one of these cases.""",2
"I then only have to learn a (linear) mapping from 4096 dimensions to 300 dimensions, and feed the image and word vectors in a sequential manner to an LSTM, which then has a softmax layer on top (I am assuming a fixed set of possible answers, so it becomes a multi-class classification problem from vision and text data).",2
"The third one is the best option(Assuming  the word vectors were obtained from the same domain as the inputs to your  models. For e.g, if you are doing sentiment analysis on tweets, you should use GloVe vectors trained on tweets).",2
"The third one is the best option(Assuming the word vectors were obtained from the same domain as the inputs to your models. For e.g, if you are doing sentiment analysis on tweets, you should use GloVe vectors trained on tweets).",2
"This version assumes that the `pretrained_embeddings` array does not come with a mask first row, and explicitly make an all-zeros row for it here: `weights = np.vstack((np.zeros(dense_dim), pretrained_embeddings))`.",2
"What I would love to have, is the model assume a blank input or perhaps a vector of zeros, if no input is provided during the model.predict instead of throwing an error.",2
This instruction was added to the readme but not the setup.py (I'm assuming in hope that this fix will not be necessary when Theano is updated),2
"You want to move to the state of the parameter space (all network weights) that's optimal for your new dataset, under the assumption that you are already pretty close to that state, and therefore that you should be moving very slowly, at a small spatial scale.",2
"But assume that for the first sentence, the desired is only 10 ""seconds"" long.",2
Your RNN is a custom RNN i assume?,2
"You are a step away from the solution, just update to the latest keras i assume the problem is in the old dot implementation, i fixed it yesterday.",2
"For the sake of the example, assume all your attributes are numerical.",2
It's obvious that we have a dire need for better documentation and better failure UX in the codebase (assumption checking and helpful error messages).,2
"Padding is always on the left, or so we assume, but what happens in the backward pass of a bidirectional RNN?",2
"But this is very assumption-heavy: although in most cases the first element of the states list will be the last output, there is no guarantee that this would always be the case.",2
Assume that you have 1M words in your Embeddings matrix each time you back propagate you compute the updates for 1M Embeddings when most of the times only a few of them are seen in the batch examples.,2
"In fact it may cause problem when the previously unseen word is finally present, since It has an history of zeros updates the optimiser assumes that the weight is ""good"" so it is updated only a little or nothing at all.",2
"Assume 0, 1, 2, 3;",2
"Assumes that input has (M+2)*D dimensions, where D is the dimensionality 
  of the target data.",2
Assumes that y_pred has (M+2)*D dimensions and y_true has D dimensions.,2
"Assumes that input has (D+2)*M dimensions, where D is the dimensionality of the 
    target data.",2
Assumes that y_pred has (D+2)*M dimensions and y_true has D dimensions.,2
"Here is one thing about Keras, it always assume that your dimensions are `(samples, dim)` or `(samples, time, dim)`.",2
# For simplicity we assume the images are flattened.,2
# Assume it ends with a Fully-Connected layer,2
It's a Theano bug I assume.,2
"> strict enforcement of user input assumptions, and raising of helpful error messages.",2
"It assumes input is 3d, though the docstring implies that input can be 4d or more (which I suppose could happen with, e.g. time distributed image inputs), though I think that was already an issue with the `inputs = inputs.dimshuffle((1, 0, 2)` line.",2
#1282  Was written with the assumption that at least left padding works with RNNs.,2
"It used to assume (3,3) input but now it should be (1,1) rather than `(kernel_row-1)/2`.",2
So assuming you are doing 3 labels classification.,2
I assume that this wouldn't be so simple to fix this way :),2
"I assume that this wouldn't be so
> simple to fix this way :)",2
"I assume that then i can save the weights of the 1st Lstm's final state weigths using
m.layers[0].get_weights()",2
So I assume the 97.5% MemNN example could be optimized further to get to 100%.,2
# assuming Sequential model -- adapt it for Graph,2
"Assuming you are doing everything correctly, and you've found yourself in this situation, i'd suggest keeping track of the layer and then use .set_weights() once you are done doing everything else with it and ready to compile rather than using provided weights when you create the layer.",2
"Binary classification being the default is, as you said, your personal assumption.",2
And the examples do not "silently" assume anything.. the loss function is explicitly provided to the model's compile function.,2
So your statement from the blog "All the examples silently assume that you want to classify to categories" is not true.,2
"Assuming your iterator can be called multiple times, this should do what you want.",2
"We
would thus assume that there is a 1:1 mapping between units in the first p
axes of the network output, and units in the weight array.",2
@fchollet but we are still assuming the `sample_weights` are 1D https://github.com/fchollet/keras/blob/master/keras/models.py#L443,2
@EderSantana I think the only way to tackle that would be through a pretty strong assumption: weights ndim should be 2 if and only if output ndim is 3. Other weight ndim is 1.,2
Assuming the embedding is used to house word vectors...,2
Hey @jdelange - you're correct - this is assuming that you have a separate unseen test set.,2
1. Yes that assumption is implicit.,2
"If I comment the line `while 1`, it runs perfectly, but then it violates the assumption of infinite loop, doesn't it?",2
"This assumes you have a generator `sample_data` that takes the dataset as first argument, and another argument once=True to indicate that it should go through the dataset exactly once.",2
It looks like the error happens when utils.layer_utils.layer_from_config sets the custom objects in globals() assuming that they will be available to all downstream code.,2
"When you sum the mask for the average case, I assume that you want to take that sum across the time axis, so something like `return s / K.sum(mask, axis=1)`.",2
"I assume everyone uses Jupyter notebooks? (I'll make a regular .py version too, just in case.)",2
"so this is how it works , first your image gets divided into matrix , kernel 3*3 with 32 filters mean ,
the combination of filter maps you will get while multiplying the kernel size matrix i.e(3*3) with the matrix of your input let say image and let suppose stride=1 , so the filter maps will be consisting of the product of two with a difference of 1 stride(assumption).",2
"NB: I'm not making any arguments about whether this proxy is _good_ for optimization, just that it could be seen as an estimator of the AUC, under the predictions-are-class-probabilities assumption.",2
"> NB: I'm not making any arguments about whether this proxy is _good_ for
> optimization, just that it could be seen as an estimator of the AUC, under
> the predictions-are-class-probabilities assumption.",2
"And I get the same results for gradient descent if I don't provide a validation_data argument, assuming I choose to run the model past the test sets separately.",2
I don't think increasing the batch size even more is a way to go since that will take more epochs and will lead to overfitting (correct me if this assumption is wrong) and I've already noticed the reduction in performance metrics due to less weight updates per epoch.,2
I assume that prefetching parts of input data onto GPU as a macro-batch will decrease the overhead of transmitting data but as far as I am aware the only way to do this is through setting a constant tensor on GPU.,2
Please let me know if some of the assumptions I've made are wrong and I could try something else to increase the GPU utilization.,2
"This is assuming that you know what optimizer, loss function, and metric you used in your original model.",2
"It assume you use ""epochs"", but what if you train with randomly generated batches out of a data generator?",2
"Based on your approach and assuming the original fitting used the default `batch_size=32` and no `EarlyStopping`, I could infer the number of trained epochs as:

```
np.ceil(model.optimizer.iterations.numpy() / np.ceil(len(X_train) / batch_size))
```",2
"It assumes that the image sequences comes as batch x time x dim and does the reshaping of dim to image size inside the for loop, and reshapes everything back again to 3D in the output.",2
"While `model.fit` will make mini-batches that does not follow these assumptions (especially 2.). 
(edit: or do you actually assume we are learning to predict the value after `batch_size` time steps?)",2
I assume it means the code that Theano is generating has if statements nested too deeply.,2
"As one would assume, the training time for an online LSTM can be prohibitively slow.",2
In your situation I think it's assuming 99% accuracy because atleast 996/998 of the outputs are correct.,2
Assuming the code snippet you have posted is the complete one...,2
"If the changes in the weights are small enough, you wouldn't even need to reset the states of the prediction model when doing so (assuming that you are using a stateful model).",2
"Thanks @nouiz, if i'm not wrong this issue should be related to the incsubtensor that is usually used in the embedding layer to  do partial  gradient updates over the whole matrix (i don't remember if Keras does that, but i may assume it is).",2
"3. debug the py file with args_1 and args_2 being the same as the path in step 2 (for example, assume the path in step 2 is ""PATH"", then excute ""neural_style_transfer.py PATH PATH output_img"")",2
# assume we require 10 predictions,2
"I solved this problem by writing a custom accuracy function (assuming target labels are {-1,+1} )",2
"Yes, but I assume the same architecture would work whether it's one-hot vector or vectors with continuous values (I haven't used it on RNN layers but other types of layer work for both of them).",2
"Assume that you have the output of lambda merge that gives your the abs-diff, you could write a cost function like so:

``` python
def abs_diff_cost(y_true, y_pred):
    # y_true is just a place holder
    cost = K.mean(y_pred, axis=-1) + 0. * K.sum(y_true)  # this is for theano to think y_true is doing something
    return cost
```",2
"1) Assuming my classs weight distribution is e.g.  `class_weights=[ 0.85144055 ,  1.14855945]` What  should the`w_array` be like?",2
# Assuming sample_matlab_file.mat has 2 matrices A and B,2
This assumes that the training label images are stored as a single channel image with a number in range(n_classes) representing its class.,2
I assume everything's pass-by-reference and that the output tensors are after the activation function.,2
> I assume everything's pass-by-reference and that the output tensors are after the activation function,2
"I don't know if that'll mean anything for you in this instance, but I thought you should have it pointed out because the code generally assumes that the loss isn't mean'ed yet when it runs your function:
https://github.com/fchollet/keras/blob/master/keras/engine/training.py#L309",2
I'd recommend anyone to go right back to their data and don't make any assumptions or take anything for granted.,2
Batch Normalization assumes that a mini-batch is representative of the data set as a whole.,2
"Currently an assumption is made that slot variables have the same dtype as the variable, which prevents experimentation.",2
"In short what I want to do is something similar to (this is assuming batch-by-batch):

`W = get_weights(y_train) # 2D matrix same as y_train (n_samples x n_labels)`

`def my_loss(y_true, y_pred):`
      `score = K.binary_crossentropy(y_true, y_pred)`
      `score *= W`
      `return K.mean(score, axis=-1)`",2
2. Accuracy as a metric is assuming probabilities.,2
Keras assumes that you have Tensorflow installed.,2
"> Thinking of all of this, I feel like the basic assumption that a loss function MUST reduce at least one dimension is pointless.",2
"Thinking of all of this, I feel like the basic assumption that a loss function _MUST_ reduce at least one dimension is pointless; and as far as I understand, it is not required to ""make the sample weights work"", as the documentation states that broadcasting is also possible:

> If the shape of sample_weight is [batch_size, d0, .. dN-1] **(or can be broadcasted to this shape)**, then each loss element of y_pred is scaled by the corresponding value of sample_weight. (Note on dN-1: all loss functions reduce by 1 dimension, usually axis=-1.)",2
I assume these layers should raise an exception when the shape is 0.,2
"In your gist, the variable dir_path is not defined; it should contain the path to the directory containing the subfolders listed in class_names (which contains the pictures); I don't know how to share with you sudden directory, but I assume you can use any directory from your gdrive containing subfolders containing images.",2
Not mentioning that I'm assuming that `_name` will be available and writable.,2
Closing this issue due to lack of recent activity & assuming this issue as resolved .,2
"I assume you are referring to this:
> loss: Scalar tensor to minimize.",2
# Assume we already have an RDD called my_rdd with the desired information,2
Assuming post padding and int32 data type.,2
"LSTM accept 3D input, and (i assume that X is the input) the dimension of the X is only 2D.",2
I assume there is suppose to be an implicit save after fit_generator ran?,2
"Specifically it is like so in the log file I linked in my previous comment, so I carefully assume it is like so in all build logs that failed.",2
Assumed solved.,2
"So, my assumption was the problem might be related to Kaggle's GPU (TESLA P100) and its Cuda version for `tf 2.4.1`, not sure though.",2
Initial assumption was that once it emits last value in `seq` it immediately calls `seq.on_poch_end()`.,2
"Update: my implementation makes the assumption that `number of timesteps >= len(y_true) * 2 + 1` which the original CTC paper also makes, but I am unsure if Graves actually implemented it with that assumption.",2
"This would generally not affect any real world problems, where len(y_true) is generally pretty small and the number of timesteps is generally pretty large (at least to the point of fulfilling the assumption).",2
"Baidu's open source warp-ctc is probably the gold standard as far as performance goes, and they may have required that assumption in order to get it to work.",2
"But from the other comments above I assumed, that Keras really resets the optimizer when the model is saved/loaded.",2
"I think this issue arose because the shape of the data in the documentation is not revealed, and it assumes your data is in the correct shape.",2
"Which is probably not an issue of the documentation, but is an assumption it makes to where you can't just pass it any dataset and expect it to work.",2
You can do this by doing `word_index = imdb.get_word_index()` (assuming you've already done `from keras.datasets import imdb`).,2
"Furthermore, the traceback already reveals that only the first (I assume it's the first) element (image1, class1) is reaching the model:
```
    ValueError: Layer ""model_3"" expects 3 input(s), but it received 2 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(64, 64, 3) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(1,) dtype=float32>]
```",2
I have naively assumed the Layer class can deduce the ordering of the data in my tensors.,2
It seems the Convolution2D assumes _Tehano_ style data ordering by default.,2
"In this case the output of the function will be assumed to consist of
    `tf.Tensor` objects with the types defined by `output_types` and with the
    shapes which are either unknown or defined by `output_shapes`.",2
"- I am working under the assumption that the library should work equally under windows and linux, since both backends are available for both platforms (but I studied the behaviour under linux to see if at least there it works).",2
"- I also assume that the specific order in which the generator produces the batches is important and should not be altered neither by reordering the batches, nor by doubling/cloning batches when these are enqueued.",2
"This already breaks my first assumption, but I'll put windows aside for a moment and look at what happens in Linux.",2
"The current ""RNN"" api implementation in cntk_backend is kind of compromise to Keras api, base on the assumption that the last states is the output.",2
"For example, which layer has the name ""discriminator"" ? (I assume it's the output but would be good to be sure.)",2
Then restart and use that saved model for predictions. ( Assuming you are only doing predictions ),2
> Then restart and use that saved model for predictions. ( Assuming you are only doing predictions ),2
"That should yield an array of size `38000 x K`, where `K` is the number of classes your model has, assuming it is a multi-class classifier you are running inference with.",2
"Assuming you assign 1 to be dog and 0 to be cat, you can implement it in 2 ways.",2
"I assumed it had to do with eager_execution, but that doesnt seem to be it.",2
@svdHero I assume you're using TF.Keras and not Keras.,2
"In this case I would suggest... assuming that the data fits in memory, and simply extracting the data by iterating once over the dataset, then doing the split, then repackaging the output value as two Datasets.",2
"In your case you want to track model configuration and model state, rather than instance identity, and you're making the assumption that model state can only be changed via `compile()` or `fit()` (perhaps this is the case in your code, but in the general case there are many ways to modify model state, e.g. `model.layers[N].kernel.assign(V)`).",2
I assume this has not been addressed and it's still an issue present in tf 2.11?,2
"# Check input assumptions set after layer building, e.g. input",2
"As you can see, `self.compiled_metrics.update_state` assumes multiple complied_metrics will use the same `y, y_pred` as input, which doesn't work for multi-output model using multiple losses and metrics for each output.",2
I assume that many users will construct the optimizer directly when calling `model.compile()` and the docs do so in many places too.,2
"Normalizing the vector is still required to calculate the proper cross-entropy, and assuming the inputs are logits simply because they don't sum up to 1 will also result in a wrong result.",2
"The problem here is the assumption that a device with the `GPU` type is necessarily a `CUDA` or `ROCM` device, which isn't necessarily true anymore when pluggable devices are used.",2
Though I assume that the `keras.optimizers.Adam` should be able to handle multi-output models.,2
I assume your keras model `maskNet` only takes 1 image as input.,2
Because it says **converted** I think one would assume that it converts a jpg image to have a 4 channel.,2
The optimizer has a properly set `_iterations` (debunking my assumption from above) but the MultiOptimizer hasn't,2
"This is an issue with Sequential models, where they will essentially assume that any layer can be traced with a an input matching the layer's dtype.",2
"Anyway, the end goal here should be to fix tracing inside the Sequential model so it does not make invalid assumptions about input types.",2
"This assumes that the step_function does not have any side effect, but in practice that isn't the case when `add_loss` is used.",2
"Thus, it is assumed that there will be no need to tweak the internal code.",2
"So - basically - you may assume that all numbers presented in your example are equal in terms of a float32 representation.
> \- [Marcin Mo?ejko](http://stackoverflow.com/users/5974433/marcin-mo%c5%bcejko)",2
"> Assuming this is an underflow problem, why does setting `shuffle=True` cause the inconsistency while setting `shuffle=False` doesn't?",2
"It appears that the code assumes it is sorted in topological order, but something about the way this particular model is built causes it to be out of order.",2
"That bug has a cyclic structure in the graph, and Keras assumes DAGs.",2
I assume this is somehow related to the add_loss(loss) instead of regular compile(loss='...'...) and y being None.,2
But the callback `on_batch_end` assumes a single value.,2
"Nonetheless, pedantry compels me to mention that there are valid *networks* that possess cycles, although not networks in the sense we assume usually in keras - e.g. Boltzmann machines are represented by undirected graphs.",2
"However, it doesn't check whether the y array has shape (nsamples, 1), because it assumes that with a one-dimensional array, the y array has shape (nsamples,).",2
This specific issue is due to the example being written under the assumption `image_dim_ordering="th"` (it should be made compatible with both modes).,2
"From the generator method, I'm thinking about using, [from sklearn.utils import shuffle](http://scikit-learn.org/stable/modules/generated/sklearn.utils.shuffle.html) which, i'm assuming will shuffle each batch before feeding it to fit_generator() method.",2
I assumed the problem was with Keras itself but it was just dependency conflicts in my project folder.,2
"This assumes a one-to-one mapping
        between samples in different successive batches.",2
The above code can do what I want but assumes that I know what all type of possible layers can be and also what all parameters in them might ever have any input other than the default values.,2
"Additionally, It also assumes a certain relation between the layer name and its type, but we can skip that for now (I know how to solve that, I just haven't gotten to it yet).",2
"Memory usage should not be affected by the dataset size, that's what `batch_size` is for, assuming you're not loading the full dataset into memory, otherwise you have to modify your code to load dataset in batches using [generators](https://wiki.python.org/moin/Generators) or [tfrecords](https://www.tensorflow.org/tutorials/load_data/tfrecord).",2
> I assume this is related to having convolution operations inside a scan.,2
"I assume I must be using the functional API wrong, but I'm not sure why this would not be differentiable?",2
"@jayshah19949596 It was working for me for any batch sizes, I didn't check if there was multiple workers for the generators but I assume it was fine.",2
"If np.random.seed and Theano rgn (I assume RandomStreams) are independent, then when I run the same example without masking many times I shouldn't get the same results due to Theano random initializations.",2
"I've just assumed it's going to be low enough velocity that we can add users in by hand. (The email has a link for users to unsubscribe, though)",2
"2. The KC model I was implicitly assuming, on reflection, seem to be different - A bunch of different packages, each with their own `setup.py` to specify their own version dependencies that happen to be in the same repo.",2
"The assumption is that all contributions are properly documented, and the community will be able to pick up where the original contributor left off.",2
"The assumption is that all contributions
> are properly documented, and the community will be able to pick up where
> the original contributor left off.",2
@tetmin You are assuming that `X_train` and `Y_train` could be loaded into memory at once.,2
"By the way, I wrote wrapper-like class that distributes over the last 2 dimensions of a tensor of 4 dimensions or larger with the assumption that the provided layer will reduce the last 2 dimensions to 1 (such as an RNN that only returns the last output).",2
"@hkristof03,
If you are talking about the regular case, where your network produces only one output, then your assumption is correct.",2
"Note that I'm assuming `image_dim_ordering: 'tf'`, meaning that the image channel is the last dimension.",2
"> If you want variable sizes use None, like (note that I'm assuming image_dim_ordering:
> 'tf'):
> 
> import numpy as npfrom keras.models import Modelfrom keras.layers import Input, Conv2D
> 
> i = Input((None, None, 1))
> o = Conv2D(1, 3, 3)(i)
> model = Model(i, o)
> model.compile('sgd', 'mse')
> print(model.predict(np.random.rand(1, 10, 10, 1)))print(model.predict(np.random.rand(1, 32, 16, 1)))",2
@gabrieldemarmiesse I'm not sure it's a good idea to assume it's the same error.,2
"Some people will suggest you the following code (Assuming you are using keras)

from keras import backend as K
K.clear_session()",2
Am I correct in assuming that the generator has to return the data in batches in order for fit_generator() to batch train?,2
"Now, assuming that they won't do it soon (which they actually might since they've done a first step by supporting a subset of popular frameworks and it's still early in CoreML days) I'm looking for the best way forward.",2
I assume you need to figure out the values that each loss typically take and then assign weights accordingly.,2
"By setting validation_steps to be a relatively large number, I assume that validation_generator will keep randomly repeat validation data, will that still make the validation accurate?",2
"The utility is based on the following assumptions:

 * Each model replica maintains its own state
 * Batches can deterministically be split over multiple GPUs:  
    - each sub-batch is always processed on the same GPU,
    - outputs from the different replica's are always combined in the same, correct, order,
    - samples is sub-batches always maintain their order",2
"Assuming that I am expecting an output of 20 words, a one hot encoded Y becomes [vocab_size, max_output_words]. Is this correct?",2
"Assuming, that each y_i belongs to exactly one class, say: C_{y_i}, then we can write: 
<img width=""318"" alt=""Screenshot 2019-03-16 at 17 22 03"" src=""https://user-images.githubusercontent.com/9467089/54478217-0e69c480-4810-11e9-92f0-c7c9e3e01486.png"">",2
I assume it should be universal.,2
I assume you've already built that equivalent model in Keras:,2
"Assuming that you have a GAN setup where you
1. Create and compile the `discriminator`
2. Create the `generator`
3. Set `discriminator.trainable = False`
4. Create a `combined` model from the `generator` and the `discriminator` and compile it",2
"Concerning the warning itself, its presence assumes that `trainable` **must** be set before calling `compile`, whereas `trainable` is not an argument of the `compile` function.",2
"Yeah the Tokenizer class seems to have been written under the assumption that you'll be using it with an [Embedding layer](https://keras.io/layers/embeddings/#embedding), where the Embedding layer expects `input_dim` to be vocab size + 1.",2
**caveat**: It assumes that `.fit` on each of the transformers mutates the transformer itself.,2
"'We assume this was done on purpose, '
                                  'and we will not be expecting '
                                  'any data to be passed to ""' + name +
                                  '"" during training.'",2
Here I assume mmd_discriminator returns the value that is stored in `y_pred`,2
@fchollet Also I think current dynamic loop implementation assumes too much about the input and state shapes.,2
"It assumes that states are always 2D, and input sequences are always 3D.",2
It also assumes that all states have same first dim (batch size).,2
I assume some filename needs to go into where it says `__file__`?,2
"I assume when you already have TensorFlow 1.8.0 in your environment, installing 
nightly build into same environment would cause conflicts if we want to use an older version of TF later since the Python import command does not allow us to specify a desired TensorFlow version to use, correct?",2
#Assuming that this is your model architecture.,2
I can assume that you did not divided the network as it must be.,2
But they mention in the tutorial that the layer can inspect the input shape ( assum that I assign axis to None).,2
> But they mention in the tutorial that the layer can inspect the input shape ( assum that I assign axis to None).,2
I would say that the modeling assumptions of both approaches are different.,2
"In the later model, it is assumed that the model sees the complete input sequence (first 50 steps), somehow creates a summary and uses this summary to generate a new signal (last 10 steps).",2
I assume that the code that contains `RepeatVector()` is represented by variant 4 and that the code that does not contains `RepeatVector()` is represented by variant 5.,2
"I'm assuming the problem comes from the output shape becoming (None, None) after the Flatten layer.",2
"So at this point I am going to assume it's not a discrepancy in how the activation functions are computed, and that's what makes all of this so odd, we're talking about the forward pass for a very simple neural network of two Dense layers, an input and an output.",2
I guess in this case keras just assume those basic operators (`__add__`) have similar broadcasting behavior in both theano and tensorflow.,2
"I'm not sure, but I think the example assumes that `data` and `labels` are prepared elsewhere to concentrate on the functional API.",2
"Also can you please try the workaround for solving inverse kinematics using a neural network, assuming 2D environment, a robot arm with 2 segments, each of length 1.",2
# assuming theta is already in radian,2
"I assume, that the shape calcluation for DepthwiseConv2D will not differ from normal convolution, since only the filter dimension will be overwritten.",2
"@zaid478 oh, I assumed you were doing it on coursera.",2
"> @zaid478 oh, I assumed you were doing it on coursera.",2
I'm assuming so.,2
"But of course, this is based on some a priori knowledge of the system and can not always be assumed.",2
"assume y_pred and y_true have shape: (BATCH_SIZE, N_CHANNELS, H, W).
(this could be an output of a CNN after applying many conv layers).",2
"From this point I assume you have a single sample in your batch
(BATCH_SIZE=1).",2
"> assume y_pred and y_true have shape: (BATCH_SIZE, N_CHANNELS, H, W).
> (this could be an output of a CNN after applying many conv layers).",2
"> From this point I assume you have a single sample in your batch
> (BATCH_SIZE=1).",2
"I need to clone repo into specific directory, ""cd"" into it and then call this command, i assume (according to [docs]([url]%28https://github.com/fchollet/keras%29)):

```
sudo python setup.py install
```",2
"> I need to clone repo into specific directory, ""cd"" into it and then call
> this command, i assume (according to docs):
> 
> sudo python setup.py install
>",2
"for instance, assuming `true_repeated` is on a support set of [0,1]:

``` python
np.clip(true_repeated, 1e-8, 1.-1e-8)
```",2
"I am not able to understand where `states` is getting updated in whole code, as per code above you are assuming  length of states = 4",2
"- `*states` is a python trick that disguises what is actually going on; I'll explain that in a minute. but for now, just assume that the correct number of states are passed in here",2
The fundamental issue seems to be that Keras (at least the TF backend) assumes all Tensors passed in the states variable are of equal rank.,2
It's not immediately obvious what their recurrent steps assume about how variables change.,2
Am assuming there is no need to change the 'concatenate' and 'Reshape' layers to Lambda layers as well?,2
My initial assumption was to use the `transposedconv` or `deconv` layers.,2
I assumed my API knowledge was lacking.,2
"This way of modelling assumes that you can get a compact representation of the video frames for each frame independently, and then see the sequence of that compact data and draw temporal conclusions from that.",2
"Assuming the layers that output `reconstruction` and `latent_variable` are called `reconstruction` and `latent_variable` you can then define the loss as a dictionary:

`all_losses = {'reconstruction': 'mse', 'latent_variable': CustomKL}`",2
"Assuming you want to cross correlate the 3 numbers (i.e. allow the network
to look for patterns between the numbers) you want to input them as
'features', so your input shape (X) would be

X.shape = (n, m, 3) where n is the number of predictions and m is the
number of timesteps before each prediction

and output shape (Y) would be

Y.shape = (n, 3) again with n being the number of predictions.",2
"The assumption in these lines of code is that if the input is a list, then the input is the first element in the list, and the following items are the initial state (even if the initial_state is specified explicitly).",2
For some reason I just assumed that you need to call multiprocessing.,2
As your code ran successfully so I assume you might have changed the name 'test_generator' to 'validation_generator' in your 1st block of code later after the code run.,2
"# 32 floats -> compression factor 24.5, assuming the input is 784 floats",2
I assume you used train_datagen = ImageDataGenerator() before.,2
"The evaluation is the same as the end of first training, so I assume that attaching the new sequential model (Added_layers) to the base models (inception3 or resnet50) is not wrong, otherwise the evaluation should not give expected answer.",2
Is that a correct assumption?,2
"Usually, the order of files (based on their filenames) is assumed and the labels are stored (for instance all in a CSV file) following the exact same order as filenames.",2
"> Yes, that's true but assume training and prediction take place in different sessions.",2
"To more specifically,
`inter_output_model = keras.Model(model.input, model.get_layer(index = 3).output )` assuming the intermedia layer is indexed at 3.",2
"Are there any disadvantages to this method, assuming that the training generator simply continues where it has left off the previous epoch and randomizes again if all the data has been seen?",2
"First dim is assumed, so input_shape must have 2 entries for the LSTM.",2
"However, if I understand correctly, it seems that you are reading frames_per_step images assuming that all of the images are stored consecutively and that each instance has the same number of timesteps.",2
"I assume that the checkpoint writes the weights into a column named ""leaky"" and since there are two with the exact same name, it gets confused.",2
"And I assume it's 0-1-scaled, so acc * 100 is percent?",2
"let's assume you have a 3 Element data line in a file separated by spaces,
     plus a 1 element for the result: 1 2 3 7",2
My assumption that categorical_crossentropy models to binary output was wrong.,2
"I don't believe this is possible because you probably want to learn batches of sequences at once (for computational efficiency) and you would not expect the special words with fixed input gate weights to show up at the same time steps throughout all your sequences, I assume?",2
2. I assume your plots show epochs horizontally?,2
Assume that 3 images and 4 captions have label 0(negative sentiment) and 2 images and 6 captions have label 1(positive sentiment).,2
"Assuming `y_train` and `y_trainSC` are Numpy arrays, do this:
`sum_vector = np.array(y_train.astype(bool) + y_trainSC.astype(bool), dtype=int)`",2
"link attached --

https://stackoverflow.com/questions/57216216/keras-multitask-learning-with-two-different-input-sample-size

is is not mentioned but I would assume that up to the point the samples are equal...",2
Am I right in assuming this?,2
"On a side note, am I right in assuming that model.input[0] = input_layer.input = input_layer.output?",2
"This is not reproducible since it assumes a specific directory with specific content, as well as a weights file.",2
Let me know if there is anything wrong in my assumptions above.,2
I also assume that a stateless model performs a simulation on the input sequence for each prediction.,2
"Assume a single-layer LSTM as follows:
batch size = 100
time steps = 10 
inputs = 3 
outputs = 2
1 hidden LSTM layer = 6 nodes
1 Dense layer = 2 nodes (= outputs)",2
"I assume my custom layer is not outputting it's shape properly, for some reason.",2
"Which I assume is the root of the problem, the Model not being able to guess the output shape of the custom layer when using the Functional API",2
"My guess is that your default `image_data_format` in `~/.keras/keras.json` is set to ""channels_first"", whereas your data in your example assumes ""channels_last"".",2
"To answer the question about why the accuracy graph for model2 looks the way it does: I assume the large learning rate has pushed the model to either a) a very poor local minimum (returning 50%) accuracy or b) an unstable state to a NaN, inf, or similar state caused by gradient explosion.",2
"I assume you saved the weights with `save_weights`, which outputs to one file, even for a GPU parallel model.",2
"Let's take your example, let's assume that you use a `keras.utils.Sequence`, but generators are similars.",2
"I assume this means that the current implementation is, at the very least, supported.",2
# the filters that have the highest loss are assumed to be better-looking.,2
"I'm not getting any errors like the OP but I assume it's still computing the average with the zeros, correct?",2
"@Qululu Yes, your padding looks right assuming that `word_idxs` is something like `[[1,2,3],[4,2,1],...]`",2
Keras will assume that the losses correspond 1:1 with the losses.,2
"Just find out shape of each step outputted tensor, then memory is just product of all shape dimensions \* batch_size \* 4 (assuming float32), so you should be able to see which step takes all the memory.",2
Yep I assume that fixes it.,2
There are many mistakes in your assumption.,2
There are many ways to solve your problem but I will assume this based on your input.,2
## assuming dataset is an array of arrays of words.,2
"It makes the assumption that filter shape and subsampling strides are equal, and that the filter is valid for the image shape.",2
"With this assumption, the filters cover all the image without overlapping.",2
"And a 'sequence' is '[[1,2,3,4,5], [2,3,4,5,6]]' I assume.",2
"So, one would assume that loss during the training and the model evaluation afterwards should be the same, because there is only one sample that causes a loss in one batch, but this isn't true.",2
"You could assume the fully-connected layers have as many multiplications as weights (plus bias), and that the pooling layers have none.",2
"I would assume that the structure of y_pred will mirror the structure that you give the model from y_true, but I don't know.",2
"> I would assume that the structure of y_pred will mirror the structure that you give the model from y_true, but I don't know.",2
# we assume each batch has sequences of same length,2
Edit: this assumes that your output is an image.,2
So I assume predict did the backpropagation.,2
"But let's 
assume that you are predicting a 'class' of animal, as one of four leg / 
human or ape / bird / fish.",2
"@Ezereal , Assuming you are utilizing a TensorFlow backend, you can utilize the official benchmarks:
https://www.tensorflow.org/guide/performance/benchmarks",2
"I didn't find it mentioned anywhere in the docs though, and having used sklearn for long, I just assumed `y` to be one dimensional.",2
"Assuming you have an array `class_weights` where the index is the class and the value at each index is the weight, you can simply add the following in the batch generation:
`...`
`sample_weights = numpy.take(class_weights, y[:, :, 0])`
`return X, y, sample_weights`",2
"I assume that by this arrangement, tensorflow/keras will use the weights as expected.",2
"Assuming you have an array `class_weights` where the index is the class and the value at each index is the weight, you can simply add the following in the batch generation:
> `...`
> `sample_weights = numpy.take(class_weights, y[:, :, 0])`
> `return X, y, sample_weights`",2
"The original code is a bit different, but let's assume the example below demonstrates my suggestions for an output with 5 classes, where the first output is has the weight of 5.",2
set_shape is a setter method which will assign the given value as the shape attribute (assuming other requirements of set_shape method  satisfied) without returning.,2
"I assume mu and sigma is calculated from a Dense Layer, where sigma  is calculated from `sigma = exponential(sigma)` or similar.",2
I assume the performance of time_steps==1 will be worse than n time steps?,2
"That is often true, but not always. (I assume 'currently' refers to Theano 0.8.2.)",2
Sorry I assumed that you're using `tensorflow` backend and didn't notice you're using `cntk` backend.,2
"Assuming that something like the above is correct, which is not but assuming then what is the next step?",2
But it broke the Tensorboard callback (which seems to assume that all layers return one tensor).,2
"@vqdang The TensorBoard callback was trying to create a histogram of the outputs of each layer, and I believe it assumes that all layers generate one output (or similarly shaped outputs).",2
I assume you are using categorical_crossentropy?,2
Let's assume the problem of "Query-doc" relevancy and in that X can be one query and we can have multiple Ys (each of them representation one doc).,2
"Thus you assume some knowledge into the model, I assume two independent object has n features that might interact effect on the final output.",2
"Assuming input tensor shape is (batch_size,  n, 1), required tensor shape is (batch_size, n, n)
```python
Lambda(lambda x: K.batch_dot(x, x, axes=(2, 2)), output_shape=lambda s: (s[0], s[1], s[1]))
```
P.S not tested",2
Let's assume a person segmentation problem.,2
Assume image A has 1 person and image B has 5 persons; and my training data has an average of 4-6 persons in the image.,2
I've assumed that the margin should behave as a threshold for deciding whether two pairs are the same.,2
"You can do this -
If your custom layer's name is XYZ and I assume you have imported this XYZ layer in your project

import XYZ
///your whole code///
model = load_model('model.h5', custom_objects={'XYZ' : XYZ})",2
I assume you have an outdated version.,2
"For the final layer: `model.add(Dense(10))` 
I assume it means it has 10 output classes.",2
It is generally a reasonable assumption that all GPU devices on a machine have the same capabilities.,2
I assume that `y_true` and `y_pred` are tensors in the form of the model's output shape.,2
I am assuming this was got resolved already.,2
"It has been a while since I did this, but as I recall the problem was related to the fact that the output of my network was a vector while `loss='mse'` assumes that output (and the target function network output is compared against) are scalers, i.e., `cost = 1/N \sum_i (y^i_target - y^i_pred)^2`.",2
Due to the fact that the batch_size was not a divisor of number_of_samples I assume it took different samples to fill in the last step.,2
"After some research, I assume this was because the Tokenizer assigns different ids to different tokens unless they are trained on exactly the same dataset.",2
So I assume this problem with optimizers is very specific to the way I am training my network.,2
"@joelthchao Im assuming this isn't an issue with the combine_generator yield, but can't think of anything else.",2
"This debate aside, back to @zhxiaoq9's original question, one solution if you want to constrain your model's output to integers is to look into [one-hot encodings](https://en.wikipedia.org/wiki/One-hot) and use [softmax](https://en.wikipedia.org/wiki/Softmax_function) and assume the largest output represents ""on"".",2
"So instead of using one hot vector for the Labels (which would need a lot of computer memory, i.e. , if I use one hot vectors for Labels in my 100000 training examples  :: 100000 * 5000  , assuming 5000 classes ==> Memory Error).",2
- this is assuming you're currently doing the "later" part as load weights before adhoc array change.,2
"In addition, by suggesting ` axis=[1,2,3]`, I guess you're assuming a 4D Tensorflow Tensor of size `(Batch, Height, Width, Channels)`, right?",2
"- the implicit assumption of `to_categorical` is that `y` is a class vector, which means `y` should only contains elements in `[0, 1, ..., num_classes-1 ]`.",2
"# assume that y_true will be all zeros [0,0,0, .. ]",2
"I'm going to take a wild swing as assume you're using ```keras.preprocessing.image``` to vectorise your data, if so according to https://github.com/fchollet/keras/blob/master/keras/preprocessing/image.py#L321-L365 - the data is resized using bilinear interpolation by default.",2
"Note, I am not sure about exact split, the refrenced example [Keras applications](https://keras.io/applications/) suggests a split 0-172 (where 172 is not included), but I would assume that the merge block (mixed8) at 172 should be included in the bottom part to create a logical model termination?",2
-- and you can assume those two sequential models as layers and use the output tensors of those models as an input if merge layer.,2
So I don't think we can assume outputs of `left` and `right` as tensors and use it in `merge`.,2
"I assume each Embedding layer will be here as separate input, or I am incorrect.",2
"You called me rude and irritating for pointing out a mistake in your code? (assuming @jdelange is in your team), What did you expect?",2
"Assume the batch_input tensor represents a batch of video frames, the basic idea is that I want to use the base_model to process each frame first and then do some recurrent thing.",2
"You can try something like `tf.eye(D.shape[0])`, assuming `D` is a `tf.Tensor` or something.",2
"I assume everyone else in this thread was missing the `custom_object` argument, since your bug is completely specific to your own code.",2
# assumed to be generator,2
"Assuming that you want to split the data into sequences of 5 time steps you will need to do something like the following:
`X_data = X_data.reshape((20000,5,30))`",2
"Assuming that you want to split the data into sequences of 5 time steps you will need to do something like the following:
> `X_data = X_data.reshape((20000,5,30))`",2
I assume train_on_batch is similar to training on a single given batch for a single epoch.,2
"It seems many users used to use .summary() to check trainable weights count (though it was a bug, it was assumed to be the expected behavior).",2
"Also, let us assume the following pseudo-code for constructing and compiling the models:
1) Construct D
1a) Compile D
2) Construct G
3) Set D.trainable = False
4) Stack G and D, to construct GAN
4a) Compile GAN",2
"I assume your current Model is deleted when you clear the session, and re-initialized when running `evaluate()`.",2
.... assuming the model is loaded successfully,2
That assumes model is already defined with all its layers and initializers.,2
#assumed it returns the model of resnet,2
Assuming that you have already installed cuda correctly on your pc.,2
"Assuming the output of both generators is of the form (x,y) and the wanted output is of the form ([x1, x2], y1):

```python

def format_gen_outputs(gen1,gen2):
    x1 = gen1[0]
    x2 = gen2[0]
    y1 = gen1[1]
    return [x1, x2], y1

combo_gen = map(format_gen_outputs, gen1, gen2)",2
"I have not tried this, but it might work: Assuming your top-level layer is an LSTM that has return_sequences=False, you could train the model, save the weights, and then load them into a model that is identical, but has return_sequences=True in the top level LSTM.",2
"The documentation for Masking indicates that the timesteps are skipped, which I assumed means ""has no effect"", not just mapped to zero and propagated forward",2
I assume your outputs are a softmax over classes.,2
We can't really assume that it's a keras bug unless you know what is going on or that you can provide a minimal example with a very small network to reproduce the bug.,2
"For batchnorm, I heard about it but since it was never mentioned in the tutorials I followed, I assumed it's better not to.",2
"Firstly you want to flip / mirror your matrix (assuming that is how you represent the list of lists) to give you:

```
arr1_mirrored=[
[1,2,3,4,5,6,7,8,9,10], [1,2,3,4,5,6,7,8,9,10], [1,2,3,4,5,6,7,8,9,10], [1,2,3,4,5,6,7,8,9,10], [1,2,3,4,5,6,7,8,9,10],  .... more
[2,3,4,5,6,7,8,9,10,11],[2,3,4,5,6,7,8,9,10,11],[2,3,4,5,6,7,8,9,10,11],[2,3,4,5,6,7,8,9,10,11] .... more
[3,4,5,6,7,8,9,10,11,12], [3,4,5,6,7,8,9,10,11,12], [3,4,5,6,7,8,9,10,11,12], [3,4,5,6,7,8,9,10,11,12].... more
..... more
]

```
And then run a flatten across the numpy arrays to give you a single array for the rows of the matrix?",2
I assume the test set in this instance is just the batch?,2
"My assumption was, that the results would kind of be the same, because of the total same amount of epochs being passed.",2
"Also the documentation is a bit misleading, a zoom >1 minifies the resulted image, not magnifies it as I assumed.",2
"It relies on model.layers having constant ordering even after model load, which I assume it has.",2
"I did some experiments which didn't disprove this and checked the source at obvious places which might break this assumption, it looked good to me.",2
"I thought you had located the problem and I assumed that I had simply misread the stacktrace which pointed to the sampling part of the program (I read the last line and probably mistakenly attributed it to Keras which is very new to me), so I ran it again unmodified and reproduced the problem, but then I made the change to the sample method as you suggested by changing:

preds = np.log(preds) / temperature

to:

preds = np.log(preds.clip(min=0.0000000001)) / temperature

but it again failed with the following stacktrace, which is strangely less deep than the previous run I posted above.",2
"I assume you use the Theano version from github, not PyPI (sudo pip install git+git://github.com/Theano/Theano.git).",2
"Let us assume your training file was nn.py, and you are loading the trained model in test_nn.py",2
I assume this was resolved in recent TF version.,2
"The bug most likely starts in Line 109 `build()` function of `PReLU` class of file `advanced_activations.py` line
```
        param_shape = list(input_shape[1:])
```
which assumes that one the first position will contain `None` representing batch size, however for a greater tensor that has `None` at index 1 will let this being passed further resulting in `TypeError",2
"However, there is some subtle difference here - on NLP tasks, we can assume the input shape is 3D: [batch_size, sequence_length, feature_size], so we can use [tf.keras.layers.MultiHeadAttention](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MultiHeadAttention) to simplify the implementation and make it very readable.",2
"But I still think this might be a bug, since the Lambda layer assumes numpy inputs to be scalars.",2
"Now, natively I would assume I could directly use this dictionary for training if I just remember that my NN should encounter shuffled data, so I would specify `mymodel.fit(in_tensor_dict, outcome, shuffle=True, epochs= e)`.",2
I find this very counter-intuitive as I explicitly specified `shuffle=True` and so assume shuffling.,2
"The latter assumes that your model has not so many degrees of freedom, that it can ever learn to distinguish each data-point individually.",2
"So, in my case, step 1 takes about 0.4 secs (of which unpickling is the main part, assuming the queue is not empty) and step 2 takes about the same.",2
"Calling q.get() to fetch (and I assume, unpickle) a [128,3,224,224] numpy float array (72Mb) takes about 0.25 seconds on an otherwise mostly idle machine.",2
"As for loss, if you have some weights for losses as in how much should each contribute to the total loss(let's assume it is x:y, where x+y=1)",2
"I assume the intended use case for having load and save functions in Keras has more to do with being able to share pretrained models like people do with Caffe, rather than it being for pausing your own training, in which pickling is probably safer.",2
"# if it has an optimizer, the model is assumed to be compiled",2
"@titu1994 
Good catch :+1: 

Might want to confirm that this swap holds from TensorFlow -> Theano (I looked at this direction for my original code) as well as Theano -> TensorFlow (I'm assuming you tested this direction).",2
- Changed the `samples_per_epoch` to what I assume is the correct value.,2
"You are correct in assuming that stacks of multiple deconv layers with same number of filters actually learns less than UpSampling + Convolution, at least in some circumstances (with skip connections).",2
"@alxy Thanks for the suggestion, but that's assuming you know the size of the incoming tensor.",2
Let’s assume we either learn these word embeddings in the model from scratch or we update those pre-trained ones which are fed into the first layer of the current model.,2
Let's assume we have built two columns of networks in keras and these two columns are exactly the same which will merge together on their top and then feed into a dense layer which is the output layer in the model.,2
"To make it more clear, assume we have this set of vocabulary words in the language/application: {'_bar_', '_foo_', '_baz_', '_qux_'}.",2
"In our case, let's assume we consider the length of the given input to be 10 words (another hyperparameter), so we have:

`given_input = Input(shape=(10,), dtype='int32')`",2
"But I see that upcoming tf versions will move to keras anyway, so I'm looking for a way to implement complex models without keras assuming I'm doing plain classification (like wgan, or Gans that uses other networks in their loss, etc).",2
"Basically, the `batch_size` param are assumed not to be changed across a network, and this is the reason why you don't need to specify `batch_size` in model input shape.",2
"You say the `batch_size` is assumed not to be change, does that mean my reshape is the problem?",2
"Keras assumes that shapes have format of (batch_size, num_timesteps, num_features/timestep)  so LSTM operates on axis 1 and not 0",2
"I'm not too familiar with the keras code base, I would assume the ""validate generator"" is what passes the validation metric to the TensorBoard callback inside keras?",2
"Based on your file naming, im going to assume you've got 3 classes; same number of samples for each.",2
without doing enough prior research I assumed that keras would accept a sparse response variable encoding.,2
to_categorical assumes that the first class is coded as a 0.,2
I assume if someone is dead at one state they are likely to be dead in the next state.,2
I assume the MemoryCallback returns the RAM utilization on this machine.,2
This can be done by preallocating the memory out side of the loop (assuming fixed batch sizes that might not be the case; still possible with extra efford).,2
I also assume that the pasted code is a simplified snippet and that in your actual implementation you handle concurrency safely,2
"Keras assumes all inputs you feed into a rnn layer have equal timesteps, which I think is correct, but not necessary in some cases.",2
"Ah... forgot to say, I was assuming you're using Theano.",2
"@pengpaiSH @Vivek-B just to confirm:
Doing
    predictions = model.predict_generator(validation_generator, val_samples=total_samples)

will go trough the whole dataset once and only once (assuming there are `total_samples` in the folder).",2
"Stateful models require a different formulation of the training data, since batches are assumed to correspond to time steps.",2
# Assuming this is what was the problem?,2
"Assume the multi state issue is solved here, I am closing this bug for now.",2
"Assuming that you actually want something like `x if pred1 > pred2 else 0` in the end, you could simply use `return mask * x`.",2
"I'm
> assuming that it can be done with proper use of masking, but I'm not
> exactly sure how.",2
"- right padding like (1,2,3) -> (1,2,3,0,0):  then RNN will carry on the last unmasked (hidden) state on, i.e. you get (1,3, 6, 6, 6) assuming your RNN is doing simple `+` operation.",2
"2. Assuming you want to just zero-center it, find the mean, m_tr, of your training data",2
"> 2. Assuming you want to just zero-center it, find the mean, m_tr, of your training data",2
"@carmelrabinov your code assumes the lengths of vectors (number of timesteps) in each batch is the same, correct?",2
I would assume that is precisely what the model is learning: to predict the same "optimal" output regardless of the input.,2
"After reading most solutions posted here, I found that what worked for me was decreasing learning rate of the Adam optimizer to something below the default value assumed by Keras (0.001)",2
Lets assume I have 12 features into consideration to predict my output value... and I have 1 year of data ie 365 rows...,2
# Assume we have a pretrained model,2
I assume Celery doesn't like me spinning up a process inside its subprocess.,2
It appears to be a bug in windows but it could also be a poor assumption made in keras wrt multiprocessing that manifests on windows.,2
"My solution to the problem was, assuming that the centers of my training data would contain information about most of my scenes, I sliced my arrays with x elements around the center.",2
I base my assumption on the fact that it seems to be able to extract the weights into a numpy array with `.get_weights()` function and save them e.g. as `.npy` file.,2
"Also, try plotting accuracy(you haven't mentioned your goal using unet, I am assuming accuracy means something).",2
"Assuming a batch_size = 5 for simplicity, I then compute my sample weights like this:

```  python
labs = [y.argmax() for y in y]
sample_weights = class_weight.compute_sample_weight('balanced', labs) 
```

and the result is:

```
[1.25       0.83333333 0.83333333 1.25       0.83333333]
('sample_weights shape', (5,)) 
```",2
"This makes sense, I assume it would disconnect the graph.",2
"Let us assume we have a masking:
> 
> 0 0 0 1 1 0 0 0",2
I assume you meant to link #6035,2
"Am I right in assuming that data is read from HDD, and not RAM when passing a `HDF5Matrix` to `model.fit`?",2
"Even if the embedding weights are not trained well, they could be useful assuming a high enough output dimension.",2
"I had indeed hardcoded the theano image layout into the layer, but I assumed that this wouldn't matter, as long as ""th"" was selected in the keras.json.",2
# assuming a 2D Convolution was run by hand before this layer.,2
# I assume that a convolution before this layer has prepared 3 features per coordinate,2
I was assuming tensorflow-gpu uses cuDNN.,2
I assume this `tf.keras.preprocessing.image_dataset_from_directory` is a shortcut only for the most common use cases.,2
"I designed a diagram that shows how the genetic algorithm works as an optimizer in a very small neural network with very small size of population individuals. 
(it is the same logic used when breeding dogs assuming the end goal is having a very very tiny dog breed over generations)",2
Assume an initial population of 3 lists of random weights & biases.,2
for Conv2D assuming the x-axis is the "time steps" and the y-axis are several variables...,2
"for example,assuming K.set_image_dim_ordering(""th""),  the input shape of CNN2D is (batch,filters, x, y)",2
If someone is thinking of giving a simple example assume 'valid' padding for this variables dimension since it seems to be the one used inside  'causal' padding ....,2
"Previously, I assume the default activation of CuDNNLSTM is None, so when loading weight to LSTM, I need manually setting the activation of LSTM as None.",2
"Also, for whatever this output is, I assume it should be normalized to be between 0-1?",2
"o I assumed that it's the most recent one, but it's not.",2
"I'm assuming, for example, that  a legacy BatchNormalization layer wrapper might be named legacy_batchnormalization_support .",2
"Here the y_pred and y_true are assumed to be one-hot coded, which is usually recommended and used in standard keras model.",2
And various metrics like the standard deviation of these results will give you a sense of the error bounds of your estimate (conditioned on assumptions about the validity of the underlying model structure).,2
"However, assuming a correct usage of the API, I'm not sure it would ever happen in the first place: it's impossible for the softmax function to produce an output `[0., 0., 0.]` because $e^x > 0, \forall x\in \mathbb{R}$.",2
">       Assume x = [[1, 2], [3, 4]]   and y = [[5, 6], [7, 8]]
>       batch_dot(x, y, axes=1) = [[17, 53]] which is the main diagonal
>       of x.dot(y.T), although we never have to calculate the off-diagonal
>       elements.",2
"Assume axes = 0,or 2,how to understand?",2
"> Assuming tensor A with shape (a,**k**) and B with (b,**k**,c), A.dot(B) gets a tensor with shape (a,b,c), where **k** can be considered as 'contracted'.",2
"I cant say I have the real answer as to why, but I would assume it is to be more flexible.",2
"> I cant say I have the real answer as to why, but I would assume it is to
> be more flexible.",2
Many objective functions built into keras *are* obtained by maximum likelihood. e.g. the mean squared error loss function is the maximum likelihood under the assumption that the data is normally distributed about its mean with variance the same everywhere.,2
"You assume channels come first, but whether channels come first or last depends on the configuration in `$HOME/.keras/keras.json`.",2
"Basically, the single length list correction resulted in a bad assumption in the Graph class.",2
Here's the hacky solution I just came up with (assuming you're going to use the `scalar_input` in some custom or lambda layer.,2
"Due to what I can only assume is event scheduling, `callback.on_train_end()` was not getting called quickly enough, so `get_minibatch()` was looping indefinitely.",2
".flow() would require resampling a numpy array, probably using scipy's functionality, so I guess it's assumed you will just resize it yourself since the data already fits in memory.",2
"Assuming batch_X.shape is (N,1440,1920,3) and batch_Y.shape is (N,1440,1920,1),
    this function would crop the same (224,224) region from the XY pair for each image
    in the batch, then return (yield) the cropped batch.",2
"Assuming batch_X.shape is (N,1440,1920,3) and batch_Y.shape is (N,1440,1920,1),
>     this function would crop the same (224,224) region from the XY pair for each image
>     in the batch, then return (yield) the cropped batch.",2
"When I changed to  

``` python
output_shape=lambda shape: (shape[0], shape[2]). 
```

(assuming shape has 3 dims), then everything just worked well.",2
"However, I assume @sparkingarthur means to study the differences between making predictions on the serial model and one the parallel model (and in this comparison that's OK), and I think these lines do exactly this: 

```
    if gpus == 1:
        trainPredict = serial_model.predict(trainX)
        testPredict = serial_model.predict(testX)
    else:
        trainPredict = parallel_model.predict(trainX)
        testPredict = parallel_model.predict(testX)
```",2
"If so, both exposure and contrast are linear adjustments and don't add any new information: exposure is just a scale change so your (assumedly convolutional) network shouldn't care, and increases/decreases in contrast should wash out to neutral during training.",2
"I'm mostly interested in it since I assume my data to sometimes be pretty dark, sometimes not, and I hoped that creating more (artificial) data would increase the robustness.",2
"And yes, your assumption is correct: I want to get a specific slice in the time-dimension for every batch.",2
"Also, I think there is another really big assumption in `compute_accuracy`: they fix a threshold at 0.5, but it actually may not be the best value to choose.",2
"@fchollet length isn't that big, though I guess it was pretty dumb of me to assume `RepeatVector` has anything to do with the problem (though lately I haven't had much time to think)",2
"For example in the code by @wollip (assuming there are no `BatchNormalization` layers inside `Wrapper1`):
```
# Assume no BatchNormalization layers inside Wrapper1
inputs1 = Input((None, 1))
x1 = Wrapper1(inputs1) #3
x1 = BatchNormalization()(x1)  # Does not trigger the error if saved later on.
Wrapper2 = Model(inputs1, x1, name=""Wrapper2"")
```",2
"Note: quick solution assumes last step is the the classifier (decent assumption) and the unpickled pipeline has just a keras model and not a KerasClassifier because the KerasClassifier is really for exploration, not deployment.",2
@NourozR am I correct in assuming that you are using a mean squared error loss function?,2
Especially with the assumption that when I get around to it I can recover that speed with parallelization.,2
I assume that tf specific things like clear_session() and such are not needed?,2
I assume I did at least one thing not as you expected so don't be shy with comments :),2
Where things get hairy is specializing code in training.py and elsewhere that assume a deferred computation model.,2
# assume here eff_net_model is defined and has been fitted,2
From the example lines above I'm assuming that time_slots is 10 and vector_size=1.,2
"I suspect, though, that there's a concatenation layer in your network that concatenates the inputs and targets, which won't work in this case because you've expanded a dimension on `batch_x` but not `batch_y` (though I'm making a lot of assumptions here).",2
"I assume the colab folks re-build regularly, but I don't know what their schedule looks like.",2
"This assumes that you statically know the rank of your input tensors -- in this case, I was assuming that there are no ""uniform inner"" dimensions beyond the ragged dimensions, but you could adjust it if that's not the case for you.",2
"Ah ok I assumed the toggling of the two would be coupled, considering the existence one is motivated by the other.",2
"@rfernand2 Assume you using TensorFlow backend (import keras.backend as K),  ""h"" and ""c"" can be accessed by [K.get_value(state) for state in layer.states].",2
"I didn't pay attention here, since the original paper (https://arxiv.org/pdf/1608.06993.pdf) was doing global average pooling, so I assume that applies for all the implementations.",2
I assume your model is not build right.,2
"The type I'm putting in the arrays (from preprocessed_input()) is <type 'numpy.ndarray'>, so I'm missing some basic principle I assume.",2
"I'm assuming that it is because it doesn't know how to compute the moving
means across multiple GPUs?",2
"I'm not sure what the effects of doing this are (I'm assuming there is some handling of `trainable` in `tf.Variable.__init__` and we're changing trainable after that has been called, so...), but when I do this it stops training it so I guess I'm going with it.",2
"I assume you have a data table (row_numbers, column_numbers)
so , 16 is column numbers ,it must take that as input data (well python counts from 0 by the way).",2
I am assuming this is because of drop out.,2
"I had assumed the nans were occurring in general, before any training.",2
Let's assume that your network's input is 224x224x3.,2
"I also assume these tf ops don't make much sense on a CPU, so perhaps it's not too bad to make the _Cudnn_ prefix visible in Keras' API to make the GPU assumption extra obvious.",2
"3. Assume the indexes of postive samples are k1,k2...kr，where r is the total number of positive samples",2
"Assume considering the need of evaluation efficiency, we want to retain the current implementation, I still think at least we should add another callback class(Just use scikit-learn metrics), so that the users would have a possibility to choose.",2
Would simply `gen.preprocessing_function = my_function` be enough (assuming `gen` is my instance of the generator) or does keras do something else in the background that we should replicate?,2
"Further, this script demonstrates that for CGANs (I'm assuming it also applies to the non-conditional variants), saving and loading does not preserve the discriminators state.",2
# assuming you want the 3rd layer from the last,2
What is special about it? (Assuming the xt-1 on top is a typo),2
"I don't know if this can be fixed easily, there must be some assumption in the callback that there is only one model per session.",2
"I assume these parameters are named for consistency with the
> convolutional kernels and changing them might be tricky (though I'm not
> sure if consistency with the convolutional layers is really a good
> criterion here).",2
It's possible users (like me) were/are incorrectly assuming that dropout here is the same as dropout in the literature.,2
"It's possible users (like me) were/are incorrectly assuming that dropout
> here is the same as dropout in the literature.",2
"The regularization is applied to the whole matrix and can drive rare entries to zero, the constraint (assuming it is also applied to the whole matrix) provides control over this.",2
"For a pythonist, a person would assume that making it as list or tuple would be almost identical.",2
So I assumed it should be OK for sequential models too.,2
"Well, the main problem is that Model.from_config and model_from_config make different assumptions regarding the configuration parameters:",2
"- **model_from_config** assumes that the configuration is a dictionary of 2 keys: one is 'class_name' (i.e. 'Model'), and the second is 'config' (i.e. the full model configuration).",2
- **Model.from_config** assumes that the configuration is the full model configuration (i.e. the value of 'config' key from model_from_config method),2
"If x is a list, it assumes that it is a list of data (aka, if you have [multiple inputs](http://keras.io/getting-started/functional-api-guide/#multi-input-and-multi-output-models)) .",2
There is an assumption that lists are only used to handle multiple inputs.,2
Clearly it's an assumption that needs to be fixed.,2
It might assume more delicate care with your data (and would at least pass the correct batch inference code correctly),2
"> You'll see that if x isn't a list or a dict, it assumes x is the data.",2
"If x is a list, it assumes that it is a list of data (aka, if you have multiple inputs) .",2
"You'll see that if x isn't a list or a dict, it assumes x is the data.",2
`len(X[0])` works in my case if I modify my generator to return X incapsulated into a list (i.e. `yield [X]` instead of `yield X`) to "trick" Keras and go past the assumption that lists are only used to handle multiple inputs.,2
I think the best way to handle this would be to a) drop the assumption that lists are only used in case of multiple inputs b) handle lists by checking the type of the input everywhere you need to.,2
"I will try to modify my experiments to work around Keras's assumptions, but I think this is a big limitation for Keras that should be addressed.",2
I assumed that moving it into the `train` subfolder was enough?,2
> Is it correct to assume that in one timestep the Input x_t goes through 32 LSTM blocks?,2
"It seems that, assuming I am reading the CI logs correctly, this error is happening only some of the time.",2
"> It seems that, assuming I am reading the CI logs correctly, this error is
> happening only some of the time.",2
"We assume this was done on purpose, and we will not be expecting any data to be passed to ""custom_variational_layer_2"" during training.",2
"I assume we can get additional speedup if the computation would be kept on the GPU as far as the loss function (using the CPU just to add the losses), but this would mean you will need to use the native tensorflow optimizer instead of the keras one, so more work and less backward compatibility.",2
"Assume this is a 2D case, the shape of x is `(dim1/rows, dim2/cols, channels/num_featuremap)`.",2
"@anewlearner I think you are mixing up the data shape of `x` which is `(number of samples, rows, cols, channels)` assuming you are in the backend of TensorFlow.",2
"If a tuple, it only specifies the first dimension onward;
         sample dimension is assumed either the same as the input:
         `output_shape = (input_shape[0], ) + output_shape`
         or, the input is `None` and the sample dimension is also `None`:
         `output_shape = (None, ) + output_shape`",2
"An example `number of samples = 131` first batch no problem but on the second batch 3/2 gives you an error, assuming your exhausting all the samples in each epoch.",2
2. the part that overrides the compile method assumes your optimizer is explicit.,2
"I assume that gevent serializes data for its async operation - and as such, it has tried to serialize data related to the Keras model, which actually couldn't be serialized.",2
"There is no problem with your algorithm (I assume) and most probably, keras will be updated before the variable *= will be completely removed from tensorflow.",2
"# `from_config` assumes `cls` is either `Functional` or a child class of
  # `Functional`.",2
If I'm reading this correctly the default from_config for a Model subclass assumes the model is a Functional model and makes no attempt to handle other Model subclasses.,2
I haven't looked around for other places where this is happening but I assume that there are more cases where this causes problems.,2
> I haven't looked around for other places where this is happening but I assume that there are more cases where this causes problems.,2
Assuming I would like to predict 7 days ahead outcome.,2
"Basically, your data will be processed independently (as it is assumed to be temporal different).",2
"Your batch size should be 1 in your case, I assume?",2
"Assume some initial hidden state it would take the first time slice of that batch, feed it as input to the hidden layer along with the initial hidden state and compute output for this time step; it then feeds the second time slice along with the previous hidden state as input to the current hidden state and generates output etc. until we have processed the last time slice (this could be called a forward pass through the RNN).",2
It is easy to assume that you can pass multiple inputs here as anywhere else.,2
"So, I'd assume that generating a single batch with your configurations consumes way too much memory.",2
"Given that usage of dictionaries is allowed and the given the fact e.g. for the `loss` argument in `model.compile` the keys are *the determining* property to match which output goes with which loss, it is reasonable to assume the same for the `outputs` argument in `Model` (and likewise for inputs).",2
"Moreover, you are trying to convert (I assume it is something similar to mobilenet).",2
3. Avoid assuming "you should always track either master / the latest release" will be feasible for everyone.,2
"We should push out new releases of `preprocessing` and `applications` every time we do a Keras release. Inversely, having the new modules do independent releases doesn't seem to be an issue, assuming that the new releases keep backwards compatibility (which they should).",2
> Avoid assuming "you should always track either master / the latest release" will be feasible for everyone.,2
It seems that keras just assume basic operators (`__add__`) among tensors have similar broadcasting behavior in both theano and tensorflow.,2
"Since both backends are affected I assume this is an issue on Keras, right?",2
"Since both backends are affected I assume this is an
> issue on Keras, right?",2
"From my understanding, the reason behind this is that load_model  `model_from_json` by default assumes everything declared within the model is contained in Keras, hence you have to hardwire everything else outside keras.",2
"The notebook runs on a GPU with small batch sizes of `32` to keep resource usage low, so when the number of stacked layers increases, there should be free resources available to allocate, assuming a quasi-parallel execution. However once again that was not the case:
- 1 model: ~5 seconds epoch
- 2 models: ~10 seconds epoch
- 3 models: ~15 seconds epoch",2
"If no such list is provided, it assumes its value to `tf.trainable_variables()`.",2
"3. However, I assume this as a bug.",2
All you did just being toxic and assuming you know the answer.,2
"Since the same code works on one system and doesn't on a different system (which I assume features a different OS), then it is a platform issue.",2
I assume this isn't a frequent occurrence?,2
Is there a reason why `Embedding` assumes the input is 2D?,2
I guess the code assumes a different dim_ordering,2
"# assumes shape variables: 
#    batch, time, feat_size, emb_size, rnn_size",2
"@alyato No, I recommend you to use `Sequential()` model rather than normal `Model()`, assuming that the model is actually sequential.",2
"However, your assumption is correct about why it is not performed on the Inception models.",2
"Yes, I have encountered a similar issue reproducing the baraldilorenzo example, and I assume one has to find the correct version of the weights files to match the version of Keras.  (Running Theano, Keras 2.02)",2
I assume it's not the case.,2
"My assumption is that with the keras multi-gpus function, it basically just make a same replica on another gpu but doesn't deal with the memory problem.",2
"ahrnbom, Using model.get_weights() and model.set_weights(), the weights of a normal LSTM can be transferred to a stateful LSTM, assuming the architectures are otherwise identical.",2
"@bstriner  i think @mjs-wpi assumed that this is a functionality Keras already has, but is not documented.",2
I then assumed that is must have been an undocumented feature in Keras.,2
"So because an error message wasn't thrown and things got better, I assumed Keras had an undocumented feature.",2
I am assuming the issue was resolved.,2
"However, this assumes the independence relation between the 2000 classes.",2
"- yesterday, upgraded to cudnn v5 and cudnn v5 assumes cuda 7.5",2
"- assuming the  cuda 7.5 install not being exactly what cudnn v5 expects,  my only (desperate last attempt) solution was to completely wipe the os and reinstall to 7.5 from a fresh install",2
Some additional places I've run into that assume `'channels_last'` are [this line](https://github.com/keras-team/keras/blob/be112e1f48bbdf24d0a714b9cafc3fc9f43c7738/keras/backend/tensorflow_backend.py#L3041) and [this line](https://github.com/keras-team/keras/blob/be112e1f48bbdf24d0a714b9cafc3fc9f43c7738/keras/backend/tensorflow_backend.py#L3048) in `tensorflow_backend` `sparse_categorical_crossentropy`.,2
"Assuming that your training data are:
``` python
X_train (5 x 1 matrix)
array([[596768455815000],
       [612882670787000],
       [602179976392000],
       [808020878060000],
       [726154800929000]], dtype=int64)

Y_train (5 x 1 matrix)
array([[0],
       [0],
       [0],
       [0],
       [0]])
```",2
"Assuming Keras follows the implementation described Hochreiter & Schmidhuber, the hidden state is the same size as the cell state, or output size.",2
Pickle is not a reliable way to serialize objects since it assumes that the underlying Python code/modules you're importing have not changed.,2
"Assuming you have binary categories (class 0 and 1), you can do 2 things:",2
Keras' `LSTM()` assumes you want as many "memory blocks" as cells.,2
"I'll extend my example from above assuming you have already trained a model:

```python
model.save_weights(""filename"")

# Now we will load the weights after creating a new model instance
model = keras.models.Sequential([
  # Your model architecture etc.
])

model.load_weights(""filename"")
```",2
*Note the assumption here is that you need to ensure that the order in which your data flows from the directory is the same for each generator*,2
They assume that there's some kinda circular import of matplotlib occuring but I have no idea how to make things right,2
I assumed something earlier and thought this was the original BRNN architecture style (aligning in this way).,2
# Assuming your model includes instance of an "AttentionLayer" class,2
> # Assuming your model includes instance of an "AttentionLayer" class,2
"However, I think it is a reasonable assumption to say that it will take approximately the same time across each epoch so the information from epoch 1 completion could be used as an approximation for further epochs",2
"My assumption is no, though I am unaware how verify this absolutely.",2
"I did discover (late last night), that the [`kernel_initializer`](https://keras.io/initializers/) has a number of options for setting up a distribution from which (I assume) the weights are drawn.",2
The small differences I assume are due to the use of cuDNN.,2
Theano backend conv2d assumes kernel variable is shared.,2
"Assuming all layers in `keras.layers.wrappers` always have **exactly one layer** they're wrapping (@fchollet, is this invariably true?) this pull request appends the wrapped layer's name and class name to the graph for visualization.",2
I assumed that theano compiled with non-mkl BLAS was cached by the first env (`INTEGRATION_TESTS`) and the next envs (`KERAS_BACKEND=theano`) just uses the cache without recompiled with mkl.,2
"We don't know the exact reason, thus I just assumed that the new CNTK suffers from memory leaks.",2
The fact that `validation_split` simply selects the last examples from the data set is not obvious and displaying this warning would surely save plenty of time anyone who may assume otherwise as well as serve as a reminder to those who might not have considered it an issue.,2
I assume not since it's implementing very similar functions from other backends.,2
The current weight loading code assumes all Keras 1 models have Theano dim ordering and so things get messed up.,2
"Assumed shape transformation: `(nb_samples, time, nb_outputs)` --> `(nb_samples * time, nb_outputs)`",2
"Normally, masking assumes that our output tensors are of shape `(samples, timesteps, outputs )`.",2
"This, unfortunately, breaks multi-input or multi-output models as it assumes that `val_data` has a fixed length of 3 (or 4 if self.mode.uses_learning_phase it True).",2
Convolution kernel is assumed to be shared variable ("variable" rather than "placeholder").,2
"Example, assume images are 28x28 as in the mnist example",2
"Currently assumes matrix 2nd order tensor multiplication, instead of the vector dot product.",2
Casting `y` to an `int` array seems safe to me since the docstring/logic assume that `y` is 0-indexed integers already.,2
"I tested it under Linux only, but PyMC's progressbar also uses ""\r"", so I assume this works on every plattform.",2
Assuming each inner list to consist of tokens.,2
Assume we use one of the pre-trained CNNs of Keras and we want to fine-tune it.,2
"There is some assumptions for the code happens in the context:

1. All the weights will be convert to a lazyinitVariable. They will be replaced to DVariable at different time by different type of model.

2. Any model created within the scope will have the layout_map attached to them, and the map will be used to create DVariable for the model. If there is no model created in scope, then the LazyInitVariable will never be converted.

3. For subclass model, since the weights are created when the first time __call__ is invoked, we inject the __call__ to first init the variable with lazyinitVariable, and then map to DVariable. In this case, the layout_map_scope actually does nothing when user create the subclass model, since the weights are not created yet. The scope only allow the model fetch the layout_map, which can be inject to model.__init__ as well. But for API simplification purpose, we consolidate into just one API. 

4. For functional/sequential model, since their weights are created eagerly, the DVariable creation happens at the init_graph_network. The scope approach is mostly used for this case, since the variable creation happens before functional.__init__. It will be too late if we inject the layout_map at __init__.

5. The DVariable creation has some special logic for disabling lazy_variable_scope, which was causing issue for functional model. The variable initializer usually uses tf.random.Generator under the hood. It will create the stateVar when init, and will be convert to a LazyInitVariable if the init happens in the scope. We would like to disable the scope for that case, since the init should happen with the tf.function on a dtensor device scope. The stateVar will be created as DVariable.",2
"i assume i have same problem: 
I have the 7.5 installed  with tensorflow and when I try (like in the tutorial about gpu)
with tf.device('/gpu:0'):
  a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')
  b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')
  c = tf.matmul(a, b)
  print(c)
  sess.run(c)

it breaks !
(in torch7, I have no pbs with gpus)",2
"Can confirm I've encountered the same issue - I was able to hack around this by manually defining the symbol as `NULL` in my project, which I assume may crash at runtime:

```objc
// To work around a nasty linker issue in TensorFlowLiteSelectTFOps
const void * uprv_getICUData_conversion = NULL;
```",2
"Assuming you have loaded train and test data then the code executes up to the save_model function, the error is produced by attempting to save the model as either h5 or hdf5 (while h5py works fine) and produces the following error:

NotImplementedError: Saving the model to HDF5 format requires the model to be a Functional model or a Sequential model.",2
"For any amateur users like me, please find the following prerequisites to use your custom model in the [Android application](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_on_mobile_tf2.md)
Suggested Setup ( Assume you are using TensorFlow version >= 2.3):",2
"Like this example (I changed it to BatchNormalization cause of different version of TF but I assume it still applies):

```python
import tensorflow as tf
import numpy as np

input_shape = (224, 224, 3)
inputs = tf.keras.Input(shape=input_shape)
x = tf.keras.layers.BatchNormalization()(inputs, training=True)
x = tf.keras.layers.Convolution2D(32,(3,3))(x)
x = tf.keras.layers.MaxPool2D((2,2))(x)
x = tf.keras.layers.Flatten()(x)
out = tf.keras.layers.Dense(2,activation = 'softmax')(x)
model1 = tf.keras.Model(inputs, out)

input_shape = (224, 224, 3)
inputs = tf.keras.Input(shape=input_shape)
x = tf.keras.layers.BatchNormalization()(inputs, training=False)
x = tf.keras.layers.Convolution2D(32,(3,3))(x)
x = tf.keras.layers.MaxPool2D((2,2))(x)
x = tf.keras.layers.Flatten()(x)
out = tf.keras.layers.Dense(2,activation = 'softmax')(x)
model2 = tf.keras.Model(inputs, out)

# have different weights
[print(np.all((a==b)), a.shape, b.shape) for a, b in zip(model1.weights, model2.weights)]

model1.save_weights(""temp.json"")
model2.load_weights(""temp.json"")

# have the same weights
[print(np.all((a==b)), a.shape, b.shape) for a, b in zip(model1.weights, model2.weights)]

# the respective calls that will be invoked on the models
# model1.layers[1]._get_training_value(training=True)
# model2.layers[1]._get_training_value(training=False)
```",2
"Let's assume 'my_bs_ts_feat_tensor' is such a tensor: 

I can currently scan along the timesteps axis by applying: 

```
my_bs_ts_feat_tensor = tf.transpose(my_bs_ts_feat_tensor, perm=[1,0,2])
my_bs_ts_feat_tensor = tf.scan(fn=some_scan_fn, elem=my_bs_ts_feat_tensor)
my_bs_ts_feat_tensor = tf.transpose(my_bs_ts_feat_tensor, perm=[1,0,2])
```",2
"But here's an experiment (and assumptions) to test it:

1. A very long while loop may be substituted for a long running task (with parallel iterations set to 1)
2.  1. With proper `control_dependencies` set, one can measure computation time of a set of ops.
     2. If two devices have different compute power, one can guess the device placement by the amount of time taken, faster task would mean it was placed on the device with better compute.
3. 1. Since both long running tasks are assigned to different devices, they should run concurrently.
    2. One can guess the device placement is wrong if they are run in sequence. Can be guessed from total time, or from print statements.",2
"So, assuming you want to run single-batch inference, this code works (Note the `reshape` to 1-dim tensor before `tf.gather`):

```
  names = tf.keras.Input(shape=(2,), dtype=tf.string, batch_size=1)
  model = tf.keras.Model(
      inputs=names,
      outputs=tf.gather(tf.reshape(names, [2]), tf.constant([0])),
  )

  print(""KERAS OUTPUT IS"", model(np.array([1, 2], dtype=np.str)))

  model.save('./output')
  converter = tf.lite.TFLiteConverter.from_saved_model('./output')
  tflite_model = converter.convert()
  with open('model.tflite', 'wb') as f:
    f.write(tflite_model)

  interpreter = tf.lite.Interpreter(model_path='model.tflite')
  interpreter.allocate_tensors()
  input_details = interpreter.get_input_details()
  output_details = interpreter.get_output_details()
  interpreter.set_tensor(input_details[0]['index'], np.array([[1, 2]], dtype=np.str))
  interpreter.invoke()
  print(""TFLITE OUTPUT IS"", interpreter.get_tensor(output_details[0]['index']))
```",2
"I was thinking of creating something like this that assumes all sequence lengths are the same if no sequence_length is passed:

```
def ctc_loss(labels, inputs, sequence_length=None, preprocess_collapse_repeated=True,
             ctc_merge_repeated=True, ignore_longer_outputs_than_inputs=False, time_major=True):
    if sequence_length is None:
        if time_major:
            sequence_length = tf.fill(tf.shape(inputs)[0:1], tf.shape(inputs)[1])
        else:
            sequence_length = tf.fill(tf.shape(inputs)[1:2], tf.shape(inputs)[0])
    return tf.nn.ctc_loss(sparse_labels, inputs, sequence_length,
                          preprocess_collapse_repeated=preprocess_collapse_repeated,
                          ctc_merge_repeated=ctc_merge_repeated,
                          ignore_longer_outputs_than_inputs=ignore_longer_outputs_than_inputs,
                          time_major=time_major)
```",2
"Assuming this is correct behavior and nil needs to be checked for on the go side then the following patch fixes the problem:
```
diff --git a/tensorflow/go/tensor.go b/tensorflow/go/tensor.go
index e8fa21a..6cbf759 100644
--- a/tensorflow/go/tensor.go
+++ b/tensorflow/go/tensor.go
@@ -205,6 +205,9 @@ func (t *Tensor) WriteContentsTo(w io.Writer) (int64, error) {
 func tensorData(c *C.TF_Tensor) []byte {
        // See: https://github.com/golang/go/wiki/cgo#turning-c-arrays-into-go-slices
        cbytes := C.TF_TensorData(c)
+       if cbytes == nil {
+               return nil
+       }
        length := int(C.TF_TensorByteSize(c))
        slice := (*[1 << 30]byte)(unsafe.Pointer(cbytes))[:length:length]
        return slice
```",2
"I assumed the problem might be with memory, but for smaller batches I get the same error:
```
LLVM ERROR: Cannot select: 0x7fe90c0d4608: i16,ch = AtomicCmpSwap<Volatile LDST1[%_fusion.typed16(addrspace=1)]> 0x7fe90c07f388, 0x7fe90c0d4e28, 0x7fe90c0d4ef8, 0x7fe90c0e6fe0
  0x7fe90c0d4e28: i64,ch = CopyFromReg 0x7fe90c07f388, Register:i64 %vreg0
    0x7fe90c0d4e90: i64 = Register %vreg0
  0x7fe90c0d4ef8: i16,ch = CopyFromReg 0x7fe90c07f388, Register:i16 %vreg3
    0x7fe90c0d5440: i16 = Register %vreg3
  0x7fe90c0e6fe0: i16 = and 0x7fe90c0d4ef8, 0x7fe90c0d5100
    0x7fe90c0d4ef8: i16,ch = CopyFromReg 0x7fe90c07f388, Register:i16 %vreg3
      0x7fe90c0d5440: i16 = Register %vreg3
    0x7fe90c0d5100: i16 = AssertZext 0x7fe90c0d49b0, ValueType:ch:i1
      0x7fe90c0d49b0: i16,ch = CopyFromReg 0x7fe90c07f388, Register:i16 %vreg1
        0x7fe90c0d46d8: i16 = Register %vreg1
In function: _fusion__1
```",2
"Assuming you have a model, you can compare performance on CPU vs platforms using the following tools:
1. [Benchmark tool](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/tools/benchmark) for latency performance.
2. [Accuracy tasks](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/tools/evaluation/tasks) to gauge correctness. There is also the [inference_diff](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/tools/evaluation/tasks/inference_diff) tool that provides raw output errors for CPU vs delegate, as long as you know how to interpret the output tensors.",2
"Regarding the logic, here's one option (assuming zero index):

```
sort probabilities
if prob[k-1] != prob[k]
    // happy ending
else
    if handle_ties == include
        // return all positions greater than or equal to prob[k-1]
    else if handle_ties == exclude
        // return all positions greater than prob[k-1]
    else if handle_ties == sample or index
        // get all positions greater than prob[k-1] (which will be returned)
        // get all positions equal to prob[k-1] (ties)
        // fill remaining positions (according to sample or index)
```",2
"Assuming you're using a `BasicDecoder`, the [step method does three things](https://github.com/tensorflow/tensorflow/blob/r1.2/tensorflow/contrib/seq2seq/python/ops/basic_decoder.py#L126):

1) Runs the decoder's cell for 1 step ([139](https://github.com/tensorflow/tensorflow/blob/r1.2/tensorflow/contrib/seq2seq/python/ops/basic_decoder.py#L139))
2) Feeds the cell's output to the `Helper`'s `sample_fn` to generate `sample_ids` ([142](https://github.com/tensorflow/tensorflow/blob/r1.2/tensorflow/contrib/seq2seq/python/ops/basic_decoder.py#L142))
3) Feeds the cell's output and the sample_ids (and a few other parameters) to the `Helper`'s `next_input_fn` ([144](https://github.com/tensorflow/tensorflow/blob/r1.2/tensorflow/contrib/seq2seq/python/ops/basic_decoder.py#L144))",2
"We would still have to support `Optimizer.apply_gradients`, which IMO should be implemented along the same lines, but with only a subset of the hooks, since that method assumes the users want control of computing the unaggregated gradients themselves:

```
class Optimizer:
  def apply_gradients(self, grads_and_vars):
    gradients, variables = ...  # Unpack the tuple.
    gradients = self._aggregate_gradients(gradients)
    gradients = self._process_aggregated_gradients(gradients)
    self._apply_gradients(gradients, variables)
```",2
"As per my point of view -
It should not just assume that the l2_cache_size will be there:

```
  # Gather the rest
  info = cpuinfo.get_cpu_info()
  cpu_info.cpu_info = info['brand']
  cpu_info.num_cores = info['count']
  cpu_info.mhz_per_cpu = info['hz_advertised_raw'][0] / 1.0e6
  l2_cache_size = re.match(r'(\d+)', str(info['l2_cache_size']))
  if l2_cache_size:
    # If a value is returned, it's in KB
   cpu_info.cache_size['L2'] = int(l2_cache_size.group(0)) * 1024
```",2
"Note that there is a different (but I would assume related) error when using `model.predict` instead of `model.fit`:
``` python
import tensorflow as tf
import numpy as np

DO_BUG = True

inputs = tf.keras.Input((1,))
outputs = tf.keras.layers.Dense(10)(inputs)
model0 = tf.keras.Model(inputs=inputs, outputs=outputs)

if DO_BUG:
    with tf.Graph().as_default():
        inputs = tf.keras.Input((1,))
        outputs = tf.keras.layers.Dense(10)(inputs)
        model1 = tf.keras.Model(inputs=inputs, outputs=outputs)

model0.predict(np.zeros((4, 1)))
```
```
Traceback (most recent call last):
  File "".../tmp.py"", line 16, in <module>
    model0.predict(np.zeros((4, 1)))
  File ""...\tensorflow\python\keras\engine\training_v1.py"", line 988, in predict
    use_multiprocessing=use_multiprocessing)
  File ""...\tensorflow\python\keras\engine\training_arrays.py"", line 714, in predict
    callbacks=callbacks)
  File ""...\tensorflow\python\keras\engine\training_arrays.py"", line 253, in model_iteration
    if model._compile_distribution:
AttributeError: 'Functional' object has no attribute '_compile_distribution'
```",2
"Assuming your ids are consecutive, you could do this with `scan` as follows:

```
from __future__ import print_function
import tensorflow.compat.v2 as tf

tf.enable_v2_behavior()

ds = tf.data.Dataset.from_tensor_slices(([0, 0, 0, 1, 1, 2, 2, 2, 2, -1], [1, 2, 3, 1, 2, 1, 2, 3, 4, 1]))

empty_batch = tf.constant([], tf.int32, shape=[0,])
initial_state = (-1, empty_batch)

def scan_func(old_state, input_element):
  current_id, accumulated_batch = old_state
  id, feature = input_element

  def _accumulate():
    new_accumulated_batch = tf.concat([accumulated_batch, [feature]], 0)
    new_state = (id, new_accumulated_batch)
    return new_state, (current_id, empty_batch)
  
  def _accumulate_and_emit():
    new_state = (id, tf.concat([empty_batch, [feature]], 0))
    return new_state, (current_id, accumulated_batch)
  
  return tf.cond(tf.math.logical_or(current_id == id, current_id == -1), _accumulate, _accumulate_and_emit)

ds = ds.apply(tf.data.experimental.scan(initial_state, scan_func))
ds = ds.filter(lambda id, batch: tf.shape(batch)[0] > 0)

for elem in ds:
  id, batch = elem
  print(id.numpy(), batch.numpy())
```

which produces:

```
0 [1 2 3]
1 [1 2]
2 [1 2 3 4]
```",2
"Assuming you have two text files, line delimited, I think the solution would look something like this:

```python
image_filenames = tf.contrib.data.TextLineDataset(""image_index.txt"")
images = image_filenames.map(lambda filename: tf.image.decode_image(tf.read_file(filename)))
output_target_strings = tf.contrib.data.TextLineDataset(""output_targets.txt"")
output_target_values = output_target_strings.map(lambda target: ...)  # Insert type conversion code here.

combined = tf.contrib.data.Dataset.zip((images, output_targets)).repeat().batch(BATCH_SIZE)
iterator = combined.make_one_shot_iterator()
next_element = iterator.get_next()
# ...
```",2
"If this assumption is correct the problem arises from line 529 In [graph_constructor.cc](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/graph/graph_constructor.cc):

```
for (int i = 0; i < node_def.input_size(); ++i) {
      StringPiece input_name = node_def.input(i);
      TensorId id(ParseTensorName(input_name));
      if (opts_.input_map.count(id) == 0) {
        // If an input is not mapped, then the input should appear in the graph
        // being imported.
        auto iter = gdef_nodes_.find(id.first);
        if (iter == gdef_nodes_.end()) {
          return errors::InvalidArgument(""Node '"", node_def.name(),
                                         ""': Unknown input node '"",
                                         node_def.input(i), ""'"");
        }
        outputs_[iter->second.gdef_index].push_back(n);
      } else {
        // This input is mapped to an existing edge. Therefore this input is
        // as good as being already processed.
        --pending_count;
        DCHECK_GE(pending_count, 0);
      }
    }
```",2
"I assumed that the checks performed by `tfcompile` were too tight, and took a chance:
```
diff --git a/tensorflow/compiler/tf2xla/functionalize_control_flow.cc b/tensorflow/compiler/tf2xla/functionalize_control_flow.cc
index faa88ecfe..fda3cbd00 100644
--- a/tensorflow/compiler/tf2xla/functionalize_control_flow.cc
+++ b/tensorflow/compiler/tf2xla/functionalize_control_flow.cc
@@ -383,8 +383,8 @@ Status FunctionalizeLoop(Graph* graph, Frame* frame,
         }
       }
       if (arg.exit == nullptr) {
-        return errors::InvalidArgument(""Missing Exit successor to "",
-                                       arg.switch_node->name());
+        // return errors::InvalidArgument(""Missing Exit successor to "",
+        //                                arg.switch_node->name());
       }
     }
   }
@@ -454,7 +454,7 @@ Status FunctionalizeLoop(Graph* graph, Frame* frame,
       graph->AddEdge(in_edge->src(), in_edge->src_output(), while_node, i);
     }
 
-    if (!arg.is_loop_invariant) {
+    if (arg.exit != nullptr && !arg.is_loop_invariant) {
       std::vector<const Edge*> edges(arg.exit->out_edges().begin(),
                                      arg.exit->out_edges().end());
       for (const Edge* edge : edges) {
```",2
"Digging into stace output, It seems like builder is trying to find `as` using some incorrect assumptions, and failed:
```
134767 execve(""external/local_config_cuda/crosstool/clang/bin/../../../cuda/bin/../open64/bin/as"", [""as"", ""-I"", ""."", ""-I"", ""external/nccl_archive/src"", ""-I"", ""external/local_config_cuda/cross""..., ""-a64"", ""-mppc64"", ""-many"", ""-mlittle"", ""-o"", ""bazel-out/local_linux-py3-opt/bi""..., ""/tmp/cc7ZvHce.s""], [/* 19 vars */] <unfinished ...>
134767 <... execve resumed> )           = -1 ENOENT (No such file or directory)
134767 execve(""external/local_config_cuda/crosstool/clang/bin/../../../cuda/bin/../nvvm/bin/as"", [""as"", ""-I"", ""."", ""-I"", ""external/nccl_archive/src"", ""-I"", ""external/local_config_cuda/cross""..., ""-a64"", ""-mppc64"", ""-many"", ""-mlittle"", ""-o"", ""bazel-out/local_linux-py3-opt/bi""..., ""/tmp/cc7ZvHce.s""], [/* 19 vars */] <unfinished ...>
134767 <... execve resumed> )           = -1 ENOENT (No such file or directory)
134767 execve(""external/local_config_cuda/crosstool/clang/bin/../../../cuda/bin/as"", [""as"", ""-I"", ""."", ""-I"", ""external/nccl_archive/src"", ""-I"", ""external/local_config_cuda/cross""..., ""-a64"", ""-mppc64"", ""-many"", ""-mlittle"", ""-o"", ""bazel-out/local_linux-py3-opt/bi""..., ""/tmp/cc7ZvHce.s""], [/* 19 vars */] <unfinished ...>
134767 <... execve resumed> )           = -1 ENOENT (No such file or directory)
134767 execve(""/trinity/shared/apps/cv-ppc64le/gcc/5.4.0/bin/as"", [""as"", ""-I"", ""."", ""-I"", ""external/nccl_archive/src"", ""-I"", ""external/local_config_cuda/cross""..., ""-a64"", ""-mppc64"", ""-many"", ""-mlittle"", ""-o"", ""bazel-out/local_linux-py3-opt/bi""..., ""/tmp/cc7ZvHce.s""], [/* 19 vars */] <unfinished ...>
134767 <... execve resumed> )           = -1 ENOENT (No such file or directory)
```",2
"Let's assume I am in a python shell and I start training a model:

`model.fit(X,Y, batch_size = 8)`",2
"Now assume I want to this inside python:

for i in range(10):
         import numpy as np ;
         import datetime ; 
         np.random.seed(datetime.datetime.now().microsecond)
         from keras import ....
         train()
         evaluate()",2
"CNTK fails, since once it has seen the first batch, it assumes the second dimension is fixed to 100:

```
Traceback (most recent call last):
  File ""do.py"", line 19, in <module>
    model.predict(x)
  File ""/home/david/.virtualenv/py35/lib/python3.5/site-packages/keras/engine/training.py"", line 1594, in predict
    batch_size=batch_size, verbose=verbose)
  File ""/home/david/.virtualenv/py35/lib/python3.5/site-packages/keras/engine/training.py"", line 1218, in _predict_loop
    batch_outs = f(ins_batch)
  File ""/home/david/.virtualenv/py35/lib/python3.5/site-packages/keras/backend/cntk_backend.py"", line 1609, in __call__
    output_values = self.metrics_func.eval(input_dict, as_numpy=False)
  File ""/home/david/.virtualenv/py35/lib/python3.5/site-packages/cntk/ops/functions.py"", line 626, in eval
    _, output_map = self.forward(arguments, outputs, device=device, as_numpy=as_numpy)
  File ""/home/david/.virtualenv/py35/lib/python3.5/site-packages/cntk/internal/swig_helper.py"", line 69, in wrapper
    result = f(*args, **kwds)
  File ""/home/david/.virtualenv/py35/lib/python3.5/site-packages/cntk/ops/functions.py"", line 760, in forward
    keep_for_backward)
  File ""/home/david/.virtualenv/py35/lib/python3.5/site-packages/cntk/cntk_py.py"", line 1568, in _forward
    return _cntk_py.Function__forward(self, *args)
ValueError: The trailing dimensions of the Value shape '[4 x 200 x 16]' do not match the Variable 'Input('input_1', [#], [100 x 16])' shape '[100 x 16]'.
```",2
"**Predict generator** gives the following individual and _reasonable_ predictions (for 10 hydrangea images and 10 nature images, in separate folders as required by the method), only one incorrect classification assuming the 0.5 threshold:

```
[   0.2020] | [ True]
[   0.0083] | [ True]
[   0.0004] | [ True]
[   0.0125] | [ True]
[   0.0046] | [ True]
[   0.9373] | [*False*]
[   0.0029] | [ True]
[   0.0412] | [ True]
[   0.1569] | [ True]
[   0.1617] | [ True]]

[   0.9631] | [ True]
[   0.9625] | [ True]
[   0.9087] | [ True]
[   0.9652] | [ True]
[   0.9863] | [ True]
[   0.9646] | [ True]
[   0.9638] | [ True]
[   0.9635] | [ True]
[   0.9592] | [ True]
[   0.9679] | [ True]
```",2
I assume it would help to look at what my custom max pooling layer is doing and here it is:,2
"KerasClassifier.fit(self, x, y, ...) assumes that all labels that a model can predict exist in the training data (i.e. in 'y'):

// line 203
self.classes_ = np.unique(y)",2
"3. Here is the full code until failure, assuming you loaded a dataframe called ""climate"":
ags <- seq(2)
lag_names <- paste(""lag"", formatC(lags, width = nchar(max(lags)), flag = ""0""), sep = ""_"")
lag_functions <- setNames(paste(""dplyr::lag(., "", lags, "")""), lag_names)
climate %>% dplyr::mutate_at(dplyr::vars(Temp), dplyr::funs_(lag_functions)) -> lagged
train <- lagged[6:90, ]
test <- lagged[91:95, ]
prep <- caret::preProcess(train, method = c(""center"", ""scale""))
trainT <- predict(prep, train)
testT <- predict(prep, test)
x_train <- trainT[, 4:5]
y_train <- train$Temp
x_test <- testT[, 4:5]
y_test <- test$Temp
x_train_arr <- array(unlist(x_train), dim = c(length(x_train), 1, 2))
y_train_arr <- array(data = y_train, dim = c(length(y_train), 1, 1))
x_test_arr <- array(data = x_test, dim = c(length(x_test), 1, 2))
y_test_arr <- array(data = y_test, dim = c(length(y_test), 1, 2))
# Model inputs
lag_setting  <- 5 # = nrow(test)
batch_size   <- 5 # evenly divisible
train_length <- 85
tsteps       <- 2 #how many lags
epochs       <- 30
model <- keras_model_sequential()
model %>%
  layer_lstm(units            = 20, 
             input_shape      = c(tsteps, 1), 
             batch_size       = batch_size,
             return_sequences = TRUE, 
             stateful         = TRUE) %>% 
  layer_lstm(units            = 20, 
             return_sequences = FALSE, 
             stateful         = TRUE) %>% 
  layer_dense(units = 2)

model %>% 
  compile(loss = 'mae', optimizer = 'adam')

model
history <- model %>% fit(
  x_train_arr, y_train_arr, 
  epochs = epochs, batch_size = batch_size, 
  validation_split = 0.1
)",2
"I assume this happens because I am using a dense layer with a softmax function so I can access with the get_output_at function two tensors:


Code:
----------------------
layer.get_output_at(0)
layer.get_output_at(1)

Output.
---------------
Tensor(""dense_3/Softmax:0"", shape=(?, 7), dtype=float32)
Tensor(""test/dense_3/Softmax:0"", shape=(?, 7), dtype=float32)",2
"Things look ""much better"", assuming we want to learn XOR:

```
Training done.
[[ 0.05998931]]
[[ 0.90797085]]
[[ 0.91271895]]
[[ 0.10119713]]
```",2
"Hi, I am trying to build a multiple inputs LSTM model, I expect to use price and sentiment to predict the future price, and since I assume the price for time t will be affected by previous 51 hours' price, I have one def function to help me look back 51 hours:

```
def create_dataset(dataset, look_back):
    dataX, dataY = [], []
    for i in range(len(dataset) - look_back):
        a = dataset[i:(i + look_back), 0]
        dataX.append(a)
        dataY.append(dataset[i + look_back, 0])
    print(len(dataY))
    return np.array(dataX), np.array(dataY)
```",2
"Assuming your dataframe is filled with the masking value -1 up to the timestep max_sequence_length:

```python
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Masking, Conv1D, GlobalMaxPooling1D
model = Sequential()
max_sequence_length = 188
model.add(Masking(mask_value=-1, input_shape=(max_sequence_length, self.cnn_config.input_dim)))
model.add(Conv1D(filters=self.cnn_config.filters, kernel_size=self.cnn_config.window_size, activation=""relu""))
model.add(GlobalMaxPooling1D()) # or model.add(Flatten())
model.add(Dense(1, activation='sigmoid'))
```",2
"To add another recipe, if you want to look at a Graph and don't want to change outputs of your already trained graph, you can use something like this (assuming two inputs):

``` python
imd_f = theano.function([model.inputs[name].input for name in model.input_order],
                        model.nodes['your node name here'].get_output(train=False))
imd_f(np.array(inp0, dtype='float32'), np.array(inp1, dtype='float32'))
```",2
"- Second, since keras doesn't yet support sparse input (correct me if I'm wrong :P ), I assume it wouldn't be so efficient to have those binary vectors; 
  So that's why I became interested in the Embedding layer.",2
"Assuming this is how weights are obtained for updating during training in a `Sequential` model:

```
weights = []
for every layer in model:
    if layer is trainable:
        weights += layer.weights
set update equations for every w in weights.
```",2
"This solution did not work for me in the 2.2, so inspired by the previous solution and assuming targets true values have missing values, I suggest this simple code, in which I suggest replacing NaN values with the prediction values:

```
import tensorflow as tf
from tensorflow.keras import losses

class MeanSquaredErrorLossThatIgnoresNaN(losses.MeanSquaredError):
    def __init__(self, *args, **kwargs):
        losses.MeanSquaredError.__init__(self, *args, **kwargs)

    def __call__(self, y_true, y_pred, sample_weight=None):
        y_true = tf.where(tf.math.is_nan(y_true), y_pred, y_true)
        return losses.MeanSquaredError.__call__(self, y_true, y_pred, sample_weight=sample_weight)
```
Ussage:

`model.compile(..., loss=MeanSquaredErrorLossThatIgnoresNaN())`",2
"Here is a quick mock up that assumes one hot encoding:

```
from abc import abstractmethod

from keras import backend as K

class GlobalMetric(object):

    @abstractmethod
    def __call__(self, y_true, y_pred):
        raise NotImplementedError(""Method not implemented."")

    @abstractmethod
    def update_states(self):
        raise NotImplementedError(""Method not implemented."")

    @abstractmethod
    def reset_states(self):
        raise NotImplementedError(""Method not implemented."")

class TruePositives(GlobalMetric):

    def __init__(self, threshold=None):

        self.__name__ = ""true_positives""
        if threshold is None:
            self.threshold = K.variable(value=0.5)
        else:
            self.threshold = K.variable(value=threshold)
        # tp = true positives
        self.tp = K.variable(value=0.0)

    def __call__(self, y_true, y_pred):
        self.update_states(y_true, y_pred)
        return self.tp

    def reset_state(self):
        self.tp = K.update(self.tp, K.variable(value=0.0))

    def reset_states(self):
        self.tp = K.update(self.tp, K.variable(value=0.0))

    def update_states(self, y_true, y_pred):

        # Slice the positive score
        y_true = y_true[:, 1]
        y_pred = y_pred[:, 1]

        # Softmax -> probabilities
        y_pred = K.cast(y_pred >= self.threshold, 'float32')
        # c = correct classifications
        c = K.cast(K.equal(y_pred, y_true), 'float32')
        # tp_batch = number of true positives in a batch
        tp_batch = K.sum(c * y_true)

        self.tp = K.update_add(self.tp, tp)
```",2
"I tried modifying this function to remove this assumption (ie. not split up the inputs in this way if the initial_state is specified), but then an error gets raised a few lines later during the call to rnn (tensorflow_backend.py, line 2332, at the beginning of the function:
```
def rnn(step_function, inputs, initial_states,
        go_backwards=False, mask=None, constants=None,
        unroll=False, input_length=None):
    """"""Iterates over the time dimension of a tensor.
...
# inputs: tensor of temporal data of shape `(samples, time, ...)`  # <-- confirming the assumption that a single tensor is expected.
#            (at least 3D).
...
ndim = len(inputs.get_shape())    # <-- raises the error: ""AttributeError: 'list' object has no attribute 'get_shape'""
```
which again assumes that inputs is a single tensor, and not a list of inputs, an assumption that I see is present in the rest of that function as well, including the specification of the inputs argument in the docstring.",2
"in the first lstm layer at charachter level I want the layer output only at the end of sequence which is the end on the word(let assume I have a padded  ) so I set return_sequences=False to force it not to output for each input character only at the end, on the other hand I want the second layer receive input for each word and out put for each word as well, so return_sequences=True is for this layer; some questions raises here : 

1.  what is really relation between the batch_size here with return_sequences=False/True ?

2.  if dont force the first layer to output at the end of seq it works but it's not what I need and when I force it, I receive the dimension error of second layer input ,how to solve it?",2
"> in the first lstm layer at charachter level I want the layer output only at the end of sequence which is the end on the word(let assume I have a padded ) so I set return_sequences=False to force it not to output for each input character only at the end, on the other hand I want the second layer receive input for each word and out put for each word as well, so return_sequences=True is for this layer; some questions raises here :

> what is really relation between the batch_size here with return_sequences=False/True ?",2
"For example (assuming tensorflow backend with BHWC tensor layout):

```python
def loss(y_true, y_pred):
    x_training = y_true[..., 1:]
    y_true = y_true[..., :1]
    # implement equation 2 here
    error = ...
    return error

# build your model as you already do
x = input = Input(shape=[1, None, None])
x = ... 

# concatenate the input with the output image
x = concatenate([x, input], axis=3)
model = Model(input, x)
model.compile(loss=loss, optimizer=SGD())
```",2
"Assuming you're using tensorflow, try this:

```python
import keras
import tensorflow as tf
model = keras.models.load_model(<model_file>)
model._make_predict_function()
graph = tf.get_default_graph()

def some_route(...):
	...
	global graph
	with graph.as_default():
		outputs = model.predict(inputs)
	...
```",2
"Assume I am planning to training network with input patch size of 128*128,",2
"2. Assuming `gan` is the combined model, `generator` and `discriminator` are the submodels, then one can carry out constructing the models as follows:

```
def create_generator():
    generator = Sequential()
    ...

    return generator


def create_discriminator():
    discriminator = Sequential()
    ...
    return discriminator


def create_gan(generator, discriminator):
    discriminator.trainable = False

    gan_input = Input(shape=(INPUT_SIZE,))
    generator_output = generator(gan_input)
    gan_output = discriminator(generator_output)

    gan = Model(inputs=gan_input, outputs=gan_output)
    gan.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5))

    gan.summary()
    discriminator.trainable = True
    return gan
```",2
"Actually I think I have the objective function that does this (assuming the undefined outputs are set to 0):

```
def non_zero_mean_squared_error(y_true, y_pred):
    return theano.tensor.mean(theano.tensor.square(theano.tensor.sgn(y_true)*(y_pred - y_true)), axis=-1)
```",2
"i.e. assuming you have two workers and a batch size of 32 here are the index of the data they would work:
```
worker 1:
0 - 16 => i=0
32 - 48 => i=1
64 - 80 => i=2
....

worker 2:
16 - 32 => i=0
48 - 64 => i=1
80 - 96 => i=2
....
```",2
"In this case the output will be assumed to
    consist of objects with the classes, shapes and types defined by
    `tf.TypeSpec` objects from `output_signature` argument:

    >>> def gen():
    ...   ragged_tensor = tf.ragged.constant([[1, 2], [3]])
    ...   yield 42, ragged_tensor
    >>>
    >>> dataset = tf.data.Dataset.from_generator(
    ...      gen,
    ...      output_signature=(
    ...          tf.TensorSpec(shape=(), dtype=tf.int32),
    ...          tf.RaggedTensorSpec(shape=(2, None), dtype=tf.int32)))
    >>>
    >>> list(dataset.take(1))
    [(<tf.Tensor: shape=(), dtype=int32, numpy=42>,
    <tf.RaggedTensor [[1, 2], [3]]>)]",2
"If my assumptions are right, then this should work for dense, conv and separable conv layers:

import numpy as np

/# here you need to create the model

print('\n'.join([
    'layer: ' + type(l).__name__ +\
    ', output shape: ' + str(l.output_shape[1:]) +\
    ', weights: ' + str(sum([i.size for i in l.get_weights()])) +\
    ', multiplications: ' + str(sum([i.size for i in l.get_weights()]) * int(np.prod(l.output_shape[1: -1])))\
    for l in model.layers
]))",2
"2. **sparse_y_pred**: `IoU` and `MeanIoU` assumes both `target` and `output` are sparse signals, where categories are represented as natural integers.",2
"Conversely, `OneHotIoU` and `OneHotMeanIoU` assume both are probability distribution vectors.",2
"I assume that nobody has reported this, because usage of the rectangular image shape is the most common usage.",2
"- [ ] At the moment, I am very cavalier about things like ""layers with multiple input nodes""; I pretty much assume that everything will have a single input node that can contain one or more inbound layers.",2
"The Poisson loss is the negative log likelihood of data y_true given predictions y_pred, according to a Poisson model (assumes that y_pred > 0).",2
"I tried your implementation for my case but it dosent seems to work the loss still negative, I am assuming that I am using the hierarchical softmax layer correctly.",2
"The problem seems to be that the relevant part of `topology.py` assumes that just because the output tensors have their `_keras_shape`s defined, the `inputs` will also have them.",2
"We should not consume all ValueErrors and assume they fit the case where a
custom layer has not been registered.",2
The unit tests for `preprocess_weights_for_loading` also assume the input/output to be lists of numpy arrays (which is why the tests fail to detect [the error reported](https://github.com/keras-team/keras/pull/9112#issuecomment-372988910) in PR #9112).,2
2. Keras assumes the only one dataflow graph in the backend.,2
"Essentially: if you pass in a tuple into `output_shape`, Keras assumes `(nb_samples,)+output_shape`.",2
"If you pass a function into output shape, Keras assumes `tuple(output_shape())`.",2
"AutoEncoder **init()** assumed both encoder and decode have same number
of parameters and regularizers; this is not the case when using default
Dense encoder/decoder in current revision of Keras for instance.",2
"Remove  model_from_config method (which assumes the 'config' key to
exist).",2
"In addition, this change will cause Sequential models to start enforcing the input shape assumptions they were created with.",2
"Previously, Sequential would enforce the input shape assumptions of the first layer in the model.",2
"Also, we are now exposing `sample_weight` and `mask`, this is safer and more flexible that always assuming that the output and desired are always either `sample x time x dim` or `sample x dim`",2
One core assumption of the class is that the underlying generator must be able to produce infinite amount of data.,2
"The current Embedding class does not support mask propagation for inputs larger than 2 dimensions, as the `get_output_shape_for` method assumes a 2D output.",2
[`keras/setup.py`](https://github.com/fchollet/keras/blob/master/setup.py#L1-L2) already  assumes`setuptools` exists.,2
The schedule function for the LearningRateScheduler callback assumes that the learning rate argument is called lr.,2
"The current master branch code assumes these two sets are the same, which can cause graph construction to fail.",2
The tensorflow rnn() code assumes the outputs.dtyep is equal to the inputs.dtype (the part used only with a fixed batch size).,2
The tensorflow rnn() code currently assumes the 'outputs.dtype' of the step function is equal to the 'inputs.dtype' (the part used with a fixed batch size).,2
"There raises an error when utilizing mask in layer `ConvLSTM2D(x, mask)`, which is caused by the assumption that `mask.ndim == x.ndim - 1 ` in function `K.rnn()`.",2
"Normally, you would assume that after a layer which encodes inputs in such a way, you would no longer need a mask - however, in this case, it is possible that different numbers of sentences are passed for a given input, meaning that we still require a mask of shape `num_samples, num_sentences` to guard against this.",2
"The implementation in the `compute_mask` function of this PR assumes that if the dimension has changed by `n`, the output dimensions are just `input_shape[:-n]`.",2
"All examples run through under both Python2 and Python3, so I assume everything is in working order.",2
"This PR tries to check if a GPU device is available, and if so, works under the assumption that conv and pooling ops will be executed on GPU, thus allowing the native use of NCHW layout when using the channels_first data format, in TensorFlow.",2
"* Require stateful metrics layers to be actually stateful: It seems a bit confusing to me that the Layer of a stateful metric doesn't need to have the stateful attribute set - with the assumption that all Layer metrics will be stateful, and behaving statefully even without this attribute.",2
Is that a good assumption to make for the future?,2
"# This call will crash without this patch because
# it is assumed the parameters `x` and `y` are
# provided here and not via the ops
# x_train_batch and y_train_batch",2
"The behaviour of `Sequential.get_config` seems like a strange inconsistency but it also seems very intentional, so I assume it's about backwards compatibility.",2
"as title, mnist_sklearn_wrapper.py assumes image_dim_ordering to be ""th""",2
"This is to prevent situations where one assumes that using e.g. `keras.callbacks.ModelCheckpoint` will work and then trains an expensive model for an hour just to find it crashing due to such an unforeseeable, yet preventable problem.",2
"Though it is assumed, it should be stated explicitly for sake of clarity.",2
model.fit assumes it can figure out the size of the input.,2
there seems no reason to assume the output size of rnn should be the same as the state size.,2
- I assumed `convert_weights` would be helpful in embedding something like VGG net for feature extraction,2
When I saw the cost 'rmse' I simply assumed that the name say what it does root-mean-square.,2
Was under the assumption that older builds will be terminated when new commits came in.,2
> Was under the assumption that older builds will be terminated when new commits came in.,2
I assume this is because TensorFlow doesn't exist for Windows (yet?)?,2
I have assumed the latter and done the changes.,2
"@Danielhiversen I assume the `ValueError` is raised when running the tests with some backends, and not raised with other backends.",2
"Not sure what fraction of people reading the README.md would be targeted, but I would assume it would be far below 1% (0.1%?).",2
"By the way, @fchollet and @kuza55, I really don't like how these metrics are tested by simply hardcoding a value from the sklearn equivalent and assuming everything works if that single check works.",2
"whithout changing the public API and adding breaking changes, I don't know how I can check where does the tensor/ integer/float come from in those cases (I took those examples from the keras test suite so I assumed that the users could do it too).",2
And here is it assumed that the number of dimentions of the loss (and weights) is the number of dimensions of the network output minus one.,2
"Where you pointed out, in `compile()` in `training.py`, where I make that assumption, we don't have the weights yet to check the size.",2
- The 1:1 mapping between inputs and targets is an important assumption and we should not break it,2
"Ultimately I'm assuming anyone trying to do this is going to have to write their own Keras layers to handle those odd inputs, so there's certainly merit to the argument that these checks shouldn't be *too* easy to disable",2
We have no choice but just to assume that 9 jobs share computational resources and the last job left suffers from the timeout issue due to the lack of memory.,2
"While you assume that users want to capture the weights on `N-p`-th epoch, we don't know the exact local optimum in reality.",2
"The assumption behind early stopping is that by monitoring a quantity on the validation set, we can improve generalization, so it would be consistent to assume that model weights corresponding to epoch `N-p` (where the quantity monitored on the validation set has its best value) are more likely to generalize than those corresponding to epoch `N`, where the monitored quantity on the validation set is worse.",2
"I do think that the proposed implementation is more consistent with the assumptions of early stopping than the current one, though.",2
You should never assume that any library (or any of its dependencies) will only make stdout/stderr writes that you expect.,2
"Like `""backend"": ""mxnet.keras""`, assuming mxnet guys have added a `keras` sub module which is a valid backend.",2
This assumes that the deserialization process will know about the expected array dtype.,2
2. Adding a TF optimization is quite complex I assume?,2
I assume that this code is copying the file to the tmp directory before loading it.,2
"I changed the input dataset, making the target values assume the values `[0, 1, 2, 3]` instead of `[1, 1, ..., 1]`.",2
It seems that the `layer_test` function assumes that the layer has a single input and a single output.,2
"That shows how to create a TFRecord and read it (assuming you've merged the pull request), then train on mnist & test.",2
"If we wanted to include code into Keras that has multi-GPU support I assume we don't want to be using tf.device, even if we haven't settled on a Theano backend implementation.",2
Assuming librosa is available is fine.,2
"The [get_gradients](https://github.com/fchollet/keras/blob/master/keras/optimizers.py#L72) code is written assuming that there can be more than one element in the returned grads, but you may also be right that really there will only ever be one element.",2
"Assumes that fit_function returns a list, labeled by out_labels.",2
"I assumed when I saw more polymorphism in this PR and the other PR for input/output dimension computation that maybe it was just a repo-wide preference to allow implicit sequences, happy that's not the case!",2
In travis we should assume float64.,2
You can't really assume early stopping is being called on a previously saved model right?,2
This example makes a lot of assumptions (that there is validation data and that the only two metrics are accuracy and loss).,2
Assuming the is a precursor to https://github.com/keras-team/keras/pull/16943,2
I assume that is some sort of start output symbol.,2
I assumed they would not be a need for full docstrings since they are private.,2
I assume giraffe gave wrong results since ImageNet doesn't seem to have giraffes as a class - see class list here - https://gist.github.com/aaronpolhamus/964a4411c0906315deb9f4a3723aac57,2
It looks to me that this PR assumes that the Theano backend is being used.,2
"Keras uses the cudnn batch norm (http://deeplearning.net/software/theano_versions/dev/library/sandbox/cuda/dnn.html) with mode=""spatial"" which assumes axis=1, and then fails to broadcast (because axis 1 doesn't have dimension 1).",2
This makes the assumption that the batch size will be a constant 4.,2
The problem with the above is that it assumes that a tensor3 object is the type of the input - and therefore all of the necessary information is known to do the Reshapes correctly.,2
"Not sure if it is necessary, but a more complicated alternative would be to assume that int size should mirror floatX.",2
"You might be interested in tracking both a weighted and unweighted metric when you are optimizing for some weighted sub-problem that you have devised, but you still want to make sure the model is performing its initial job well, that is, its accuracy regardless of the weights (assuming a classification problem).",2
"The discrepancy isn't observed if `input_shape <= (224, 224, 3)` so I assume that is why it wasn't noticed before.",2
"Since I assume many will try to do transfer learning using weights from models in the Model Zoo plugged into new models, this could be a big issue",2
"This changes intermediate representations substantially, but should not affect significantly the last layer probabilities (assuming the network has been trained until convergence).",2
"@fchollet If we have, say, 100 batches in validation_data this would mean plotting 100 histograms, one per batch, on a same plot *every epoch* (assuming TensorBoard callback is configured to capture histograms every epoch).",2
"While TensorFlow assumes `depthwise_kernel_shape = (row, col, input_dim, depth_multiplier)`, Theano does `depthwise_kernel_shape = (input_dim * self.depth_multiplier, 1, row, col)`.",2
I would assume it should be more efficient.,2
"0. Assume one has loaded in a pretrained model with batchnorm, e.g., ResNet50.",2
Is it safe to assume this also affects VGG16 and that I should install this Keras fork?,2
"Pre-commit run is normally initialized by commit action, assuming the hooks are installed.",2
"Since such an interface is assumption-heavy, making the UX work smoothly will require very thorough assumption checking and helpful error messages.",2
I assume you have seen this before,2
"Note that `masked_weights` is assumed to be the same length as `obj_output` which is the output of the objective function, which as far as I know for every objective function, given an input of shape `(timesteps, samples, dimensions)` returns a score of shape `(timesteps, samples)`",2
"I thought of submitting a PR for those changes a year ago, but considering that the script was simply an example, I assumed it would benefit by adhering to the original paper.",2
I assume numeric accumulation is handled differently by cuDNN.,2
"Assuming that I restrict the rank enough, this can have significant computational savings.",2
"A) seems to be in use with other frameworks, and works with the assumption of smaller `weight_decay` on the same order as the `learning_rate`.",2
"Wouldn't it be safe to assume that when monitoring an accuracy, we should stop when accuracy is no longer increasing, by default?",2
"If the decision comes to change the existing functionality, I assume that is going to be a much longer process.",2
"Your code assume input is in numpy type, which is right during `flow` but fail in `fit` when it calls `x.dtype`.",2
"It seemed to me that letting callbacks have a pointer to the original model offered the maximum flexibility, which I assume we are going to need when building visualization UIs.",2
"> It seemed to me that letting callbacks have a pointer to the original model offered the maximum flexibility, which I assume we are going to need when building visualization UIs.",2
"I don't know about any ops that are created, but the names of the weight variables are as follows; I assume the ops have similar naming differences:",2
"Given these assumptions, it follows that the switch between the two behaviors should be a `compile` argument (like `sample_weight_mode`).",2
"- These methods were written with recursive containers in mind and should work correctly, assuming that the original `get/set_weights` methods do.",2
"This seems to assume `current_shape[0] != current_batch_size`, ie. `current_shape == X.shape[1:]`.",2
This made the assumption that Keras supports 3D input into Dense layers (required for networks that include at least one Recurrent layer and one non-recurrent layer).,2
"Since that example isn't doing anything special, I assume a wide range of models would be broken as well.",2
"But this is assuming that the last dimension is the feature dimension, such that its mask value is determined by its other `K.ndim(x)-1` indices.",2
"It's true, but this PR cannot be merged since it makes the assumption that Keras always use Theano.",2
I provide the warning you suggest but otherwise I assume the user meant to override defaults when they provide `steps_per_epoch`.,2
"Perhaps I also misunderstood the API usage, my notes below assume changes are needed to support TFRecords.",2
"In several places `model.fit()` [assumed that either x or y is not None](https://github.com/fchollet/keras/pull/6928/files#diff-299cfd5886683a4b012f286403769fc1L1322), which isn't the case if the data is supplied by a Tensor op.",2
Sample_weights in `model.fit()` assumes `x is not None and y is not None` in many places.,2
"- Compiling with no loss for `output`: `model.compile(loss=None)` (assuming `output` is the only output, otherwise use a dict to specify the losses or lack thereof)",2
"Assuming that you mean #7046: it looks very large, with several different things going on",2
"If your data does not come from a placeholder, or if your training does not follow the ""one loss/target per output"" assumption, then you would probably be better off using a TensorFlow-specific training loop, like Estimator. In that case Keras would just act as a topological engine for building models.",2
"> Assuming that you mean #7046: it looks very large, with several different things going on.",2
"I assumed it to be like a yield op that would just run continuously once started and fill up its queue, and also cause all previous ops to execute.",2
"I was just using that StagingArea as a queue to help buffer data & disk I/O, assuming it works as I expect.",2
"We assume this was done on purpose, and we will not be expecting any data to be passed to ""x_train_out"" during training.",2
"I assume its like a mesh network, each node with multiple inputs and outputs.",2
"- Again, this might sound stupid if my assumption about the working of `Graph` is wrong.",2
I assume this is on GPU; do you have the same for CPU?,2
"cuDNN does, though, but I assume you were not testing on GPU?",2
"In all the objectives, except for categorical crossentropy, the code assumes, that the labels are vectors and not matrices.",2
"I think that assumption is ok, since only in multi class problems the labels are one-hot encoded.",2
"> assuming all processes take the same amount of computation time, then all the files should be in order.",2
My comment was to point out one of the assumptions since I happened to come across it.,2
Too many assumptions; this would break people who process timeseries data while using the default `channels_first`.,2
"my assumptions about the transformations were that if they work for 1,3, or 4 dimensions they should work for N-dimensions.",2
"Then I can make another API addition and a unit test to go with https://github.com/keras-team/keras/pull/8106 (current unit test just merged in PR https://github.com/keras-team/keras/pull/8172, assumes identical semantics for `verbose=1` and `verbose=2`",2
I assume you are trying to avoid that?,2
"If we don't, we should add a unittest to make sure the assumption that was violated gets tested in a modular way.",2
The way I understand your explanations is that you intend to perform an inner product (dot product) between a rank m tensor (input) and a rank 1 tensor (weights) along the last rank of both tensors [assuming they have same dimension].,2
"In most use cases, `value_mask` would usually be the same as `key_mask`, assuming we do the multiplication by the mask before the attention operation.",2
"That should hopefully cover everything, assuming the build passes.",2
"- `cpu_relocation=True`, `cpu_merge=True` (the usecase assumed by @ghostplant): a base model exists on GPU and a user don't have NVLink.",2
This is unnecessary because a base model is already placed on GPU as you assumed.,2
Right now this is built to accept the output of a previous RRN layer as input because it assumes that the time axis is at 1.,2
"I assume that no error means that TensorFlow can write to the log, not that the visualizations will be correctly rendered by TensorBoard (because of the epochs alignment).",2
I'd assume this would be a common task to use the `EarlyStopping` callback for.,2
I'd assume this would be a common task to use the EarlyStopping callback for.,2
"But I assume that incorrect names affected values during your weight translations, because the `NASNet-mobile.h5` with `d9e0bd...` has random values only for the weights `reduction_right1_`.",2
"2. We need to focus only ImageNet models, because the `keras/applications` is assumed to be coupled with `decode_predictions` which returns ImageNet labels.",2
"And these assumptions are not always true, it's still useful because it matches the most common task in real-life and it's very intuitive to understand how layers work.",2
"And these assumptions are not always true, it's still
>    useful because it matches the most common task in real-life and it's very
>    intuitive to understand how layers work.",2
"> The implementation in the compute_mask function of this PR assumes that if the dimension has changed by n, the output dimensions are just input_shape[:-n].",2
"This would be a list/tuple of dimensions which your Layer reduces (automatically assumed to be none), which would allow the direct computation of the mask in `TimeDistributed` by computing `K.any(input_mask, reduced_dimensions)`, as this would return a mask value of 0 for that dimension iff there was no input.",2
There is a bug though: you assume `constants` are appended to `inputs` inside `rnn` but in fact they are appended to `states` (see e.g.: https://github.com/fchollet/keras/blob/master/keras/backend/tensorflow_backend.py#L2479).,2
"We could disable a lot of tests for Theano, Since models, topology,engine are already tested in TF, we can fairly assume that if the backend is well tested, there should not be any problem with Theano.",2
"# assume mnist was saved as an npy file and that
# NumpyInput is a YieldOp implementation",2
"We need some mechanism to make sure we keep updating these values as new training data is fed (I assume that calling the layer with train=False will trigger computing/caching of the values, and calling it with train=True will reset the values).",2
"@julienr I was thinking this would be useful for debugging shape mismatch errors, especially those arising from incorrect assumptions about reshape/flatten/embedding.",2
"> @julienr I was thinking this would be useful for debugging shape mismatch errors, especially those arising from incorrect assumptions about reshape/flatten/embedding.",2
I think they may be due to the shape assumptions; we may have to revert to inserting None entries everywhere in the shapes.,2
But I assume you won't want to put a full Inception model in the Keras repository just for testing.,2
"Assuming this latest merge passes the unit tests, this PR should now actually be an atomic commit where the parameters for `_standardize_input_data()` make sense and are actually utilized.",2
"In fact, for an adversary, account-based is easier to by-pass than IP-based (assuming that you are not doing both).",2
"Again, it is harder to obtain new IPs than to obtain new accounts, and account-based identification does not buy anything over IP-based identification, because email addresses are trivial to obtain and adversaries can be assumed to have access to hundreds of thousands of them.",2
"I assume it is experimental when not documented, at the same time it is merged.",2
"@JonathanCMitchell Yes I was looking at the EWA weights, and erroneously made the assumption that the session would load the EWA weights of the model.",2
And I believe all those assumptions are safe.,2
"I've been running on the assumption that the first variable of the `states` matches the output, (see this 

```
output = T.switch(mask, output, states[0]) # output previous output if masked.
```",2
> I've been running on the assumption that the first variable of the states matches the output,2
I think  its based on the assumption that no one uses the `rnn` api directly but a lot of people do.,2
# assumes pre-padding with '0' as index of non-character.,2
1) I think we need to be more defensive about assuming mask types.,2
"# Hey, this is making a lot of assumptions...",2
"The actual metric TruePositive is not great (I was going to clean it up), assumes a very specific structure of the input (2-class one hot encoding).",2
"I assume this is an minimal repro for the issue and not intended for merge, is it?",2
In a way assuming the one-time thing can only fail if the file or its format changes.,2
This change breaks multi-input or multi-output models as it assumes that the length of val_data is fixed to 3 (or 4 if self.model.uses_learning_phase is True).,2
"@farizrahman4u it's dangerous, because it assumes the batch size doesn't matter.",2
While waiting for this request to be accepted and available with the regular install of Keras I'm assuming I could pull the f-deconvolution3d branch of keras and build from source?,2
I've historically installed keras with pip/conda but I'm assuming that following the instructions in the /docker ReadMe file would suffice.,2
"Assuming a correct usage of the API, we should have:
- either categorical_crossentropy(Y, [0.**0**5, 0.89, 0.**0**6], from_logits=False)
- or categorical_crossentropy(Y, [0.5, 0.89, 0.6], from_logits=**True** )",2
"It would be even better to calculate
`sigma = np.cov(x, rowvar=False, bias=True)`
because current version (with dot product), just like Ng's example, assumes normalized data, what is not always true.",2
"Let's assume, you have 10 million pics, you split the train, valid, dev sets into 3 sets, i,e: 80%,10%,10% (test is separated also, on top of the 100%) then you decide to change the split to 95%,5%,5%.",2
"On seeing the argument `go_backwards` most developers would intuitively think of theano's scan api, and assume that `Recurrent` behaves exactly like `scan()`, so its better to leave it that way.",2
"However, the TerminateOnNaN callback itself doesn't seem to discriminate between the two, so I've gone ahead and assumed it's acceptable behaviour.",2
This looks better as it is more generic and makes less assumptions.,2
"If Travis detects it as abuse, then it should be assumed that it is unsafe behavior that may end up getting blocked on some platforms.",2
I'm assuming a wrong exception type is asserted somewhere now.,2
#Assumption: All inputs have same shape.,2
"Please note when considering this problem, I always assume it is in case of
bi-directional RNN.",2
I assume they haven't tried re-training it since the release of V2.,2
"Here we are talking about the gradients that are `aggregated by summing` - That's why I assumed the same should be done to metrics, and this is what we talked about in https://github.com/keras-team/keras/issues/15509 and it seemed a good direction - see https://github.com/keras-team/keras/issues/15509#issuecomment-948794332",2
3. `TPUStrategy` + default training loop: `first` is assumed,2
4. `TPUStrategy` + custom training loop: `first` is assumed,2
"@mthrok assuming we're looking at a square matrix, then yes.",2
- metric is a layer: assume it's stateful,2
"We should do it all under the hood sticking as closely as possible to existing Keras conventions, assuming that's viable.",2
"Also, it seems a bit confusing to me that the Layer of a stateful metric doesn't need to have the `stateful` attribute set - with the assumption that all Layer metrics will be stateful, and behaving statefully even without this attribute.",2
"Assuming pep8 passes, LGTM.",2
"When starting new threads with `Threading`, it becomes impossible to stop the children threads with a KeyboardInterrupt (unless some specific dispositions are taken, I assume).",2
The problem is in line 2104 of tensorflow_backend.py that assumes output dtype to be equal to the input dtype. (This is not the case in the Embedding layer),2
I wrote eye assuming a square matrix.,2
The issue seems to be that CuDNN is [*assumed* installed if CUDA is available and a GPU is being used](https://github.com/fchollet/keras/blob/master/keras/backend/theano_backend.py#L540).,2
"There is some assumptions for the code happens in the context:

1. All the weights will be convert to a lazyinitVariable. They will be replaced to DVariable at different time by different type of model.

2. Any model created within the scope will have the layout_map attached to them, and the map will be used to create DVariable for the model. If there is no model created in scope, then the LazyInitVariable will never be converted.

3. For subclass model, since the weights are created when the first time __call__ is invoked, we inject the __call__ to first init the variable with lazyinitVariable, and then map to DVariable. In this case, the layout_map_scope actually does nothing when user create the subclass model, since the weights are not created yet. The scope only allow the model fetch the layout_map, which can be inject to model.__init__ as well. But for API simplification purpose, we consolidate into just one API.

4. For functional/sequential model, since their weights are created eagerly, the DVariable creation happens at the init_graph_network. The scope approach is mostly used for this case, since the variable creation happens before functional.__init__. It will be too late if we inject the layout_map at __init__.

5. The DVariable creation has some special logic for disabling lazy_variable_scope, which was causing issue for functional model. The variable initializer usually uses tf.random.Generator under the hood. It will create the stateVar when init, and will be convert to a LazyInitVariable if the init happens in the scope. We would like to disable the scope for that case, since the init should happen with the tf.function on a dtensor device scope. The stateVar will be created as DVariable.",2
"fix a bug when model.fit assumed that x[0] has len, not true for sparse matrices (#6916)",2
Fix crossentropy loss by assuming last dimension as classes,2
Changed GPU driver version assumption,2
Fix error caused by incorrect rank assumption in tf.image.flip_left_right,2
[CherryPick2.6][TF XLA AOT] Assume aarch64 is always available.,2
"With the current implementation, TF-TRT converter will assume that **all** Conv2D layers are quantized in an engine.",2
"When binding metal buffer to tensor, the current implementation assumes the metal buffer to be in bphwc4 format.",2
"Based on the assumption that the meta-data of a tensor rarely changes between steps, we expect that on most times the cache will only be updated once.",2
"#4820 
I assume there is only one daemon thread consumes event_queue.",2
"If it isn't set its assumed to be 0
and the old code path runs.",2
_DepthwiseConvolutionConverter_ was designed based on the earlier definition of batch-group-convolutions and assumed that only depthwise filter convolutions used batch-group-convolutions in tf2xla.,2
That assumption is no longer valid and hence the incompatibility.,2
**Problem2**: The build scripts were written for Windows to assume only optimized builds.,2
"2:> Add assumption, that begin size and input dim are equal",2
"3:> Add assumptions, that begin, end, stride should be of same size",2
The changes make the assumption that callbacks with `_supports_tf_logs=True` also support numpy logs.,2
"- When we reload INT8 models that are saved with `save_gpu_specific_engine=False`, a new engine will be built using the saved calibration tables (assuming calibration was done before saving).",2
"Here the test assumes, that the allocation id does not change in any place.",2
"Removed the note from file: 
`// NOTE(ebrevdo): This assumes memory is little-endian.`",2
"Having this assumption broken, leads to the regression failures we see above.",2
"All existing make targets generate binaries for dedicated hardware (chip, board) and make assumptions on the way, the debugging log is written.",2
It is assumed that the new data is in the '/root/custom_data' directory in the Docker container you're training with.,2
"Besides, I think there might be some format issue on the '*' which I assume they should be used to highlight the ""In particular"" and ""With one exception"" sentence.",2
"Basic first-pass implementation of the Mean operator (assumes mean is always taken over axis 1 and 2, shader code likely has room for optimization)",2
"<li>Code that is overly dependent on the exact names attached to symbolic tensors (e.g. assumes there will be &quot;:0&quot; at the end of the inputs, treats names as unique identifiers instead of using <code>tensor.ref()</code>, etc.) may break.</li>",2
<li>Code that tries manually walking a <code>tf.keras.Model</code> layer by layer and assumes layers only ever have one positional argument.,2
"This assumption doesn't hold       true before TF 2.4 either, but is more likely to cause issues now.",2
Code assumes only strings inputs and then interprets numbers as valid `tstring`s.,2
"In addition, it assume current directory is the top directory of tensorflow, which is inflexible.",2
"Currently, `BoostedTreesClassifier` assumes that the labels are float in the gradient calculation and errors if they are integer.",2
"The user can backpropagate through the qr factorization and they should know what assumptions (limitations) are being made by the autodiff methodology, as detailed in the reference document:

[QR and LQ Decomposition Matrix Backpropagation Algorithms for Square, Wide, and Deep Matrices and Their Software Implementation](https://arxiv.org/abs/2009.10071)",2
Rem Assume that Python is installed to `C:\Program Files (x86)\Python`.,2
I assume it is meant to be LD_DEBUG?,2
I'm assuming that there won't be any change in the tests because of [this commit](https://github.com/tensorflow/tensorflow/commit/a1bc10f9e28cd3d33e91bfaedd8199e4590f2893).,2
"The existing code assume the shape of ```y_true``` is ```(num_samples, 1)```, always reduce in the last dimension which leads the incorrect output.",2
I'm assuming it should be the same as `quantization.md` that I'm fixing?,2
"This test reads half of the elements and assumes that the amount left
is more than will be prefectched which can be equal to the number
of CPU cores.",2
The previous approach I tried was dynamically editing the ecosystem poms using Python XML so that they would inherit from the parent pom but it made a number of hard-coded assumptions about the structure of the poms.,2
"Following on from [this discussion](https://github.com/tensorflow/tensorflow/issues/44491), `Dataset.map` docs imply setting `determinism=True` in `Dataset.map` will make the returned dataset deterministic (assuming the original is).",2
"It's quite natural to assume that ops are evaluated in order provided, especially since that's what cpu version of Tensorflow does (at least on every implementation I tried).",2
I assume that we are not handling unknown Tensorshape based on how it is being handled in 'Not Equal to`,2
"Since the model files have to be copied out of the apk due to assets directory readonly status and inability to create the FileChannel directly, it is assumed that you have done so to internal storage with the same context that is passed into the overloaded constructor.",2
I had assumed that it would round to the nearest integer; I was wrong.,2
"I assume that this behavior is deliberate and should be defined, rather than left undefined or implementation-defined.",2
"I looked a little into the context of how the variables 'last_node' and 'graph_info_->num_nodes()' are used. num_nodes() implies that the quantity returned is unsigned/non-negative, although the same assumption cannot be clearly made about last_node.",2
I cast last_node to size_t under the assumption that it is being utilized as a size/non-negative quantity.,2
"I'm assuming this is not by design but rather a bug, based on what I see in keras-team/keras#7035.",2
I don't know enough history with TensorFlow's code base though I assume `WIN32` should only be inside `tensorflow/core/platform`?,2
"Unfortunately, some clients, as in Java, assume this feature to be present in both cases.",2
"@advaitjain I haven't removed uint8 support yet since that's pretty much all the tests are for, so I'm assuming its in use here?",2
"In tflite_convert/toco, it's assumed that there is a BiasAdd
before or after a BatchToSpaceND.",2
"Please also note that this PR will not cause any test cases regression for TensorFlow, and it is also compatible with TF Lite models generated before because if the `Metadata` field is not found in the saved model, the loader will assume the model is generated with the same host endianness (which is basically what is happening without the changes).",2
Later transformation assume the contracting dims are consecutive to compute and compose permutations.,2
"This
allows splitting across the dynamic dimension though it assumes the dimension
can be legally split.",2
"Intermediate quantized type should be an I32 under all circumstances however
the lowering assumed the intermediate type was the same as the output type.",2
"The unit tests only tested taking gradients w.r.t. constants, as it was assumed there would be no functional difference between taking gradients w.r.t. variables and constants.",2
"This PR/commit removes them, assuming they are indeeded no longer required / dead-code.",2
"It seems like `model_dir` should maybe be renamed to `model_path` (assuming that it should link the file, not the directory which it is in)?",2
"It seems that it's a more common workflow than I assumed, and should be relatively foolproof.",2
"However, current code does not handle generators and assume the objects have a `shape` [training_generator.py#L458-L475](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/engine/training_generator.py#L458-L475)",2
The logic for the conversion has this assumption.,2
"This CL makes sure that this
assumption holds, and adds tests for NCHW format.",2
Assume one defines of an epoch to just mean how often the model is evaluated on the validation data.,2
I assume since some of them included the file the rest had access.,2
"Previously, the Concat layer had a bug where we only checked if the first input was a tensor, and then assumed all N inputs were tensors as well.",2
**Cause 1**: The CMake scripts were written to assume building from CMake directly due to it's usage of the CMAKE_BUILD_TYPE variable.,2
**Cause 2**: The CMake build scripts were written to assume 'Release' builds would only be built.,2
**Cause 3**: The CMake build scripts were written to assume 'Release' builds would only be built.,2
I'm assuming because the compiler doesn't strip out unused symbols and tries to link against it.,2
It also forces the pruning of unused custom ops in the PostQuantizePass by assuming all custom ops have no side effect.,2
"In current [`tflite::eigen_support::IncrementUsageCounter()` ](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/kernels/eigen_support.cc#L27), it assumes that `Eigen::setNbThreads()` changes the number of Eigen thread.",2
"This PR assumes 

a) oneDNN is upgraded to 2.1 (PR #: https://github.com/tensorflow/tensorflow/pull/47743) and 

b) stock TF and TF+oneDNN are using same oneDNN build (https://github.com/tensorflow/tensorflow/pull/47679)",2
"When giving feedback, please assume that I barely know what I'm doing.",2
"Currently, the ImplicitBatchModeCompatible strategy creates profiles with the
assumption that the first dim is always the batch dim.",2
"This helps people debugging their code, as otherwise they may assume `tf.gather` throws an error when invalid indices are present (it currently does so only when executed on CPU).",2
"The test previously assumed that all devices support float64, which isn't true for our device.",2
Simplify conditional compilation by assuming CUDA >= 10.0.,2
"The second case assumes that, in addition to [TF_DeleteTensor](https://github.com/tensorflow/tensorflow/blob/71c1ae43e2504da27ab60d1848b5fc0deec3fb31/tensorflow/c/tf_tensor.h#L111), the string should be deallocated with [TF_TString_Dealloc](https://github.com/tensorflow/tensorflow/blob/3fcba829d82ea34245db62afd45b9523e8db02d4/tensorflow/core/platform/ctstring.h#L28).",2
"This assumes that the included files are the ONLY ones used for r1.15
tests.",2
- It is assumed that the input graph is frozen.,2
This assumption will be removed in a follow up PR.,2
2. Freeze the graph - omitted since we assume frozen input graph,2
This avoids having to add a new config option for the NCCL2 header location by assuming /usr as the install location when NCCL is installed via debian.,2
The `MakeEdge` implementation assumes that there exists an output at `output_index` of `src` node and an input at `input_index` of `dst` node.,2
The builtin `BaseException` class defines a generic `__reduce__` method which assumes that the `args` attribute corresponds to constructor arguments.,2
"a `keras.Model` does not have a `_get_distribution_strategy` method, which is now assumed for the `Tensorboard` callback.",2
"The code wrongly assumed that os.system(cmd) returns the exit code of the
process.",2
The conversion includes a simple buffer assignment assuming that there are no branches.,2
"The current implementation of Tanh/Sigmoid activation functions for int16 (input/output) assume that
the parameter scale is POT (power of two).",2
I assume this is added to cover the use of the posix function sleep(seconds) which is not available on windows.,2
"That results in quite a few TF unit-test failures, because TF side assumes/expects the default to be 1024, and launches GPU kernels at runtime with block-size == 1024.",2
The for loop that follows this check assumes that `axis` is between `0` and `input_dims.size`.,2
"This PR primarily fixes the anchor text in the installation instructions, which I assume is fairly popular.",2
The pylint sections of `tensorflow/tools/ci_build/ci_sanity.sh` do not run on MacOS because they contain code that assumes the existence of `/proc/cpuinfo`.,2
The script `tensorflow/tools/ci_build/ci_build.sh` assumes that the `nvidia-docker` utility is present when running with a GPU-enabled Docker image.,2
"This assumption makes it difficult to check whether your code will configure, build, and link against CUDA when the machine you're running on doesn't have NVidia's development toolchain installed.",2
The tests //tensorflow/python/compiler/tensorrt/test:batch_matmul_test_gpu are flakey when evaluated on Ampere GPUs where TensorFloat32 evaluation is available because the thresholds have been calibrated assuming full float32 precision.,2
"In this case the output of the
    function will be assumed to consist of `tf.Tensor` objects with the unknown
    shapes and with the types defined by `output_types`.",2
"In this case the
    output will be assumed to consist of `tf.Tensor` objects with the shapes
    and types defined by these two arguments together.",2
"In this case the output will be assumed to
    consist of objects with the classes, shapes and types defined by
    `tf.TypeSpec` objects from `output_spec` argument.",2
It was also that the Structure module internally relied on the assumption that incoming objects would have the "dtype" property (see get_flat_tensor_types function).,2
"I can add a commit to make that change, assuming the reviewers are okay with it...please let me know if that is needed.",2
I declared it as a custom operator despite the RFFT having recently been promoted to a built-in operator as I assume that the decision whether an operator should be built-in or custom is not up to an external contributor to make.,2
"~This does not appear to increase the binary size at all (using `wc -c` to check), so I assume it may already have been linked but not exposed.",2
This does assume that `patch` command is on `PATH`.,2
"Assuming `a` and `b` are tensors, `a @ b`  is equivalent to `tf.matmul(a, b)`.",2
"Until now, the default value was assumed to be `num_phys_cores_per_socket`.",2
This PR adjusts the assumption based on the actual num_threads.,2
It then uses that API to configure some gemm_rewrite_test and matmul_test cases to use float32 rather than TF32 since those tests' tolerances were developed assuming full precision.,2
It then uses that API to configure various gemm_rewrite_tests to use float32 rather than TF32 since those tests' tolerances were developed assuming full precision.,2
"The current method for dealloc assumes that encoding succeeded, but segfaults when a string tensor is garbage collected whose encoding failed (e.g., due to mismatched dimensions).",2
"If the first node was assigned to CPU, these nodes caused a segfault in GetDeviceAllocator because we assumed that if a node had a device set, that device was a GPU.",2
"1. Assumptions
Current: variables are updated by optimizer operations
This PR : all the gradients are made by tf.gradients, the gradients of trainable variables are the target of aggregation in synchronous training",2
Assuming the example above: The userange of %0 are the operations inside the left block in between the first and last use of %0.,2
"Given the number of blog articles / youtube just on this topic by Google, I think it's fair to assume that we all understand how critical this topic is.",2
"The reason was that tf.image.flip_left_right assumes rank == 3 in case
of unknown rank.",2
"3. Thread one could then incorrectly assume that the function still
   existed, and fail to find it in the `FunctionLibraryRuntime::items_`
   map, causing a segfault when it attempted to increment the refcount
   on an uninitialized object.",2
"I believe that when this op uses cuDNN convolution functionality, it benefits from all the determinism solutions associated with that, including deterministic algorithm selection (assuming that still works).",2
"The reason was that the initializer passed could be v1 or v2 depending on the mode of the build, but only v1 mode is assumed (which has different signature with v2).",2
The issue is caused by the fact that shape inference in `common_shape_fns.cc` only assumes int32 without proper handling of diffent types.,2
This fixes a small typo in the release notes in the r2.0 branch with the assumption that the change will propagate into the master branch and/or later releases from the r2.0 branch.,2
"I assume this wasn't causing problems to people with NumPy up to 1.11.3, but it's better not to assume a specific NumPy version.",2
This is consistent with assumptions already made by JAX code.,2
This code change does assume it's set correctly,2
"In those
recent NDKs, clang assumes NEON vectors are aligned to 128-bit boundary,
and thus generates 128-bit address hints.",2
This particular test assumes int64 support.,2
"This is based on the assumption that the input models have leading
tfl.quantize ops and tailing tfl.dequantize ops.",2
This should not break the public release but I assume the non-default internal implementation will need updating.,2
"Under the assumption that 6 significant figures is good enough, I increased the threshold that the test cases use when comparing gradients.",2
Inconsistencies could cause bugs because Python layer may assume oneDNN is disabled when it's not.,2
"It is assumed that this compile failure will be fixed by code updates either on the TF side or eigen side, after which the eigen patch file will again not be needed",2
Maintainers: I'm assuming that you would prefer the smallest possible PRs in order to extend the support across all/most predefined metric functions; even though that increases is overhead from your side in dealing with reviews / CI-handholding.,2
It's assumed that matrix bias and vector bias don't co-exist.,2
"The x86 part I assume means the 32 bit compiler is used, while the amd64 part means you are building an 64 bit application, two very different things.",2
This seems to be caused by the annotation processor using the system's default encoding but for the compilation UTF-8 is assumed.,2
I am assuming it is meant to link to `ISSUE_TEMPLATE.md` instead of `ISSUES.md`.,2
I couldn't find it in the commit history but I assume there was a reason to not bring along TensorBoard right away.,2
"Not certain why it isn't triggered on other uses of the return from GetTensorData, perhaps being within control-flow constructs causes g++ to assume the nullptr case is already handled.",2
- Remove the assumption that `VarHandleOp` is an immediate parent of `ReadVariableOp`.,2
description in `b_is_sparse` should be "assume most values in `b` are zero" instead of `a`.,2
Single test case proves that everything was wired up correctly since I assume the `LRNGrad` code was thoroughly tested.,2
"Closing for now, I assume this is on the roadmap, @zheng-xq and @leary-google ?",2
"I assumed since it was assigned to @itsmeolivia, I shouldn't yet merge.",2
It's safe to assume they're all supposed to be converted (except in RELEASES.md).,2
Am I correct in assuming that this PR provided a variant of `tf.split` which supported dynamic arguments --- i.e. for which arguments `num_or_size_splits` and/or `num` can be integer-typed tensors?,2
"I'm aware of `tf.dynamic_partition`; but, am under the impression that a `dynamic_split` method would be decidedly more efficient (owing to implicit contiguity assumptions).",2
@caisq @martinwicke  I assume you guys are looking at this :),2
(assuming this is an accident),2
@danmane I assume this PR is obsolete?,2
"(I couldn't find any reference to the build files anymore, so I'm assuming they can be deleted)",2
"therefore ignoring CLA, assuming CLA is all taken care of in master branch.",2
@jart I am going to close this for now to keep our PR list small - I assume it's on your TODO list to get this working internally first -- please coordinate with @DrMarcII once you get something working to get this PR in.,2
We could just enable them for Linux assuming they're not slower there.,2
This then assumes that the rank is static – I don't know enough about TF to know if that is a problem.,2
"The change looks good to me, assuming the tests pass.",2
I assume none of our automated tests use this because of the Hadoop distribution dependency.,2
"also lots of failures, but I assume you're looking at that.",2
"Unless they're reading in plain text, then it's safe to assume they will be able to follow links by themselves.",2
I'll assume this is a mistake.,2
I'm assuming this is transient.,2
I assume this PR was created in error -- I will close it.,2
"But if you allow '/anything:here', the parsing logic basically has to assume that anything other than 'job', 'task', and 'replica' must be a device, which is error prone.",2
I'm assuming there's a performance advantage to using `+ 0.5` instead of `tf.round`?,2
"The old behavior is
```
new = old * (max+0.5)
```
with the assumption that values are between 0 and 1 before.",2
#I assume this is somewhat equivalent to the ProfileContext's role,2
"I was
assuming those estimators support multiple series (for example multivariate
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/timeseries/examples/multivariate.py)
so I could use part of the series (one of the columns in the data)  as
weights.",2
"Test failure seems like infra failure, since one of the previously failing suites passed, I'm assuming it's all good.",2
I'm assuming this pull request wasn't intentional?,2
"Example (assuming 1.x):

```
import tensorflow as tf
x = tf.ones((10, 10))
if x:  # will error out
  print('hey')
```",2
"If yes, I assume they should follow the same guidelines, right?",2
"> assume they should follow the same guidelines, right?",2
"Even simpler: ` //tensorflow/python/keras/layers:lstm_v2_test` bazel target, I assumed passing the directory would run all tests there.",2
My assumption is that the runtime boolean suggestion only applies to the later scenario.,2
> My assumption is that the runtime boolean suggestion only applies to the later scenario.,2
"Also, to reiterate: I suggested not to use ""#ifdef"" under the assumption that it's easy to implement.",2
So I assume this fix may only be in 2.0 unless it is cherry-picked by 1.13.,2
I am closing this as well since I assume you'll be doing this from internal together with the new API design.,2
"In the meantime, I am going to close this since I assume you'll be doing this internally.",2
"Yes; it's an extension now that bijector inverses (and inverse log det
jacobian functions) can return tuples - under the assumption that the
preimage is always len(tuple)-valued.",2
"Tests were previously failing since the scipy `halfnorm`'s first arg was not `scale` as I assumed, but `loc`, where loc is both the mean of the base distribution and the fold point.",2
"I had assumed that the internal issue was with the definition of `workspace_root` in `tensorflow.bzl`, so I thought you were suggesting some different way of defining `workspace_root` inside the `BUILD` file directly.",2
"Also, I assume the `reduction=tf.losses.Reduction.NONE`kwarg is necessary to be able to apply the masks in the batch dimension?",2
"> Currently, the assumptions are:
>
>    1. the TensorArrays size is the time dimension
>    2. the TensorArrays contain Tensors with the same shape assumption as
>    Tensors that are directly in the cell state",2
# assume beam_ids > -1,2
"This property needs to be documented, because one might somehow assume that using the sparse version would do the same thing as the dense one, just more efficiently when you have sparse updates.",2
"Assuming this passes, could you squash this PR into two commits: one containing @buaaliyi's changes and one containing yours?",2
"@rohan100jain Added new commit, updated description to clarify how `num_classes` is computed, and updated example code to hopefully clarify further what labels are assumed to exist.",2
@pooyadavoodi you might be running it on the wrong directory (it assumes it'll be run from within the root directory),2
Looks like the CLA bot might need some time to propagate (assuming your account is covered by a corporate CLA?).,2
@drivanov I assume that you are still working on this as there are comments that aren't addressed yet.,2
"@ebrevdo: I assume adding 'scope' is the right change to the API, can you confirm?",2
That problem should be easy enough to fix - I assume that just needs a new line the tf_http_archive stanza?,2
"Since you have the sed_hyphen_i lines lower I think the assumption is that
it is not.",2
"> I am assuming ./configure is the only one who touchs .bazelrc, is that ok?",2
"Assume you already have C API headers, the import library and the DLL for tensorflow in your local base in the following structure:
```
$ tree
.
├── hello_tf.c
├── include
│?? └── tensorflow
│??     └── c
│??         ├── c_api.h
│??         ├── eager
│??         │?? └── c_api.h
│??         └── LICENSE
└── lib
    ├── tensorflow.dll
    └── tensorflow.lib
```",2
"> The next steps assume that the IDF environment variables are set :
> 
> The IDF_PATH environment variable is set
> idf.py and Xtensa-esp32 tools (e.g. xtensa-esp32-elf-gcc) are in $PATH
> esp32-camera should be downloaded in components/ dir of example as explained in Building the example(below)",2
"However, looks like you haven't removed the assumption of dims <= 4.",2
"This should be merged pretty soon, assuming no tests fail.",2
Rather I would prefer smoothing to be defined all the way to the left and right with a reduced window (which is what I assume happens initially) on both sides.,2
"I would expect that `tf.io.gfile.isdir(x)` should always return the same boolean as `tf.io.gfile.stat(x).is_directory`, assuming no errors.",2
So I assume it won't be a problem,2
"The script assumes it's run from that directory, it's probably better to `cd` to something like `dirname $0`.",2
I would assume that the placement is always on the same device.,2
"This can't break cmake, so assuming infra failure.",2
"For instance if someone does not know `LOG(FATAL)` crashes , they might assume that `ParseInstructionList` legitimately returns false if `root_node` is `nullptr`.",2
I assume there's a use case?,2
These commit messages should be meaningful so that the list of commits in the PR make sense and also so that the commits make sense in the commit log of the master branch after the merge (assuming the commits don't get squashed).,2
I assume something similar happens with the AMD toolchain.,2
I'm assuming this has to do with BUILD dependencies?,2
">> Yes, assuming that your histogram output is an integral type that is either unsigned or won't overflow at runtime.",2
"@freedomtan Clarification: What I had to revert was the addition of whole_file_reader_op on Android, which I assume was just needed for a one-off test, and should not have been part of the original PR?",2
"I'm going to close this, assuming that we're acting on this.",2
I assume XLA only has this check because it uses DT_INVALID for uninitialized variables.,2
"We tracked this problem all the way from kubeflow which uses a lot of TensorFlow components, and they all make the assumption that s3 is present, but it was removed so using a newer tensorflow breaks the components (tensorboard, tf serving, for example)",2
"> We tracked this problem all the way from kubeflow which uses a lot of TensorFlow components, and they all make the assumption that s3 is present, but it was removed so using a newer tensorflow breaks the components (tensorboard, tf serving, for example)",2
"Simply kicking off CI again will do, assuming no one is breaking the HEAD on GitHub again.",2
"I'm assuming it has to be attended to, but I'm not entirely sure how to interpret the log.",2
"I'll close this, assuming that the above is sufficient.",2
@martinwicke @vrv Should be okay to merge assuming approval from @zheng-xq .,2
"I just assumed that because this was so similar to the traditional dense layer and because it is very commonly used in RL that it should be added to TensorFlow, but if you think it would fit TF add ons better then I can submit a PR there.",2
"m assuming this is something that will get resolved upstream, and I do not need to worry about it.",2
I'll go ahead and write the example in the RFC assuming the existence of `tf.io.gfile.GFile(...).load_directory(...) -> bytes`,2
Would it make sense to integrate this change without those other changes (assuming no one has time to do them yet)?,2
"I am not sure if `SaveModel` on its own does this, I assume it does not.",2
"Existing code that checks for ""device:GPU"" is likely specialized for CUDA GPUs, so I don't think it's correct in general to assume we can alias over it.",2
"I assume you are trying to find it by some sort of import, which would not work as the script is not added as an api.",2
"With our PR, we tried to remove the above assert assuming that type of data and the system match.",2
"More seriously, some more structured guidance for non-Google committers would be helpful, as there is a lot of assumed knowledge of the Google development processes that external committers just don't have.",2
"I didn't review the change for the existing for to add use_explicit_precision, assuming that will be gone.",2
"this line works:      PadONNXResult<<<1, 1, 0, stream>>>(param, outputIndexData, nmsIndicesOutput);
I assume they mean the same. do they?",2
"> this line works: PadONNXResult<<<1, 1, 0, stream>>>(param, outputIndexData, nmsIndicesOutput); I assume they mean the same. do they?",2
Feel free to ping me on this PR here WED this week or after assuming I have not gotten back to this thread to provide the link and more info.,2
"I've (for now, based on confirmation from you and @nluehr (thanks!)) assumed that the tf packaged in the image is functionally identical to tf nightly (since i've replicated fp16 AMP with XLA speeds for 1x V100 on my image).",2
"Hi Pete,

I'd assume the PR was on Ice due to the Freeze - thus hadn't follow-up on it.",2
My assumption is that we should now be able to get this merged.,2
"Assuming things look good, the last thing I need to do is update the documentation to indicate that 1/2 dimensional broadcasting is supported.",2
@andydavis1 I assume this is okay now?,2
"My only suggestion would be to make the system smarter with respect to argument types (like adding float types to int types should automatically return a float, assuming shapes are compatible).",2
I'm removing myself as reviewer because I assume that we'll integrate this via SIG IO (where hopefully the same build issues won't be a problem!)...,2
"That is because I assumed hanging indentations should be of 2 spaces, like code indentations, but actually pylint excepts 4 spaces.",2
"Assuming the tests pass, LGTM.",2
"So your assumption that input_dims should be `[1,2]` is not true.",2
I am assuming there's no need to really test the python API part since it eventually comes down to the C++ API anyway.,2
Many tutorials for example still assume pandas to be part of official tensorflow dockers but it seems to be gone during the move from `docker` to `dockerfiles` as the official source.,2
"I assume yes, but you may have more context.",2
The numa-related bits that you're touching in this change were written into the code base a long time ago on the assumption that someday we'd want do numa-specific memory allocation and registration,2
Is this assumption correct?,2
Instead it should be safer to assume that metrics_config is either a dict or a list of dicts.,2
@yifeif   Do you mind merging after the tests pass (assuming they pass).,2
"@yifeif I assume you'll be merging this in after the tests passes, etc?",2
"I've changed the commit to add shard count instead, assuming all tests are independent.",2
"As mentioned internally, this change incorrectly assumes that the channel_multiplier is 1.",2
"> As mentioned internally, this change incorrectly assumes that the channel_multiplier is 1.",2
So I assumed it was OK.,2
"Assuming it does, it should be reasonably easy to fix by manually editing

```
 core/ops/compat/ops_history.v0.pbtxt
```

to remove the types that are invalid.",2
"@av8ramit assuming this passes tests (which I believe it should), can we wait for this before cut?",2
I'm slowly catching up but the problem seems to be that tensorflow/python/tools/saved_model_cli_test.py assumes both x86 and aarch64 are always available.,2
"This is 33% better memory efficiency that a conversion to float16 would offer, assuming float16 models take 50% less memory than float32 (`1. - .33/.5 = .33`).",2
"I assume
FindOpenMP hits those correctly.",2
"I assume
> FindOpenMP hits those correctly.",2
// Assumes that endian-ness is same for float and uint32.,2
I would assume they would fail because `requests` is not added to `workspace.bzl`.,2
The [test cases](https://github.com/tensorflow/tensorflow/blob/235192d47cfb375c0cc93c1deefb9e440715bf35/tensorflow/python/kernel_tests/stage_op_test.py#L240-L275) assume FIFO behaviour.,2
The native lib is typically assumed to be preinstalled.,2
"I assume it makes more sense once everything is merged, and I would like to get idea what that will look like.",2
however - apparently you can update the index to mark it as assume-unchanged.,2
"For now, the API will just assume filter/bias has already reordered if we simply change the `vectorCount` to 32 in the cudnn code sample or if we enable int8x32 in this PR.",2
"Ideally, the implementation would use the fused version if possible, assuming there are no significant numeric differences.",2
"I assume this didn't trigger CLABot reevaluation, as the action was taken outside of Github.",2
"I assumed there is a separate step to create this, but I cheated by just copying another copy I had to the path.",2
I saw some 64 bit assumptions and some things that we don't support currently.,2
"My last comment was:

""Okay, I'm fine with this description assuming the other reviewers agree that this description actually matches what the code does.""",2
"* We're not using NEON in the current build (I'm assuming because of the ARMv6 target), but I think it's provides pretty significant optimizations (@petewarden knows more about the details of this than myself).",2
"Just for illustration purposes, let's assume that `PyUFunc_RegisterLoopForType` had the following declaration (I've removed some parameters to make it simpler, but the most important `PyUFuncGenericFunction` is still there):
```
int PyUFunc_RegisterLoopForType(PyUFuncGenericFunction);
```",2
"However, assuming that I was not mistaken about this issue, it would still not work.",2
I saw that you added a commit that addressed all the comments so I assumed the PR is ready for review.,2
"It's not clear to me whether you want to build or run TensorFlow with
different CUDA versions, but I think this PR should not affect either (for
building, assuming we allow specifying the cuBLAS include directory during
./configure)",2
"I didn't look over these very carefully, since I assume they are almost identical to the ones that were removed.",2
Perhaps there's some unspecified assumption that this PR would break?,2
"@josh11b @asimshankar can we do an API check now, I'd love for this to land in 1.10, assuming we are ok with it.",2
"* Also, if the environment variable is set to """", then assume the user wants to use the default value.",2
1. The log-joint has more than one variable (currently it seems that `leapfrog_step` assumes that the inputs cannot be a list),2
"The API of ` tf.nn.embedding_lookup_sparse` requires:

> This op assumes that there is at least one id for each row in the dense tensor represented by sp_ids",2
"@drpngx @BrianOn99 The demo currently assumes a 90 degree rotation, so I don't see an issue with this, unless I'm misunderstanding something.",2
@osdamv You should be able to assume that width == stride when using the camera 1 api,2
"The class MultiBoxTracker(its job is draw the boxes, the detection works fine) pretty much assumes everything would have the api2, IMHO  the detector demo requieres a lot of more of refactoring and sadly is a part I don't need for my project, if you wish I can upload my changes",2
"@vrv: there are some assumptions about shapes being fully defined at graph construction time in ` _dynamic_rnn_loop`, as highlighted in my comment posed on Nov 15, 2016 above.",2
"Due to these assumptions, I cannot write unit tests with inputs with unknown shapes at graph construction time, as is desired by @ebrevdo.",2
"> @vrv <https://github.com/vrv>: there are some assumptions about shapes
> being fully defined at graph construction time in _dynamic_rnn_loop, as
> highlighted in my comment posed on Nov 15, 2016 above.",2
"Due to these
> assumptions, I cannot write unit tests with inputs with unknown shapes at
> graph construction time, as is desired by @ebrevdo
> <https://github.com/ebrevdo>.",2
I will open a new PR for the test code as I assume we want to observe if failing before this PR is pulled.,2
"> I will open a new PR for the test code as I assume we want to observe if
> failing before this PR is pulled.",2
@tensorflow-jenkins: test this please (I'm assuming this is correct ahead of time).,2
Our current assumption is that there is a working CLA in place.,2
"Linux XLA didn't exist at r1.0, so I'm assuming this is probably good.",2
"Assume that the user has a workflow with two models:
```
input -> model_A -> model_B -> output
```",2
"This is probably the most correct (assuming the things you want to show are usage warnings), and e.g. matches what numpy does, but it's a lot of work, and might require rethinking log levels.",2
@sb2nov This is ready to merge assuming it passes tests.,2
"This change is big enough in terms of the impact on installation that we
may want to wait another full 7 days until we exit RC (assuming everything
else is clear).",2
"In the span of working on this PR I was just using print statements in combination with `--test_output=streamed`, and I'm assuming there must be a better way to do this.",2
"You are right that it doesn't support multi-label classification, which is a bummer, but as far as I can see, your approach (as it is right now) doesn't either, because it still uses confusion_matrix which AFAIK assumes a single class per element.",2
I assume if there was a way to do this using `SymbolicGradient`/`REGISTER_OP_GRADIENT` you already would be?,2
I assume `TF_AddGradientsWithPrefix` will use them eventually?,2
The user was assuming the shape was constant which wasn't true.,2
Shouldn't we create this considering that in mind because most of the users by default will assume this because of common programming paradigm,2
"90f612774e6 [XLA/GPU] Plug in a basic latency estimator for GPU - Assume latency is high between async-start/done pairs - Assume custom calls for cuBLAS, cuDNN and softmax are high cost, else medium cost.",2
// assume validation passed,2
I guess one or more of the assumptions spelled out in the comment are causing the error.,2
"After a few years of using bazel we have found there is absolutely no way to be successful without a significant amount of configuration in a root `.bazelrc` file, so I didn't even consider this as an issue since I assume any significantly complex iOS application will have to have the same.",2
"@tensorflow-jenkins test this please

(I assume I'm supposed to test again?)",2
I doubt that we can make the assumption here that all downstream users will handle splat constant tensors in an "optimized" way.,2
It would be nice to avoid introducing always-on patterns at an early stage like HLO to assume a specific downstream use case.,2
"Instead of adding it as a folding pattern, given the concerns of materializing large constants (and assuming everything downstream handles splat constants effectively) maybe make it opt-in.",2
My assumption earlier was that an n-d const op is *always* better than a 0-d const + broadcast - either if you don't optimize or if you optimize (in which case it's easier to optimize/rewrite with n-d const + another op).,2
"As there is not linalg constant, I assume to standard.",2
My assumption earlier was that an n-d const op is always better than a 0-d const + broadcast - either if you don't optimize or if you optimize (in which case it's easier to optimize/rewrite with n-d const + another op).,2
An internal test assumed the file you renamed in this PR to contain the string 'ptx'.,2
"I'm also weary of having code elsewhere that assumes `out_logits == concat[true_logits, sampled_logits]`.",2
I'm assuming that since this is still a WIP we should hold off on reviewing and testing it.,2
"Since the `decode_gif` option always has three color channels, this will return a 3-D tensor for single-framed gifs (assuming the image is larger than 1x1) and 4-D tensors otherwise.",2
I assume it's because the working directory isn't what the test expects. (It looks like the similar code `image_ops_test.py` isn't running as part of the Windows build because it's in `python/ops` rather than `python/kernel_tests`.),2
I'm assuming that the failures are completely unrelated to the PR.,2
"I assume that end users, especially those unfamiliar with hardware, would rather not tweak the network parameters, unless the goal is benchmarking.",2
"@asimshankar it says, we make assumption that one session has one graph:
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/c/c_api.h#L59",2
"Assuming to be a scripting mistake.`, which seems to be a clang config error.",2
"Our publishing to website pipeline goes via md, so that would be easiest, probably, assuming we want to have documentation for the go part on tensorflow.org.",2
"My assumption though is that session.close() will be called automatically by the __del__ method when session goes out of scope, so functionally the logic here would be identical.",2
"fine for API, assuming tests are fixed.",2
Assuming you've seen this?,2
"@martinwicke Right, I'm assuming the docstring is meant to explain how the functionality works, in which case expanding out the full functionality makes it clearer.",2
"I will have to assume there will always be three channels, then -- but I guess that's fine?",2
"I'll wait with fixing this problem in the entire project until after you've moved to Python 3 completely, so we could switch straight to `raise foo from bar`. (Assuming I won't be too busy then.)",2
"I haven't fully investigated the model but here is my assumption:
* The model itself is very small with just a handful number of weights. So using quantization won't save you much space. 
* However, quantization adds some overhead to the model size (e.g. a map between quantized values and float value) which result in the small difference that you see.",2
LGTM assuming tests pass,2
"@danijar: I assume this is okay since you contributed this already to master.

(This is a weird edge case @willnorris)",2
"Okay, the CPU tests are failing because I haven't adjusted the code that creates the pip package (It still assumes that eigen is located in `eigen_archive/eigen-eigen-\w+`).",2
I tested Windows CPU and Linux GPU and assumed that would be enough.,2
"However, I think they'll cause the existing distributed tests to fail, because they assume that the old flags are valid.",2
In particular [`dist_mnist_test.sh`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/dist_test/scripts/dist_mnist_test.sh) makes assumptions about the flags that `mnist_replica.py` accepts,2
I think I incorrectly assumed that it wouldn't happen just by looking at the regex.,2
"There were some external tests/apps making assumptions about the lifetime of the TfLiteIntArray used for the resized tensor, so had to make a small fix there.",2
Would have assumed that code to have been fairly well exercised.,2
"Cosine decay  does not automatically assume restarts, it defines how learning rate decays / the shape of its decrease.",2
"That makes it impossible for us to detect when ends the list or when starts the next input, and we lose track of the input attributes (we actually assume each input is a single one).",2
">    That makes it impossible for us to detect when ends the list or when starts
>    the next input, and we lose track of the input attributes (we actually
>    assume each input is a single one).",2
I assume that this might be beneficial for people that are used to standard keras in order to have the same API also for the `tf.keras`.,2
"I assume that one shouldn't use imports from `tensorflow.python` at all, right?",2
"I think of it as follows: assume in step {t-1} we got (_, old_state, cur_input, context) = decoder_fn(...).",2
"> I think of it as follows: assume in step {t-1} we got (_, old_state,
> cur_input, context) = decoder_fn(...).",2
"Our `simple_decoder_fn_inference` happens to be a specific decoder_fn that uses argmax for cell_output to get discrete words & then do embedding lookup from the argmax results (so we made an implicit assumption that at training time, `inputs` passed to the `dynamic_rnn_decoder` was looked up from the same `embeddings` matrix).",2
"Okay, I assume we are all good on the code now and I will start writing docstrings followed by `kernel_tests`.",2
I assume it should be accessible both while training and validating.,2
"Furthermore, I assume the only major challenge left (before writing docstrings and building) is the equality test mentioned by @ebrevdo ? (please see latest ""requested changes"").",2
I assume the code is finalized now.,2
I assume the reason why we use `tf.convert_to_tensor` was because the user might supply a numpy matrix instead.,2
"I assume the reason why we use tf.convert_to_tensor was because
> the user might supply a numpy matrix instead? (@ebrevdo
> https://github.com/ebrevdo?)",2
I think @dfki-mako was assuming this.,2
"I think this is better as a tutorial / file outside of the repo, as it currently makes several assumption about the environment it is going to run in (i.e: what happens if someone wants to use TensorFlow on Fedora? ArchLinux? Gentoo? NixOS?; `apt` won't work on either of these and the script would just be one extra file in the directory).",2
"Can you take this to TensorFlow/networking, assuming it's not fixed there?",2
"Would appreciate any extra info on that, as I said, it's very hard to reproduce since everything is working great on my MacOS, but I assume that target architecture could be different.",2
I would assume the gradient performance of a `RaggedTensor` could be better than a corresponding dense `Tensor` since the number of entries in a `RaggedTensor` is often less than that in a dense `Tensor`.,2
So I assume the slow down is caused by another piece of code.,2
"@drpngx Yes, as in case of CUDA, we assume an OFED package is installed with all the drivers and user space libraries for RDMA to properly function.",2
@byronyi I assume you're still working on this?,2
1. We assume an optimizer is an optimzier wrapper if and only if it has an `_optimizer` attribute.,2
I have now annotated the v1 version with @tf_export(v1=['debugging.assert_shapes']). (I assume v1 is for graph mode as the other v1 versions of assert functions return the op explicitly),2
"I assume that refactoring <op>.h is a routine step in porting any TFL op to TFLM, and many ops have been ported by doing that.",2
"However, there might be other code bases that assume iterators work with `generator_fit()`.",2
"To me it looks wrong, and my assumption is that donation can only be applicable for aliased buffers, i.e. one should not donate a buffer that is not aliased.",2
Assuming you are still seeing an error because of `swift_rules_dependencies()` in the WORKSPACE?,2
"This will get into our automation for merging, you don't need to do anything else now (assuming the bots manage to pass all the tests).",2
"> This will get into our automation for merging, you don't need to do anything else now (assuming the bots manage to pass all the tests).",2
I have assumed that rsqrt(variance+epsilon) always positive to be the base case (ground truth).,2
"I manually fixed it, accepting both forms of the doctest, as one is a `tf.function`, the other one is assuming eager execution.",2
I assume this is a test related to `tf.contrib.slim`.,2
"This assumption about DCHECK may be true on ""big"" Arm and x86, but it's not true on embedded.",2
"The RFC states that there could be more than one device with the same `device_type` (e.g., ""GPU"") under the assumption that there will be another key, `sub_device_type` (see [figures here](https://github.com/tensorflow/community/blob/master/rfcs/20200624-pluggable-device-for-tensorflow.md#supported-user-scenarios-of-pluggabledevice)), to distinguish between different devices during kernel lookup, e.g., `{device_type=""GPU"", sub_device_type=""DIRECTML""}`.",2
"Our assumption was that the `device_type` could be `GPU` and `device_name` was basically the equivalent of `sub_device_type`, which allows TensorFlow to differentiate between the built-in `GPU` devices and the other devices internally if needed.",2
I'd write a separate PR but I assume it will hit the same issue with copybara.,2
Regarding the changes in `tensorflow/core/api_def/python_api/api_def_Add.pbtxt` I'm assuming I have to remove the endpoints and add `visibility: HIDDEN`?,2
"I'm assuming that along with adding examples to `python/ops/math_ops.py`, I will similarly have to do the same to `core/ops/math_ops.cc`.",2
"> Assuming we do, the same change needs to be made there as well I assume.",2
"Oups, sorry, I assumed too quick that it was unrelated again, I’ll check it out",2
"If the lib is building for mobile, then lib is stored in a arch-related folder, if is it building for ""server-side"" (I guess the designer somehow assumed that if it is building for linux/mac, then it is building for host), then the lib is just stored into a ""lib"" without arch info.",2
"This assumes that for native/disk filesystems, `os.path.join` ""knows"" the right separator to use and that all other filesystems (`ram`, `gc`) `/` is the right separator.",2
"> This assumes that for native/disk filesystems, os.path.join ""knows"" the right separator to use and that all other filesystems (ram, gc) / is the right separator.",2
"Assuming that they are yours, you can simply squash them.",2
My first assumption was it was different line endings... but after a binary diff it showed that it had not changed.,2
I going to assume the difference might be command line build single configuration build vs Visual Studio IDE build.,2
I'm assuming it would work.,2
"I assume there are some modules in the filetree that aren't explicitly imported by one of their parents or tested by the tests in `tf_tests.cmake`, and so we've been getting away with having fewer modules in the CMake files.",2
That is assuming that custom_am_bsp_low_power_init() gets called first...,2
"@dandelionmane I wrote this change under the assumption that dependent projects might choose to write their own ./configure scripts, that define the .bazelrc in their root directory.",2
"Assume we have three .bazelrc files:

- ~/.bazelrc
- ~/tf_serving/.bazelrc
- ~/tf_serving/tensorflow/.bazelrc",2
"@dandelionmane <https://github.com/dandelionmane> I wrote this change under
the assumption that dependent projects might choose to write their own
./configure scripts, that define the .bazelrc in their root directory.",2
"Assume we have three .bazelrc files:

   - ~/.bazelrc
   - ~/tf_serving/.bazelrc
   - ~/tf_serving/tensorflow/.bazelrc",2
"Assuming it's all fine (lots of things have changed since the list time we tried this), then I'm fine removing the strip.",2
"If you need a gif for tests (I'm assuming you do), can you make or use one that is <20k?",2
"@petewarden said LGTM, so I'll assume he means it.",2
Assuming this has been resolved.,2
"Up to Jianwei, but I'm assuming we're not taking renames here and will do any necessary renames during the move to core.",2
My assumption is that the memory savings should be modest.,2
"I triggered the tests again, assuming they pass, assign me and I'll merge this.",2
"MacOS's built-in `sed` wants the empty string, `gsed` doesn't which is why there is a check (though for platform, assuming if you're on mac you're not using gsed):

```shell
function sed_hyphen_i() {
  if is_macos; then
    sed -i '' ""$@""
  else
    sed -i ""$@""
  fi
}
```",2
I assume the test failures due to API change are expected and just require manual approval/override?,2
"@vrv @gunan Also, since this is a PR to master (rather than 0.12.1 that gcr.io/tensorflow/tensorflow:latest-devel-gpu is currently based on), I assume this won't affect containers until at least 1.0, unless an update is made to 0.12.1, which I assume is probably not advised at this point, but of course it's your decision :)",2
"For the record, I assume it will behave the same way on hardware, so it's not really Renode-related",2
[TensorFlow `v2.6.2`](https://github.com/tensorflow/tensorflow/releases/tag/v2.6.2) was _just_ cut (minutes ago :rocket:) so it should be up on PyPI soon I would assume.,2
bazel-out/x64_windows-opt-exec-50AE0418/bin\tensorflow/core/protobuf/saved_object_graph.pb.h(137): error C4430: missing type specifier - int assumed.,2
bazel-out/x64_windows-opt-exec-50AE0418/bin\tensorflow/core/protobuf/saved_object_graph.pb.h(138): error C4430: missing type specifier - int assumed.,2
My assumption is that `-mcpu=cortex-a57` should be removed from all CMAKE_*_FLAGS in XNNPACK config (not only for GNU id) if they are not empty to avoid any compiler configuration issues.,2
"LGTM, assuming it passes the tests.",2
"Looking at the log (and assuming you are running internally on ROCm) , it seems that you are running with sharding enabled.",2
"> Looking at the log (and assuming you are running internally on ROCm) , it seems that you are running with sharding enabled.",2
"@akuegel,  I am assuming you will handle the issue of `--arch=sm_70,compute_75` being hard-coded in `.../build_test.sh` on your end.",2
"> @akuegel, I am assuming you will handle the issue of `--arch=sm_70,compute_75` being hard-coded in `.../build_test.sh` on your end.",2
"Are there any reasons that Android build should depend on `kernels_experimental` at all, assuming this library's purpose is to be used by pluggable devices?",2
"Are there any reasons that Android build should depend on kernels_experimental at all, assuming this library's purpose is to be used by pluggable devices?",2
"The commit author email is `lipracer@gemail.com` right now, I assumed this is a typo.",2
Tensorflow still fails to build when using the negativo17's cuda package because nvvm can't be found (it's assumed to be under `cuda/nvvm`),2
@gunan I assume the Windows cmake failures here can be ignored?,2
assuming that the JIT client op can create such a thing.,2
"With resources, you need to know which inputs are not updated, because when you only have counts of variables you have to work with the assumption that the last 'N' inputs and last 'M' outputs are retained resources.",2
"Get rid of the following `__init__` arguments: scope (no longer used), layer_norm (assume true), and layer_norm_columns (assume true).",2
Err (in the new cell for `layer_norm_columns` assume False: that's your code :),2
"Marking as WIP until you have resolved test failures (it's not checked off the list yet, I assume it's not done).",2
"If ldconfig does not know the location, then the user is prompted and the default location is `CUDA_TOOLKIT_PATH` which should give us a good chance of finding libnccl assuming it was put in the proper location.",2
I also like the move that the build system assumes the files are stored where installed by apt-get when possible.,2
Assuming header is at /usr/local/cuda-9.0/include/nccl.h,2
The build script assumes that nccl can be found without extra additions (I think) @aaroey I think you made the build script changes for nccl.,2
"I had to modify one other unit test which assumed that the random flip functions can only handle 3D input data, which caused the tests to fail.",2
I will still be pursuing the single contracting dimensions assumption in algsimp.,2
"I will
> still be pursuing the single contracting dimensions assumption in algsimp.",2
"For example, assume 2 mac test runs for 2 different PRs.",2
My assumption here is that the `.hlo.text` files are mostly identical for the cuda and rocm targets and only differ in some minor areas.,2
"With that commit gone, this PR is no longer needed...assuming that commit does not come back.",2
"[Intel community CI build - Windows CPU](https://tensorflow-ci.intel.com/job/tf-pr-win/1136/) passed, so I'll assume this PR is safe for x86 and will proceed with merging.",2
I think this hits a principle of development for MLIR passes: the only invariant you can assume on your input is that the verifier is passing.,2
I assume it was a copy & paste error from the second example that operates on numpy arrays.,2
"I assume it will be more performant to express them directly, than just using backprop though a fairly complex graph.",2
2. I could checkout the branch Pbanavara made fix it up and commit the results (also fixing the conflicts with master) assuming I had permissions to do so.,2
I assumed the test suite would catch if there had been any problems.,2
I assumed it was irrelevant.,2
I also assume here that `NotImplementedError` > `ValueError` ?,2
"Otherwise it looks like it should be good to go, assuming the tests pass.",2
I assume that branch is closed now.,2
"For context you can assume, there is some function `get_data()` which fetches one sample of data point from database on every call and returns `None` when one epoch is completed.",2
"For context you can assume, there is some function
> get_data() which fetches one sample of data point from database on every
> call and returns None when one epoch is completed.",2
I’m assuming `third_party` is just some internal CI folder.,2
"Assuming, the `//tensorflow/core/kernels:portable_tensorflow_kernels` target is correct, could you provide more details about the fail.",2
But this approach assumes specific hardware config for running tensorflow tests which may not be desirable.,2
"The deprecated_graph_mode_only decorators mean we don't run them with 2.x behavior, probably because they assume Graph+Sessions.",2
@rafafael03 Since the PR is merged you should be able to get it from the tf-nightly build (pip install tf-nightly-gpu) from tomorrow I assume.,2
"This may happen as part of switching to https://github.com/abseil/abseil-cpp, assuming they also use (or switch to) std::int64_t.",2
"Assume a 3D tensor with 2D-images along the 3rd dimension, now I'm doing a fft2d.",2
I'm seeing a reasonable speed improvement of R-CNN training after upgrading from 1.13 to master (which I assume is due to the GPU NMS kernel),2
"It does look like though it is assuming 32 lanes per warp, eg [here](https://github.com/ROCmSoftwarePlatform/tensorflow-upstream/blob/develop-upstream/tensorflow/core/kernels/depthwise_conv_op_gpu.h#L1510).",2
"@whchung I don't have enough background to tell what impact this assumption has on AMD Gpus, mind taking a look and remind me what I should do for the default 32 lanes per warp?",2
"> It does look like though it is assuming 32 lanes per warp, eg [here](https://github.com/ROCmSoftwarePlatform/tensorflow-upstream/blob/develop-upstream/tensorflow/core/kernels/depthwise_conv_op_gpu.h#L1510).",2
"@chsigg I synced with @whchung offline and we agree that the assumption on 32 lanes per warp to be addressed al-together in future PR, together with `kGpuWarpAll` [here](https://github.com/tensorflow/tensorflow/blob/ce09f4ad03a5a97dae2db17b76b95288bbf4bdb1/tensorflow/core/util/gpu_device_functions.h#L137).",2
* I assume that the `zmq_msg_recv()` call can block.,2
"As such, I assume it should be sufficient if @MarkPKCollier signs the agreement.",2
"For nested functions, I assume you see these in the style guide that I provided:",2
6. Using fprintf() for the debug log makes the assumption that the target has a file system.,2
> 2. Using fprintf() for the debug log makes the assumption that the target has a file system.,2
"cc_shared_library migration is intended to eliminate all of the code duplication between the .so, so I assume there shouldn't be a change in binary size right?",2
Am I correct in assuming that's unrelated to this PR?,2
"I don't have a range of devices around for benchmarking, but given that the iPhone Xs runs the DFT on CoreML, I would only assume a bigger performance benefit for older models (and an identical one for newer models).",2
"But, I referred the sample from existing exception handling and made the changes assuming the goal of that is to let someone else satisfy the operation before returning the error.",2
"@akuegel  oh I see, The lint CI didn't fail so I assumed every thing is good, but I will make sure to check for tabs in future.",2
@sanjoy Just get some feedback from CuDNN and CuDNN depwise convolution actually assumes the multiplier needs to be one.,2
"Assume they are based on the same paper, can we close this PR?",2
Assume it's true.,2
Some parts of `AttentionWrapper` assume that the output size is defined at construction time which would not be the case here.,2
My assumption was that CMSIS has fallback paths for all cortex M targets.,2
"If I understand correctly the above comment, TFLite-for-Microcontrollers breaks this assumption by actually using this as the user code path?",2
Let's assume the windows failure is some environment issue.,2
Assuming we want `ROCm` and `Cuda` into one class:,2
"IMO, creating lists (white/grey/black) to control bfloat16 rewrite in grappler pass could create confusion: on one hand, it means that we do not trust kernel writer/developer by assuming that they could register L2Loss for bfloat16 type by mistake, while on other hand, it expects them to register their ""correct"" bfloat16 op (Conv2D for example) with the grappler pass (by adding it to the white list).",2
"> IMO, creating lists (white/grey/black) to control bfloat16 rewrite in grappler pass could create confusion: on one hand, it means that we do not trust kernel writer/developer by assuming that they could register L2Loss for bfloat16 type by mistake, while on other hand, it expects them to register their ""correct"" bfloat16 op (Conv2D for example) with the grappler pass (by adding it to the white list).",2
"> > IMO, creating lists (white/grey/black) to control bfloat16 rewrite in grappler pass could create confusion: on one hand, it means that we do not trust kernel writer/developer by assuming that they could register L2Loss for bfloat16 type by mistake, while on other hand, it expects them to register their ""correct"" bfloat16 op (Conv2D for example) with the grappler pass (by adding it to the white list).",2
I would assume that any functionality in XLA also should not have the hard dependency on libnvrtc availability either.,2
The original assumption was that tensor sizes (except string tensors) did not change over the course of training.,2
"As new models appear, the assumption is not valid anymore.",2
"Looks good, assuming that's the right way to import `compat`.",2
I assume it is flaky.,2
Currently we use half of the number of physical cores for all threading settings in TFLite interpreter and delegates in assumption that typical Android device chip set implements big.LITTLE architecture (this assumption is kind of statistically proven to be fair since using all physical cores leads to the lower performance).,2
"In this way you can send future PRs in parallel (assuming you don't depend on the failing targets), and at least we can make some progress.",2
"Neverthess, I think it makes more sense to analyze performance using an artifact that is closer to what is executed (and figure out how to maintain metadata to present meaningful feedback to the user) instead of analyzing an artifact that is close to what user sees and make assumptions about how will the user program be ""compiled"" into graph computation.",2
When users do remote data processing I believe we can assume they are sufficiently power users to know what they are doing.,2
I'm assuming we can't use anything similar for building TF; just for the runtime.,2
The rpath mechanism assumes only that the cuda lib pip packages are installed adjacent to the tensorflow package. (Things would not work in a corner case such as installing the cuda libs among the the system packages while installing tensorflow in a "system-site-packages" venv.),2
> The rpath mechanism assumes only that the cuda lib pip packages are installed adjacent to the tensorflow package.,2
Currently Tensorflow assumes that certain files exist in the same directory as each other.,2
For example `link.stub` and `nvlink` are assumed to both be in `cuda_config.cuda_toolkit_path` [here](https://github.com/tensorflow/tensorflow/pull/42187/files#diff-27368da6eb4c2514a27a4d9733bc9b57L1073-L1074).,2
"In TF-TRT, the creation of graph segments that are convertible to TensorRT is a Grappler pass and requires shape inference, assuming valid feeds.",2
"This is because aggressive constant folding assumes that the shapes of placeholders match the actual feed, as TF-TRT does.",2
The state proposed here is very confusing: when I'm editing a method which has `Cudnn` in its name I assume it's cudnn-specific.,2
I'm assuming this is a Kokoro failure?,2
"I have work for couple of fusions (with DNNL aka INTEL_MKL) based on this PR, i.e., an assumption that remapper runs before arithmetic_optimizer.",2
"2. I can see this not being a priority and to be honest, I cannot really say what the potential bad side effects of this would be (assuming the obtained element was a copy of the corresponding bytes in the buffer).",2
Currently they are assumed to be immutable (at least that's my understanding) and that's why I thought such an addition to the API would be fine.,2
"CI failure does not look related to these changes, seeing the same failure on #56345 (which has no code changes) so I assume this is noise.",2
"Let's assume we have a fuseable network:

- BN -> loss -> BN_Grad",2
"I see, the testing framework assumes that there are no spaces while figuring out the shapes of the tensors that are randomly generated as inputs for the tests.",2
"Assuming this is correct, how do we go about marking this PR as ""merged"".",2
"The problem with your solution is that it assumes that the threadpool use for executing parallel map is always the interop threadpool, which is not the case.",2
"The PR has been updated, I assume it will fix the error.",2
I'm assuming you'll squash it anyway so it's good to go I think.,2
"Since this is already not the case, I'm ok accepting this as is (I have not reviewed the code, assuming the code is ok).",2
> I'm assuming this doesn't have a noticeable performance impact when tracing is not enabled?,2
Well the code here is unchanged so I just assumed that the issue still persists. (We always build with this patch applied),2
I'm assuming these four build failures are unrelated to my pull request.,2
> I'm assuming these four build failures are unrelated to my pull request.,2
"But since I'm assuming XLA is baked into TensorFlow's big .so file, it's probably not as trivial as writing a cc_binary() to define a custom tip for the entire TensorFlow build.",2
I'm assuming you're still working on this.,2
"But as I said, at least when it comes to the input tensors there are a few exceptions were that assumption does not hold.",2
"But as I said, at least when it comes to the
> input tensors there are a few exceptions were that assumption does not
> hold.",2
I assume the performance regression discussed above has been fixed?,2
@rachellim Assuming it does fix the issue cleanly as a cherry-pick.,2
When I was searching for atrous_conv1d I only found atrous_conv2d and assumed only that one is implemented (and I implemented one myself mimicking atrous_conv1d implementation before realizing there's general convolution which handles all cases).,2
"@jbms assuming tests pass, is this approved?",2
I'm going to assume the build timeout is unrelated since no tests were added.,2
"I would assume that the first was simply an error, but I am hearing that this is all due to natural language ambiguity, so I am not sure, maybe I'm misunderstanding something here?",2
I assumed this was a bug.,2
- One problem with my original implementation is that the exclusive use of a node is assumed.,2
> One problem with my original implementation is that the exclusive use of a node is assumed.,2
I assume 90% of the situations are covered by that and then you can always use the ctor args to overwrite values that are gotten wrong or are non-standard.,2
"Assume the record is `1` bytes and the footer is `2` bytes:
```
HRFF
```",2
I'm assuming this needs to be rebased.,2
I would assume this is unrelated?,2
Assume the CLA is signed ;),2
I couldn't see the log but assume that is a CI or network error?,2
"I haven't seen the `coordinator` error before, assuming it's some rare flakiness.",2
I assume this is unrelated?,2
"For the case where no weights are given and they are assumed to be one, then it would be best to have the implementation call CUB as it will be _significantly_ faster.",2
I assume the changes in API definition since then will have made this fail tests.,2
"@drpngx Not knowing enough history about the code base though I would assume the reason of having `keepdims` instead of `keep_dims` is to align with `numpy`? e.g., 

https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.amin.html#numpy.amin",2
I would assume setting desired fps and scale require more discussion about the API/etc.,2
"The error related to `MacOS CPU Tests` is the timeout of 
```
//tensorflow/python/kernel_tests:slice_op_test
```
, which I assume it is unrelated.",2
I assume v1.6.0 will be released fairly soon.,2
@martinwicke I assume this requires an API review.,2
Maybe we could move forward to merge with this PR (assuming no other outstanding issue) so that the original issue #12344 could be closed?,2
I had assumed that the kernel launch would be automatically handled by the framework (e.g. in `TensorExecutor`),2
"Currently this PR checks if the output is zero in the backward op and if so, assumes it was dropped.",2
But this assumption is not necessarily correct.,2
"@jhetherly it sound to me like we can merge this, assuming the tests pass.",2
It is generally assumed that any individual Op is much less expensive than a cluster of many ops.,2
Assuming you will take care of that part.,2
"I assume this together with `if_gpu_is_configured` helped address linker issues, if any",2
"So I'll see if I can get Jenkins to test it as well - I'm assuming it is a bot:

Jenkins, test this please.

(Reminds me of this :-) https://www.youtube.com/watch?v=MFqxdvggAxM",2
It looks like we do rely on the assumption that taking a subslice past the end returns an empty slice.,2
I assume it's these from the Windows log?,2
"I added the CMSIS include paths to tensorflow/lite/micro/tools/make/ext_libs/cmsis.inc
in the context of #41860, assuming they are necessary.",2
"Indeed, I was wrongly assuming that all functions were inlined prior to running Grappler with this flag, but it is possible to mark some functions so that they won't be inlined and mark them as needing to be processed by the TF-TRT optimization pass.",2
the fix assumes that the problem will have gone away by the next major compiler release.,2
Assuming this holds more or less the same for half and double this amounts to 16.8 seconds on our older 32 core Power8 machine with nvcc 8.0.61.,2
My device actually fails quite a few of the tests because they are written with the assumption that devices support the full intersection of CPU/GPU types (which out device currently does not).,2
Assumption is that Arduino use the default path. (Actually jacking in a CMSIS_PATH have some other problems basically because it is unpatched but it is out of scope for this PR.),2
"Not sure where it comes from, though I assume a rerun might be able to fix it?",2
@quantumlicht I would assume you may get more help from StackOverflow as there are more users there.,2
"I assume git is treating it differently from a regular file because it's actually a submodule, but I'm not sure how I'm supposed to switch local branches cleanly with this behavior.",2
"> You change from Operation* to Optional seem to assume a single result everywhere, There aren't any multi-results op?",2
"About the scalar part, i am sorry for the confusion may be i was not very clear last time, this is part of the symmetric quantization i.e scalar values can be quantized assuming the range to the min and max of the data type, this is the same i tried to do even in the Test cases as well.",2
"@aselle Yeah, I think there's more to a general reimplementation of `np.repeat()` than what I posted in that answer (assuming I'm thinking of the same one as you...).",2
"I'm assuming that if it passes, then we can ignore @mrry comment, otherwise we will need the author to make that change.",2
We will merge assuming the tests are happy.,2
Am I correct in assuming the tests for that should be placed into the file elemental_ir_emitter_test.cc?,2
will assume that for the moment.,2
I assume the 1x1 and mxn results in the second table are just noise.,2
This code assumes that the broadcast is valid.,2
"However, assuming we can get to linalg (for example assuming that the shape at runtime has no `1` component and we hence never need to expand; the scalar case you use would be an example for this), we can lower this to three linalg operations that we then fuse.",2
I'm happy for this to be merged (assuming it passes review) with the understanding it will be removed when the C plugin interface is available.,2
"Shall I rebase the PR and force-push, assuming that my branch caught the tree at the bad moment?",2
"So instead the assumption is that a distributed filesystem handles the shards, and each parameter server can just dump whatever they have to it.",2
"This assumption is annoying if there is no distributed filesystem, but I don't think copying all the shards to a single machine helps.",2
I've made changes to address this based on the assumption that setting the variable value in configured will set it in the configure script.,2
"Both of these test cases assumed 32 byte alignment, hence the failures.",2
I suspect that your training diverged as the optimizer is not active in the forward pass (assuming you don't do inference on the backward pass).,2
"> I suspect that your training diverged as the optimizer is not active in
> the forward pass (assuming you don't do inference on the backward pass).",2
I guess I assumed that there gradient testing utilities were a bit too magical.,2
"Assuming this works in the general case, the downside is that it will prevent some optimizations like the one done in cross entropy gradient function which computes only the product between dependent parts of gradient and Jacobian.",2
I'll assume it's fixed in the other pull request.,2
Another example is our libpng config assumes a specific version of zlib.,2
"It looks like the underlying #26731 is fixed, so I'm assuming we can close this now?",2
"I haven't tried `--host_action_env` yet (it is very new) but I assume `--action_env` already sets those, especially as we use `--distinct_host_configuration=false` already.",2
Approve assuming this is a pure reverting commit,2
I assume this PR was opened in error.,2
"Now that oneDNN 2.5 is out, we will probably need another patch to move the oneDNN version for the mkl_aarch64 build from 2.4 to 2.5, assuming that's the intent for the x86 build.",2
"It is probably ok, but it does cast some doubt on the quality of this test. Increasing the threshold (or changing the seed) are acceptable, assuming we have made extra certain that our new scheme does not introduce some bias.",2
I will start by making tests as advised in #4686 for the `dynamic_rnn_decoder` and I assume you would like kernel tests for this seq2seq loss function as well?,2
"@rajendraarora16 I assume the failure is unrelated to your change, but since I cannot find any logs, I'll run the tests again to be safe.",2
"It seems ModelAverageOptimizer assumes there's not any MODEL_VARIALBES, but that's a bad assumption.",2
The "MODEL_VARIALBES assumption"  is fixed.,2
"The one chosen in
TF is: float images are assumed to be [0,1) normalized (unless HDR), and
integer images are [0,max] representing fix point [0,1).",2
I am still not convinced that doing this in Python is better than doing this in placer but assuming the PR addresses my comments below I support the change.,2
"@meteorcloudy I believe @vit-stepanovs contributed that particular piece of code, and I assume he used overlapped I/O here because it's the easiest way to read from a particular offset **without** a race condition if multiple threads are accessing the file. (@drpngx: I'm not sure what race condition you mean here. The return value is non-deterministic, sure, but as long as we handle it as Yun does here, I think it's threadsafe.)",2
"Looking at your PR more closely, it seems like I misunderstood the nature of your change (and the nature of `slice_input_producer()`, which I had mistakenly assumed produces batches rather than single elements...).",2
"So I built one with the following command:
`g++ -shared -o tensorflow/lite/tools/make/gen/linux_x86_64/lib/libtensorflow-lite.so -Wl,--whole-archive tensorflow/lite/tools/make/gen/linux_x86_64/lib/libtensorflow-lite.a -Wl,--no-whole-archive,--as-needed -lstdc++ -lpthread -lm -lz -ldl`
(assuming I compiled the static library with `make -f tensorflow/lite/tools/make/Makefile BUILD_WITH_NNAPI=false TARGET=linux TARGET_ARCH=x86_64`)",2
I am assuming you must have made many benchmarks across different models with this fix on your custom versions of PT-XLA.,2
"Jonathan, I assume this is good to go pending tests?",2
"I'm going to assume it's ok, and attempt to pull this in.",2
I didn't update the Go wrappers because I assume they're updated automatically.,2
"There are few places in pluggable_device_process_state like `AllocatorParts` will require changes to accomodate the SimpleAllocator design, currently it assumes the Device memory allocator is BFC.",2
"> There are few places in pluggable_device_process_state like `AllocatorParts` will require changes to accomodate the SimpleAllocator design, currently it assumes the Device memory allocator is BFC.",2
We are assuming the API review will be done by @fchollet .,2
"There is also -DCMAKE_BUILD_TYPE:STRING=Release passed to the grpc cmake but assume that is never looked at,, else this this would have been broken in past.",2
"I'm not very experienced with bazel, so I assumed I'm supposed to be running the bazel commands from the tensorflow directory.",2
"Assuming this eventually happens, I'd be inclined to add `Tensor.shape` as an alias for `Tensor.get_shape()`, instead of accepting this PR.",2
Note that another difference between v0.x and v1.x is that v0.x assumes matrices are in column major order and v1.x assumes row-major.,2
I'm assuming this is an accident (like most of these branch merge PRs are).,2
"You are assuming that we will agree that such a linter will be a good thing to apply universally, while for example we may decide to excluded every tests from the linter.",2
I assume you'll have to re-trigger CI since that doesn't seem to run automatically.,2
"The first line:
    !/usr/bin/env python
assumes that the default python is the version that we are using to build.",2
But the jump is from 1.5.3 to 2.0.0 so I assume there would be some porting required (I have not looked into it yet tho).,2
"How exactly were you going to run the tests on Android devices, assuming the `kernels:all` build would succeed with this change?",2
"I removed the `--noenable_platform_specific_config` + `--config=macos` combo (the former prevents the implicit `--config=macos` assuming bazel on M1 still detects the host system as macos, the second one adds it explicitly) triggered by `--config=macos_arm64` assuming it's a no-op.",2
@gunan assuming @aselle is gone already.,2
(assuming this is an accident).,2
assuming it's transient.,2
> assuming it's transient.,2
"@fayeshine - If this was the ""MNIST for Beginners"" tutorial, I'd agree with you, but seeing as this is tutorial is ""for experts"", we should assume that users will have some experience building neural networks in other frameworks or languages, and will likely have used dropout before.",2
"I assume this is safe to remove, but please tell me if otherwise.",2
"> My assumption was that irregardless of the input being quantized or not,
> negation is agnostic of the zero-point.",2
> Is this assumption flawed?,2
"My assumption was that irregardless of the input being quantized or not, negation is agnostic of the zero-point.",2
Is this assumption flawed?,2
"Assuming, you added the modifier to work around some issue on Mac.",2
"My concern with the current PR is it may lead to confusion, as reading code full of CU*** prefixes I would assume it's CUDA-specific and does not touch ROCm.",2
We assumed that this one was missing.,2
"Assume we have a custom OP like this:

	template <typename T>
	class NumericResource : public tensorflow::ResourceBase
	{
	private:
		std::atomic<T> value;

	public:
		NumericResource() : value(0) {}
		T get() const { return value; }
		void inc() { ++value; }
		virtual std::string DebugString()
		{
			std::ostringstream oss;
			oss << value;
			return oss.str();
		}
	};
	typedef NumericResource<int> IntResource;

	class IntVarOp : public tensorflow::ResourceOpKernel<IntResource>
	{
	public:
		explicit IntVarOp(OpKernelConstruction* context) : tensorflow::ResourceOpKernel<IntResource>(context) {}
	private:
		virtual tensorflow::Status CreateResource(IntResource** resource)
		{
			*resource = new IntResource();
			return tensorflow::Status::OK();
		}
	};

	REGISTER_KERNEL_BUILDER(Name(""IntVar"").Device(""CPU""), IntVarOp);",2
"This change assumes that the maximum sequence length is known and fixed, which breaks backwards compatibility.",2
"We cannot accept this PR because it assumes a fixed length when calculating
the log_crf.",2
"Assuming your test actually adds 9 seconds to the total test time, I think it'd be good to shrink it even more.",2
This is fine for API review assuming that one change is made.,2
"@guschmue am I assuming that this PR might also address the gap seemingly underlying #6184, i.e. see specifically [this issue comment](https://github.com/tensorflow/tensorflow/issues/6184#issuecomment-267374882)

Or am I overinterpreting here?",2
"So after the rebase, on my local machine:
```bazel test //tensorflow/c:c_api_function_test```
works, however, I am assuming the gpu cc CI is setup to run linking to cuda or something like this.",2
Assuming they build things should progress from here.,2
I prefer device_fn over ps_strategy due to the fact that device_fn is more general but ps_strategy assumes ps is not the cluster.,2
"But in future, this assumption might not hold anymore.",2
"I assume it would fail on Windows and pass with the new check added, but don't have a Windows machine to really confirm that...",2
"Fix Block::splitBlock and Block::eraseFromFunction that erronously assume
    blocks belong to functions.",2
"The current logic assumes that ShapedType indicates a vector or tensor, which will not be true soon when MemRef subclasses ShapedType",2
"Implement the
    inverse convresion assuming affine expressions are simplified and
    canonicalizied, detect subtractive and multiplicative forms of the stripe
    operation.",2
"The current implementation makes some assumptions about what can be a shaped type, which aren't really necessary.",2
This assumes a specific file path format that breaks on MSVC.,2
"IndexedAccessorIterator makes some assumptions about the element type that do not hold for the result type, i.e. pointer elements.",2
We are already assuming that size() calls fit into int64_t in a number of other cases like the aforementioned getRank() (since exabytes of RAM are rare).,2
If we want to avoid this assumption we will have to come up with a principled way to do it throughout.,2
"Simplifying assumptions are made for now on the views and the ranges that are constructed
    in the function and are not passed as function arguments.",2
The dispatcher previously assumed that it wouldn't receive requests for repetition N before reaching the end of repetition N-1.,2
"Previously GetNext assumed that a downstream iterator would always have recording enabled before calling GetNext, so GetNext would always ""turn it back on"" at the end.",2
"This CL also makes a similar change to RunWithBorrowedArgs, which previously made the same assumption.",2
"// Assumes `get_next_fn` returns 1, 2, 3, ...",2
"For example, if the tensorlist isn't passed to TensorListResize/TensorListPushBack, then we will assume the Tensorlist's size isn't changed.",2
"In particular, the Eigen code used for MatrixSolveLS and MatrixTriangularSolve assumes no aliasing.",2
(3) Adds constructor for AddSymbolicGradients that assumes OnesLike when grad_inputs aren't provided.,2
Both the compile and preprocessing ops are assumed to be inside of tf_device.launch ops.,2
"Without this, you need to
pessimistically assume that they are all unaligned and copy all of them.",2
// assume you have a tensor with dimensions,2
"Since the op is named ""TFLite_Detection_PostProcess"", the selective build script will assume the register fuction named as above.",2
"However, if that assumption is not true, a custom op is required.",2
ASBS assumes request latency can be minimized at a specific number of batch processing threads.,2
It handles Resource subtypes as well and assumes all variant subtypes are cast compatible.,2
This CL also does some cleanup in shape_util and layout_util where we have assumed that shapes are either arrays or tuples.,2
"That is, it assumes that `ref`, `indices` and `updates` have a series of leading dimensions that are the same for all of them, and the updates are performed on the last dimension of indices.",2
"We make the assumption that it is always legal for a TensorFlow operation to
have its operand become ""more shaped"", but for operations not in the
TensorFlow dialect a Cast is introduced to preserve the operand type.",2
"Also, it is intentional as users often make assumption that serialization is stable and build systems under such assumptions, so we might as well start from a smaller set that's serializable in a stable way and expand as necessary.",2
This change also adds the assumption that FloatRef would always be the first ref type in tf_types.def and all non-ref types would be defined before FloatRef.,2
"Assuming that the cluster ops are going to be compiled to XLA, which only supports While ops where the operand and result shape matches, we drop the attribute to enable more exact shapes.",2
The pattern previously assumed that the transfer read had an identity map.,2
"Previously, arrowheads were only added to reference edges (because we assumed users knew about the convention that arrowless edges flow upwards).",2
Add batch_gather that assumes a series of leading (dense) dimensions.,2
"That is, it assumes that `params` and `indices` have n-1 leading dense dimensions, followed by a sparse dimensions over which we want to gather.",2
"Since a fusion node is never splitted, we can assume that if a parameter was
reused, it will stay that way even if additional instructions are fused in.",2
"This was problematic because
previously also non-TPU-nodes were functionalized at this stage which caused
issues in the TF v1 session runtime that assumes certain nodes are left
unchanged.",2
* fixes assumptions made throughout the code about the position or ordering of nodes.,2
"Also, remove the assumption that RetVal nodes have a single input.",2
"Add explicit casts for a few ops that assumed it could implicitly cast to/from
float and int for all types T. (The assumption doesn't hold for Eigen::half.)",2
Graphs generated via model parallelism has sharding annotations but does not propagate them into functions as it is assumed functions are inlined.,2
"As per LLVM Language Reference,
if the linkage attribute is omitted, the function is assumed to have external
linkage.",2
"This assumption often fails and users
consistently report the bugs from internal/external users.",2
"A few docstrings and comments are slightly incorrect as of this change, as they assume the new behavior is on by default.",2
This pass assumes indices in padding maps match the ordering of replicated inputs (from the parent `tf_device.replicate`).,2
"This pass is used for preparing the IR for Graph export, where the exporter currently assumes the IR is in the tf_executor and tf dialect, and devices are attributes on the tf_executor/tf ops.",2
"For now, if the bride is not forcibly enabled, it is assumed to
be disabled.",2
Add qint8 support to ConcatV2 on the GPU (assumes an int8x4 format).,2
Add reference pdf to qr backward and add assumptions to docs,2
Select op's kernel assumes two inputs have the same quantization parameters.,2
This is used to early detect IR that violate the assumption in `tpu_rewrite_pass`.,2
Also first time writing a textmate grammar so I assume a lot can be improved :),2
"Most of the
   code depends on this assumption.",2
"The display_name will be used to display the series in TensorBoard, in lieu of the tag, assuming that it is specified. (When it is not specified, behavior will stay the same.)",2
"- input_batch_dimensions: Index of the dimension which represents the dynamic batch (currently we support 0 assuming data is (Batch, Height, Width, Depth)), -1 should be set if input_batch_dimensions[i] is a fixed input.",2
"Previously, generic unsorted segment reduction logic in tflite assumes segmentation is to be computed only over first dimension of input.",2
"It also assumes the
elements of the vector or tensor have been trunked to the data type sizes in
the input character array, so it extends the trunked data to 64 bits when it is
retrieved.",2
"There is an implicit assumption here that Env::Default() is loaded after InitializeCreateGcsFileSystemFnPtr is called, but this seems to hold out in practice.",2
"Add the ability to verify assumptions about layout assignment after propagation
is done.",2
"Currently, all the new ops are added with the assumption that their kernels
support quantization.",2
No cpu tag is added because cpu is assumed to be the implicit device.,2
In this implementation there are no size threshold for `ConstOp`s for unfreezing and it also assumes that there are no `ConstOp`s existing in session initializer functions.,2
Add warning about assumed input_signatures,2
"Added SquaredDifference to layout pass, and fixed the test for layout pass (it assumed Add/Mul/Sub would not be substituted with Mkl ops)",2
Added an option to assume that the shape of fed nodes in unknown since any shape can be actually used.,2
"Added an option to run shape analysis assuming the shapes of the feed nodes are
valid.",2
"Adding 'half_pixel_centers' bool attribute (default False) to resize ops which when true, assumes that pixels are 0.5,0.5.",2
- Add comments regarding assumptions made and other info.,2
"This assumption was quite outdated, and using call() directly will miss all the check and setting we have in __call__().",2
"The _NHWCToNCHW and _NCHWToNHWC in bias_op_test.py
only took into considerations about 4D situation,
as it assume that third-to-last dim is the channel
dimension.",2
"Conservatively assume affine loops are not parallel in presence of operations
other than affine.load, affine.store, affine.for, affine.terminator that may
have side effects.",2
"Best to
assume it exists so the user can implement.",2
Auto exporter is written with the assumption that op names would closely match the xla client API name.,2
"During blocking_key_value_get(), pybind11 assumes that the std::string value is valid UTF-8.",2
Previously it was assumed overrides would be statically on or off (either way the override itself could have been non-static).,2
We assume that clients already know how to gracefully handle failure to profile.,2
"TensorFlow Lite
does not currently support such control flow, and toco currently relies
extensively on the assumption that graphs are acyclic.",2
"This assumption is guarded by CheckInvariants, so cyclic graphs result
in early failures.",2
"If the function wasn't traced under strategy.scope() nor strategy.run(), we assumed strategy wasn't involved.",2
"The code relied on the assumption that libcurl wouldn't call the read callback
if the header specified Content-Length: 0, which is not true on MacOS and
overall is a wrong assumption to make.",2
ArithmeticOptimizer assumes valid feeds in aggressive mode.,2
"As a simple heuristic for tf.Assert, we assume that string and int32 are on host so to avoid the need to use cond.",2
Assume errors are rare in OP_REQUIRES*() macros.,2
Assume input has RankedTensorType,2
Assume zeros shapes for statically proven to be zero gradients,2
"Consider 2 examples e_1 and e_2 with positive labels {0, 1} and {0}, assume that the top ranked label for e_2 is 0.",2
It assumed that there is at least one user of the linalg::GenericOp.,2
"Compilers are producing different
code and resulting in bad assumptions.",2
"Ruy
s plain-NEON (non dotprod) path currently relies on the assumption that that's never the case (when padding packed matrices with the zero-point, if the zero-point is the lowest representable value, it generates the bad case for the ""fast int8 kernel trick"", -128*-128 + -128*-128 overflowing int16).",2
"This change assumes that a TF subgraph/op does not cross the boundary of a HLO
computation and always put top-level TF subgraphs/ops under HLO computations.",2
"The assumption is that since the entries are sparse (they are all populated, but most are never Active()), using the map will save memory and make iterating over the Children() more efficient.",2
"Set fused=False for batch norm, because the test assumes no bessel's
correction.",2
* assume stale step,2
"4. ReplaceSendRecvs() in FoldConstants lib assumed that all input nodes are
removed during rewriting the graph.",2
"This assumption is not necessarily true,
and it could add a duplicate node in the graph.",2
"4. ReplaceSendRecvs() in FoldConstants lib assumed that all input nodes are
removed during rewriting the graph.",2
"This assumption is not necessarily true,
and it could add a duplicate node in the graph.",2
"Plan is to switch from this LTS to the next one and then to releases on master, assuming each one of them is throughly tested and nothing breaks.",2
"There are many reasons why an operation can fail, propagate the error instead
of assuming the cause.",2
"Change `from_config` of Model class to *not* assume that `cls = Functional`, since `cls` can be a child class of `Functional` for subclassed Functional models.",2
"Note that in some cases
we are not yet ready for registering the int64 types, because there is
already an int64 type registered that assumes data is in device memory.",2
The major downside to this is that the cases that *may* modify an operation in-place will need an explicit cancel on the failure branches(assuming that they started an update before attempting the transformation).,2
"Currently, the kernel assumes that the int8/int16 input always has symmetric per-channel quantization filter and there is no check for that.",2
"For example, the sender may fail, and a different machine
can assume its position and restart from a checkpoint.",2
Clarify tensor_utils neon memory alignment assumptions.,2
"This should handle scf.if and shape.assuming regions,
which we care about in kernel_gen.",2
"Such succinct pretty printing is currently enabled based on the following simplifying assumptions:

1. The reduce-op wraps a single inner-op in the associated region.
2. The inner-op is one of mhlo::AddOp, mhlo::MaxOp or mhlo::MinOp.
3. The reduce-op consist of at least one input-operand; The operand-types of
   inner-op should be derived trivially from the element-type of reduce-op's
   first input-operand.
4: The  arguments of the region's only basic block are forwarded perfectly
   to inner-op's operands.
5. The reduce-op, inner-op, blocks arguments, and the return-op all have the
   same location.
6. The single operation result is perfectly forwarded to the reduce op
   return.",2
"The constant folding rules assumes value attributes of operands are already
verified to be in good standing.",2
Convert back from MLIR (assume it was StableHLO) to an HloModule.,2
"Prior to this change, we assumed that the number of real outputs of the TF
function was equal to the number of outputs of the Python function.",2
"This
assumption was incorrect, as the Python function might return non-Tensor
objects whereas the TF function exclusively returns Tensors.",2
"Should fix a performance regression where we looked up a CustomDevice each EagerExecute since we're now caching the lookup in EagerOperation (assuming the device name doesn't change and TFE_OpReset is used, like we do when executing from Python).",2
"This pattern assumes that the quantization parameter propagation pass has
propagated the quantization parameters to all the quantizable ops.",2
"Previously, the SPMD for SaveOp assumes that the `prefix` input is a constant folded tensor.",2
"Assumptions: This CL is a child of cl/492550159, which leaves Layout Operations undeleted for XLA SPMD layouts.",2
"The code before cl/307496027 assumes the actual length of input_sizes is always
4 and always permutes the vector.",2
#NAME?,2
Define a graph and flib_def in tests so that passes can assume there is one.,2
"This test assumes the following:
1. The list of layers is the same between the two models --> This isn't always the case because functional models include the input layer in the list, while sequential models don't.
or
2. The checkpointed weights are loaded in a specific order (this was the cause of the flakiness)",2
Until now we were passing int32 and assumed the compiler would elide double negation of int32 via inline calls.,2
"We usually assume in several places in our code base that a Reshape is not elementwise, but bitcasts are considered elementwise in some locations.",2
"Disable constant folding for more tf.dbg tests, as they make assumptions on the
underlying graph structure.",2
"Disable constant folding for the tf.dbg test, as it makes assumptions on the
underlying graph structure.",2
"This assumption often fails and users consistently
report the bugs from internal/external users.",2
"It would be nice to disable the
problematic assumption by default and enable it safely when users aware of the
option.",2
"With distribution strategy, traced ConcreteFunctions may contain training specific logics that assumes the variable is a distributed variable.",2
Distribute Coordinator currently assumes TF_CONFIG to be the only way to configure a strategy.,2
"Previously, we assumed it was safe to autotune on GPU 0 and then use that
autotuning result on GPU 1, if the GPUs are the ""same model"".",2
"For grouped convolutions, we assume that in the backward input convolution
case, the input and output feature dimensions of the kernel are adjacent.",2
"We chose to drop
the trivial identity map rather than inject it in places that assume its
present implicitly because it makes the code simpler by reducing boilerplate;
identity mappings are obvious defaults.",2
This CL generalizes the expansion such that it does not assume that `prefix` is a constant - it works for both constants and non-constants.,2
"Do not assume Attribute nodes always have a QN - it may be missing for attributes of dynamic objects, like function calls.",2
Do not assume Node.in_edges() is sorted by dst_input.,2
Do not assume hasattr is available in Metric.__del__,2
Do not assume in_edges() are sorted by dst_input.,2
Do not assume number of outputs for While node is always the same as number of inputs.,2
Do not assume order on std::unordered_map,2
"A `ShapeOp` in a virtual device is not assumed to be invariant across replicas, so its operands should not be mutated.",2
Don't assume MaybePaddedAndSlicedInput moved the padding into a kPad.,2
Don't assume all int32 ops belong in host memory.,2
Don't assume the default graph in graph_actions.evaluate().,2
"Update the parser test to check for unique'd hoisted map to be present but
without assuming any particular order.",2
"This order may change further as map simplification is
improved, there is no reason to assume a particular order.",2
"During GPU layout assignment, don't assume dots have been canonicalized.",2
"* Any code that is overly dependent on the exact names attached to symbolic tensors (e.g. assumes there will be `:0` at the end of the inputs, treating names as unique identifiers instead of using .ref(), etc.)",2
"* You have code that tries manually walking a model layer by layer and assumes layers only ever have 1 positional argument (This doesn't hold true in head either, but it becomes marginally more likely to cause issues w/ the newer op lambda layers)",2
"If the arguments shapes passed in to the servie.cc API do not have a layout, it is assumed the caller is willing to accept the natural layout propagated by the XLA compiler.",2
"Similarly, if the ExecutionOptions has a shape for the result, but no layout is set in such shape, it is assumed the caller is willing to accept the natural layout propagated by the XLA compiler.",2
"After this change, `tf.linspace(start, stop, num)[-1] == stop` holds for all values assuming num > 1, because we just set it directly to `stop`.",2
"This test reads half of the elements and assumes that the amount left
is more than will be prefectched which can be equal to the number
of CPU cores.",2
"It
was assumed this would be true when the shape is fully known, but
`TensorShape::IsValid` can be true when the number of dimensions in the shape
is unknown as well.",2
It assumes that client and server are running the same version of Tensorflow.,2
Do not assume outputs.dtype is equal to inputs.dtype in rnn() (tensorflow_backend.py),2
tf.metrics.mean_per_class_accuracy does not assume num_classes,2
Do not assume outputs.dtype is equal to inputs.dtype in rnn() (tensorflow_backend.py) (#5715),2
"This includes ensuring all the interfaces do not assume that data is real or if they do, they give an assertion when complex data is passed to them.",2
"I'm asking either;
- if `tensorflow` could be added as a declared dependency to the `keras` package, so it may be downloaded automatically if people install `keras` stand-alone, that `keras` does not assume people have already installed it.
- or, why `keras` exists as an independent package, and/or if the plan is to eventually deprecate it in favour of `tensorflow`",2
"The reason that lists are not supported is that Theano builds everything as tensors, or matrices of matrices, so everything must have the same dimensionality (Theano does not assume it should pad with 0s where lengths differ).",2
Input shape: This layer does not assume a specific input shape.,2
Existing code does not assume anything of the sort.,2
"To fix this, one needs to alter source code in [this folder](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/python/feature_column) to ensure proper dtypes are passed to variable constructors (whose methods seem to be doted with the necessary parameters; so the API probably does not need to change, some arguments just need to be explicitly passed instead of assuming that the layer's dtype is always float32).",2
"It checks if paths passed to `tensorboard --logdir=logs/events` are relative or absolute, and properly resolves relative paths to the current directory instead of assuming they're relative to $HOME.",2
"If this breaks code you maintain, instead switch to using tf.raw_ops
to directly control what graph ops are emitted from the TF high level
APIs instead of assuming TF will never delete stale branches of forward
compatible code.",2
Generalize _XlaRecvAtHost and _XlaSendFromHost by adding a device_type attribute instead of assuming TPU.,2
Pass tensors directly to Hexagon per-channel helpers instead of assuming indices.,2
I suggest to insert a proper `RESHAPE` to achieve the right dims rather than assuming that the CPU's memory layout is the "correct" way which isn't true.,2
Do not assume that the group name in use will be the same as the username so explicitly refer to the provided build user group for setting the group on chown rather than assume it will be the same as the username.,2
Use the `FloatLiteral` call rather than assuming it is FP32.,2
"Rather than assuming that the target device doesn't support OpenCL and failing if it does, I've changed the test to instead just verify that when enabling OpenCL, it either works correctly or throws the expected exception.",2
"Do not assume that the group name in use will be the same as the
username so explicitly refer to the provided build user group
for setting the group on chown rather than assume it will be the
same as the username.",2
"[XLA] Service::CreateModuleConfig should take the backend as a parameter, rather than assuming it's creating a module for the execute backend.",2
"When `tf.image.flip_left_right` is applied to the `tf.Tensor`, the function does not assume a rank-3 shape and flips the image along the correct axis.",2
"It would be nice for this script to auto-detect available devices and not assume GPU support since a shipping, supported platform does not provide CPU support.",2
"* By default, `tf.contrib.signal.inverse_stft` does not assume that the input STFT was generated from `tf.contrib.signal.stft`, and therefore does not divide the window by the squared sum of its magnitude as librosa [does by default](https://github.com/librosa/librosa/blob/0dcd53f462db124ed3f54edf2334f28738d2ecc6/librosa/core/spectrum.py#L302-L311).",2
">     * By default, `tf.contrib.signal.inverse_stft` does not assume that the input STFT was generated from `tf.contrib.signal.stft`, and therefore does not divide the window by the squared sum of its magnitude as librosa [does by default](https://github.com/librosa/librosa/blob/0dcd53f462db124ed3f54edf2334f28738d2ecc6/librosa/core/spectrum.py#L302-L311).",2
"But you're
correct, this op does not assume that about the input.",2
"OK tensorflow is scheduling ops non-deterministically because its not assuming knowledge of when inputs will become available (network transfers, multiple ops running on multiple CPU cores).",2
"So we have to say something generic, and not assume that anyone doing this is using one of the builtin losses with `Reduction.NONE`.",2
I think we'd have to rewrite our tutorials and examples to not assume relative path otherwise.,2
"I do not assume a dataset that fits entirely in memory, actually, my main usage scenario is datasets which are far from that.",2
Please do not assume that everyone use OOP.,2
for example we cannot assume that each estimators params has a field 'learning_rate' or 'feature_column'.,2
"If considering length penalty, we can not assume early finished shorter path be better then longer ones.",2
Please check to make sure that you are not assuming that path separators are `/` in your tests.,2
"If OP2 and OP1 become CLUSTER2 and CLUSTER1, and OP2 depends on OP3 as in example 2, clustering of CLUSTER2 and CLUSTER1 shouldn't cause much problems because it is assumed that OP3 is relatively cheap (which is not assumed if OP3 is instead CLUSTER3).",2
"On other words, we cannot assume that we read only v2 checkpoints just because we want to write only v2 checkpoints.",2
"Scratch should be initialized with the same descriptor as output_matrix, and not assume that output_matrix is column major.",2
Do not assume Blocks belong to Functions,2
"Fix TransformedDistribution so that it does not assume the event shape matches
the event shape of the base distribution.",2
"# If `loss_fn` is not a function (e.g. callable class)
            # or if it not in the `losses` module, then
            # it is a user-defined loss and we make no assumptions
            # about it.",2
"> In my opinion there should be no assumption about how something basic like
> a variable is used.",2
"* In terms of the parity between 'zero grad' and 'no grad update' -- `tf.gradients()` is a util function and thus should faithfully return the gradient result, and make no assumptions about how client would use the result. How to use the gradient if NaN/Inf, should stay in client code.",2
"> * In terms of the parity between 'zero grad' and 'no grad update' -- `tf.gradients()` is a util function and thus should faithfully return the gradient result, and make no assumptions about how client would use the result. How to use the gradient if NaN/Inf, should stay in client code.",2
"> > * In terms of the parity between 'zero grad' and 'no grad update' -- `tf.gradients()` is a util function and thus should faithfully return the gradient result, and make no assumptions about how client would use the result. How to use the gradient if NaN/Inf, should stay in client code.",2
"That may or may not be true, and regardless, Keras makes no assumption that your data generator will be written in such a way as to release the GIL and as a high level library simply balances Threads vs Processes [via the pickle_safe](https://github.com/fchollet/keras/blob/master/keras/engine/training.py#L397) flag and makes the safer assumption that the processing will be CPU bound and thus spawn only 1 thread.",2
"Not resetting makes the assumption that data passed to subsequent fit calls is from a similar distribution, while starting the optimizer from scratch makes no assumptions at all.",2
"Finally, we now pass in a dictionary of {param: constraint on param} - as the input to get_updates is now a dictionary rather than a list, we cannot assume that the constraints and the param list from the dicionary will always coincide.",2
All output which is not assumed by application programmers or application users should be written into stderr.,2
> You should never assume that any library (or any of its dependencies) will only make stdout/stderr writes that you expect.,2
"I agree that I should not assume it, but a good library should not do it.",2
"Without this change, the entire collection is wrapped in a PerReplica which breaks assumptions of downstream code.",2
"For
instance if we have:

digraph {
  A -> C
  B -> C
  A -> D
  B -> D
  C -> E
  D -> E
}

with A and B with different liveness (let's assume neither A nor B are
compilable by XLA), we previously would not cluster C or D.",2
Removes reliance on the assumption that tensorflow::int64 is long long.,2
"With this fix we don't assume that the tensorflow project is the build
root.",2
"With this fix we don't assume that the tensorflow project is the build
root.",2
"The GPU kernel previously assumed that the threshold type matches
the box/score input types, and resulted in an invalid memory read
if they were different.",2
"The previous logic assumed that all mhlo.dot is at most R2 but that isn't
the case.",2
"The slice parameter for this was assumed to be 1,1 for last two dimensions of MatrixDiagPartOpV3 input.",2
"The code was written with the assumption that on failure an error would be
issued by another verifier.",2
"TransposeConv has tensor 1 as its weight, but the definition and tests sometimes assume tensor 2 as weight.",2
"Worse, the conversion of ViewOp to the LLVM dialect assumed the wrong order of
operands with offset in the trailing position, and erronously relied on the
permissive parsing that interpreted trailing dynamic offset values as leading
dynamic sizes.",2
"2. The scattering mechanism assumes that 0.0 always corresponds to a padding region, but this is not the case when there is only single valid path (0.0 = log(1.0)).",2
Previously we assumed there was no splitting in the batch for warmup but this was not true.,2
- Simplify the code as I know understand more assumptions of this part of the stack.,2
The assert assumed that the escaped character could not appear at the end of the string.,2
GetPassState incorrectly assumes all graphs are for CPU/GPU when called during Run.,2
"My theory is that the models in these tests are not trained enough for that assumption to always hold true, which is why they are flaky.",2
Fix and test issue with incorrect target shape assumption check.,2
Fix assumption in ConvolutionGroupConverter that we never have more than 32 bits,2
Fix assumptions that a Shape must be a tuple or an array.,2
"However, in many places in XLA we assume either a tuple or array.",2
"In C++14 there is no implicit conversion from `llvm::StringRef&` to `absl::string_view` but it exists in C++17. As TF is still on C++14, LLVM/MLIR/TFRT updates that assume C++17 will break TF and will need similar fixes as this one.",2
"Fix breakage from ""Assume errors are rare in OP_REQUIRES*() macros""
due to a bad definition of TF_PREDICT_TRUE in macros.h.",2
"While constructing the return op, the code assumes that the key-value pairs in SmallDenseMap `resource_arg_to_new_output` are in the same order as they are inserted.",2
- it assumed that it was ok to blindly upgrade from v1 to v2 even if when the v1 function is exported in v2 with a different name (e.g. Keras optimizers),2
That assumption was incorrect.,2
"It removes the assumption of AffineMap having at least one result and
stores a pointer to MLIRContext as member of AffineMap.",2
Fix castings with invalid assumptions in mlir/lite.,2
Fix castings with invalid assumptions in mlir/tensorflow.,2
"The strides in the memref descriptor encode the multipliers for
indexing and not subsampling strides, as the old code assumed.",2
"Previously we assumed all ShapedType have a known rank but that isn't
always the case as UnrankedType is also a ShapedType so we have to call
hasRank() before calling getRank().",2
"We no longer assume that the first `n` instructions of a given HLO comptuation
are the `n` parameters to that computation.",2
"In particular, the call to ToIndexArray<2> here https://github.com/tensorflow/tensorflow/blob/1f3da84a89702d3b4f234ee83762d738caffe098/tensorflow/core/kernels/xent_op.cc#L99 would fail, since the call assumed the array had two dimensions.",2
"The issue is caused by the fact that shape inference in `common_shape_fns.cc`
only assumes int32 without proper handling of diffent types.",2
"his change makes XLA:CPU upgrade f16 matmul to f32, thus
  breaking the test's assumption of how many bytes of memory should be used.",2
"This is okay only under the assumption
that there are no writes to the predicate tensor racing with the switch.",2
Fix docstring Args/Raises/Returns parsing (Don't assume there is a blank line between).,2
"- dominates() for blocks was assuming that there was only a single block at the
  top level whenever there was a hierarchy of blocks (as in the case of 'for'/'if'
  instructions).",2
"The reason was that tf.image.flip_left_right assumes rank == 3 in case
of unknown rank.",2
"It assumed sizeof(struct) == sizeof(struct
components).",2
"Previously, the pass
assumed that the function call can only happen from the function input node,
and could not perform inter-procedural shape propagation through functions
called using PartitionedCall.",2
Current legalizations assume data format to be either NHWC or NCHW.,2
"The
`std::push_heap` call was assumed to act solely as a front/back-swap and
sift-down operation.",2
"This assumption seems consistent at first glance with the syntax of alloc:

```
    %tensor = alloc(%M, %N, %O) : memref<?x4x?x8x?xf32>
```",2
Fix incorrect assumption that all methods have a positional first argument.,2
"The code wrongly assumed that os.system(cmd) returns the exit code of the
process.",2
Fix invalid assumption in BreakUpIslands pass,2
"Previously the pass assumed that the island containing a user of an island value
always has to be a direct parent of the user.",2
We were incorrectly assuming that the local device ordinals formed a dense set.,2
This 3rd constraint is well-known in the case of tiled layouts that don't assume implicit padding: the boundary tile may be only partial and has size given by `problem_size % tile_size`.,2
"In all uses of `documentation_path`, except the ""reference_to_url"" it's safe to assume that `is_fragment` is `False` (this is the current correct behavior).",2
"I was assuming that the gml_st.materialize builder would always uniquely infer
the result type, but that is not the case.",2
"Remove CHECK-LABEL to avoid assuming the relative order
between the additional info and the output IR.",2
"But parameterized_docker_build.sh assumes a single file, which has caused nightly docker build failures such as:
http://ci.tensorflow.org/view/Nightly/job/nightly-docker-cpu/58/
http://ci.tensorflow.org/view/Nightly/job/nightly-docker-gpu/55/",2
"Currently, these ops assume start indices are always signed, leading to
incorrect results in cases of overflow (e.g. a u32 start index of 2^31
is wrapped around to INT_MIN).",2
The original assumed only float32.,2
"The Network class incorrectly assumes all have subclasses have the same derived
behavior of having an extraneous inbound and outbound node.",2
"- DeScalarizeGatherIndices was assuming that gather_indices must be of at least
   rank 1.",2
"The original made the assumption that the dtype is int32 when it could
also be int64 - leading to a crash due to mismatched type.",2
"Internally, the op assumed they
were the same, which resulted in a bad memory access.",2
"Intermediate quantized type should be an I32 under all circumstances however
the lowering assumed the intermediate type was the same as the output type.",2
"It was previously assumed that every op can only execute once for a given session run, however ops can have multiple kernel executions within a single run and within the same device, thus showing up multiple times in the stats pbtxt.",2
The lowering assumes that the 'gather' op attributes are identical in both MHLO and LMHLO.,2
Fix the assumption of static weights in MergeDensify,2
Fix the logic of assuming arg_attrs/res_attrs is non-empty,2
"Additionally, improves performance by not re-running the reduction N times,
and fixes a bug on a fast path where the initial element was assumed to be always zero.",2
* Only skip if both the cond and body are only calls (which was wrong before and could result in assuming the call was already outlined but instead left a mismatch of operands);,2
"The current code assumes that quantized_func_count and composite_func_count have
the same set of keys and only prints summary for ops that are in quantized_func_count.",2
Fixed a bug where ConvertTFStridedSlice::RewriteNewAxisMask assumed the strided_slice input had RankedTensorType.,2
"Lower general dot attempted to avoid extra reshapes but made assumption that
all types of dimensions would be contained.",2
Fixed to not make this assumption.,2
"The problem arised from the assumption ""threshold: fallback to BLAS if n*m*k above this"", which is wrong (the threshold populates an upper bound until which JIT code is generated).",2
"Fixed the shape function of the SplitV op that incorrectly often assumed that
the shape of all the outputs is the same.",2
"The special handling of tf.GeneratorDataset in side-effect analysis violated
assumptions for indirectly tracked dependencies, leading to missing control
dependencies even for other unrelated ops surrounding a tf.GeneratorDataset op
(checked by a new test).",2
Calls out assumption of non-empty output in ConcatCPU() docstring.,2
"3. Thread one could then incorrectly assume that the function still
   existed, and fail to find it in the `FunctionLibraryRuntime::items_`
   map, causing a segfault when it attempted to increment the refcount
   on an uninitialized object.",2
Fixes the requantization logic that assumes the user of the requantized op is TFL::QuantizeOp.,2
"It assumed the common .py file was in the current directory but it was not, and it did not know how to build it.",2
Fixing int32 assumption for save_restore_tensor.cc and adding a python "end to end" test for saving large partition variables.,2
"Ensures that new tests added using tf-mlir-translate for graphdef conversion doesn't assume shape inference is enabled, making it easier to see what needs to be updated later.",2
PyBuffer is still the default types used and it is assumed in some places in python frontend.,2
"So don't assume they're still around, in the atexit handlers.",2
* Fix docstring and test in TFP that assume that Gamma is not reparameterized.,2
"- fix bugs / assumptions: correctly copy memory space and elemental type of source
  memref for double buffering.",2
Generalize assumptions in IdentifyLoops and StronglyConnectedComponents.,2
@foxik I think an issue with what you are proposing is we really can't assume a batch dimension at all.,2
I might be wrong but DBN's are gaining quite a traction in pixel level anomaly detection that don't assume traditional background distribution based techniques.,2
Also don't assume that dynamic backends won't support separable convolutions.,2
* Don't assume external backend won't support NASNet,2
Don't assume what a batch generator does,2
"While not production-ready and without any tests, I have created [a patch](https://gist.github.com/StanislawAntol/ce9fb48d112a133cabb92be1c093f1cd) on top of `TensorFlow v1.6.0-rc1` that adds a valid reference implementation for `tf.maximum` (i.e., doesn't assume input2 is a scalar) into `TensorFlowLite`.",2
Don't assume it's going to be easy!,2
Yes in general we can't assume anything about the structure of a subclassed Model.,2
"I realize you're probably using the layout `[batch, height, width, channels]` because that's what the TF conv ops use (`NHWC` layout), and I'm sorry for the confusion, but the FFT ops don't assume that layout.",2
No it doesn't assume that at all.,2
"You need to do as the error message says and provide a `grad_ys` argument to `tf.gradients` if `ys` is complex, because the TF gradient infrastructure currently won't assume that `grad_ys` is all ones if the type is complex, as it does when the type is real (I'm not totally sure why this is... maybe the original author of that code didn't want to assume that `1+1j` was the proper `grad_ys` for a complex number because its magnitude is greater than 1?).",2
Don't assume that GPU 1+ follows this same pattern!!,2
"**EDIT** If you're an admin and see this, please don't assume I've dropped it.",2
"That said, note that by default tfcompile doesn't assume any target-specific features (SIMD, etc).",2
"I like the first option since it concisely covers both the case of users not providing a value for `shuffle` and for users providing a non boolean value, but also doesn't assume the use case (users might want to shuffle in cases other than just training?)",2
Don't assume the minor version is a single character: `'3.10' >= '3.4'` is `False`!,2
"In general, a shaped type should be anything with shape, rank, and element type properties, so use sites shouldn't assume more than that.",2
don't assume the indefinite buffer allocation have exactly one logic buffer buffer.,2
So that it doesn't assume it is called in the "root" scope of variables.,2
NFC: Don't assume that all operation traits are within the 'OpTrait::' namespace.,2
"Also fixed a potential bug (we can't assume in general
that `TPUReplicateMetadata` is on the top level) and adapted tests.",2
[SE] Don't assume that the CUDA context has not changed in the outermost ScopedActivationContext.,2
[XLA] Don't assume 1 spatial dimension in the algebraic simplifier,2
"We need to always require a ""consumer"" node (since that's what the graph is
rendered around), and we can't assume the graph remains the same for negative
fusion decisions (since the consumer might be different).",2
"Currently, the pass assumes embedding ops to be directly in a function and was working only because functional control flow to regions pass introduces call functions so the embedding ops ended up being in a separate function.",2
"Code generation for DMA transfers was being done with the initial simplifying
assumption that the alloc's would map to scoped allocations, and so no
deallocations would be necessary.",2
Drop this assumption to generalize.,2
"The caller may assume that out_tensors is empty if end_of_sequence is true.
(There's such a CHECK in repeat_dataset_ops.cc)",2
"Previously, the code made the assumption that the two operands have matching
shapes, but did not enforce the equality.",2
I tried some things but the pass seems to be having many assumptions and will require closer look to trim the simplify it.,2
"For tf.StridedSliceOp, if no ellipsis_mask exists then an implicit ellipsis_mask at the end is assumed.",2
"The way VirtualScheduler currently checks node ready is to count how many
input nodes are ready; it's possible that a certain pattern
(e.g., Switch - Merge) can break this assumption; both outputs of
Switch is triggered, and then Merge becomes ready twice.",2
"Today this pattern assumes:

  1. Input has rank 1
  2. The reshape reshapes it to a tensor of shape Nx1.",2
"But for the sake of being more conservative, for now we will only apply this
rewrite pattern when the reshape returns a tensor of rank 2; but we do remove
the original assumption #1 (X has rank 1) in this CL.",2
"The helper method assumes that the op has at least one output and generates segfault, otherwise.",2
I had originally assumed that each block corresponded to a single minibatch entry.,2
"But for any reasonable batch size, this assumption broke down and I would accidentally skip copying some minibatch data to the output Tensors.",2
Doing so makes some assumptions (the name of the restore op) and is prone to accidental conflict.,2
"If max_seq_length is set and rank is unknown, assume the input tensor is rank 2.",2
"This implicitly assumes custom devices always have lower priority, which is
fine, I think.",2
"We might need to be smart about custom resource devices as TF code might assume
resource-using ops are always colocated with the resources, though.",2
This pass assumes that global tensors have been marked immutable before (e.g. by running the optimize global tensors pass).,2
"This path assumes that all the VariableV2 ops is read-only via verifying the
heuristic method that assumes that all the users of them is Identity op,
fed directly.",2
"This progress should be done in the very last
stage of the TFLite converter API since the model optimization toolkit assumes
that each tensor object has its own buffer object.",2
"This should also enable TensorLists containing
  OptionalVariants (previously some of this code assumed any nested
  variant was also a TensorList).",2
"The codes currently have two assumptions:
1. The number of columns is a multiple of 16 so all blocks are full blocks.
2. The number of columns is less than 4064",2
Implemented sparse matrix vector multiplication assuming input matrix is in BCSR (block compressed sparse row) format with block pattern 1x16.,2
"Remove assumption where resource variables could not be included as
outputs of the body.",2
"This depends on the PrimitiveType, before we always assumed it to be double.",2
"Since, it is a dynamic property, we conservatively assume it has side-effects.",2
"Previously the reshape op in this pattern is assumed to have the same input and
output ranks.",2
"If it isn't set its assumed to be 0
and the old code path runs.",2
"In BROADCAST mode (used by Mesh-TensorFlow), assume that all cores return identical copies of the full output.",2
"Since we have broken the assumption that the input is batch-split on axis 0, it makes no sense to assume that the output will emerge batch-split on axis 0.",2
"At conversion time, batch size dim in the input signature will be written to 'None', and converter will then assume the batch size is 1.",2
This assumes the shape of the variables don't change between compilation and execution.,2
"In model_to_estimator, only run get_weights when there are initialized Keras variables(which assumes there exists a session).",2
"The inner calls of nested calls are not inlined until the execution of the kernel of `tf.XlaLaunch` op after the pipeline, and that means we cannot reuse some TPU passes in the pipeline, since they assume no function calls, e.g. `MarkOpsForOutsideCompilation`.",2
"Here we assume the input graph function is on a single host, but
might involve multiple devices.",2
"If the attribute is set to `true` then the backend can assume that the
gather/scatter indices supplied by the user are sorted what should enable
the generation of more efficient code.",2
"[0] Under the assumption that transposing or reshaping are not expensive enough
to pay the price of keeping around a new potentially large constant (in
particular, some of these may have been equivalent to free bitcasts).",2
The assumption of MLIR to Graph that the nodes only in that Graph needs to unique is not correct as DirectSession seems to be shared across many graphs.,2
Many methods (e.g. make_seeds) assume that `algorithm` is an `int`.,2
"This applies even to
Keras's assumption that data is passed in (x, y, sample_weight) format.",2
"When the caller fails to specify a ""head"" to use for a metric, assume that the
metric should use the class predictions.",2
Fix HLO Transpose op verifier to not assume static inputs,2
"In other words, the current implementation assumes that the initial shape refinement (which does not have access to the inner TF computation) should be sufficient to fully identify the static shapes of called TF function's arguments and results.",2
"This
allows splitting across the dynamic dimension though it assumes the dimension
can be legally split.",2
"It performs all computations via XLA and
assumes constant folding will simplify.",2
"As far as I can tell, this doesn't affect layouts at all, so for now I'm assuming it's a different miscompile.",2
"We previously would check that there were no fallback blocks, which is equivalent to assuming that a user called FreeAll before the destructor was called.",2
"Naturally GetChildren returned the directory marker for the specified directory whenever it existed, represented as an empty string, which violates assumptions that people normally have from this functions.",2
"We
also assume that only one instance will ever write tensors to a given
run.",2
This also cleans up function_test.py to assume the C API is enabled.,2
"Prior to this change, the lowering pass assumed that the If op
functions would be available in the If op's graph.",2
"In particular, for a resource-allocating op
with empty or anonymous `shared_name` attribute we can assume that the resource
being created is unique which wasn't utilized before.",2
The input size is still assumed to be the output size in the case where the innermost dimension of the input is not statically-defined.,2
Mark some constraint/assuming ops legal in shape_to_descriptors.,2
"The issue is caused by the fact that shape inference in `common_shape_fns.cc`
only assumes int32 without proper handling of diffent types.",2
The root cause of the bug was that TFDBG previously assumed that node names are unique across all partition graphs.,2
"This CL relaxes this assumption, by dumping the GraphDef and tensor data from different devices into different sub-directories under the dump root directory.",2
"Set fused=False for batch norm, because the test assumes no bessel's
correction.",2
"It assumed that the IGatherLayer has same output dimensions as tf.gather, which is not the case.",2
"The ForeverRepeat op assumes if the first repetition produces no data,
    all future repetitions will produce no data.",2
"- this completes several TODOs, gets rid of previous assumptions/restrictions
  in composeMap, unionBoundingBox, and reuses common code",2
"Else, it's assumed that one is referring to a target inside the external repo.",2
"Misc. updates/fixes to analysis utils used for DMA generation; update DMA
generation pass to make it drop certain assumptions, complete TODOs.",2
"- dma-generate: drop assumption of ""non-unit stride loops being tile space loops
  and skipping those and recursing to inner depths""; DMA generation is now purely
  based on available fast mem capacity and memory footprint's calculated",2
This assumes that the underlying data (if it comes from `std::string` or `const char*`) outlives the key.,2
"However, **relying on this assumption is dangerous and may result in undefined behavior**, if the underlying data is freed from the memory and the keys point to garbage values.",2
Modify SelectAndScatterExpander to assume documented definition of ReduceWindow padding.,2
"We need to assume that tensors
are unhashable.",2
"The assumptions they make about layouts seem to be
incompatible with the ones we make in the MLIR CPU pipeline.",2
"The initial assumption that before layout assignment, all ops have the default
layout, turned out to be wrong.",2
This should give us time to address test failures and resolve questions about the underlying assumptions.,2
The existing logic to remove the back up checkpoint file at the end of training (on_train_end) is subject to improper deletion in such case (here we're assuming sync multi-worker training):,2
Move merge assuming ops test (old broadcast propagation pass) into the mhlo dir,2
"We assume a TF process will
link in kernels for all the ops it uses so we should not need to additionally
link in :all_kernels into compilation_passes.",2
"These methods assume that a function is a valid builtin top-level operation, and removing these methods allows for decoupling FuncOp and IR/.",2
"No longer assume that the default job is ""localhost"" in graph mode
DistributionStrategy, since it depends on the session.",2
The implementation relies on this assumption.,2
"This CL makes sure that this
assumption holds, and adds tests for NCHW format.",2
I tried this but looks like we make assumptions in the code around this and not sure what can break as a result (an initial attempt had quite a few failures).,2
"This requires a few adjustments, because so far it was assumed that the shared
memory tiles always consist of the last two dimensions, but for 210 transpose,
we want them to consist of the first and last dimension.",2
"Most paths to IndicesValid() implicitly assume that the indices are in the standard, row-major, order.",2
"For example, SparseToDenseOp makes this assumption, and it accounts for the majority of time spent in IndicesValid().",2
"This assumes that
the GPU topology is identical at each worker, and hence the same ring order is
good for all workers.",2
"2. **sparse_preds**: `IoU` and `MeanIoU` assumes both `target` and `output` are sparse signals, where categories are represented as natural integers.",2
Requires fixing a tangential use-after-free where the context assumed all of the thread-local executors were still allocated at shutdown.,2
This CL assumes that the best single rule for loop peeling is to ensure that there is a single loop without any padding needed.,2
"Other peeled loops could be peeled again to remove more padding, but the assumption is that in the common case, this will not be worth the IR size/compile time increase.",2
"Previously, it is assumed that the private functions' names are unique.",2
"ROCm 3.5+ (more specifically the hip-clang compiler) assumes a default value of 256 (for max threads per block) for GPU kernels, for cases where that value is not explicitly specified via the __launch_bounds__ attribute.",2
"But we still would like to preverve the
ordering on a best effort basis, so that problems caused by incorrect
assumption on the ordering doesn't look that it works without distributed
strategy, but breaks with strategy, which is very hard to debug.",2
"For the short form parsing of Switch op, the assumption is that all data input and outputs have the same type, and the predicate is tensor<i1>.",2
"Here, we assume that the result quantized element types as well as all intermediates have the same quantized type as the operands.",2
"The previous conversion assumed that absl::string_view is identical to
std::string_view, which might not be the case.",2
"So far, we assumed that if it is a fusion node, we are always dealing with
multi-output fusion, and each reduce in the fusion is an operand of the tuple
root.",2
We assumed that framework developer does not know much information about how one estimator/model_fn is constructed.,2
"This reduces the possibility of trainers unnecessarily restarting under the
assumption that a closed queue is a recoverable error.",2
* fixed bug with assuming input tensor is 4D,2
"In theory we could make the
shape computation cheaper by assuming the user has provided
a well-formed array (all inner dims are consistent), but this
avoids the worst overhead for common vector inputs.",2
Most RewritePatterns for region operations assume that the entry arguments to each region are yet to be converted.,2
TFG has been introduced many utilities and has many assumptions in the operation manipulation.,2
"This implies the assumption that if a real GCS object has file name ending with ""/"", it is always a directory mark rather than an object carrying actual contents.",2
"It assumes that ""StatefulPartitionedCall"" and ""PartionedCall""
 ops always use the default gradient that can be computed by the loader when
 needed.",2
SplitV op takes split sizes so we could support that assuming that the input size matches the requested sizes.,2
Originally the kernel would have been implemented assuming the static input shapes and wasn't updated with bounded dynamic shapes.,2
Relax assumed alignment for small (<512 byte) buffers in XLA JIT.,2
Relax assumption about CUDA library path,2
"The assumption that it is always at /usr/local/cuda/lib64 has led to build failures, e.g.,
http://ci.tensorflow.org/view/Nightly/job/nightly-matrix-mac-gpu/100/TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=gpu-mac/console",2
Relax assumption about default file permission in file_io_test.py,2
Relax data size assumptions for timeseries_dataset_from_array.,2
"* Previously, strong assumptions were made about how numpy.ndarrays
  are formatted as strings.",2
"This CL relaxes the
  assumption and fix the affected tests for tfdbg and eager.",2
"This property made it more difficult to create a Layer that supports
RaggedTensors, since by default every user-created Layer class was assumed to
not work with RaggedTensors.",2
It is incorrect to assume they do not have side-effect.,2
"The test assumes that all devices are either CPU or GPU, which is not true when XLA is enabled.",2
Remove false assumption in delegate test code.,2
"The assumption behind this CL is that these irritations are less important than
the ongoing frustration of maintaining the complex include path in multiple build
systems.",2
"Parts of TF Lite already assumes NEON support, so this check is redundant.",2
Remove some unnecessary assumptions from DotMerger pass.,2
It doesn't need to assume that DotDecomposer has run before it.,2
"We don't expect any changes to generated code, as currently the assumptions
which are removed still hold.",2
We assume AsyncOpKernel outlives its done callback.,2
"The returning TensorHandlePtr* implicitly assumes the handles are stored in a continuous memory space, which isn't specified in the contract.",2
Remove testing assumption that outermost stack frame does not belong to the *_test.py file. This is not true in all test environments.,2
"This made assumptions about how DenseElementsAttr structured its internal storage, which may change in the future.",2
"TopK will specify a computation to sort into descending order, and
the current logic assumes that the sorting is done into ascending order.",2
Remove verification of assumption that doesn't really hold.,2
"The version which implicitly assumed the computation to be summation remains
CrossReplicaSum.",2
* We make the assumption that one of the two union members is always active.,2
"* There are no longer any assumptions about the memory layout of the
  implmentation of std::unique_ptr.",2
ResourceOpKernel destructor can't always assume the resource is still there.,2
"Return real cuDNN error on allocation failure, do not assume all errors are OOMs",2
Most of the time We assume parameters are readonly.,2
"However if a parameter is aliased with an output, we can safely assume it is writable (its content will be overwritten by output anyway).",2
This makes calling Dataset.map deterministic when stateful ops are in the map_fn (assuming the user doesn't pass deterministic=False to map or tf.data.Options).,2
Rewrite TpuExtractOutsideCompilation pass without assuming clustering.,2
Estimator assumes a particular config_pb2.ConfigProto that configures the underlying session.,2
Currently the resource op lifting pass is only used for the TPU bridge and it is assumed for all TPU computations variables are all initialized.,2
"OpLevelCostEstimator::GetDeviceInfo() returns GFLOPs/sec and GB/sec of
the assumed machine, but currently it assumes the device type is either CPU
or GPU.",2
"Device type not CPU / GPU currently causes crash; to avoid such a case, we
assume unknown device type as transfer operations over PCIe; setting
default PCIe x16 gen3 bandwidth to avoid crash.",2
"If the
source rank in collective context is negative, then we assume this is a single
node collective and take the rank of the caller of broadcast send as the source
rank.",2
"o Introduced templated BroadcastHelper routine in literal.cc that
is specialized for different primitize byte sizes (without this,
primitive_size was a runtime variable and so the compiler couldn't
do a very good job of optimizing the memcpy that occurred per
element, and would invoke the general memcpy path that assumes the
byte count is fairly large, even though in our case it is a
tiny power of 2 (typically 1, 2, 4, or 8).",2
"There is still some assumption in GetBlockByIndex's bit operations that
some quantities fit in uint16.",2
"Simplify MakeBlockMap: it already assumes that the input rows/columns
are rounded up to next multiple of kernel block dims.",2
"The current branching is confusing: reviewers glancing at the code assume that
the first branch corresponds to the eager mode, and miss `or len(tout)`.",2
Assume input pruning always enabled.,2
- enforce the assumptions better / in a simpler way,2
"Relying on lexicographic order turns out to be brittle, as it assumes the writer writes everything in lexicographic order.",2
"This assumption is violated in at least 2 cases: optimizer slot variables are stored in their own groups, and Keras layers are sorted by layer name first.",2
"In Standard to LLVM dialect conversion, the binary op conversion pattern
implicitly assumed some operands were of LLVM IR dialect type.",2
"This means the rest of the runtime can assume TensorHandles are on physical devices, and gives custom device tensor handles some freedom to evolve.",2
The TF2 MLIR bridge assumed that this was not possible.,2
"For now, assumes both
operands have the same shapes.",2
Current Build and Verify methods of the TransposeOp assumes that the quantized axes of input and output are the same.,2
"Before, our ReductionToVector emitter assumed all reduction shapes are equal.",2
"This doesn't seem to hurt anything, and sounds cleaner than just assuming that the ""last"" node in the graph is the output.",2
"If the log path looks like /gs/foo/bar/baz, we assume it's a reference to a GCS
object named bar/baz in bucket foo.",2
"NOTE: This CL assumes that the domains of the registered session factories
do not overlap.",2
"Current, we have the hidden assumption that all outputs of parallel_execute op are from tpu cluster.",2
"My plan is to get Models to the point where they can be reconstructed from object-based checkpoints (probably one more change), add in SavedModel export (assuming no dynamic control flow for now), then add this ""SavedModel+Python"" format to Model.save / load_model.",2
"Currently, the function_def_to_graph_def function assumes the `value` field in `arg_attr` has the `list` field.",2
"This is based on the assumption that the input models have leading
tfl.quantize ops and tailing tfl.dequantize ops.",2
Current gather implementation assumes the next op is always quantized.,2
"And Layer.__setattr__ in general will now ignore @property.setters when tracking, on the assumption that the setter itself will assign to something (or as in this case disable tracking).",2
"Estimator class doesn't have visibility into whether weighted losses are used, so the default was assumed to be SUM, because it's correct-ish in either case.",2
This assumes a shared filesystem for all tasks.,2
Currently assumes variables are floats; there are TODOs to rectifiy this.,2
"Prior to this change, `Optimizer` assumed that `not
context.executing_eagerly()` implied that every variable that it was to update
was constructed in a graph.",2
"That assumption is incorrect --- TensorFlow
functions can mutate variables captured from or lifted into the eager context.",2
"TFLite runtime always assume int32 padding in the Pad kernel, however it could also be int64 according to the spec.",2
"The existing implementation of the Op definition generator assumes and relies
on the fact that native Op Attributes appear after its value-based operands in
the Arguments list.",2
"As such, this change removes that assumption.",2
"Now the assumption is made that the
default value in the gradient TensorArray index is zero with the correct shape.",2
"The Graph construction code assumes that the GraphDef's NodeDefs match
the OpDef specifications.",2
"A follow up change will add an ops.colocate_with() to Python that adds
this attribute to nodes, and will be used to replace calls to 'with
tf.device(foo.device)' in TF library code, which assumes that devices
have been specified.",2
"TensorFlow: update documentation for tutorials to not assume use of bazel
	(when possible).",2
"Prior to this change a TensorHandle was assumed to reside on CPU if

  device_ == nullptr || (ctx_ == nullptr || ctx_->HostCPU() == device_)",2
"(2) A function to compute global shape using dynamic local shapes, assuming the dynamic shape only happens in the first dimension",2
"It performs C=C+A*B and assumes the input A,B, C and the output are dense arrays on the host.",2
The reason: PyErr_SetObject (called in SetRegisteredErrFromStatus) assumes that the GIL is acquired.,2
"In multithreaded python any call to a python API function can release the GIL,
so we should not assume our data structures haven't changed across calls to
the python API.",2
"This is based on the assumption that the transpose and reshape ops are from
preparing conv2d and depthwise_conv2d ops.",2
"TFLite resource kernels, e.g, resource variable and hashtable resources, have an assumption that resources in TFLite will be identified by 32-bit integer keys.",2
This CL makes Lite MLIR convert the tf.resource type to 32-bit integer type in the flatbuffer conversion process in order to implement the above assumption.,2
"We used to assume that job is localhost, which may not be true in a multi worker environment.",2
"Turn off layout optimizer (as with all other optimizers) in the memory
optimizer test, because the test assumes no modification of the graph.",2
* Fix assumption of ranked shape in GetDimensionSize op.,2
"Note that cudnn_rnn_v3 only support sequence_length, which assumes that the input data is right-padded.",2
"The existing logic assumes the state[0] of the step function is same as the
output, which is not necessary true anymore.",2
Update comments about threading assumption in send/recv callbacks and add a unit test for host callback,2
Currently we assume `main` funciton must be present in the MLIR code.,2
Update the multi-threaded pass timing to not assume that total time will be different from user time.,2
Update the nightly release smoke test to assume it's already in a virtualenv.,2
This prevents the user from assuming that all symbols are actually known before performing a transformation.,2
"Assumes
RankedTensorType when computing the quantization information.",2
This will make it possible change change the default behavior in the future by updating the meta optimizer code to interpret that default value differently (e.g we could assume default means heuristics).,2
"Use a more appropriate data type for List ops, as their type var only points to the dtype of the tensor it holds (and assumes it's a tensor), and not to the complete element type.",2
A more permanent fix would address the issue in `inspect` which makes an incorrect assumption here: https://github.com/python/cpython/blob/53d2b715d10e5c81cb9c86fd25e88ace4e41bc25/Lib/inspect.py#L924,2
This CL assumes the CopyToMesh Op only allows isometric transports -- preserving the layout; most (if not all) current users of copy_to_mesh inside tf.function from I checked follows this pattern.,2
"Difference from original CL: add '-no_cuda11' tag filter, which is necessary because this change upgrades from CUDA 10.1 (which I assume was not updated yet by accident) to CUDA 11.",2
"For example, using CUDA terminology, and assuming a 2-d grid with processorIds = [blockIdx.x, threadIdx.x] and numProcessors = [gridDim.x, blockDim.x], the loop:
```
   loop.for %i = %lb to %ub step %step {
     ...
   }
```
is rewritten into a version resembling the following pseudo-IR:
```
   loop.for %i = %lb + threadIdx.x + blockIdx.x * blockDim.x to %ub
      step %gridDim.x * blockDim.x {
     ...
   }
```",2
"Previously if ANY value in the selector of kSelect is dynamic, we over-conservatively assume all resutls are dynamic.",2
Verify dimensions before we assume we have at least 2 (i.e. before we end up calling dim_size with a negative dim index).,2
"This change is motivated by the fact that, when eager execution is disabled, library functions assume that tensors returned from `internal_convert_to_tensor` are in fact `Tensor`s and not `EagerTensor`s.",2
"When resolving dynamism fails, conservatively assume value is dynamic.",2
"When reuse is False in variable_scope, treat is as None (inherit from parent).
(All known callers already assumed that this was the case before.)",2
Assume they are already set.,2
"[AutoSharding] Remove dependence on the assumption that for a module parameter tuple, the get-element-tuple instructions that access the tuple elements are in the same order as the tuple elements themselves.",2
This assumption was being made previously when extracting alising information for the HloInputOutputAliasConfig of an input module.,2
Previously DRR assumes attributes to appear after operands.,2
[DelegatePerformance] The average warmup latency is generally assumed to be greater than the average inference latency.,2
"It assumes that ForOp builder added a terminator to the body, but it's not the case.",2
"string and std::string are not necessarily the same thing in TF, but this code assumed that they are.",2
"JAX will use IFRT for
key classes, while it will assume a PjRt client in many code locations, which
will be incrementally updated to become more portable.",2
"Due to a special structure of the resulting loop
nest we can make some assumptions about the operations in its body.",2
This op assumes that such a value exists though.,2
"This CLs adds proper error emission, removes NYI assertions and documents
assumptions that are required in the relevant functions.",2
This CL also documents the `substExpr` helper function assumptions.,2
The assumptions are properly propagated up already.,2
"The AsmPrinter wrongly assumes that all single ssa-id AffineMap
are the identity map for the purpose of printing.",2
"- Allow all ops that are in a single use non-public function to be inlined, assuming post
  inlining, the function will be deleted.",2
"By default assume
  that ops can be duplicated.",2
"Currently, we assume that broadcast with ""expansion"" of 1 -> N happens whenever
operand dim == 1. It is not true when result dim is also == 1.",2
"This fixes a subtle bug in the GPU module caches, which assumed that no two GPU
modules are loaded from the same memory location.",2
"In this way, we can again
guarantee the needed assumption for the lifetime of the caches.",2
"In the case of
empty tensors the result shape is not the same as that of the reused input
buffer (as assumed previously).",2
"There is nohing abstract about abstract stack trace: it assumes a particular
storage, and it is passed by value everywhere, making extending this class
virtually (pardon the pun) impossible.",2
Fixes an abstraction violation by the dlpack code that meant it assumed the StreamExecutor implementation.,2
"When set to true, the implementation assumes the
host is using major-to-minor layout and handles the rewrite internally.",2
"In light of this, the whole discussion about const makes total sense to me now
and I would systematically apply the rule that in the end, we should never
have any const XXX in our codebase for unique'd types (assuming we can remove
them all in containers and no additional constness constraint is added on us
from the outside world).",2
"Previously, this would be handled incorrectly
by CreatedContexts::Add, which was assuming that inserts into the map
always succeeded.",2
The HostStream implementation assumed that closures enqueued on a thread pool of size 1 ran in FIFO order.,2
"The optimized code is similar to
   `IndicesValid32BitFastPath()`, which optimistically assumes that the tensor
   is valid and falls back to slower code in the failure case, except it does
   not have the 32-bit limitation.",2
[TF XLA AOT] Assume aarch64 is always available.,2
"Currently, the ImplicitBatchModeCompatible strategy creates profiles with the
assumption that the first dim is always the batch dim.",2
"Previously, the XLA argument parameter was incorrectly assumed to be
corresponding to the index in the vector of `XlaCompiler::Argument`.",2
[TF/XLA] Make an assumption that reference variables cannot occur inside tf.function,2
"* Change the way that the clustering was done by flowing down along the branches of the switch node separately;
  - It was previously wrong to assume that the operands of an op are in the same control scope if they are not a switch or a merge node, as a zero-input op (such as a const) could be referenced by both ""branches"" of a switch without this op not being exclusively in either branch.",2
We assume that the models are stored in the SavedModel format.,2
"On the other hand,
TensorFlow assumes all function arguments with int32 values are on host memory
unless the kIntsOnDeviceAttr attribute is set to true.",2
"When the Shape OP is inside
an TRTEngineOp and the TRTEngineOp segment executes natively, TF assumes all
the outputs of the TRTEngineOp are in GPU.",2
"The explicitly vectorized reduction kernel assumes that the input and the output
layouts are ""same"" (not identical which is not possible, but have the same
ordering of the un-reduced dimensions).",2
"This test was for concurrency, but also made the assumption that floating point operations are deterministic which is not true with autotuning.",2
Until now we'd conservatively assume interference where there would not be any interference because of the copies inserted.,2
"Using BroadcastInDim directly shouldn't change the compiler output
assuming that the optimizer was doing its job.",2
"This change assumes that a TF subgraph/op does not cross the boundary of a HLO
computation and always put top-level TF subgraphs/ops under HLO computations.",2
"The assumption is that the old instruction and the new instruction would perform the same function, and that they would be correlated to the same TF op.",2
- Do not assume that we use output 0 of X and Y.,2
The pass currently assumes that there is no circular dependency among the per-host functions.,2
The pass currently assumes that any tf._TPUCompileMlir op is always wrapped by a tf_device.launch op whose body contains only the tf._TPUCompileMlir op.,2
"This largely works fine, but causes problems for TensorFlow Probability's JAX backend, which assumes properties like `numpy.int32 == tf.int32` hold.",2
Assuming `SourceOp` has three results.,2
"Using this assumption allows considerable code simplification,
at which point EmitTilingKernel becomes so simple that the function it's using
can be inlined.",2
[XLA/GPU] Assume the new row reduction algorithm for the tree reduction rewrite,2
"In rough pseudocode (for simplicity ignoring boundary conditions: assuming our
columns have exactly 128 * 32 elements, and the row size equals to the number
of blocks * 32):

```
void reduce(float** in, float* out) {
  __shared__ float[32][33] cache;
  int thread_id = GetThreadId();
  int block_id = GetBlockId();

  int tile_size = 128;

  float accum = 0;
  for (int i=0; i<tile_size; i++) {
    accum += in[thread_id.y * tile_size + i][block_id * 32 + thread_id.x];
  }
  cache[thread_id.x][thread_id.y] = accum;

  __syncthreads();

  accum = cache[thread_id.y][thread_id.x];
  accum = warp_reduce(accum); // Sum all the values of `accum` in the same warp.

  if (thread_id.y % 32 == 0) {
    out[block_id * 32 + thread_id.x] = accum;
  }
}

```",2
"Previous logic assumed that there are always 32 threads/block and miscompiled
if the setting was different.",2
- Assume latency is high between async-start/done pairs,2
"- Assume custom calls for cuBLAS, cuDNN and softmax are high cost, else medium cost.",2
"b) In conv-canonicalization, we incorrectly assumed that the input
    permutation was equal to the output permutation.",2
"In case of cyclic call graph, e.g. recursion, we over-approximate and assume any aliasing at the call site.",2
Sadly the assumption that vector-matrix multiplication is matrix-matrix multiplication withextra 1-dimensions is baked into many places.,2
"Crash fix: The concat transform assumes that the inputs are 2D, and crashes if
they're not.",2
[XLA:GPU] Add an @llvm.assume(linear_index < threads_per_block * num_blocks).,2
[XLA:GPU] Assume that tuple sub-buffers are available at runtime.,2
"Previously we assumed this was not the case, and allowed front-ends to
pass in a pointer to tuple without also passing in pointers to
sub-buffers.",2
"This allows doing dynamic slice updates inplace for fusions in which all
outputs are potentially bitcasted dynamic slice updates that use the same
update shape, assuming that the parameters being updated have a unique
consumer.",2
"Such stores can in fact be vectorized,
unlike the assumption stated in the code.",2
"The autotune code assumes a clean slate, but there might be things from
previous program executions still pending on the streams owned by the executor.",2
"This
relies on an assumption that the computation of the result tensor elements in
the tile only needs the elements in the pre-loaded tile for the parameter.",2
"Any
instruction inside a fused computation that may break this assumption can cause
incorrect kernel code generation.",2
"This relies on an assumption that tensor buffers are 4 byte aligned and have a
size of 4N bytes in order not to access the buffers out of bound.",2
"This change just re-arranges existing code, and makes sure that we use the
layout of the current output as opposed to assuming all outputs reuse the first
layout.",2
"This is easier than I thought because we can assume that all tuple members have
the same number of elements.",2
"* ""optimize-for-latency"" algorithm assumed that each thread would want
   the maximum number of registers it could have, and chose a block size
   small enough to accommodate this.",2
As a consequence fix fused_scatter test wrongly expecting rematerialization due to previously assumed zero device memory size.,2
Update several places to remove the assumption that the devices present have device ordinals [0..n).,2
"I previously tried separating out all of the PJRT TPU dependencies,
but this caused problems in libraries that assume TPU support is
always linked in (namely chex).",2
"Before, we assumed that if you passed --use_fake_data, you didn't care
about the output of the computation.",2
"Remove the assumption that all entries in the registry are for the CPU
platform.",2
[XLA] Assume that CustomCall instructions created with dynamic dimensions from the client are valid with any padding value.,2
This is fixed by modifying copy_insertion.cc to check all related HloValues without assuming they are ordered.,2
"Previously, we were assuming allocations for a given HloBuffer that had the same
offset needed to be colocated.",2
[XLA] Fix HLO graph dumper not to assume that instruction names start with "%".,2
[XLA] Do not assume shape always has layout when computing ByteSizeOfElements,2
"Previously MakeFakeArguments assumed that anything which flows into a
dynamic-(update-)slice is an R1 value.",2
"When allocating alternate memory for conditionals, we assume the conditional
will always evict the value back to default memory before the end of the called
computations.",2
Remove the assumption that users of conditionals are always getTupleElement.,2
"This assumption does not change how the algorithm works and removing the
assumption should not break anything.",2
"Previously kCustomCalls assumed that aliased operands were forwarded unchanged, so any copies of reused operands were removed by the CopyInsertion pass.",2
"Part of the problem is that it was computing

  erf(x) = x * polynomial1(x^2) / polynomial2(x^2)

and assuming that we had enough precision that neither of the polynomials would
overflow.",2
"1. It was assuming that index 1/2 of dynamic-slice/dynamic-update-slice
contained all of the slice indices.",2
"It can be confusing when reading and one might assume
that the actual buffer where the output lives is in {0} instead.",2
[XLA] Fix invalid assumption in HloComputation::CloneWithReplacements.,2
"CloneWithReplacements assumed that the `extras` instructions came before all
other instructions in the postorder traversal.",2
"Previously the HloEvaluator would always assume the predicate is an array of
boolean type, and does not handle cases where on_true and on_false are of Tuple
types.",2
"Always assuming the buffer combining criteria causes the copy_insertion_test to fail when tested under the debugging mode, when LiveRangeStrictBefore is invoked to check the ordering of different buffers which are not combined.",2
"[XLA] In HloEvaluator, fix an issue where the return type and native type are assumed to be the same for HandleImag and HandleReal, when in fact they should be float and complex64 (or float for HandleReal's case), respectively.",2
"The evaluator assumed the input value to be 0 when out of bound, which is likely to produce wrong output when the reduction function is not Add.",2
[XLA] Misc updates on scatter op handling that assumed single output.,2
"This heuristic assumes an implementation of fusion that requires recomputing the producer, which is specific to those backends, rather than inherent to fusion.",2
"For example, in a number of places, it assumes we have a total ordering to
  our instructions, but in fact the fake ordering we generate is only a partial
  order.",2
"[XLA] Remove the assumption that the non-CPU backend is the default if more
than 1 platforms exist, now that ComputeConstant no longer requires a dedicated
CPU backend.",2
"1- Memory space assignment no longer allocates these buffers, assuming
     BufferAssignment will allocate them.",2
"2- Memory space assignment now assumes these inputs/outputs will live in the
     alternate memory for the entire duration of the computation, hence
     accounting for the reduction in available space in the alternate memory
     space, fixing out-of-memory errors.",2
"Previously LayoutAssignment left GTEs alone, assuming they came in with
the right layout.",2
Do not assume that the shape remains the same.,2
"In the process of tracking down timeouts in THE ISOLATOR, I had assumed that
time spent was dominated by either generating input data, executing the input
data on various backends, or comparing the data.",2
"Never assume you know where
the time is spent in a program; the profiler may surprise you.",2
"They assumed that the src, dst and set operands are interleaved.",2
Fix assumption in getTiedOpResult that there is just a single result.,2
"However, the current python binding infra will generate the constructor __init__() without the `return` as the first arg, which assumes the shape function can provide a fully inferred type (including an accurate element type). This leads to ""inferred type does not match actual result type"" errors in JAX.",2
* EagerPyFunc now validates its assumption that returned tensors are backed by memory on the same device that the EagerPyFunc kernel executed on.,2
"Disabling global graph
on eager mode breaks too many assumptions so first introduce a flag indicating it.",2
"These two
cases happening together was generating invalid SPIR-V blob because we
previously assume the parent block to be the block containing the terminator.",2
[tHLO] Assume only canonical mhlo.scatter ops to be lowered to tHLO.,2
"When this happens, we exit ForeverRepeat early, assuming that it will never be able to produce data.",2
[tf.data] Changing the `tf.data.experimental.rejection_resampling` implementation to avoid relying on the assumption that a dataset copy produces elements in the same order as the original dataset -- which is not guaranteed to be true (e.g. for shuffled datasets).,2
"Previously, attempting to deserialize a tensor containing one or more SparseTensor objects would trigger an assertion failure, either in Eigen (because it attempted to manipulate an empty Eigen tensor) or the SparseTensor Reshape() code (which assumed all ranks were >= 1).",2
"The previous logic would only advance to the next slot if the
element emitted was from the first index tried (on the mistaken
assumption that anything else would be sloppy).",2
"The layout optimization assumes that all ops without explicit device assignment will be placed on GPU (if possible), which is not true for ops without tf.data user-defined function and result in incorrect layout optimization.",2
[tf.data] Remove (incorrect) assumption from file cache op kernel that a caller will not call `GetNext` once end of the cache has been reached.,2
"For instance, this assumption does not hold for ParallelMap or MapAndBatch kernels.",2
[tf.data] Removing an incorrect assumption from the input pipeline optimization logic.,2
"Specifically, no operation inside a `GraphOp` can be assumed to have no uses because it could be specified as a `fetch`.",2
"The previous assumption that `self._output_tensor_ids` is always a tuple
is incorrect.",2
"Certain parts of source_utils_test.py assume that traceback always
returns the last line, which is true all the way up to 3.7.",2
Code in `ResolveAxis` assumes the constraints and only checks it using a `DCHECK`.,2
"That is, by carefully changing the buffer index in the flatbuffer serialization, we can force the TFLite interpreter to consider a read-only tensor to be a read-write one and assume that there is an operator that has this tensor as output, writing to it and allocating memory before the tensor is used as input.",2
"In such situations, we may want to tolerate some incomplete state of the operation, since it is not fully created, by relaxing some assumptions.",2
Removed code for detecting graph capture mode assuming that in graph capture mode we don't have memcpies with different contexts.,2
clarifying how num_classes works w.r.t. assumed possible classes,2
"num_nodes() implies that the quantity returned is unsigned/non-negative, although the same assumption cannot be clearly made about last_node.",2
"For now we assume the incoming custom op is a resize_bilinear, it is expected any other custom op will cause the program to error out",2
"This assumption is
good enough for all existing DTensor use cases, but may be broken at some point
for heterogeneous oriented use cases (e.g. multi-pod).",2
remove low_level_metadata due to wrong assumption.,2
These tests mostly have assumed equal-sharding layout of the variables.,2
"With this change, it's assumed that, if there is an explicit squeeze_dims
argument to tf.squeeze() and the dims in question are not known at shape
inference time, the input dims will be assumed to be 1.",2
"After the node insertion, assuming both B and C have non-Ref input, the graph becomes:

A:0 ---3---> Copy -----------4----------> B
                      |
                      ---------5--------> C
                      |
                      ---------6--------> X",2
tfdbg core: remove assumption about _SINK node from test,2
"The merge happen in the TraceContainer (by appending, thus order is not conformed), however internal container sortTracks, but external OSS container don't sort container (assuming xplane's integrity of event ordering).",2
"- ExpandGatherDimsInAccumulator was assuming that gather_indices must be of at
   least rank 1 (by calling CollapseFirstNDims).",2
"As a result, the assumptions made by the EagerPyFunc kernel implementation about the placement of returned tensors would be violated.",2
I'm assuming that after @vrv 's suggested changes you won't need to modify tensorflow/core/BUILD.,2
@yogeshg you can either wait for the PR to be accepted (assuming it will be) or just take the relevant changes from the callbacks.py file in my commit https://github.com/fchollet/keras/pull/5679,2
"A minor inconvenience is that the batch size is set, so if your model expects N batches, you need to pass in N-1 dud batches, and then use pred = pred[0] since you only care about your real batch (Assuming the first batch was the real one)",2
"Considering that most optimizers have adaptive step sizes, it seems wrong to assume that model averaging is in general equivalent to gradient averaging (as done in Simonyan&Zisserman).",2
So the API should make as little assumptions as possible.,2
"So I assume a safe way of merging multiple sources is to, for each source, go from the very beginning towards the end to construct a sequential model, then merge them (after I did so, the code worked)?",2
"It does by-pass the implicit assumption that loss should be computable on a per-sample basis, but that shouldn't matter.",2
"Assuming your doing speech to text, your model will learn that 3 is associated with the silent token output.",2
"Then your model would get to the same level (loss) in _half_ the epochs, assuming your data is perfect. Still really good to know that patience is key in this.",2
# We assume the time index to be masked is axis=1,2
"Since `tf.nest` cannot make any assumption about the type of the keys, I think it requires a constructor with on positional argument.",2
"I'm not assuming that images are stored consecutively in one folder, because even if they are stored in subfolders inside each class, ImageDataGenerator class will read them all as if they are together and will loop through the images/frames inside each folder.",2
Am I making some wrong assumptions here.,2
So is it fair to assume we perform a matrix multiplication of the weight for a particular cell with the contents of the cell ?,2
Is it correct to assume that in one timestep the Input x_t goes through 32 LSTM blocks?,2
"So my question is, is it safe to assume all tf.keras apis work with sparse tensors?",2
"This is not an assumption, this is fact when the batch size passed into the model.fit is not 1( `batch_size != 1` )",2
"Previously the documentation stated ""Computes <statistic A> at a given <statistic B> <X>."", there was no guaranteed and consistent behaviour in case the specified <statistic B> cannot be assume value <X> on the provided sample of scores and labels (e.g. required recall of 0.7, but only either 0.6 or 0.8 can be reached).",2
"We can't promote the input to rank 2 there, because `tf.reverse_sequence` does not make assumptions about the exact rank of the input.",2
I assume here that the cell does a convolution on the input. Which may be not true (but for the moment it works since ConvLSTM2DCell is the only cell class that exist for 5D tensors).,2
- File based vocabularies will only be scanned once.,1
"- by mistake I set it on, it would break compatibility",1
- loading weights to the same class should always succeed,1
"- other combinations are not compatible and should throw a ValueError
  - they do not throw now",1
"It should be more intuitive and we use it already
internally.",1
"Since the paper will most probably will not evolve a boolean argument
for two conventions is enough.",1
- it's also possible and actually simpler,1
"- move back to test_topology.py where it should be
- split into two parts - GRU/LSTM can run without GPU, CuDNN variant need it
- adjust imports",1
"`self.bias[0]` should be 1D, but CNTK returns 2D.",1
"The mayor optimisation a part of the Max over time are:

- Dropout in the Embedding layer.
- Longer input sequences (400 instead of 100), made possible from the speedup of the Max Over Time.
- Adam optimizer.",1
They should be independant.,1
"- Making sure there is no code between functions declarations, this is easy to miss and unexpected.",1
Logic should be put in functions or in `if __name__ == '__main__':`.,1
- Should read `protocol` rather than `protoocol`.,1
- Should read `discretized` rather than `discritized`.,1
- Should read `augmentation` rather than `augmentaion`.,1
"This is a significant refactor of the internals of the layer, which will break
SavedModel compatibility with previous versions.",1
"The usage of the layer will
remain the same, so a compatible layer should be generatable from the same
training script.",1
"- Static vocabularies passed on init will be consistently clonable with the
   layer config, rather than clonable only in the file based case.",1
"# The 2nd commit message will be skipped:

#	add PIL to enable testing of preprocessing code",1
"# The 3rd commit message will be skipped:

#	try a different way to install PIL on travis",1
"# The 4th commit message will be skipped:

#	include PIL only in python 2.7",1
"# The 5th commit message will be skipped:

#	test image preprocessing",1
"# The 6th commit message will be skipped:

#	fall back to Pillow for python 3 image processing",1
Test functions should be small and target as few functionalities as possible.,1
I believe we could add them to the docs.,1
"The new shape should be of size 5, here it is only 4.",1
"I did not find a commit where it would work before, but i could have missed it.",1
When an exception is raised the resource might not be closed.,1
This may eg. result in depleting the number of file handles for the process.,1
I think it was meant to be passed it to the `__init__` of the parent class.,1
Numpy ndarray should be serialized as Python list. (#10727),1
* Numpy ndarray should be serialized as Python list.,1
Readers expect frequent patterns to be defaults when calling functions.,1
I think it improves readability.,1
"Hence, the current condition will discard the last word, ie. index=20000.",1
I used `np.newaxis` for users who may not be familiar with the `None` indexing.,1
This is a pull request to divide #12076 into multiple sub-PRs making it easier to review (the diff will be smaller).,1
"Usually, this is what a user wants, but there are edge
cases where one might want to do this (for instance, projection
shortcuts in Residual Networks).",1
"The documentation says that [1]: 

> If [classes are] not provided, the list of classes will be automatically inferred (and the order of the classes, which will map to the label indices, will be alphanumeric).",1
The message print on_epoch_end would be overwritten by ProgbarLogger.,1
This should allow Theano to perform lazy evaluation.,1
Potential deconv model saving fix? (#4999),1
Adding this cast to a tuple seems to fix this issue.,1
"The publishing URL should be the homepage of Keras, instead of github.com.",1
There should be no publisher for software.,1
"Fix issue in keras.layers.Dense.call that could cause deadlock.

(It's not ok for `call()` to recursively call itself, because it will get wrapped in `@tf.function` when saved in a SavedModel; and `@tf.function`-wrapped functions are not allowed to have recursive calls.)",1
"When converting ExtensionType inputs to match the expected dtype, only use tf.cast if the value doesn't already have the expected dtype.  (Not all ExtensionTypes add dispatch handlers for the tf.cast method, so we should avoid calling it unless it's necessary.)",1
"Fix bug in KerasTensor.set_shape, where kt.set_shape(None) would erase existing shape information.  (set_shape should refine the shape, not replace it.)",1
"From the documentation it is not entirely clear that if mask_zero is set
to True, the input_dim argument should be equal to the size of the
vocabulary + 2, as index 0 cannot be used anymore.

(This behaviour seems a bit strange, as it has as a consequence that the
first column of the weights of the embeddings will never be used or
updated. The resulting network thus has a redundant set of parameters).",1
"This is potentially a breaking change for subclassed models that process scalar data, as well as for certain Sequential models that were called with incorrectly-shaped data.",1
"Previously, if Model.fit/evaluate/predict saw a batch of data of shape (batch_size,), it would uprank it to become (batch_size, 1).",1
"If the first layer was a Dense layer, input rank would not get checked, meaning that a model such as `Sequential([Input(shape=(dim,)), Dense(...)])` could get called with data of any rank as long as the last axis had the correct dimension.",1
"After this change, only data of shape (batch_size, dim) would be accepted (i.e. rank 2).",1
"Note that this does not affect Sequential models defined with an explicit input shape (as long as they're called on correctly shaped data), nor Functional models, because such models will standardize their inputs to what they expect.",1
"For instance a model built with `Input(shape=())` that receives data of shape (batch_size, 1) will reshape it to (batch_size,) and inversely a model built with `Input(shape=(1,))` that receives data of shape (batch_size,) will reshape it to (batch_size, 1).",1
2) Method functions and non-method functions should be distinguished from each other.,1
"Since, the module name of non-method functions should be included in the signature in the docs (like `keras.preprocessing.sequence.pad_sequences(...)`) whereas for the methods of classes it should not be included (like `compile(...)` for `Sequential` class).",1
"Only None should be supported on the Progbar target parameter,
target values of -1 are an unsupported implementation detail
that may be removed in the future.",1
"It would be even better to have full-fledged stateful layers documentations, but I lack the knowledge and experience to explain that well.",1
"* Went through PEP8 errors and corrected all (except for the imports which following the numpy seed, but this should be ok).",1
* Adding unit tests to check for expected predict_generator output shapes.,1
Allows preprocess_weights_for_loading() to consider layers wrapped in TimeDistributed or Bidirectional (#5836),1
* Allows preprocess_weights_for_loading() to consider layers wrapped in TimeDistributed or Bidirectional.,1
I needed this for a Kaggle competition and it seemed useful in general so I thought I'd contribute it back.,1
"Possibly we could craft such data that both tests can be
merged and parametrized.",1
"This will raise a UserWarning when the user modifies model.trainable
and tries to print a model summary or launch a fit without having
called .compile.",1
"For consistency with other examples where auxiliary dimensions are defined, I think it would be better to explicitly assign them a value.",1
load_weights will fail if shape mismatch (#10266),1
Doc expects a list containing 2 tensors.,1
I'll refactor it later,1
"It seems that multiple skipif decorators get evaluated eagerly, not lazily.",1
Maybe some change in pytest?,1
"The process_function_docstring would fail to parse the “# Argument” 
and “# Returns” of class functions.",1
"This was because it expected the
“# Argument” string to be preceeded by exactly a newline and 4 spaces,
but for class methods, that would be a newline and 8 spaces.",1
This fixes the problem by expecting a newline and some number of space.,1
* Maybe fix CNTK,1
"* Clean support for stateful metrics logging, some refactoring of progbar & compile",1
"The existing contract of state_size[0] to be output size is bit
weird and might cause unnecessary contrain for supporting higher
dimension input/output/states.",1
"For backward compat reason, if a cell does not implement
output_size, the state_size[0] will be used as output_size.",1
"This should hopefully make things a little easier
to read.",1
* Forgot that the message should be present only when loading imagenet weights.,1
"However, security conscious users would get a hash of the file from a separate channel (e.g., from the page hosting the model if it also displays the checksum) and would use that to make sure that the model they download is exactly the one they intend to.",1
"Some wrappers in tensorflow-addons (eg. `MultiOptimizer`) only accept the list of grads/vars as positional arguments, and reduce the remaining arguments into `**kwargs` that will be passed onto the inner optimizer.",1
[MP] RNN.call should get initial state from full input spec (#10845),1
* RNN should get initial state from full input spec,1
Fix bug for KerasTensor._keras_mask should be None,1
"This fix tries to fix a couple of issues in the error
string of `def switch(..` where `cond_ndim` and `expr_ndim`
are undefined, and should be replaced with `ndim_cond` and `ndim_expr`.",1
`model.compile_metrics` will be empty until you train or evaluate the model.,1
"enable string formatted filenames (e.g. weights.{epoch:02d}.hdf5), so
every epoch will be saved to a different file without overwriting.",1
There will be a behavior change after this cl.,1
1. Unseeded initializer will always generate same value after creation.,1
2. Unseeded initializer will raise a warning if it is reused (called) multiple times.,1
"This is to avoid reuse the instance for multiple variables, which could generate same value when shapes are the same.",1
"3. Seeded initializer will always generate same value after creation, instead of determinist sequence.",1
"The 3 new APIs are used to enable/disable/check the usage of `tf.random.Generator`, which will be the new backend for all the RNG in Keras.",1
"We plan to switch on the new code path by default in tf 2.8, and the behavior change will like to cause some breakage on user side (eg if the test is checking against some golden nubmer).",1
These 3 APIs will allow user to disable and switch back to legacy behavior if they prefer.,1
"In future (eg tf 2.10), we expect to totally remove the legacy code path (stateful random Ops), and these 3 APIs will be removed as well.",1
This module will be removed in 0.20.,1
Update to 1.21 will cause some test failure.,1
"When the tensorflow version is r1.2 and lower, the name of list_devices() funtion's output will not have ""device:"" keyword, because of the PR #8567.",1
This change will work just fine.,1
"This should both improve performance overall, and make for a more uniform experience
using the preprocessing layers.",1
"To keep your images a certain dtype (e.g. to display them after transformation), you
can still set the dtype on the layer, which will be respected.",1
"2. All the python code will be retrieved via pip install, rather than pip rule.",1
"This is possible since we remove the tf from workspace, which has high priority than the PIP package from local venv.",1
This setting should enable us to have "pip uninstall keras-nightly" once we add it to tf-nightly as a deps.,1
"The new approach give user just a scope, which user should use to create their DTensor model.",1
"These apis by default will not do anything, but users can override them for customized logic.",1
"2. The wrapper takes an extra key argument to make the arglist unique due to tf.function tracing mechanism: if args are of the same shape and dtype, they would be treated as the same call.",1
"1. Switch from Lambda to merge, otherwise code will not run.",1
"The implementation of bAbi [End to End Memory
Network](https://arxiv.org/pdf/1503.08895v5.pdf) in the example
seems to be missing the Softmax Layer.",1
"Also, the question encoder
[here](https://github.com/fchollet/keras/blob/0df0177437ce672d654db6d7edfdc653aaf67533/examples/babi_memnn.py#L186) seems to sum over the probabilities and the question vector as suggestted in the original paper.",1
6) Adam optimize won't have vhat if amsgrad is not present.,1
Make autogen.py compatible with Python 3.5 and 2.7 (seemed to be using 3.6-only features?).,1
"A new version of keras optimizer will in future replace the old optimizers, and we will keep supporting the old optimizer in legacy namespace.",1
A new-version optimizer is going to be available in TF 2.9 release.,1
"Although the new optimizer is now under experimental namespace, it will in future become the default optimizer.",1
"For backward compatibility, we will continue support the current optimizer in the legacy namespace.",1
"Although the new optimizer is now under experimental namespace, it will in future become the default optimizer. For backward compatibility, we will continue support the current optimizer in the legacy namespace.",1
a test demonstrating the expected values of loss/metrics when configured reduction method is sum,1
"A ValueError on creating a layer could
reflect a number of issues and should be surfaced directly.",1
"This will make it easier to bring uniform output modes to the full set
of preprocessing layers with categorical output.",1
Add an expected failng test for #14086,1
"Add BaseAugmentation layer, which could be used by image related KPLs.",1
We might expose this to public.,1
"My reading of regularizers is that they cannot be reused, but it doesn't actually fail in any way and seems like it results in only regularizing the last layer.",1
Having an exception prevent this would probably improve the ergonomics.,1
"With this method, I believe no other recurrent method will need to overwrite
get_output.",1
The issue is probably because we only use the keras:keras target (which doesn't include API generation part).,1
* Update the doc: specify non picklable arguments should not be used with multiprocessing,1
"'one_hot' will automatically uprank the last dimension of your input if necessesary,
and create an encoding for every element in the batch individually.",1
"By adding this
explicit output_mode, we can remove the implicit behavior where output_mode='multi_hot'
would uprank all vector inputs and effectively one hot encode them.",1
"This output mode will encode every element in a input batch individually, and append a new
output dimension (for the encoded arrays) to the input shape if necessary.",1
"The change is currently hidden in a kwargs and not exposed as public API, we might expose it in future after proper testing in production.",1
"I thought as the docs cite other methods, it would be good to provide a citation for this optimiser.",1
"I chose the title of the lecture in question, if there's a better title I'm sure that can be used instead, but I think the citation should be there.",1
* Add regexps to verify that the expected error is being raised,1
"Sparse will only apply when output_mode is ""one_hot"", ""multi_hot"",
""count"", or ""tf_idf"" and the last dimension of the output contains
bins for every element in the vocab.",1
"Sparse will be a more efficient
output option when vocab size is large.",1
"Ragged will only apply when output_mode is ""int"", and will output
a ragged tensor after string splitting where the final dimension
contains ragged vocab indices of variable length.",1
* DataFrame should be handled correctly if list/dict is passed as model inputs/outputs,1
"Tokeniser serialisation was added to `keras_preprocessing` [1], but it was not linked here, so one could not import it from `keras.preprocessing.text`, one had to use `keras_preprocessing.text`.",1
"It is unclear to my why the SyncOnRead variable behaves differently for __add__ and tf.math.add(). v1 + v2 will return pre-replica value and tf.math.add(v1, v2) will return aggregated value.",1
Which seems to be necessary information about `categorical_crossentropy` as `sklearn` has it as `log_loss` hence its beneficial for people migrating from `sklearn` and other people who learned it as `log_loss`.,1
* Fixed potential training-on-validation issue and removed unused imports,1
"* Added support for passing external constants to RNN, which will pass them on to the cell",1
"Regularizers could already return scalar values when used as a kernel regularizers and a bias regularizers, but not when used as activity regularizers.",1
"Not changing keras.utils.test_utils, because that change exposes
(what looks to me like) a latent bug",1
The previous code would always fail to detect the 'weights' argument.,1
"Simply replacing getargspec would cause the tests for some of the legacy
layers to fail because the passed 'weights' argument is bad.",1
"If the input to KerasRegressor.predict() is an array with one example,
then the output should be a 1D array with one example, not a 0D array.",1
We are going to let ResourceVariable be a subclass of CompositeTensor.,1
"Specifically, to track resource variables embedded in composite tensors, we will need to manually expand composite tensors layer by layer instead of replying on tf.nest.",1
Currently resource variables are atoms and considered to have the same structure as tensors.,1
So we could have one branch to be a resource variable and the other branch to be a tensor.,1
"After making resource variable as composite tensors, resource variables will be tf.nest sequences instead of atoms.",1
We are planning to make tf.Variable a subclass of CompositeTensor.,1
"To reduce the risk of rollback, in phase one, tf.Variable will become a CompositeTensor but don't get expanded to dt_resource tensors with expand_composites=True.",1
"In phase two, we will allow tf.Variables to be expanded into dt_resource tensors.",1
The CL will prevent infinite recursion in phase one.,1
"After phase one is landed, this CL will be reverted in phase two.",1
Note: This CL shouldn't change existing behavior because tf.Variable is currently not a CompositeTensor or ExtensionType.,1
"Firstly, by having `XlaClusterFormation` Pass, it will encapsulate `StatefulPartitionedCall` op within a cluster so that the composite resource ops can be decomposed.",1
"After that, the reads and assign resource ops will be lifted outside of the newly created device cluster.",1
This change ensures that lookup layers with equal configs and vocabs will use the same indexing when doing forward and inverse lookups.,1
"Fixes a couple bugs related to getting and setting vocabs:
 - set_vocabulary can now be called if num_oov_indices > 1
 - get_vocabulary will return correct results when num_oov_indices > 1",1
"[For example](https://keras.io/preprocessing/sequence/#pad_sequences):
> `keras.preprocessing.sequence.keras.preprocessing.sequence.pad_sequences`

which should be: `keras.preprocessing.sequence.pad_sequences`.",1
"For example, [this is for `apply_transform`](https://keras.io/preprocessing/image/#apply_transform):

> `keras.preprocessing.image.apply_transform` 

which should simply be `apply_transform`, first because it is the method of a class (i.e. `ImageDataGenerator`) and second because the referenced module name is wrong (and this [has caused confusion](https://stackoverflow.com/q/51311062/2099607)).",1
"Plus, the way `autogen.py` works, the module name is repeated two times in the signature, but for the non-method functions it should be removed only once (that's why I have added a condition).",1
"In `keras.utils.unpack_x_y_sample_weight`, only a tuple or list
will be unpacked into a x, y, sample_weight triplet.",1
"All other
input values will be returned as simply the value for x.",1
"However in `keras.utils.pack_x_y_sample_weight`, all ""nested""
`x` values will be grouped inside an additional tuple.",1
Different replicas will get different random-number streams.,1
"This layer is considered as a core KPL, since we already have RandomContrast.",1
All the image related KPL will be exposed in the keras-cv later as well.,1
"As far as I can tell there is no reason not to support class_weight with
time distributed data, rewriting the standardize_weights function with
that in mind.",1
"When output_mode is ""one_hot"", ""multi_hot"", or ""count"" output dtype will follow
the global policy unless a dtype is explicitly set on the layer.",1
"When output_mode is ""int"" output dtype will default to int64, unless a dtype is
explicitly set on the layer.",1
"An explicit floating point output will lead to an
error.",1
"When invert=False the oov token is unused (and likely never touched by the
developer).",1
"We should only error if invert=True and there is a ambiguity
in the inversion lookup.",1
"Also, simplify the vocabulary error checking code, and make the expected
format when specifying a vocabulary including special tokens more explicit.",1
"For SparseCategoricalAccuracy, `y_true` should be integer labels and `y_pred` should be probabilities.",1
"`Sequential.set_weights` would fail for nested `Sequential`
containers.",1
"Since KPL is only targeted for v2, we don't need to worry about the keras.learning_phase(), and should be safe to do if/else check on `training`.",1
"Also during our benchmarking, seems like this periodic overwriting is harmful to performance.",1
It seems that "tanh" is a more sensible activation choice.,1
"Also for GRUs, tanh seems to be the default:
see http://arxiv.org/pdf/1412.3555v1.pdf Section 3.2",1
This change will make the tf.Variable in the tf.random.Generator be visible to savemodel code when tracing the tf.function for model/layer.call.,1
This will ensure keras integration test to only run with the code from local workspace.,1
"Alternatively, self.states could be created as a float16 variable, which would simply the logic and have better performance, but this could break checkpoint compatibility between float32 and mixed precision.",1
"Although `tf.Module` has a built-in `variable` property, it may not worth the effort to let people write code changes.",1
"This simplifies the calling code, and ensures that we print all tags found the summary events if the assertion fails, which helps debug cases where summaries are still being logged but under a tag name that differs from the expected one.",1
"This
should be more efficient, but more importantly should make
implementations easier to understand.",1
This removes the automatic upranking of rank 0 and rank 1 inputs so this is possible.,1
"As a consequence, the default axis=-1 will treat rank 1 inputs as single samples, and
normalize each dimension of the input individually.",1
"If you would like to pass batched or unbatched scalar data into the layer, and normalize
every element, you should pass axis=None.",1
* BUG: random_normal_variable should check dtype,1
"I chose 30 additional days for closing because sometimes people go on vacation for a few weeks, this way they'll have time after being notified.",1
"bad refactor on make_logs member, should've been in the CallbackList class",1
"Basically we will skip saving/loading weights in the optimizer, as we always require users to recompile the model with a new optimizer instance.",1
Batch Normalization should squeeze mean/var/beta/gama tensors when calling tf.nn.fused_batch_norm (#10684),1
* Batch Normalization should squeeze mean/var/beta/gama tensors when calling tf.nn.fused_batch_norm,1
TF Batch Normalization should use FusedBatchNorm when axis = -1 (#10742),1
Other reduce dimensions should be dome afterwards with K.sum,1
"This means that K.batch_dot will have the same behavior in both
tensorflow and theano.",1
"One blocker is when a ResourceVariable is reconstructed from a dt_resource handle, it will lose the _distributed_container attribute.",1
Moving the attribute from ResourceVariable to handle so this attribute will persistent through packing and unpacking cycle.,1
"Before this commit the `updates` member
could would use another input as the `get_output` method, if the
input was changed.",1
* Update docstring comments to better explain expected behavior,1
This refactoring will allow the simplification of some code in #8296,1
Bug fix: Models with shared layers shouldn't be considered Sequential like (#8025),1
* Fix actual output shape vs expected output shape comparison test,1
"The expression of  pictures should be (img_height, img_width, 3) or (3, img_height, img_width), not (img_width, img_height, 3) or (3, img_width, img_height).",1
So builds not using TF mirror will break.,1
We should decide which store to go with by default.,1
Note: Using h5 without zipping will not work with GCS (due to H5 using its own file pointer).,1
This issue could be worked around via special casing.,1
"But since that may have circular references, that's not sufficient to get it garbage collected immediately.",1
"So, the s values in glorot_uniform, lecun_uniform, and he_uniform should have been multiplied by sqrt(3) before being passed into uniform() function.",1
"As mentioned in Keras webpage https://keras.io/api/models/model_training_apis/, keras shouldn't allow different data types for input (x) and target (y).",1
Keras layers that use RNG (mostly dropout related) will now use stateless RNG op + tf.random.Generator for seed generation.,1
"Since tf.random.Generator contains a tf.Variable for state tracking, this means layers like Dropout can't be created in the layer.call(), which will fail the tf.Variable loop creation check.",1
"Depending on the containers used and the implementation, this may either cause an
out-of-bounds array access or a wrap-around, which will use some elements more than
one in an epoch, thus potentially biasing to those elements which are repeated.",1
"As with other categorical layers (e.g. CateogoryEncoding and StringLookup),
Discretization will support an output_mode, and one_hot, multi_hot, and
count output.",1
"As with other categorical layers (e.g. CateogoryEncoding and StringLookup),
Hashing will support an output_mode, and one_hot, multi_hot, and
count output.",1
"Since the dropout layer and other layers that uses RNG will create the variable when training=True, if user code branched based on that, the current order will raise an error from tf.function about creating variable in non-first call.",1
Change to trace the training=True function first to avoid this potential issue.,1
Changing it to match get_output in Dense seems to have fixed the problem and behaves identically.,1
The environment variable patching will be removed once all usage of dtensor.DTensorCheckpoint is migrated to tf.train.Checkpoint api.,1
Clarify expected label formats for crossentropy losses (#12095),1
* Clarify expected label formats for crossentropy losses,1
Class constructor arguments should be documented in the class docstring in the "Arguments" section.,1
All the new docs should be located in keras-team/keras-io,1
"Remove all the examples, and new examples should be located in keras-team/keras-io",1
"My original docs only included the dimensions of the parameters (no batch dim) and were correct, but I think its better to change the functions to reflect the current docs.",1
"Explains the new pull request procedures for Keras 1, Keras 2, and keras-contrib, should resolve https://github.com/fchollet/keras/issues/5270.",1
"The dense gradient tensor expected by tensorflow
should be extracted with the .values function.",1
"Maybe resolves https://github.com/fchollet/keras/issues/8227, although maybe GeneratorEnqueuer.seed should be eliminated altogether, because currently it's not used anywhere in Keras code.",1
"It probably applies Fran?ois Chollet and Google too, but I'm only a member of ""All other contributors"" so I figured the other changes should be made by those respective rightsholders. :-)",1
"This pr borrows the idea from https://github.com/keras-team/keras/commit/cb3469215ab78219a0ae58f566ddeba2fe6242fb, which seems to be a appropriate method.",1
As mentioned in discussion https://github.com/keras-team/keras/pull/16001#issuecomment-1167067659 BatchNormalization momentum should not equals to 0.,1
"Keras was casting any loss value to float32 under the hood, which was probably for code simplification reason.",1
"In my env, the error shown below occured, and it would be fixed by this change.",1
"By default TensorFlow allocates all gradient matricies on gpu:0, which makes it pretty much impossible to do parallelize a large model.",1
"I think it's also meant to set gradient computations to be done on the device where the operations are stored, but my belief about that comes from https://github.com/tensorflow/tensorflow/issues/2441",1
"I'm not sure why this isn't the default in TF, so I'm not sure if this should be behind a flag or something, but having to make my own patches to keras to do multi-GPU training seems like the wrong answer.",1
"Without the fix, the profiler dir will always be deleted for non-chief node under MWMS mode when Keras TensorBoard callback(https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/TensorBoard) is used.",1
"I copied the old LossScaleOptimizer, since I couldn't find a clean way of factoring out the common code.",1
I tried creating a LossScaleOptimizerBase mixin class with the common code that both LossScaleOptimizer and LossScaleOptimizerV3 would subclass.,1
Right now NumpyIterator wont let us use multichannel data but it's common in satellite datasets such as [Kaggle's Dstl Satellite Imagery Feature Detection](https://www.kaggle.com/c/dstl-satellite-imagery-feature-detection) or [spacenet](https://spacenetchallenge.github.io/).,1
"In most cases the fix is to pass dtype=object explicitly, but in some cases where the raggedness seems accidental other fixes were used.",1
This method will be used by optimizers/metrics in follow up cls.,1
"This change allows the mask to have any shape, and the input will be broadcast to match the shape of the mask.",1
This makes it possible to use masked grouped normalization in a wider variety of cases.,1
"Problem: If the rnn cell has any (recurrent) `states[i]` whose shape is different from that of the `output` (`states[0]`), there will raise an `ValueError` when updating that state.",1
"The stop_gradient documentation states that the argument should be a list of
variables.",1
This commit handles both cases as can be expected.,1
We will send announcement for the formal switch when we finish all the migration/workflow work.,1
We will add more documents and setup the developer workflow in the near future.,1
- previously (#6693) only options and run_metadata could have been passed,1
* Remove passing feed_dict to TF K.function() since it would be constant.,1
* Revert "Remove passing feed_dict to TF K.function() since it would be constant.",1
"Currently, `import keras` will fail if pydot is not installed
(for example, in a fresh virtualenv without the `keras[visualize]`
option).",1
It may be confusing for some people for a model with only one output.,1
"In a valid use case, this conversion only happens when users set optimizer via model.compile(), so they won't notice the conversion happens and find the discrepancy.",1
"This will avoid any variable creation when first use the generator in a tf.cond, eg for dropout, etc, which will resolve into error like b/206821407.",1
Fixed the issue where the summary of non-sequential models would not display content of "Connected to" column,1
"the version tag should be 1.2.0, afaik 1.1.3 doesn't exist",1
count_params should report count for all weights.,1
The BaseLossScaleOptimizer will be exported as tf.keras.mixed_precision.LossScaleOptimizer so that type check on tf.keras.mixed_precision.LossScaleOptimizer would pass for both LossScaleOptimizer and LossScaleOptimizerV3.,1
"For example, a test may be disabled temporarily if it is broken, or it may be designed to not run on OSS permanently.",1
"`no_oss` will now be considered to disable broken tests, while `oss_excluded` will be used to permanently exclude a test from running on OSS.",1
"This will avoid loading DTensor, which is currently breaking in OSS.",1
This will improve the experience for those subclassing the `Conv` class.,1
This will provide a well supported API to do this.,1
Will populate to all the layers that has weights in follow up cls.,1
"We only need this currently for Identity initializer, since tf.function will convert the tf.MatrixDiag to tf.constant.",1
Setting ```order=0``` will speed up random shifts significantly.,1
"For a multilabel AUC metric, we expect that for each data point we will have one or multiple labels.",1
"The resulting shape will be the same whether it is taken from `y_pred` or `y_true`, but `y_true` is not always available at compile time.",1
This is troublesome when using distributed workers as the last one could fail.,1
"in Parameter Server Strategy, the last worker may finish sooner than earlier scheduled worker resulting in incorrect metrics being returned.",1
"urlretrieve will blindly swallow any 4xx and 5xx responses
and then save the html error response in the local file.",1
"This
is probably exactly what we don't want, because not only will
the program crash if there is a network hiccup when the error
file cannot be opened, but it will continue to do so when rerun
until the corrupt cached file is found and manually removed.",1
Disable callbacks_v1_test on MacOS as we do not plan to retrospectively fix legacy only tests.,1
The logic is particular to tf.distribute internal implementation and should live in tf.distribute.,1
Do not apply the static shape specified via `keras.Input` when conforming incoming Tensors to the input shape as it could be incorrect.,1
"In a TF1 session, we can't know when devices are set up (and tables
are ready to be initialized), so the table initialization will need
to be done by the user, e.g. with tf.compat.v1.tables_initializer().",1
I would try to be as explicit as possible in the first example of the functional API,1
DOC: models should be compiled upon loading (#2428),1
Docker WORKDIR should be /data (#11991),1
"If this Docker is for Keras' users (not developers), then the Docker WORKDIR should be `/data`.",1
"Embedding is supposed to return None for its mask when it's not in
masking mode.",1
This will ensure to select the performant implementation XLA TPU.,1
End user probably doesn't care about what's the algorithm used for RNG.,1
I suggest that keras.engine should not be part of the official Keras API.,1
"Since `keras.layers.Layer` is the same as `keras.engine.topology.Layer`, it would be simpler to just point the API to the former.",1
Take max of squared distance and K.epsilon() because some data points will throw `nan` for euclidean distance.,1
"Eventually, support for deserializing these classes may be removed.",1
Explicitly setting XLA on for optimizer causes unexpected behavior on TPU.,1
"Moreover, instead of raise KeyError, we log a warning and directly return because during model.save(), the update_step() will be retraced, and when XLA is on it will have key missing.",1
The layer_test will be used by keras-cv/nlp and tf-addons.,1
"Expose Kokoro config folder to OSS, since we would expect end user to run this as well.",1
"This issue is due to an unexpected loss of dimensionality when
composing the backend tensor operations ""reshape"" and ""squeeze""
when there are dimensions of length 1.",1
"Second, it changes the implementation of squeeze(x,axis) so that the
Theano backend should behave similarly to the TensorFlow backend.",1
Fix bug in EinsumDense layer that caused it to incorrectly report that the input shape and output shape would not match at a shared dimension.,1
This issue would occur only for equations with an input with an ellipsis on the left and the same letter (dimension) in the input and the output.,1
Fix bug in shim with exporting and possibly checkpoint restoration.,1
The way the documentation is parsed for the Keras website made some lines of the documentation beginning with "Default:" look funny.,1
fix float32 issue: int32 times float32 will generate float64,1
"Most of them are failing since the actual code are expected to run only in v2 (eg need eager/resource variable, or certain fix we added is only applied to the v2 code path).",1
"When saving a Hashing layer in a model previously, it would save with
a floating point dtype, even if the layer was input strings and outputing
ints.",1
"We will ignore floating
point dtype in that case.",1
index_array should be initialized when self.batch_index is zero.,1
"We used nonzero() on the weights in order to ensure that if there
happened to be a NaN or an Inf in the output that was going to be masked
about by the weights anyway, it wouldn't propagate (because 0*inf = NaN)",1
"This fixes that, and also fixes what I believe was an issue where I was
calling mean() instead of dividing by the sum of the sample weights.",1
Fix issue in which the file download progress bar would report incorrect progress data.,1
"LiL sparse matrices would not work correctly due to dtype being
different.",1
"We would switch hash types when saving and loading because of a config
error.",1
Fix shapes should be tuples.,1
"When output_sequence_length is set, for dense tensor input, we would error
out when the static shape contains None on any dimension.",1
fix TypeError: fit() got an unexpected keyword argument 'show_accuracy',1
Looks like eec61d9 changed the stride from 1 to 2.,1
Fix typo in docs. loss_weight should be loss_weights (#2343),1
Fix typo where label should be used.,1
fixed calculate_class_weights where it would yield an np-array with shape[1] == 1 which is not mappable.,1
"In the case of greyscale images, channel axis should be of length 1, however a warning was still displayed due to incorrect checks.",1
"In v1, since there isn't a global policy, the layer compute_dtype will be ""_inferred"" from input, and the inferred dtype are actually populate on the cell.",1
"For any layer that has a weight with different name as its attribute
name, tf checkpoint will add a dependency that is not visible to keras.",1
"For KPL that need to coordinate between image/label/bbox, it might need to generate transformation based on the input (eg shape of the image, number of bbox, etc).",1
"In future, when we need to add more input types (eg segmentation masks), we will add a new optional param to the `get_random_transformation` method",1
Model evaluation (test) using the _test K.function should be also stateful for stateful recurrent networks,1
Further work may be needed to split up the long file with individual metric definitions.,1
However having a single file per metric may be too granular.,1
Noise should be multiplicative for GaussianDropout,1
Generator should use Process Lock when pickle safe instead of Threading Lock (#6911),1
* Ensure generator lock will be process version instead of threading lock,1
add .gitignore to filter the files shouldn't be included.,1
Going forward `Conv` layer subclasses should prefer `Conv.convolution_op()`.,1
"Fixes issue #1734 non-existant .h5 files will not be created, IOError will be raised.",1
This could be a valid use case if user has logic to expand and reshape certain inputs within the model.,1
Having this as warning should be good enough to prevent user from making any error.,1
"However, on line 846, deg2rad() is applied to the argument, implying that the argument should be given in degrees.",1
"Issue #8249 runs into a problem where the max hash size is low, resulting in files being potentially overwritten.",1
"As batch size increases, the probability that any given file will have a conflict in the hash reduces.",1
This seems to just be an unforeseen bug because a batch size of one is uncommon.,1
"I believe others may want
to try that out too.",1
These should match.,1
"The existing tests, where I'm changing the expected values are because I believe the old values are incorrect.",1
It rather confused me; I believe my proposed naming is clearer.,1
I believe this is the correct combination of masks and weights,1
So I think it's easier to keep track of what is _not_ handled by `convert_to_tensor` instead of what is.,1
I think it represent better meaning.,1
"From line 1907 - 1918: when call tf.reshape(x, shape), (*before*)shape=(-1) will raise ValueError: Shape must be rank 1 but is rank 0 ...",1
"I think (-1) in python refers to the Rank-0 shape, though [-1] or (-1,) refers to the Rank-1 shape instead.",1
"Through analysis, I think it is caused by the processes weren't freed after the `evaluate_generator` accomplished.",1
I think that's going to be the only pep complain..,1
It's possible that it's really meant to be closed after "(which is the default)" by adding a second closing parens to to close the outer statement.,1
"I wasn't sure, but this seemed more likely in my mind.",1
"If a user calls a layer:
```
my_layer({""images"": images})
```

we should return a dict back to them.",1
"If include_top, MobileNetV3 should return the feature map without pooling.",1
"If you make `refs` an instance attribute, this will cause `HDF5Matrix` to open the same HDF5 file more than once (which should never happen).",1
"Impact: This should be a low-impact change as it only affects the case where `center` or `scale` are False when fused batchnorm is in use, and they are both on by default.",1
This should fix the problem`Exception: Invalid layer: LRN2D` while loading a model that includes LRN2D.,1
The code above could reproduce the problem.,1
"* Import statements now try to add the various backends one by one, so that most tests will run even if only one backend is installed",1
Importing tf.keras might resolve into keras in PIP package when testing in OSS.,1
move self.l1 and self.l2 outside K.sum may increase the performance of calculating the norm.,1
"In deep learning, the norm should not be very large (a large norm will make loss function useless), so move self.l1 and self.l2 outside K.sum will not cause overflow problem",1
"In new saving logic, make it possible to save compile() arguments and recompile loaded models.",1
"In tf2, the training flag should always be python boolean.",1
"All other ""int"" output from KPLs (Hashing, StringLookup, IntegerLookup and TextVectorization)
is int64, we should be consistent.",1
"When a corpus has less than MAX_NB_WORDS, num_words will be set to len(word_index) .",1
"However, since the index is zero based it causes an IndexError. eg. When there are 57 total words in the corpus you get the error 'IndexError: index 57 is out of bounds for axis 0 with size 57' since the index should stop at 56 (zero based).",1
"If building TF with XLA option enabled, an additional
`xla_gpu:0` device will be exposed to users which is a domain
for running graph in XLA mode.",1
"Should skip this device to
avoid the number of multi_gpu improperly inferred.",1
"This is one test file failing, due to the monkey patching happens in the dtensor.init(), and I will need to dig more about the root cause (probably due to patching tf.Variable with DVariable, and cause logic difference for instance type checking.)",1
"Since we won't have a keras.dtensor.initializer public API (it will be too much work for end user to update their code), we should make the existing keras initializers work with dtensor.",1
Input should allow shape=`()` (#8544),1
Input should allow shape=`()` in the event that the final shape of the tensor should be `(batch_size)`,1
"Note that this is only enabled without explicit tf.keras.Input(), since the input layer could not produce a nested structure of input tensor.",1
"It will only work when model is built without input layers, and called with structure of inputs at runtime.",1
The seeded initializer will no longer produce same random value across multiple calls.,1
"Instead, it will produce different value, and multiple initializer created with same seed will produce same sequences.",1
This change will the make the seeded initializer behavior align between v1 and v2.,1
"The new approach will be turned on when all the internal tests are fixed. V1 graph mode, the behavior is not change.",1
"It is possible, for example, that the ModelCheckpoint is configured to use save_weights_only=False, which is not (yet) supported by SidecarEvaluator, and a reminder here should help.",1
It may however be less convenient since it requires get_config() to be implemented and the use of a custom_object_scope.,1
One thing unclear is it seems checkpoint/saved model could still include optimizer's weights after explicitly excluding optimizer weights from model weights.,1
This would allow additional speed ups if anyone has ideas on some particular test.,1
It seems that there are some other IT tests that could be sped up.,1
"In the example script lstm_seq2seq_restore.py and lstm_seq2seq.py, when
parse the data using line.split(""\t""), it will return 3 values rather than
2, a simple modification can fix it.",1
"The aggregate_gradients is not necessary for user under DTensor, but since aggregate_gradients is a public API, it will be nice to just let it do noop, rather than raise an error to user, which they will just remove the call in their code.",1
Remove axis argument - it will always be 0 when called by predict,1
"Added ""If None, it will default to `pool_size`."" to be consistent with explanation of 1D, 2D layer",1
Will remove the corresponding endpoints from tf api folder when we switch the repository.,1
"When we want to move keras out as a component, we need a target that only contains tf core code (doesn't include keras), and keras could rely on it as a build dependency.",1
"To keep the status quo, I add the both tf.keras and oss keras to tensorflow_no_contrib, so that tf.keras API will be still available at this target.",1
"Kernel_size, pool_size should be positive integers",1
Lambda layer:get_output should use get_input.,1
Lambda should not support masking implicitly,1
"When learning_phase is not set, access the backend.learning_phase() shouldn't set the global state.",1
"maxlen is passed to _remove_long_seq which filters out sequences; the
documentation stated sequences would be truncated.",1
"In certain use cases, load_weights() would cause OSError if called repeatedly on many different files.",1
The proposed addition will now make sure the HDF5 files are closed before exiting.,1
Other changes are cleanups made possible by the removal of the experimental mixed precision API.,1
"The LSO subclass implementations would raise an error, but the LSO subclasses are not called if a non-optimizer is passed.",1
"Using `NotImplementedError` as default is problematic because it would fallback to using default serialization resulting in a library-created type (`keras.saving.saved_model.load.XXX`), plus it's customary for subclass Models to start with super class' `get_config` and update key/value pairs into it.",1
"Previously, it was possible for custom objects to leak outside of the custom_object_scope() context manager when used in a multi-threaded manner.",1
Make it possible to configure nb of threads in TF,1
Make it possible to process single images with `imagenet_utils.preprocess_input`,1
Since MaxoutDense does not have activation it might be misleading to include "activation" as one of the arguments in the function docs.,1
I'm sure some people forget to do that.,1
Note: there are enough saving-related utils that we should centralize them in their own namespace instead of overloading `utils`.,1
Besides the `models` namespace is likely to be increasingly used for actual model instances (e.g. the SAM optimizer model...),1
Possibly faster RNNs,1
The py_object_to_proto lib need a slight update to config the root path since we will make tensorflow.keras as the root when visiting all the keras related API.,1
ndim_tensor should support one dimensional tensors.,1
"When the shape is fully dynamic and the rank is not even statically known, `compute_output_shape` will fail.",1
Should subsample Convolution1D on correct axis,1
"Beforehand, slow generators could have caused race conditions and
crashes with 'ValueError: generator already executing', e.g. if
a validation generator filling up the queue took longer than a single
epoch that elapsed meanwhile.",1
model should use binary accuracy for binary crossentropy loss (#3098),1
"Nesterov acceleration is not implemented now, will have a followup change to handle nesterov acceleration.",1
"* Added support to make sure that previous epochs, which may pass the
baseline test, are kept in variable history.",1
WARNING:tensorflow:From .../lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3148: calling l2_normalize (from tensorflow.python.ops.nn_impl) with dim is deprecated and will be removed in a future version.,1
Num of params should be int (#6100),1
Objective outputs should rescale based on sample_weights,1
"stride value implies the input argument of 'stride', and dilation_rate implies the input argument of 'dilation rate' of Conv1D function.",1
"Or, at least both stride and dilation_rate should be written in code, not only dilation rate as before document",1
"Soon tensorflow.org will render `Deprecated:` as a notice box, so switching these `Warning:` to `Deprecated:` seems appropriate.",1
Otherwise it'd timeout with ~1 out of 100 runs.,1
"The old usage of tf.keras.preprocessing.sequence.pad_sequences will continue
to function.",1
Passing batch_size seems irrelevant as `None` is its default value in `test_loop`,1
"IndexLookup has to persist its attribute ""sparse"" so that a deserialized
layer expected to produce sparse tensors does so.",1
"Previously, many unit test files started with `enable_v2_behavior`, which would have caused them to run in V2 mode when executing with a V1 test flag.",1
The correct behavior would in fact be to skip such tests when executing with a V1 test flag.,1
"The error message didn't have a space between words, so it looked like ""we expect thetensors to have a static batch size.""",1
"Change in y value in Validation part to remove error ""ValueError: The model expects 0 input arrays, but only received one array.""",1
"Change in y value of validation_data to remove error ""ValueError: The model expects 0 input arrays, but only received one array."".",1
"fix bug in TFOptimizer, this optimizer should call tensorflow native optimizer with the named param var_list",1
"To use this SAM api, the task should be compatible with `model.fit()`, which means tasks requiring CTL cannot use SAM now, e.g., neural style transfer.",1
"We also move models.py into models/ folder, as we are expecting to see more customized models being added into models/ folder.",1
"* The default activation for input is `tanh`, not `linear`, as
  the previous doc string might mislead readers to think.",1
"Keras saving/loading: Add a custom object saving test to verify the `keras.utils.register_keras_serializable` flows we are expecting users to follow work, and will continue to work with the new design and implementation coming in.",1
"We will use the new HashedCrossing layer to compare performance with
feature_column.crossed_column",1
This seems to no longer be needed with more recent releases of `keras_preprocessing`.,1
Remove manual tag on training_test since it's supposed to be running.,1
"This is trying to isolate the dependency from keras to TF so that OSS keras could
rely on the PIP package only (the proto build deps is not available from PIP).",1
Remove the old field and replace with new version should have no impact for any existing saved saved_model binaries.,1
"Remove the usage of legacy keras code, which will be deleted soon.",1
Remove those packages which will be fetched by tensorflow.,1
[WIP] will be added after `TimeDistributed` generic layer.,1
Removed seemingly useless self-assignment (#12514),1
"Removing assert y_pred in range [0, 1] in metrics because they may be logits.",1
Residual connection should have the same dimension in case of no projection matrix (#2688),1
"We won't support raggeds for all image preprocessing layers for now, but will
support it for the resizing layer so it can be used as the first in the chain
to make all images in a batch uniform size.",1
* simplify check_rnn_operation (fully considering KNP as ground truth),1
Add a layout_map.scope() method which will replace `layout_map_scope`.,1
The new method will make it more look like the `strategy.scope()`.,1
Should downsample on `steps`.,1
Should fix issue #1522.,1
"Small fix to array_to_img function, it won't change the value of x when set scale=True now.",1
So far all the weights will have fully replicated layout (since they are usually small counter).,1
"Some rare use cases set `epochs=0`, we should avoid breaking them.",1
"some tensorflow tests skipped for now, will raise an issue for these",1
"In Python 3 weights.sort could throw a TypeError exception, if the
names are all None",1
"Rather than overload a single argument by type (with different implications for adapt), we will
split out a num_bins argument for the adapt use case.",1
"When either layer receives an image that is smaller than the crop box, we will
take the largest box inside the input image of the target aspect ratio, and resize
it to fit.",1
"The mean, normalization and output type should always equal the compute_dtype.",1
"TerminateOnNaN calls model.stop_training at the end of a batch, which without check in fit_generator will be ignored",1
"In the same way that if the loss's name begins with an underscore it is trimmed, the class name option should do the same.",1
Tensorboard callback by default should disable profiling.,1
Whether perform profiling should be at user's discretion.,1
tf.keras.layers.TextVectorization(vocabulary=["foo"])(["foo"]) would fail with an error.,1
"We should instead check rank during
call, after converting to tensor.",1
That seems wrong too.,1
Sklearn (e.g. the Bagging estimator) expects a value error if a parameter isn't recognized.,1
"With the previous changes,
this would result in the successful resolution of `__tf_tensor__`
on these types, overriding their registered conversion functions.",1
"The existing code might hit issue when certain dimension is unknown, eg None for batch dim.",1
"The new stateless mode is intended to be used by keras.Initializer, so that the generator will not contain or refer to any tf.Variable.",1
"This will cause a behavior change to seedless initializer, which will now produce same value if it is called multiple times (with same shape).",1
The initializer change will come in a follow up cl.,1
Update the docstring of the metric.result() for expected return types.,1
"The metric result should be a scalar tensor, which will help any consumer of this value, eg callbacks.",1
The test/benchmark could break if run the keras code against TF v1 behavior.,1
"Theano tile() expects Python int, so casting from numpy.int32 to Python int. (#4330)",1
Theano: deconv2d should also shuffle filter_shape. (#4631),1
"There
are plans to remove private module namespace access so
this fixes keras to first try accessing through the public
namespace, and then going through the private one for older
versions of TF.",1
"They should output
a vector of accuracies instead of single scalar to be compatible
with keras.engine.training_utils.weighted_masked_objective function.",1
"This allows a Lambda
layer to be the first layer in a net, which was previously
impossible.",1
"This block looks like it's meant to be an implicit string-concatenation block (i.e. `('foo ' 'bar.')` => `foo bar.`, but the extra comma means it is a tuple.",1
"This class will first convert both the labels and predictions into the all-class format, then applies the computation steps of class `IoU`.",1
"This class will first convert both the labels and predictions into the original format of the labels, then applies the computation steps of class `MeanIoU`.",1
"This ensures that users are at least aware of the fact that weight_metrics exists, and normal metrics will not be impacted by sample_weight.",1
"This is backwards compatible with ""labels"", and we should also eventually rename ""augment_label"" -> ""augment_target""",1
The existing tf.compat.v1 symbol will still work since tensorflow.compat.v2.compat.v1 is same as tensorflow.compat.v1.,1
"This is to prepare the stateless initializer change, that initializer
instance will constantly produce same value after creation.",1
"When
applying a Convolution2D with border_mode='Full', images will grow in
size, this Layer allows to shrink them back to its original size (or any
other size)",1
"This may cause some issue like keras.utils.multi_gpu_model(model, gpus) function can not work under r1.3 of tensorflow.",1
"This
meant that __call__ could be very slow on complicated structures.",1
"This provides a checklist of things we will
look for from contributors.",1
"This seems like a good place to use the on_epoch_end callback to
print the generated text, instead of explicitly performing iterations
with epoch=1.",1
This seems to generate qualitatively better results and is technically more correct.,1
"This should
work for all versions.",1
This was giving `TypeError: mel() got an unexpected keyword argument 'hop_lengthgth'` error. Please verify and merge.,1
This will remove the overhead for declaring the tf.function for every call to the call_with_layout.,1
This will be used for other APIs like DTensor and quantization in future.,1
"This will help GitHub automatically recognize and classify this license as the
Apache 2.0 license, rather than an unidentified license:
https://github.blog/2016-09-21-license-now-displayed-on-repository-overview/",1
"This will make it consistent with the existing API, so that user won't hit issue if they use positional arg to init the strategy instance.",1
This will be used in KerasCV,1
"Although they are still implementation details, this will allow user to do type checking as well as type annotation for their code.",1
This will become an issue after we switch to use OSS keras.,1
"This will result in a warning from numpy:
VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future.",1
This will reduce the change to copybara when new visibility is needed.,1
This will allow the tf.Variable created in the tf.random.Generator to have proper name scope.,1
This will change TF to import the keras code from the workspace.,1
"This will allow parameterized tests to work correctly in both 2.7 and
3.4",1
This will allow subclassing layers to pick if we will auto-vectorize or not.,1
"Thus, we will flatten the args.",1
"TimeDistributedMerge needed to be imported into layer_utils, so it could be serialized to to_json",1
Network.to_json should handle numpy.ndarray correctly. (#10754),1
Users can now return layers in the config and get the expected result when calling `keras.models.from_json(model.to_json())`,1
1) The JSON encoder will now encode the registered names of layers (still follows previous behavior of using the class name if the object is not registered),1
"Under the hood, the functional model will check if any of the inputs are intermediate keras_tensor, and create clone for related inputs/output/nodes for new model.",1
"With the upcoming stateless initializer change, the current behavior of
keras initializer will cause issue for unseeded initializer in PSS,
which call the initializer multiple times with potentially same shape
and different offset.",1
"Update keras to use tf-nightly, which should be exactly the same as tf-nightly-gpu.",1
"Update the format fix first, and will followup with new changes.",1
"We should refer the paper accepted in ICML 2015, instead of arXiv.",1
Since the method name is `compute_output_shape` returns should be `an output shape tuple` not `an input shape tuple`.,1
"In light of SuperConvergence [1], the user might want to increase the learning rate during training so saying 'reducing' is no longer appropriate.",1
"Grouped convolutions in a compiled (but not XLA compiled) function will
fail on the CPU.",1
Use the latest tf-nightly since the OOM issue from nightly might be fixed.,1
"in get_from_module(), a unicode identifier should be treated as a str
type.",1
Warn when epoch sees more samples than expected,1
Warning did nothing useful and there's pretty much no way a user reading it could have made sense of it.,1
"We do not believe we have usage of these layers in TF1, and would like to
discourage future users attempting to user augmentation layers with the
incompatible TF1 base model class, so we are removing the symbol export.",1
We should remove it.,1
"When interactive logging is disabled (using absl logging) and verbose=""auto"", we will use verbose=2, which does not print the progress bar.",1
We won't be able to access those API in the __init__ file if they are not exposed as Keras API.,1
"ValueError: Error when checking target: expected dense_4 to have shape (2,) but got array with shape (4,)",1
"Can anyone help me in rectifying the following error: ""Error when checking target: expected dense_4 to have shape (1,) but got array with shape (10,)""",1
"(1,1) tuple instead of None will crash AveragePooling2D",1
.fit method could have an argument for deleting broken files,1
[BUG] Number of trainable weights seem to change after model compilation,1
[BUG] Omitting loss in model.compile will result in unhelpful error message,1
[install] error: Could not find suitable distribution for Requirement.parse('scipy>=0.14'),1
"[Vgg-finetune] ValueError:expected sequential_1 to have shape(None,2) but got array with shape (16,5)",1
__init__() got an unexpected keyword argument 'reduction',1
__init__() got an unexpected keyword argument 'inputs',1
keras 1.2.1 TypeError: __init__() got an unexpected keyword argument 'outputs',1
__init__() got an unexpected keyword argument 'node',1
load_model: __init__() got an unexpected keyword argument 'name',1
TypeError: __init__() got an unexpected keyword argument 'rescale',1
TypeError: __init__() got an unexpected keyword argument 'input_shape',1
"TypeError: __init__() got an unexpected keyword argument 'name' while loading saved model in Keras 0.3.2, python 2.7",1
__init__() got an unexpected keyword argument 'update_freq',1
_preprocess_numpy_input in keras.applications.imagenet_utils should not be in place,1
_raise ValueError('All target arrays (y) should have  ValueError: All target arrays (y) should have the same number of samples._,1
"`Dense(units=1)` output shape is not `(batch_size, 1)` as expected",1
`get_config()` doesn't work as expected when trying to load a model with custom objects,1
`image_dataset_from_directory()` should return both training and validation datasets,1
`predict` should be able to activate learning phase,1
2.3.0 ImageDataGenerator : unexpected keyword argument 'interpolation_order',1
"3 Dimensional weight matrix -> TypeError: Expected int32, got None of type '_Message' instead",1
3 Possible Essential Features for `model.summary()`,1
A Convolutional Neural Network Model Could not be loaded,1
A Possible Mistake in Autoencoder Example in Keras' Doc,1
A solution of this issue seems to not work in my case.,1
A Suspected Bug in binary_crossentropy,1
A suspected bug in the LSTM layer using cntk backend,1
TypeError: add() got an unexpected keyword argument 'activation',1
add() got an unexpected keyword argument 'input_shape',1
Exception: All input arrays (x) should have the same number of samples.,1
"All input arrays (x) should have the same number of samples. Got array shapes: [(593, 4096), (327, 4096)]",1
"AssertionError: Could not compute output Tensor(""ctc/Identity:0"", shape=(None, 1), dtype=float32)",1
AssertionError: Could not compute output Tensor when using multi_gpu_model(),1
"AssertionError: Could not compute output Elemwise{add,no_inplace}.0",1
"AssertionError: Could not compute output Tensor(""sequential_6/dense_31/Sigmoid:0"", shape=(None, 784), dtype=float32)",1
"AssertionError: Could not compute output Tensor(""dense/Sigmoid:0"", shape=(None, 1), dtype=float32)",1
Autoencoder seems to not work at all,1
BaseLogger callback seems broke in v2 - KeyError and wrong seen sample compute,1
Batch Normalization moving_mean parameter seems to ignore the initializer.,1
Batch size does not seem to change and ResourceExhaustedError keeps happening,1
BatchNormalization() returns unexpected error when using cntk backend,1
"BEFORE(Error when checking input: expected conv1d_37_input to have 3 dimensions, but got array with shape (50000, 2))   AFTER( Input 0 is incompatible with layer conv1d_39: expected ndim=3, found ndim=4 )",1
Better error message for Unexpected result of `train_function` (Empty logs).,1
binary_crossentropy possible numerical instability,1
BinaryCrossentropy should support a way to reduce over NO axes,1
"bortedError: Operation received an exception:Status: 3, message: could not create a dilated convolution forward descriptor",1
Breaking changes should break the legacy code,1
BUG in topology.py: self.is_placeholder should be always True,1
Bug: Default 'nb_words' value should be set in 'Tokenizer' constructor,1
"want to stbilize video from using cnn, for that i tried to estimate homography transform parameter,but i am facing a problem that output of a model should be keras tensor",1
callbacks.EarlyStopping should allow to specify a target accuracy to reach.,1
callbacks.EarlyStopping should accept a function to compute the monitored quantity,1
Cant seem to use metrics when compiling a combined model,1
"Character Embedding convolution1d: Input incompatible with layer, expected ndim=3, found ndim=4",1
cifar10_cnn_capsule.py should implement evaluation for test samples,1
class_weight should support lists,1
"CNN + LSTM ValueError: Input 0 of layer sequential_10 is incompatible with the layer: expected ndim=5, found ndim=4.",1
CNTK can run the MaxPooling2D(pool_size=0) which has will lead to error in Tensorflow and Theano,1
compile() should not require arguments when not training,1
Computing mutual information in loss function looks impossible to me with current library,1
Concatenate vector with multiple timestamps that should be ignored,1
"Conv1d with Error: expected dense to have shape (None, 800, 1) but got array with shape (200, 1, 1)",1
ConvLSTM2D: return_sequences=False returns a 5D tensor (should return 4D),1
"Convolution1D, unexpected keyword argument 'input_length', keras0.1.3",1
Convolutional Layers seem to be broken,1
"ValueError: could not broadcast input array from shape (1048576,7) into shape (1024,1024,3)          _get_batches_of_transformed_samples(self, index_array)",1
Predict_generator problem - could not broadcast input array,1
"could not broadcast input array from shape (1600,860,3) into shape (1)",1
"ValueError: could not broadcast input array from shape (256,256,3) into shape (256,256)",1
Could not pack sequence.,1
keras v 2.2.4-tf save model ValueError: Could not pack sequence.,1
cuda_dnn.cc:521] could not convert BatchDescriptor  CUDNN_STATUS_BAD_PARAM,1
Custom loss function depends on multiple models' loss function seems error-prone,1
Custom metric fails with "ValueError: Metric should be a callable",1
Custom regularizers don't seem to be accepted as `custom_objects` while loading a model,1
Custom simple loss function generates unexpected results,1
Deconvolution2D : output_shape issue and possible fixes,1
Deeplearning4J: InvalidKerasConfigurationException: Expected model class name Model (found Functional).,1
"Different `kernel_size` and `strides` values on `DepthwiseConv2D` (with `padding=same`) will trigger significant inconsistent results across Tensorlfow, CNTK and Theano, even using norml parameters like `kernel_size=2,strides=1`.",1
keras.preprocessing.image.DirectoryIterator should perform the same checks as keras.preprocessing.image.DataFrameIterator,1
DirectoryIterator should have a sorted filenames when shuffle=False,1
Discussion for possible new dataset API / extension,1
doing tensor indexing but got AssertionError: Expected all args to be Tensors or Variables; but got CompositeTensor,1
Download directory should only be checked for writability if the file is not present,1
DropOut seems to be broken,1
Dropout should give an error message when rate is greater than 1,1
Early stopping callback will stop early even if improvement when patience = 0,1
EarlyStopping callback won't restore best weights unless training stops early,1
EarlyStopping should print mode details.,1
Embedding layer input should be floats,1
Embedding layer with mask_zero=True gives unexpected weighted accuracy,1
Embeddings's weights doesn't look well with other languages,1
Encoder-Decoder model expects a uniform 3D input for variable timestep data,1
Epsilon for ZCA Whitening should be parameterizable,1
"Error on fitting 3D UNet model: Expected to see 1 array(s), but instead got the following list of 2 arrays. On Fit model",1
"'Error when checking : expected lstm_2_input to have 3 dimensions, but got array with shape (1, 46)'",1
"ValueError: Error when checking input: expected input_4 to have 2 dimensions, but got array with shape (1, 1, 24)",1
"Error when checking input: expected conv2d_21_input to have 4 dimensions, but got array with shape (1, 1, 224, 224, 3)",1
"ValueError: Error when checking input: expected layer_1_input to have shape (128, 128, 1) but got array with shape (128, 128, 3)",1
"ValueError: Error when checking input: expected input_1 to have 5 dimensions, but got array with shape (1221, 50, 50, 1)",1
"ValueError: Error when checking input: expected input_1 to have 4 dimensions, but got array with shape (300, 1)",1
"R ValueError: Error when checking input: expected simple_rnn_input to have 3 dimensions, but got array with shape (1661, 3)",1
"ValueError: Error when checking input: expected input_1 to have 4 dimensions, but got array with shape (2120, 1)",1
"ValueError: Error when checking input: expected lstm_47_input to have shape (128, 1) but got array with shape (1, 11)",1
"ValueError: Error when checking input: expected dense_5_input to have shape (4396,) but got array with shape (4096,)",1
"ValueError: Error when checking model input: expected convolution2d_input_1 to have shape (None, 96, 128, 1) but got array with shape (0, 1, 96, 128)",1
why showing ValueError: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected.,1
"Expected to see 4 array(s), but instead got the following list of 1 arrays",1
"Exception: Error when checking model input: expected input_4 to have shape (None, 5, 3, 244, 244) but got array with shape (3778, 5, 3, 224, 224)",1
Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected.,1
"Expected to see 1 array(s), but instead got the following list of 12331 arrays",1
"Error when checking model input: expected no data, but got:",1
"ValueError: ('Error when checking model input: expected no data, but got:',",1
"ValueError: Error when checking target: expected dense_20 to have shape (3,) but got array with shape (22,)",1
"Array shape doesn't correspond with expected shape of final layer: ValueError: Error when checking target: expected flatten_1 to have shape (10,) but got array with shape (11,)",1
"ValueError: Error when checking target: expected lstm_6 to have 3 dimensions, but got array with shape (9, 15)",1
"Error when checking model target: expected time_distributed_1 to have 3 dimensions, but got array with shape (1822, 1)",1
"ValueError: Error when checking target: expected dense_10 to have shape (10618,) but got array with shape (10,))",1
"ValueError: Error when checking model target: expected dense_1 to have 3 dimensions, but got array with shape (8544, 5)",1
"ValueError: Error when checking model target: expected convolution1d_16 to have shape (None, 250, 32) but got array with shape (10, 250, 1)",1
"when i load model ，then   ： ValueError: Error when checking : expected conv2d_1_input to have 4 dimensions, but got array with shape (10, 28, 28)",1
"ValueError: Error when checking target: expected aux1 to have shape (32, 32, 1) but got array with shape (256, 256, 1)",1
"ValueError: Error when checking target: expected dense_12 to have 2 dimensions, but got array with shape (60000, 10, 2, 2, 2, 2, 2, 2)",1
"ValueError: Error when checking target: expected dense_2 to have shape (5,) but got array with shape (1,)",1
"ValueError: Error when checking target: expected dense_35 to have shape (2,) but got array with shape (1,)",1
"Error when checking target: expected dense_2 to have shape (20,) but got array with shape (1000,) while running pretrained_word_embeddings.py",1
"Error when checking target: Expected activation_2 to have shape (6,6,512) but got array with shape (192,192,3)",1
"ValueError: Error when checking target: expected dense_16 to have shape (None, 1) but got array with shape (8, 4800000)",1
"Error with model.evaluate(): Error when checking target: expected dense_16 to have shape (7,) but got array with shape (1,)",1
"Getting ValueError: Error when checking input: expected conv2d_1_input to have 4 dimensions, but got array with shape (315, 720, 1280)",1
"Error when checking model target: expected activation_2 to have shape (None, 10) but got array with shape (3, 1)",1
"ValueError: Error when checking input: expected lstm_116_input to have 3 dimensions, but got array with shape (372, 28)",1
"Error when checking input: expected input_49 to have shape (512, 512, 1) but got array with shape (28, 28, 1)",1
"ValueError: Error when checking input: expected dense_8_input to have 2 dimensions, but got array with shape (60000, 28, 28)",1
"Keras ValueError: 'Error when checking model target: expected no data, but got: ', array",1
"I'm passing a correct shaped list of arrays but I get this error ValueError: Error when checking target: expected dense_1 to have shape (None, 10) but got array with shape (19 541, 1)",1
"ValueError: Error when checking input: expected input_6 to have 4 dimensions, but got array with shape (23, 512, 512)",1
"Getting error: ValueError: Error when checking input: expected dense_1_input to have 3 dimensions, but got array with shape (25000, 100)",1
"VGG16. Error when checking target: expected block5_pool to have 4 dimensions, but got array with 2 dimensions",1
"LSTM Error when checking target: expected to have 2 dimensions, but got array with 3D shape",1
"ValueError: Error when checking target: expected dense_14 to have shape (None, 2) but got array with shape (928, 1)",1
"Value Error: Error when checking target: expected dense_28 to have shape (7,) but got array with shape (1,)",1
"Error when checking target: expecting policy to have shape (None, 1) but got array with shape (60, 64)",1
"ValueError: Error when checking input: expected input_1 to have 4 dimensions, but got array with shape (4, 1)",1
"Error when checking target: expected flatten_1 to have shape (72,) but got array with shape (2,)",1
"model.fit_generator: Error when checking target: expected lambda_2 to have 4 dimensions, but got array with shape (200, 1)",1
"ValueError Error when checking target: expected activation_1 to have shape (960,) but got array with shape (480,)",1
Error when checking model target: the list of Numpy arrays that you are passing to your model is not the size the model expected.,1
"Expected to see 1 array(s), but instead got the following list of 2 arrays",1
"ValueError: Error when checking target: expected concatenate_1 to have shape (20,) but got array with shape (10,)",1
"ValueError: Error when checking model target: expected activation_1 to have shape (None, 16, 1) but got array with shape (32, 16, 7881)",1
"Error when checking target: expected Output to have 2 dimensions, but got array with shape (631, 80, 2641)",1
"Error when checking target: expected activation_1 to have 4 dimensions, but got array with shape (1, 5, 256, 256, 3)",1
"Error when checking target: expected activation_4 to have 2 dimensions, but got array with shape (14, 3, 150, 150)",1
"ValueError: Error when checking input: expected lstm_1_input to have 3 dimensions, but got array with shape (321, 1)",1
ValueError: Error when checking model target: expected time_distributed_1 to have 3 dimensions,1
"ValueError: Error when checking target: expected dense_2 to have 2 dimensions, but got array with shape ()",1
"Error when checking input: expected Length to have 1 dimensions, but got array with shape (10, 1)",1
Error when checking model target: expected activation_1 to have shape,1
"Error when checking input: expected lstm_29_input to have shape (None, None, 2) but got array with shape (51, 1, 10)",1
"Error when checking target: expected activation_2 to have shape (10,) but got array with shape (1,)",1
"ValueError: Error when checking input: expected input_1 to have shape (3, 224, 224) but got array with shape (3, 224, 244)",1
Error when checking model : the list of Numpy arrays that you are passing to your model is not the size the model expected,1
"Error in py_call_impl(callable, dots$args, dots$keywords) :    ValueError: Error when checking target: expected dense_69 to have shape (64,) but got array with shape (46,)",1
"Training Resnet50 with grayscale images:ValueError: Error when checking input: expected input_2 to have shape (256, 256, 3) but got array with shape (256, 256, 1)",1
"ValueError: Error when checking : expected lstm_1_input to have 3 dimensions, but got array with shape (50, 9)",1
"The shape of my labels array is (5000, 10), But still gets error ValueError: Error when checking target: expected dense_3 to have shape (10,) but got array with shape (1,)",1
"Error when checking target: expected dense_10 to have 2 dimensions, but got array with shape (2560, 69, 3)",1
"ValueError: Error when checking target: expected conv2d_transpose_6 to have shape (258, 258, 19) but got array with shape (258, 258, 3)",1
"ValueError: Error when checking target: expected activation_14 to have 3 dimensions, but got array with shape (32, 10)",1
Error when checking target: expected activation_1 to have 3 dimensions,1
"Error when checking target: expected dense_1 to have shape (None, 1) but got array with shape (64, 120)",1
"Error when checking target: expected dense_143 to have shape (None, 3) but got array with shape (6210, 1)",1
"ValueError: Error when checking input: expected embedding_6_input to have shape (18,) but got array with shape (2000,)",1
"ValueError: Error when checking input: expected conv2d_3_input to have 4 dimensions, but got array with shape (48000, 784)",1
"ValueError: Error when checking input: expected input_1 to have shape (None, 4096) but got array with shape (0, 1)",1
"ValueError: Error when checking input: expected input_14 to have 2 dimensions, but got array with shape (3, 1, 3)",1
"ValueError: Error when checking target: expected dense_8 to have 2 dimensions, but got array with shape (X, 172800, 3)",1
"ValueError: Error when checking target: expected model_2 to have shape (None, 256, 256, 1) but got array with shape (300, 128, 128, 3)",1
"ValueError: Error when checking target: expected dense_3 to have shape (15,) but got array with shape (1,)",1
"ValueError: Error when checking target: expected conv2d_11 to have shape (256, 256, 1) but got array with shape (259, 259, 1)",1
"ValueError: Error when checking target: expected activation_92 to have shape (2,) but got array with shape (1,",1
"ValueError: Error when checking target: expected activation_16 to have shape (2,) but got array with shape (1,)",1
"Error when checking target: expected dense_2 to have shape (None, 1) but got array with shape (3230, 7)",1
"Error when checking input: expected Decoder_input to have 2 dimensions, but got array with shape (1, 5, 5)",1
"Error when running the code to fit the ANN (ValueError: Error when checking target: expected dense_60 to have shape (1,) but got array with shape (4,))",1
Error with model.fit_generator() : List of Numpy arrays that you are passing to your model is not the size the model expected.,1
Error: import tensorflow.keras.backend as K could not be resolved Pylance(reportMissingImports),1
Error: valueError: input arrays should have the same number of samples as target arrays. Find 1 input samples and 0 target samples,1
"error: Wrong number of dimensions: expected 4, got 3 with shape",1
"InvalidArgumentError:  indices[120,2] = -1 is not in [0, 10) 	 [[node sequential_3/embedding_3/embedding_lookup (defined at <ipython-input-65-50ea16cb11fb>:5) ]] [Op:__inference_train_function_13886]  Errors may have originated from an input operation.",1
evaluate_generator ValueError: too many values to unpack (expected 2),1
evaluate_generator() got an unexpected keyword argument 'callbacks',1
"Exception: Input 0 is incompatible with layer dense_1: expected ndim=2, found ndim=4",1
Exception: Input arrays should have the same number of samples as target arrays. Found 28019580 input samples and 2142942 target samples,1
"Exception: output of generator should be a tuple (x, y, sample_weight) or (x, y). Found: None",1
"Expected 3 dimensions but got array with shape (11, 2)",1
Lower-than-expected ImageNet accuracies of pretrained MobileNet V2 & V3 models,1
Terrible issues in Keras version=2.2.0 : while_loop() got an unexpected keyword,1
Unexpected outputs from MaxPooling2D layer,1
Getting the error with retinanet TypeError: call() got an unexpected keyword argument 'training',1
"expected activation_15 to have shape (1,) but got array with shape (10,)",1
"model.load_model() TypeError: Expected float32, got {'type': 'ndarray', 'value': [[0.340, ..., -0.38]]} of type 'dict' instead.",1
pool_2d() got an unexpected keyword argument 'ws',1
"Value error: Input 0 of layer ""sequential"" is incompatible with the layer: expected shape = (None,2566,256,1), found shape = (32,128,1)",1
"TypeError: Expected int32, got list containing Tensors of type '_Message' instead.",1
"Using SpatialDropout2D() with dtype'float16' input will trigger unexpected error on CNTK and Theano, but Tensorflow can run well",1
"When 'alpha = None', LeakyReLU with Tensorflow backend have unexpected behavior",1
Unexpected results with CuDNNLSTM (instead of LSTM) layer,1
Unexpected behaviour when evaluating book example 6.3 (very different results),1
Unexpected behavior of `trainable` attribute,1
ValueError: Cowardly refusing to save variable .. unexpected suffix which won't be restored.,1
Missing comma in test results in unexpected string concatenation,1
tf.keras.BatchNormalization giving unexpected output,1
tf.keras.models.load_model does not work as expected within MirroredStategy,1
Unexpected Prediction TimeDistributed(BatchNormalization),1
"Saving a composite model that includes a custom layer results in error - None has NoneType, but expected one of: bytes, unicode",1
"expected activation_49 to have shape (4,) but got array with shape (2,)",1
"expected conv2d_3_input to have 4 dimensions, but got array with shape (600, 400, 3)",1
"expected dense_16 to have shape (1,) but got array with shape (3,)",1
"expected dense_1 to have shape (6,) but got array with shape (9,) Error",1
Scaling metric creates unexpected diagnostic results,1
"LSTM-based regression: expected dense_1 to have shape (batch_size, 1)",1
"expected dense_17 to have 3 dimensions, but got array with shape (6410, 11)",1
"expected PREDICTIONS to have 4 dimensions, but got array with shape (20, 131)",1
Unexpected print in engine/base_layer.py,1
Expected Shape error even when shape appears to match,1
Encountering Exception Error: expected shape(),1
"expected time_distributed_1 to have shape, but got array with shape",1
"expected time_distributed_9 to have 3 dimensions, but got array with shape (102, 1)",1
"Expected to see 2 array(s), but instead got the following list of 1 arrays",1
"y_ture.shape is expected to be (N,3) yet (?,?,?,?) is received",1
External input in lambda layer - which will be updated,1
Feature idea: callbacks should also receive the model output(s) for the current batch,1
"""Fine-tune InceptionV3/ResNet50 on a new set of classes"" doesn't work, while VGG16 works (suspect BN)",1
Fine-tuning pre-trained VGG16 not possible since `add` method is not defined for `Model` class?,1
fit() validation processing should also be batched,1
fit_generator complains validation_freq is unexpected keyword,1
fit_generator error TypeError: <lambda>() got an unexpected keyword argument 'count_mode',1
fit_generator seems dead lock,1
fit_generator unexpected behavior with custom generator,1
fit_generator unexpected behaviour during first epoch,1
fit_generator() unexpected behavior,1
"fit_generator, unexpected output dimension",1
Flatten layer should support sparse tensors,1
flow_from_directory seems to find no images,1
FunctionalPreprocessingStage.adapt doesn't seem to actually adapt.,1
generator seems to be memory leak(tf.1.3 keras:2.0.9),1
"Generator with Pickler: output of generator should be a tuple `(x, y, sample_weight)` or `(x, y)`.",1
"Git Repo: Typo in TAG name ""v2.7,0"" should be ""v2.7.0""  AND  ""origin/r2.6.1"" likely branched from wrong commit, missing r2.6.0 changes",1
"Given an infinity input, ConvLSTM2D will output a normal value only when the cols shape is 1",1
Gradients may become inf/nan through merge(mode = 'cos'),1
HELP i can't understand what happened thought i thought is quite right,1
Help turning .h5 weight file to json so that I could understand my results in text,1
"Help: 'Wrong number of dimensions: expected 3, got 2 with shape (32L, 60L).' in LSTM model",1
I think i find a bug in imdb.load_data().,1
Hope to add a function where we could define our own derivatives,1
Documentation will  be helpful.,1
I always get the feeling keras leaks info from validation,1
"I am using the following code to implement a siamese network https://github.com/erogol/QuoraDQBaseline/blob/master/siamese.py  But i am getting an error of Expected int32, got list containing Tensors of type '_Message' instead. at this line feats = merge([relu3, relu2, relu1], mode='concat',concat_axis=1)",1
"I think it is overfitting, what should i do to avoid overfitting and improve performance?",1
I think it is currently not applicable,1
I think this is important for ML,1
"""model.add(Dense(32,input_dim=16)), now the model will take as input array of shape(*,16),and output arrays of shape(*,32)"",why is (*,32)?",1
"I think the input_array's output arrays of shape is(*,16)??",1
I think there's an bug in serialization of advaced activations,1
I understand this is online learning but how to implement it through Keras?,1
"if go_backward == 1,  the output seqences should be reversed",1
image_dim_ordering in keras.json will be overwritten as 'th' every time keras is run,1
ImageDataGenerator save_to_dir command will lose some generating image due to filename conflict.,1
ImageDataGenerator().flow_from_directory doesn't work as expected,1
ImageDataGenerator.flow_from_generator would be nice to decouple image sources from data augmentation,1
Importing ABC directly from collections was deprecated and will be removed in Python 3.10,1
importing ImageDataGenerator will occupy all the GPU memory,1
"Importing Keras should not execute code, makes pydoc sad",1
Impossible to create dataset with non-infered labels,1
Impossible to load pre-trained weights,1
"in the test dataset the use of different batch_size will get different results. ,why?",1
Initializers based on `fan_in` / `fan_out` inference may have incorrect behavior.,1
"Input 0 is incompatible with layer lstm_1: expected ndim=3, found ndim=4",1
"Input 0 is incompatible with layer dense_1: expected ndim=2, found ndim=3",1
"ValueError: Input 0 is incompatible with layer conv2d_1: expeced ndim=4, found ndim=5",1
"Convolutional multiple filters and with Word Embedding followed by LSTM: ValueError: Input 0 is incompatible with layer lstm_13: expected ndim=3, found ndim=2",1
"LSTM keras - Value error Input 0 is incompatible with layer lstm_33: expected ndim=3, found ndim=4",1
"ValueError: Input 0 is incompatible with layer bidirectional_1: expected ndim=5, found ndim=4",1
"ValueError: Input 0 is incompatible with layer permute_1: expected ndim=3, found ndim=4",1
"Input 0 is incompatible with layer k_max_pooling_12: expected ndim=3, found ndim=2",1
"ValueError: Input 0 of layer conformer_encoder_subsampling_1 is incompatible with the layer: : expected min_ndim=4, found ndim=3. Full shape received: (None, 8000, 1)",1
"ValueError: Input 0 of layer sequential is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (57, 1)",1
"Input 0 of layer denseC1 is incompatible with the layer: : expected min_ndim=2, found ndim=1.",1
"ValueError: Input 0 of layer lstm_112 is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: (1, 72, 110907, 200)",1
Input 'ref' passed int32 expected ref type while building NodeDef,1
"Inputting Wrong Shape Within LSTM Model -- Expects 3 dimensions, only recieving 2",1
inter_op_parallelism_threads should also respect OMP_NUM_THREADS,1
io_utils.HDF5Matrix seems broken for three dimensional inputs.,1
it seems to be wrong progbar when verbose = 1 in the model.fit function,1
It seems we can speed up skipgrams?,1
'join' merge mode seems broken,1
Keras 2 is probably incompatible with some CPU & Out of Memory,1
Keras 2.1.4: Possible performance regression in ImageDataGenerator,1
Keras callback for Tensorboard seems to write duplicate parts of the graph,1
keras callbacks does not seem to work by import,1
Keras clip_norm could have potential Nan when doing gradient clipping.,1
Only expected following keys: ['dense_1'],1
Keras load LSTM/GRU model with constant mask/initial_state will raise error,1
keras metrics will not accept complex data,1
Keras models do not seem to be thread safe.,1
Keras Progbar Logger is not working as expected,1
Keras requires placeholders that it shouldn't for hybrid models,1
keras should make sure outputs for cost function are sane,1
"Keras TF ImageNet Preprocessing contradicts TF, may affect pretrained weights",1
Keras weights and architecture dont seem to match,1
keras.preprocessing.image.load_img should support byte objects,1
"keras.utils.get_file(..., extract=True) will extract original file every time it is called.",1
"Keras: error training parallel CNN's model (ValueError: Layer model_1 expects 10 inputs, but it received 1 input tensors. Input received: [<tf.Tensor 'model_1_input:0' shape=(?, 30, 125, 1) dtype=float32>])",1
Keras: ValueError: operands could not be broadcast together with shapes,1
Legacy merge may have a problem in `compute_output_shape`,1
Likely bug in Theano breaks Keras,1
load_model() couldn't work on multipe same Custom layers,1
LocallyConnected2D should raise error with negative strides,1
Looks like incorrect order of arguments for binary_crossentropy loss,1
looks like initial_epoch in model.fit not working for model's optimizer,1
loss could't converge in my custom model,1
Loss display maybe wrong for full batch,1
loss functions should infer dtype from predictions,1
"LSTM accuracy always 1.000, and the output is not as expected",1
LSTM layer producing seemingly incorrect output shape,1
Mask propagation in TimeDistributed doesn't seem to work after Embedding,1
Masking behavior of concatenation should be documented,1
Masking not working - Keras lstm model.predict seems to padd random values at the wrong timesteps,1
master branch seems not compatible,1
maybe a bug in " keras/backend/theano_backend.py: line 507 in function squeeze"??,1
maybe a bug in run multiprocess environment,1
Maybe Something wrong with the validation loss evaluation in keras,1
mnist_cnn.py and other examples failing taking longer than expected,1
mnist_cnn.py: couldn't reach 99.25% test accuracy,1
MobilenetV3 hard_sigmoid could be reimplemented using only keras.layers.,1
Model fit_generator not pulling data samples as expected,1
"Model with BatchNormalization trained with Keras 1.0.5, produces unexpected output with newer Keras versions",1
Model won't compile in Keras 0.3.0,1
Model.build(input_shape) throws the error "A merge layer should be called on a list of inputs" even though a list is provided,1
model.evaluate_generator may give wrong results when using multiprocessing.,1
Model.fit may cause an error,1
"Model.fit(..., **kwargs) unexpected behaviour",1
Model.fit(verbose=0) should print nothing at all,1
model.predict method should return numpy.ndarray but return list if input data is of length 0,1
model.predict() expect different input after loading from .h5,1
model.test_on_batch metric looks wrong after calling model.evaluate,1
Models in `tf.keras.applications` should have provision for custom naming,1
modprobe: ERROR: could not insert 'nvidia_361_uvm': Invalid argument,1
multi_gpu_model seems not to work,1
"Multiple inputs, multiple outputs passing through a dense layer, training is not as expected",1
"no keras history of tensor, and impossible to make it a Input",1
Non-trainable layer weights do not get built for Convolution2D (and possibly others),1
not expected images from autoencoder with sparsity constraint,1
"Numpy np.load(path) should be updated to np.load(path, allow_pickle) in keras/datasets/",1
"numpy.ndarray size changed, may indicate binary incompatibility",1
on_epoch_end won't be called on validation_data as Sequence instance,1
"ValueError: Output of generator should be a tuple `(x, y, sample_weight)` or `(x, y)`.",1
Output of generator should be a tuple.,1
"ValueError: output of generator should be a tuple (x, y, sample_weight) or (x, y).",1
plot_model's expand_nested looks wonky for model with multiple time-distributed layers,1
Possible bug in `self._collected_trainable_weights` with effects on GAN training,1
Possible bug in Conv + BN,1
Possible bug in metrics?,1
Possible bug in latest dev Theano install with nvidia driver 378.13,1
Possible bug in LSTM __call__ initial_state parameter,1
Possible bug in sign function,1
Possible bug in Autoencoder class,1
Possible bugs in sample_weight in model.fit() for RNN,1
Possible bug with Sequence+fit_generator on multi_gpu_model (reproducible),1
Possible bug with tensor outputs,1
"Possible bug, that using pretrained ResNet50 results in contradictory losses in training and validation set?",1
Possible bug in the pretrained_word_embeddings.py example?,1
Huge differences in prediction between versions of Keras (1.2.2 & 2.0.4) - Possible bug?,1
Possible bug in BatchNorm layer causing non-reproducible validation losses with LR=0,1
Possible bug with shared batch normalization + sequential model? [Script inside],1
Possible circular import problem,1
Possible error in formatting for Model Progress Bar,1
possible improvement in model saving,1
Possible inefficiencies in Tensorflow backend on gpu,1
Possible issue with metrics val_weighted_categorical_accuracy.,1
Possible issue in validation binary_crossentropy loss for unbalanced datasets,1
Possible Memory Leak,1
Possible problem with flow in image.py,1
Possible superfluous weight initialization Convolution2D (and potentially other layers),1
Possible theano bug when using time distributed layers (Windows),1
"Potential Batch Normailzation Bug - crashing on mode 0, not on mode 2",1
Potential Bug in detecting input shape by Conv2D,1
Potential Bug in K.squeeze for Theano?,1
predict_generator may shuffle batches if used with workers != 1,1
predict_generator: unexpected keyword argument 'verbose',1
PReLU should be channelwise,1
preprocessing utils would greatly benefit from sklearn,1
Pretrained embedding example should use UNK token for unknown tokens,1
"Procedure entry point, ucrtbase.terminate could not be located in api-ms-win-crt-runtime-l1-1-0.dll",1
Recurrent layer not accepting multiple inputs list despite source code seemingly handling such case,1
ReduceLROnPlateau Callback behaves unexpectedly when cooldown == 0,1
RemoteMonitor should send the payload with content-type application/json,1
"ResNet50 from tf.keras will not fine-tune, but the one from base keras will",1
RMSProp looks wrong,1
RNN seems to be broken on Theano after commit 08014eea360fd8d66b7baab19cdb9335f52c167b,1
Sampler function seems "indecisive" in lstm_text_generation example,1
Samples should have the option to be weighed for calculation of metrics,1
samplewise normalization should be done before featurewise and ZCA,1
save/load some specific models with bfloat datatype will lead to a crash,1
seeded data generators should return to original random state,1
Seemingly a small error in documentation,1
seems to be a bug when using merge layer,1
self.oov_token will be lost while in serializing(pickle.dumps),1
seq2seq output not as expected,1
"SequencialModel() will deal with the batch-left data, however, the GraphModel() does not?",1
setdiff1d (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2018-11-30,1
Silent swallowing of Exceptions thrown in `get_config` and potentially `from_config` / Documentation of SavedModel for custom Model,1
"SimpleRNN - Wrong number of dimensions, expected 3, got 2 with shape (119,80)",1
"skipgram seed parameter got removed in a documentation patch, seed parameter should be readded",1
skipgrams should exclude true positive context word from being sampled as negative sample,1
sklearn r2_score should work as a custom metric,1
"This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.",1
"Travis CI: ""No output has been received in the last 10m0s, this potentially indicates a stalled build or something wrong with the build itself.""",1
sparse_categorical_crossentropy implementation should use crossentropy_categorical_1hot,1
sparse_categorical_crossentropy doesn't seem to be working,1
"Specify 'use_bias=True' explicitly, the model get convergence; but use default settings couldn't",1
standardize_input_data unexpected behaviour,1
state_updates should behave like updates,1
Suggesting keras.utils.*_utils packages should not be part of the official API,1
TensorBoard histograms should use names of layers,1
Tensorboard won't work,1
"Tensorflow only: TypeError: Expected int32, got list containing Tensors of type '_Message' instead.",1
tensor'name will be renamed when output layer with activation,1
texts_to_sequences() got an unexpected keyword argument 'text',1
tf.keras.layers.Conv2D seems to accept 0 as the value of filters by mistake.,1
tf.keras.utils.split_dataset does not seem to work,1
tf.split in Lambda layer not working as expected,1
The "cos" merge mode when using tf as backend cann't get the expect result,1
the decay may not work correct,1
"the doc of  'constraints 'maybe wrong , need confirmmtion or make clear!",1
The documentation might not explain how to completely build Keras,1
the embedding function in the Tensorborad callback seems visualized the weight instead of the output,1
The estimator KerasClassifier should be a classifier.,1
The estimator Sequential should be a classifier.,1
The network takes a lot more disk space than expected,1
The output of K.dropout is not as expected!,1
The test method of model will drain memory easily and result in errors,1
The Theano backend should not clip output values by default for the binary_crossentropy function.,1
The training losses are as expected.,1
The generated images are also as expected but evaluation of the discriminator shows improbable results for GAN loss as well as auxilliary losses.,1
The weights file will not be closed after called load_weights function.,1
Theano backend will not work on AWS Ubuntu:14.04,1
theano.sandbox.cuda deprecated and will be removed,1
There may be more than one inconsistent implementations in `ConvLSTM2D` across the 3 backends.,1
There may be a bug in keras/keras/layers/merge.py,1
There seems to be a difference between models trained with fit() and fit_generator(),1
There should be a way to extend the usage of IMDB example,1
This loss expects targets to have the same shape as the output.,1
"This may be a basic question, but what is the recommended way to use Keras when I need to do some modifications to it?",1
Thread-safe utils.Sequence generator is considered not thread-safe by Keras,1
ThresholdedReLU(theta=None) will return different results using different backends.,1
Timedistributed doesn't work as expected,1
"TimeDistributed keras ""ValueError: strides should be of length 1, 1 or 3 but was 2""",1
to_graph and plot should show the shape of the expected input and output,1
train_on_batch outputs look wrong,1
trainable attribute seems to be broken in keras 1,1
TypeError: call() got an unexpected keyword argument 'outputs',1
TypeError: fit() got an unexpected keyword argument 'max_q_size',1
TypeError: softmax() got an unexpected keyword argument 'axis',1
'TypeError: compile() got an unexpected keyword argument 'loss' ',1
fit_generator error  TypeError: <lambda>() got an unexpected keyword argument 'count_mode',1
TypeError: moments() got an unexpected keyword argument 'shift',1
TypeError: fit() got an unexpected keyword argument 'show_accuracy' ---- Graph().fit,1
TypeError: load_weights() got an unexpected keyword argument 'by_name',1
TypeError: fit() got an unexpected keyword argument 'nb_epoch',1
TypeError: clone_model() got an unexpected keyword argument 'clone_function',1
TypeError: fit_generator() got an unexpected keyword argument 'shuffle',1
TypeError: load_weights() got an unexpected keyword argument 'exclude',1
TypeError: predict() got an unexpected keyword argument 'callbacks',1
TypeError: fit() unexpected keyword argument 'show_accuracy,1
TypeError: Parameter to MergeFrom() must be instance of same class: expected tensorflow.TensorShapeProto got tensorflow.TensorShapeProto.,1
TypeError: ufunc 'true_divide' output (typecode 'd') could not be coerced to provided output parameter (typecode 'B') according to the casting rule ''same_kind'',1
unexpected behavior with Lambda layer,1
unexpected Behavior when using model.train_on_batch and model.test_on_batch,1
Unexpected behaviour with steps_per_epoch leads to Out of Memory when using Sequence with workers>0 in fit_generator,1
Unexpected breaking change: Optimizer.get_weights() removed,1
Validation loss unexpectedly low,1
ValueError: Unexpectedly found an instance of type `<class 'keras.layers.merge.Concatenate'>`.,1
Loading weights as a plain text results in an unexpected output when model.fit is not called,1
Unexpected Loss values during training with high learning rate,1
Unexpected error when setting loss_weights for multi-output model,1
Unexpected output shape for Dot layer and K.batch_dot with TensorFlow backend,1
Unexpected result from BinaryCrossEntropy loss calculation in keras fit/evaluate,1
[Severe] Unexpected keras Convolution2D shape?,1
Adagrad: TypeError: Unexpected keyword argument passed to optimizer: weight_decay,1
Unexpected keyword argument 'expand_nested',1
Unexpected value for losses when using sample weights and generators,1
merge_mode="concat" behaving unexpectedly? (with the GPU backend),1
Unexpected variance when using batchnorm,1
unexpected initialization of tensorflow variables in `Model.save()`,1
Unexpected keyword argument 'ragged' in Keras,1
UpSampling2D Error: interpolation should be one of "nearest" or "bilinear".,1
UpSampling3D layer seems to tile instead of doing nearest neighbor upsampling,1
Using "kernel" for weight matrix in Dense layer seems confusing,1
Using dynamic=True in a keras Metric constructor should run the metric methods in eager mode,1
utils.to_categorical should output a matrix even if input is single element,1
val_acc seems to be unpredictable,1
Validation sample_weights in Graph seems to be same as the target,1
ValueError: `x` (images tensor) and `y` (labels) should have the same length.,1
ValueError: A `Concatenate` layer should be called on a list of at least 2 inputs,1
"ValueError: Arguments and signature arguments do not match. got: 13, expected: 14",1
ValueError: Could not interpret optimizer identifier: <rl.util.AdditionalUpdatesOptimizer object at 0x0000026DBDBD5748>,1
ValueError: Dimension 3 in Rebroadcast's input was supposed to be 1,1
ValueError: Expecting object: line 1 column 26 (char 25),1
"ValueError: generator yielded an element of shape () where an element of shape (None, None) was expected.",1
"ValueError: In a stateful network, you should only pass inputs with a number of samples...",1
"ValueError: Input 0 is incompatible with layer conv2d_14: expected ndim=4, found ndim=2",1
ValueError: It seems that you are using the Keras 2 and you are passing both `kernel_size` and `strides` as integer positional arguments.,1
"ValueError: Layer model expects 1 input(s), but it received 2 input tensors.",1
"ValueError: Operands could not be broadcast together with shapes (56, 56, 32) (112, 112, 32)",1
"Layers should either be supported by the PruneRegistry (built-in keras layers) or should be a `PrunableLayer` instance, or should has a customer defined `get_prunable_weights` method.",1
All layer names should be unique.,1
ValueError: x (images tensor) and y (labels) should have the same length.,1
Vanilla Theano replication of a Keras model does not match as expected,1
Verbose logging should go to STDERR,1
"""WARNING:tensorflow:Variable += will be deprecated""",1
We should more effectively document *what* the issues with (de)serializing Lambda layers are,1
"When I set `padding= same` in MaxPooling2D/AveragePooling2D, different parameter configurations will trigger inconsistent results on different backends, especially coping with diffrent `strides` values.",1
"When I use SeparableConv2D(padding =same) and change the 'kernel_size' and 'strides', the different backends may return different output, theano even can return a different shape output",1
"When using pycharm with remote run, the progress bar won't refresh in place.",1
Wrong input variable used( it seems),1
"First, we doesn't make the exception message include `allow_sharing`.
i.e.  the below changes will not be included:

``` diff
                     raise Exception('You are attempting to share a '
                                     'same `BatchNormalization` layer across '
                                     'different data flows. '
                                     'This is not possible. '
-                                    'You should use `mode=2` in '
+                                    'You should use `mode=2` or `allow_sharing=True` in '
                                     '`BatchNormalization`, which has '
                                     'a similar behavior but is shareable '
                                     '(see docs for a description of '
```",1
*   It's possible we don't have your GitHub username or you're using a different email address on your commit.,1
- I could make some time to look into this again.,1
- I'd vote for tackling this in a separate PR because it might need more discussion/clarification.,1
Not quite sure what you mean by "a detailed example would be advisable" and your second point.,1
I'd vote for tackling this in a separate PR because it might need more discussion/clarification.,1
This [blog post](https://www.google.com/search?q=embeddings+tensorboard&client=firefox-b-1-ab&ei=xv93WtrzL4ud5wKA7J-QCA&start=10&sa=N&biw=1272&bih=886) seems like it might provide example code and a numpy [save_embeddings()](https://github.com/nlml/np-to-tf-embeddings-visualiser/blob/master/save_embeddings.py) which can work for multiple inputs.,1
"None, as far as I know.",1
"As described in the API Design Review, I've had some trouble with this, and could use some guidance.",1
It adds a new possible value `'element'` to the option `sample_weight_mode` in `model.compile()`.,1
"- `avg` means that global average pooling
                will be applied to the output of the
                last convolutional layer, and thus
                the output of the model will be a
                2D tensor.",1
"- `max` means that global max pooling will
                be applied.",1
- New arguments should be appended at the end of a signature (unless in cases where this would be semantically inconsistent) to avoid breaking people who use positional arguments.,1
"- `baseline=None` is a better default value in this case, since metrics may be negative and 0 may be a valid metric value.",1
"I don't think we should merge this change, because:",1
"- It special-cases `Dense`, but many other kinds of layers may have activation functions, including custom layers.",1
I believe the most important information for debugging is the input/output shape.,1
- `Dense(activation)` seems like a weird notation.,1
- it doesn't seem to me that any checks are made to prevent users from calling `set_previous` with `reset_weights=False` on an incompatible previous layer.,1
"- `None` means that the output of the model
                will be the 4D tensor output of the
                last convolutional layer.",1
"- `prev` is the string that internally maps to the layer that current layer should be connected to, also internally mapped to a layer number.",1
"- If `initial_states` is a list of tensors, it will not have the attribute `_keras_history`, and will be treated as a numerical value.",1
"- If `initial_states` is passed as a keyword argument to `call`, it will be ignored / overwritten.",1
- `state_spec` may not be defined by the time it is used (`state_spec` is defined in `build`).,1
"It a user wants to specify the state numerically, they should pass a numpy array to `reset_states`.",1
- The layer will be build in `__call__` before using `state_spec`.,1
"I think this may be a useful feature, but the proposed API is too ad-hoc.",1
"- A class, when specified by the user, should be an integer, not a binary Numpy array",1
- It should be possible to yield either integer labels or categorical binary labels,1
Additionally the fact that the current iterator relies on directory structure to infer classes may make it fundamentally incompatible with multi labeling.,1
"Maybe what we need is a different generator, with a more appropriate API for this use case, not an extension of the current generator.",1
I will adjust it.,1
"But if you think it's more helpful to separate both approaches, I will change the code accordingly.",1
"- Previously, these would cause a slice of `[n : -0]` which is valid, but returns 0 items",1
"I don't think we should make this change to the API, because:",1
- A user could just subclass `EarlyStopping` to achieve the same functionality without too much trouble.,1
"Maybe we should consider refactoring `EarlyStopping` to improve the UX of adding such functionality (via subclassing), without changing the API?",1
For instance we could modularize into a private function the logic that gets the reference monitor value...,1
- Make it possible to pass additional arguments to `Lambda` and `LambdaMerege` layers.,1
"- The `Lambda` layer inherits from `Layer`, so it could be used anywhere a `Dense` layer is used.",1
"In a `Graph`, similar functionality could be obtained by first merging using `join` mode, and then a `Lambda` layer, just like any other layer you would add to a `Graph` after `join` merge.",1
- Support for automatic generation of class methods: the classes marked as "classes_with_methods" in the autogen.py file will now have all their methods (obviously not the private or the excluded ones) fully documented,1
- The documented class methods will have a "method" prepended to their name: this helps distinguish between a method and a module function .,1
- All the classes will have a "class" prepended to their name. This names are added using JS and so they will not pollute the menu bar.,1
"- Enable shared `Embedding` layer (impossible before, because of `int32` vs `floatX` issues)",1
"- Allows layers to add losses, much like a layer would add updates.",1
**Custom regularizers may no longer work.**,1
**Custom layers may see their regularizers disabled (if they were using regularizers).**,1
"We raise appropriate warnings, so these issues should be noticed by the target users.",1
"Additionally, no code would be crashing as a result of these changes.",1
"Of course a Keras `one_hot` op should be able to generally one-hot encode `nD` integer tensors into `(n+1)D` float tensors, much like `tf.one_hot`.",1
"anyway, we should not have ops that have inconsistent behavior between backends.",1
"- As-is: Two `dimshuffle`'s are redundantly performed, which may result in performance degradation.",1
"- multipliers should be handled on a per-layer basis, not on a per-weight basis, and should be abstracted into the `Layer` class.",1
"That will minimize the amount of changes to the codebase (you only need to add support in one place, not in every layer).",1
"- at the optimizer level, it should be handled like we handle constraints.",1
"That is to say, multipliers should be a dictionary mapping weights to coefficients.",1
"- Both the methods and the functions would be listed in the side menu, without a clear way to distinguish them (this does not happened in the old doc)",1
- We could prepend the class name to the methods but then they could be confused with static methods.,1
"- We should enforce a particular order: first the class description, then its methods and then the functions.",1
This could be obtained by sorting all the functions appropriately but I find it pretty error-prone.,1
"Yes, you could probably obtain this effect by playing with the ""all_module_functions"" and ""function"" parts...",1
A possible solution would be to avoid pages mixing methods and functions.,1
"In addition, a good edit of my code would be to allow the filtering of class methods.",1
- Change should be tested (in `backend_tests`),1
- now it should also work with text and multinomial time-series,1
"I think your approach is very good, but you are overcomplicating it.",1
- Code using the old interface should work.,1
- Code using the new interface should also work.,1
"In that case, we should forbid the use of positional arguments (beyond those that share the same order).",1
"- Con: But there's a chance that this may change, although a new activation that works across multiple outputs seems unlikely.",1
- Softmax is currently the only activation that I know of that won't support tesnor3 (it's actually the reason for this patch).,1
"- **Con**: I believe, in the Theano documentation, that it states that the way that tensor3 should be read is: (batch, time, value).",1
"I may be wrong on this, I will look for a reference.",1
"If this is the case, we should probably follow this.",1
- EDIT: "Rows are horizontal and columns are vertical. Every row is an example." -> the additional dimension (dimension 0) would therefore be sets of examples (i.e. batches). From http://deeplearning.net/software/theano/tutorial/numpy.html,1
"To allow this, I think we'd need to be able to reference the input shape, and somehow create a process through which the user can reference this input shape.",1
"This may be a _**big**_ problem on the last batch, where the actual number of samples != batch_size.",1
- Counts should be integers.,1
This should be *much* simpler,1
"- The way true positives are computed looks weird to me, it would only work in a special case.",1
"Any way you could break this down into key features submitted into separate PRs, such as:
- merge / fork (merge was already a layer, btw).
- dimensionality inference
- Caffe models compatibility",1
Such a massive PR will be quite difficult to review and eventually merge.,1
Unbundling it will be the only practical way to move forward with these features.,1
This PR looks Dropout to me.,1
"- Efficiency: we already have a very efficient way to save weights (HDF5), whereas dumping them to yaml would be quite inefficient both time-wise and space-wise.",1
"- examples are supposed to be 100% standalone scripts, they are not expected to follow any specific conventions.",1
- such tests would take up way more time and computational resources than necessary.,1
It's supposed to be integration tests for all common use cases of Keras.,1
"The right way to expand example testing / integration testing would thus be do add new tests in `test_tasks.py` (which could also be refactored), covering new architectures, and running in very little time on synthetic data.",1
- I think that it would be better to wrap the building of the `u` tensor into the `DenseAnnotationAttention` layer.,1
"Perhaps you could call the existing class `DenseAnnotationAttentionCell` and then make a new class called just `DenseAnnotationAttention` where in the call function you build the u tensor and then return `RNN(cell=cell, return_sequences=True)`.",1
Maybe `BahdanauAttention` or `AdditiveAttension` would be clearer and match how the mechanism is talked about in the literature.,1
"- Finally, I think it's really important to be able to output the attention weights somehow because often these are used to use as a kind of soft alignment (and these are often visualized in papers).",1
"Again, I'm very impressed by this and it would be great to see this part of Keras proper in the near future!",1
"- For the sake of completeness classes such as the `layers`, and `optimizers` have the `get_config` method, thus I think that it will be useful to add this method to callback objects.",1
"f'Received input shape {input_shape} which would produce'
                       f'output shape with a zero or negative value in a' 
                       f' dimension.",1
here is an aside: both dropout and batchnorm should be kept the same throughout the entire run.,1
Maybe in the future we should look into the way we write RNNs in Keras to support dropout and batchnorm callbacks in a generalized way.,1
This will make it easy to support more complicated and custom RNN types (like neural-gpu and conv-rnns) without having to rewrite them.,1
"Learnable constraints at each layer would indeed be interesting, I'll have to think more about that.",1
- I agree that constraints and regularizers should be classes or in a module.,1
"- I actually think its a good idea to have different terms for different parameter types, but I agree the interface is currently clunky.",1
"The reason I think its best to keep them separate, is that you may for instance want sparse weights for filters, but it wouldn't make sense to have sparse biases.",1
"And in other layer types (that I'm currently working on), different parameters may be even more different in function than weights and biases and need to be constrained differently.",1
I'll submit a new PR with the changes tomorrow.,1
"I am coming from a reactive programming background and therefore think using `rx` would be a good choice, design-wise.",1
- it may be confusing / complex to have different APIs to do similar things.,1
I think the API it introduces is potentially valuable.,1
We should have _one good way_ to do each thing.,1
"- I am not a fan of the implementation, it seems to introduce quite a few hacks.",1
"- Initializations can potentially be used anywhere, on any input shape, so should not be dependent on the number of dimensions of the input.",1
"- I believe the scheme proposed by He is sqrt(2/n_l) where n_l is the number of elements in the layer (n_l = k_k_c, with k*k the dimensions of the 2D input and c the number of channels).",1
"Could you:
- rebase so that only changes related to the PR appear in the PR (instead of, currently, 46 different files)
- rename these two activations to more explicit names
- remove the example, as I don't think it's adding much",1
"I am glad that you figured out how to implement what you wanted to implement, but I don't think it belongs in master.",1
It should probably be ready to merge now.,1
"The main change that I think is missing is to fix scipy's sparse matrix **len** support so that we don't randomly blow up when using sparse matrixes in places I haven't patched up, but I don't think that needs to be a blocker to this getting merged.",1
"I don't think it is a good idea to convert by default switch to ifelse for
Theano.",1
"Thus I don't think it should be included here, that's not the purpose of the page.",1
It should be kept short.,1
"Yes, I think you're right.",1
I don't think this has been updated when we switched to Sequence.,1
I'll take a look.,1
So I don't think the recent failures are linked to any change on our end (at least not in isolation).,1
"However, I don't think we should do something like this.",1
- Implementation details should not be part of the public API,1
I don't think I'll make the PR in the Tensorflow repo because of lack of time.,1
I'll let someone else do it if you don't mind.,1
"As a result, I don't think we should merge this PR since it would make the backend API redundant.",1
I don't think this PR is a good fit to implement attention models at this point.,1
I believe the `Model` subclassing API would make this use case far easier.,1
"We should come up with side by side code examples of similar models to figure out whether that is the case (the code doesn't have to work, it would just show the workflow with each API, the API in this PR and the model subclassing API).",1
"I don't think this substitution contributes to the codebase; it is not meaningfully simpler or meaningfully shorter, and it makes the code less immediately readable by adding a layer of indirection.",1
"The original code is 100% explicit and can be read effortlessly, but the proposed replacement presupposes some prior knowledge about the utility function in order to be readable, and even so it takes more mental effort to parse the arguments and figure out what the output is going to be.",1
It seems that `tests/test_multiprocessing.py::test_multiprocessing_predict_error` is failing.,1
I don't think it's related to this PR.,1
I don't think the build errors are related to this PR but I'm happy to make any changes necessary if they are.,1
"2. > No output has been received in the last 10m0s, this potentially indicates a stalled build or something wrong with the build itself. [build.log#L2707-L2708](https://travis-ci.org/keras-team/keras/jobs/452492103#L2707-L2708)",1
"Since this is already specified in the docs, I don't think we need a specific warning.",1
I'll close and let your newest open.,1
I don't think this should be merged into Keras.,1
"I don't think it adds much to the example, whose main purpose is to demonstrate how to write simple custom layers.",1
We won't merge it.,1
I don't think it's related to your PR.,1
This should fix the timeout.,1
I don't think this is relevant in this context because:,1
"- pydot offers no other option but to save the image we create, so we'll always save the image.",1
It wouldn't make sense to have both `to_file="img.png"` and `save=False` at the same time.,1
"- returning a Jupyter Image object is not necessarily for showing the image (show=True), you might want to get the Image object and post-process it (a common thing would be to resize it).",1
In any case returning the Image object whenever possible (when Jupyter is installed) always seems like a good idea.,1
"I don't think we should do this, since it isn't much of a simplification.",1
I'm thinking that we should seriously conder the pros and cons of using tf.keras.backend.,1
The savings would be huge.,1
"I get the points that you are making for keeping tentorflow_backend.py, but I don't think they outweights the benefits of using tf.keras.",1
I think this is a useful example and we can include it.,1
"However, it seems quite long.",1
I don't think it is reasonable to think that this will be added to the core API in the near future (it can always be found in history of this PR).,1
I don't think `target_format` needs to be passed explicitly since the name of the variable passed is always `data_format` or something really similar.,1
I think it's already understandable that `data_format` is the target format.,1
If you still think that this should be called with `target_format=...` just tell me and I'll change it.,1
"I think both are making sense, the only potential concern being that `Model.compile()` already has a long list of arguments.",1
"That said, I don't think we should block this PR on the additional discussions, so I would open a new PR to continue the discussions there and see people's opinions.",1
"However, it is certainly inoptimal to have the layer output the full probability distribution if you're simply evaluating it (i.e. you have the correct label) -- I don't think layers can have separate behaviors for train, test, and evaluation, though.",1
"On the subject, I don't think it's reasonable to copy a complex ~100LOC test just to cover tensor inputs, but feel free to do that if you think it's the better approach.",1
I think you could open a separate issue regarding this problem.,1
I don't think a closed PR will attract the needed attention.,1
If it is a minor change I see no harm in also fixing keras.applicatins - as long as it doesn't change the API (but I don't think it does),1
"@lukeyeager Huh, I don't think #5049 would fix #4392 at all, do you think there is anything they have to do with each other?",1
I don't think our masking is working 100% as expected.,1
"Maybe, an option in the example would be a good idea. but it's probably not worth it.",1
I don't think it is worth it to put as an option.,1
Will merge once the tests are complete.,1
I don't think that's possible.,1
"Btw I don't think the cosine is a good example, even with the 2-point averaging.",1
"Feel free to replace this example script with something new entirely, that would do a better job at demonstrating stateful RNNs.",1
I don't think its related to my changes..,1
Maybe we'd need to refactor it to share code with the support for accuracy (and keep the codebase simpler).,1
But I don't think we should include either.,1
"I don't think it ever makes sense to freeze those 2 _trainable_ parameters, while updating the 2 _non-trainable_ parameters.",1
This approach should properly be called "Breaking Deep Network Training by Introducing Uncorrectable Internal Covariate Shift".,1
"I think those _non-trainable_ weights should always be frozen as well, and renamed _trainable_when they aren't frozen.",1
"This issue does not affect this PR (which has BN only on the Generator, which is never frozen), but may be the reason why my attempts to put BN into the Discriminator broke things very badly.",1
"The following workaround https://github.com/fchollet/keras/issues/4762#issuecomment-321299663 seems to be working for the GAN use case, and I'll try it, but not for a while.",1
I don't think it's a good way.,1
"In fact I don't think there is a use case where one would want to shuffle the training set, but not the validation set - which is what keras does by default (`shuffle=True` by default).",1
"I don't think that's it, the tests feed in variables anyway",1
I don't think anything is out of date.,1
I do think the problem is that my `datagen.flow` is not a `Sequence`.,1
"I think there seems to be good ideas in the PR, but it requires more work in terms of code quality.",1
I don't think it makes sense to have it as part of Sequential (since it isn't sequential at all).,1
I also think it is implementable completely independently of the layers.,1
We won't merge the changes in their current state.,1
"I tried to make it only non-breaking additions that won't change how any existing code functions, but let me know what could be better.",1
"Also I don't think its really that niche, any use of parameterized nonlinearities applied to convolutional feature maps are subject to the original issue https://github.com/fchollet/keras/issues/3568 which is kind of a big deal I thought.",1
The contribution repo is being discussed pretty thoroughly in [this issue](https://github.com/fchollet/keras/issues/4944); I don't think it is available as of yet.,1
"It's nice, but I don't think there are any serious benefits over Keras code itself.",1
I don't think copybara can handle this because the root directory is not synced.,1
"Therefore, this PR should not be synced but only stays in the GitHub repo.",1
@bstriner I always think of Sonar as a Java tool but you are right.,1
It looks like it uses Pylint for code analysis mostly.,1
I think running Pylint across the code will give a good idea what will be picked up.,1
@fchollet Travis integration looks relatively simple.,1
I don't think this would be much effort to set up.,1
I don't think it consume some time.,1
"Just a heads-up: I think this is a great PR, but we are going to post-pone adding this feature a bit, because variable naming is going to interact significantly with our upcoming goal of abstracting the Keras backend away from Theano.",1
"Specifically, I don't think initialization functions should handle the naming.",1
I don't think making Seq2Seq models easy is going to be a single PR.,1
"I think some Keras examples just concatenate or replicate the inputs, which isn't ideal, especially if they might be different dtypes.",1
"- naming such as `LrSetter` should be avoided, because out of context it isn't clear what `lr` means (the `callbacks` module is not directly related to optimizers...).",1
Prefer `LearningRateScheduler` or similar.,1
"- I don't think learning rate scheduling should happen via a dictionary, instead if should probably take a lambda or function as argument, that would map an epoch to a learning rate",1
- usage should be explicitly restricted to optimizers that do have learning rates.,1
- We'll apply your fix.,1
- I don't think the changes in `mnist_tfrecord.py` are necessary (this script only exists as an example of a specific use case).,1
"I think ""consume_less='gpu'"" is a decent name in that regard (you should interpret it as ""consume less GPU time"", not as ""lower GPU utilization"").",1
I would have called it `optimize_for='cpu'|'mem'|'gpu'` but breaking the API is bad.,1
- I mostly scaled up the embedding dimensionality to make the problem more demanding such that each epoch would take long enough so that elapsed time could be measured reliably with Python's own `time`.,1
"- Particularly batch normalization and high dropout in both the embedding and the LSTM seem to have made the model perform a bit bonkers on validation data (oscillating loss, despite fitting training data as usual) after a couple of epochs, but I figured it was neat to have examples that show off some of the cool builtin layers and features.",1
I think model size should scale pretty linearly in computational time and memory usage for the three modes.,1
Batch size seems important.,1
Intuitively the batch size would have to be large enough for the GEMMs to become the bottleneck and not the transferring of data between RAM and VRAM.,1
"Hm, I'll think about it.",1
- So probably they will be named as music_tagger_cnn(crnn) or music_cnn_tagger.,1
I'd go for _MODEL__music_autotagger where MODEL is your particular LSTM/CNN/RNN/whatever.,1
"- I think from a model standpoint, maxout does things very different than a normal layer (conv, fc, etc) -- I think that the separation also ensures that people (such as myself) who use `get_weights()` and then transfer them to other code / languages would benefit from the classes being as unambiguous as possible.",1
"- Perhaps in the long term something like `model.add(Maxout(Dense(128, 128), nb_feature=4))` would be useful, but I think this would actually lose a lot of key functionality.",1
"Though the third option is nice from a semantic standpoint, I'd actually argue for number 1.",1
"- As someone who does a lot of weight visualization, I think option 1 would ensure users know _exactly_ what layer topology they're looking at.",1
"I agree that it does add some redundancy, but I think having `MaxoutDense` and `MaxoutConvolution2D` as two seperate things wouldn't be a bad idea.",1
I'd merge the shape generalization change if it were in a separate PR.,1
Maybe TimeSharedDense would be better?,1
That's a bug (will crash if the layer is goes first in a model).,1
- I think the idea of a meta-layer that takes as parameter a layer and applies it to every timestep is interesting and should be given more thought.,1
This will be helpful since I have also local changes to `caffe` that I will commit later.,1
I will look into it in the near future.,1
Also I will still be looking for a simpler way to do this step: https://github.com/fchollet/keras/blob/8a31762d0703d704befbbfe4850079bc6223f027/keras/caffe/converters.py#L29-L38,1
"Ok, I will take a look.",1
"I will, in a day, commit new changes with all the modes.",1
Anyway I will  commit changes soon to the branch.,1
@evanfeinberg I will do changes as per your suggestions shortly.,1
It would be great if you could/point me to some open source 3D data that could be a good example for this PR.,1
I will wait for someone to implement conv3d for tensorflow.,1
I will look into it.,1
I will leave it open.,1
"@fchollet Yes, I will get to it later today.",1
I think there is some problem with my training.,1
I will try to upgrade Keras from 1.1.1 to 1.1.2 as well as Theano and see the result maybe.,1
"Sorry, I have some mistake, I will close this PR soon.",1
"I will send PR in today, since translation finished a few hour ago.",1
I will change the commit message.,1
I will keep investigating.,1
"[Slightly off topic note: I am experiencing problems running the tests locally on Python 3.6 , TensorFlow backend on Windows 10; I keep getting complaints from py.test that `-n` is not a valid argument and I can't seem to find the correlated part of the documentation. - I will keep investigating]",1
"Since my lab switched to Py3, I will maintain these set of patches on my own (at least for as long as I'll keep using keras).",1
- I wouldn't be so sure about everybody in the ML community still being stuck on 2.7.,1
"That's fine, but note that it should be able to process a batch of predictions, so the output would be a list of lists.",1
"- if the weights are not convertible to Theano, then mention about conversion should be removed.",1
- should be renamed to `output_dtype`,1
- user input should be validated and helpful error messages should be raised in case of invalid input.,1
"- if this does solve the issues mentioned, then a simple test should be added to check that.",1
"- dtypes being passed should be strings in `{float, int}`.",1
The type of float used in Keras is a global setting and the user is not expected to have to worry about it with every operation.,1
"- If you wish to stack more layers (sync or async) before merging, you could use the `get_siamese_heads` API instead.",1
"I do believe this is a great feature and I want this to be merged soon too, but I think there's still some work to be done here:",1
It also wouldn't hurt to squash your multiple commits into fewer ones with more meaningful messages.,1
"- I'm concerned that this callback might behave different based on the caller (`fit_generator` or `fit`) if `model.uses_learning_phase` is `True` (my comment above, which you haven't addressed yet).",1
"- In the current state we could do the correction of preprocessing in the model, before retraining.",1
- It looks cool : `model.add(Bidirectional(LSTM(20)))`,1
"- It should be broadly useful to Keras users, not a niche feature.",1
- It should be broadly recognized as a deep learning best practice.,1
"- It should be broadly useful to our users, rather than a niche feature.",1
- It should be widely recognized as a machine learning best practice.,1
"Niche features should be maintained independently by those who need them (e.g. by extending the API via subclassing), as third-party add-on packages.",1
"We will not add new layers/etc that were recently published to ArXiv.org, even in case of claims of increased accuracy/etc.",1
"Niche features should be maintained independently by those who need them (e.g. by extending the API via subclassing), as third-party Keras add-on packages.",1
- It should have an owner committed to maintaining it in the long term.,1
"Keras-contrib has less constraints and guarantees, and would be a better fit for this PR.",1
"In particular, the code should be maintainable by multiple people on the team, not just by one technical guru.",1
I think this PR is much too complicated compared to what it achieves.,1
Really it should only affect the `compute_mask` method of `Merge`.,1
I wouldn't expect it to require any auxiliary function and I wouldn't expect it to take more than ~20 or so lines.,1
- it should not be necessary to "normalize" mask dimensions,1
- it should not be necessary to modify output values based on masking,1
It should say any not an.,1
- I think best option is to add support for (non iterated over) constants in `RNN` as per the original solution in this PR: https://github.com/fchollet/keras/commit/28795f14ba734d0d97cf292e601d7ab00039f401,1
- It would be great with feedback from more contributors.,1
"@cgratie, I think the progress reporting of the metrics has been through a bit of a balancing act between feeling responsive enough and being precise enough, hence the batchwise aggregating.",1
"As far as I know it's impossible to calculate the F-score during training (especially considering dropout layers and stuff), and it will always be an approximation.",1
This is because it's impossible to reverse the channels in-place without creating an auxiliary variable that would again lead to a decrease in performance.,1
This seems inevitable.,1
I don't think it's a big issue.,1
"I tried ""fixing"" some but not all of them, but didn't get statistically significant improvements, doesn't mean it's impossible.",1
"The tests on Travis are reliably stalling, but it's impossible at this point to tell whether it's a Travis issue or an issue with the PR.",1
We'll know soon.,1
- It's impossible to run code without logging in.,1
"If an object is pickable, it's possible to send it to another Process.",1
I believe it's possible to check if the jobs are using the wrong cache by checking the url used in the log for upload and download.,1
"It's possible the shape argument is being misinterpreted as 'name', which would be a bug in your version of tensorflow that could result from shape having been made optional, but the argument order not having been preserved.",1
"It's possible that something changed in the Numpy install on Travis (or with the VM), which in turn changed the behavior of the Numpy RNG, which caused an accuracy test to fail.",1
"It looks like this may be your first contribution to a Google open source project (if not, look below for help).",1
"Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).",1
I would argue that the fact that these operations exist in TF on bool tensors is an indication that there is a desire to do this sort of thing.,1
But I mostly thought adding them would help people who are not used to expressing logic in this form see that it's possible and help with the trickier ones.,1
I'm using Celery and it forks processes on workers (it's possible to control this behavior though).,1
When the model are small enough it's possible to have multiple models running on the same GPU.,1
It would maybe break if multiprocessing is enabled by default.,1
Should we add it in the graph somewhere so it's possible to have backward compatibility when using the Tensorboard Callback with a `Graph` model?,1
It's possible to modify this after this PR is merged.,1
"It's possible to get unexpected interactions with pytest and your main
python interpreter depending on both your classpath/pythonpath, and any
installed packages you might have.",1
"- Just to be clear, we'll need to add the keyword arg to `AttentionRNN.__call__` as well, as we need to override parent `RNN.__call__` to add the attended inputs to `input_spec` before build.",1
- added `hlength` as a possible replacement for length,1
- Line 1289: gw0 seems to start the test_inceptionresnetv2_notop but it never finishes.,1
"- Longer input sequences (400 instead of 100), made possible from the speedup of the Max Over Time.",1
"It looks like my changes do not work with TensorFlow, but your might.",1
This should make it possible to train smaller networks (for n = 2 or n = 4) that are competitive with deepers resnets while better using the GPU and therefore training faster.,1
I was also thinking the flags could make it possible to store all cost updates in a single list at some point in the future.,1
"Adding an `compile` keyword argument will make it possible:
```python
new_model = load_model('my_model', compile=False)
```",1
"To support all corner cases, an attentive cell would have to _declare_ how many constants it expects (to make it possible for RNN to split inputs and know if it contains initial states as well) which is otherwise not needed.",1
The four non-batch evaluate and predict functions in `Model` would need a `callbacks` parameter.,1
The four functions to validate & predict for arrays & generators would need similar extra code:,1
- managing `callback_model` and probably equivalents to the `stop_training` property,1
`set_params` would need to be changed to merge rather than overwrite params .,1
"The fit functions could then pass the user-provided callbacks to these adjusted functions, so the default callbacks (`BaseLogger`, `ProgbarLogger` and `History`) keep working as they do now.",1
"Not related to this PR: reading through the code, I was thinking the name `evaluate_loop` would be clearer than `test_loop` in `training_arrays.py` so all function names would be analogous to those in `training_generator.py` and `Model`.",1
"- introducing layer-level arguments that only apply to one backend is problematic, and will be increasingly problematic going forward (as we add new backends).",1
"- On a similar note, the links shouldn't read ""Try it on MachineLab"", because it sounds like an ad.",1
"- On the order: the word_index now only contains the top N most common words, I believe there is no need somewhere to compute the frequency again (those are stored in word_counter).",1
"- One thought about the training / validation process: it would be better not to use a validation split (which is too small to be statistically significant anyway), instead use the test data as `validation_data`, use an `EarlyStopping` callback (with a reasonable patience value) to stop when loss stops improving on the test data, and record the _best_ accuracy on the test data.",1
This should lead to more reliable scores (closer to optimal) and the ability to really train until convergence.,1
"This PR will try to fix some pandas DataFrame related issues, including https://github.com/fchollet/keras/pull/8199 and https://github.com/fchollet/keras/pull/8290.",1
"- Pandas DataFrame check is moved, in order to make sure that keras will check `array`/`list`/`dict` first, then `numpy.ndarray`/`pandas.DataFrame`.",1
Things that I tried or it would be nice to try in the future:,1
This would speed up starting time and speed up dataset tests enormously.,1
It seems to be the best one on the market:),1
"These will be very useful features to have, cool stuff!",1
The PR is looking good to me.,1
"- Please add unit tests (a test that would have been failing with the previous implementation but would be passing now, as well as enough tests to have full coverage of the new code)",1
"- the changes do not work as expected, try running `tests/test_shape_inference.py`.",1
- separate parallelization code from fit (ideal seems keras.utils.io_utils.py),1
"- keras.model.{Sequential,Graph}.fit_generator shares lots of code, I would factor out all the closures.",1
"What do you think - I have this code written, and it would take only a while to modify it for keras, but I want to know, if you would want to merge it afterwards.",1
"You can submit a PR, I will look at it (maybe not right away).",1
This approach should be flexible enough to allow handling a GUI and/or callbacks.,1
"There should be at most 3 commits, and exactly 2 files modified.",1
Done: should be a lot cleaner now -,1
With a single-layer network any potential error (in the conversion or in the test code) should be immediately obvious.,1
Surely this should be addressed as a fix in Theano.,1
"1. Line 10 of `keras/utils/layer_utils.py` should be replaced with
   `from ..layers.convolutional import Convolution1D, Convolution2D, Convolution3D, MaxPooling1D, MaxPooling2D, MaxPooling3D, ZeroPadding2D`",1
"2. In method `get_config` for `Convolution3D`, the key `stack_size` is no longer required and should be removed.",1
"I am working on this too, and now I am testing the code, should be ready soon.",1
Now it should be fully functional with theano backend.,1
"For long sequences, scan should be used anyway.",1
Else the graph will be too big.,1
"I cannot get it to work this way, but I can't see why this approach should be problematic with the code.",1
"Also, my opinion is that `cos_dot` or something should be part of backend instead of reimplement it every time using `batch_dot`.",1
Running them once per PR should be enough.,1
First should be a unittest.,1
[This](https://github.com/farizrahman4u/keras/blob/c55894f8fce4ebea5fe8f386b2edc76d81cd922a/examples/mnist_acgan.py#L154) should be the only place where we set the `Model`-in-`Model` `.trainable` param.,1
"@fchollet @farizrahman4u yeah, these should definitely not be in there...",1
"My two cents: this seems like a bad idea, because it will break code (such as mine) that depends on `K.switch` being an elementwise operation, which it currently is on Theano.",1
"The TensorFlow documentation seems to say that `tf.select` also accept tensors the same size as the output, so it should be possible to do an elementwise operation with that.",1
"The TensorFlow documentation
> seems to say that tf.select also accept tensors the same size as the
> output, so it should be possible to do an elementwise operation with that.",1
So that's what we should be normalizing on.,1
"When condition is scalar, it's a if/else condition (the old interface); 
Otherwise condition should be the same shape with then/else expression, and a element-wise selection is preformed.",1
`classes` should be cleaner than `nb_classes`.,1
Inputs should be modified in place.,1
"In any case, there should be unit tests.",1
so should be fixed there too I guess?,1
A unit test should be added to evidence the issue (test that fails with master but pass with this PR).,1
Then maybe the heading should be changed from `Getting started: 30 seconds to Keras` to `Overview: 30 seconds to Keras`.,1
"Looks bit misleading if we say 'getting started', and it does not.",1
Maybe `Input` should be made into a layer eventually?,1
"I went for the simple `in` check, since for this very specialised application it should be OK to relax.",1
@fchollet should be good to go then.,1
**variables** should be a list of tensors of length 5 and there is one more kwarg.,1
It looks like the cntk_func_tensors() and KC.stack should be able to handle a list of tensors as input.,1
It's just something that we should be aware of.,1
"Perhaps -INF or
it should be clipped at some large magnitude.",1
Leaving the previous default logging system as is and implementing callbacks besides it should be fine (the user can setup their own logging system by setting `verbose=0` and developing a custom logger callback).,1
"As for the API I fully agree with you, having a key-value input in the callback would make things easier, cleaner and safer for the future (ideally I think there should be callbacks in `evaluate()` as well).",1
I think it makes it a better choice over predefined inputs.,1
It's pretty useful when building models involving for example Fourier transforms so I think there is a case for having the model infer the type of the input based on first call.,1
Or at least there should be a way to specify it.,1
It should be avoided in built-in applications.,1
There should be other ways to fix the issue you mention.,1
"@sebastian-sz 
I think all model [variants](https://github.com/keras-team/keras/pull/14935#discussion_r720018839) should be included.",1
"If you do `print(K.int_shape(weights))` and `print(K.int_shape(score_array))` before the reshape, the error should be obvious.",1
Though maybe this should be documented somewhere?,1
I did quite a lot of suppositions concerning what should be tested and what should not.,1
I think I understand better what you want.,1
Allow me to open a new PR which will be way simpler and closer (I think) to what you want.,1
These tests are inexpensive and should be kept around  in some form since these classes/functions are still part of the API.,1
TF optimizers should be used with `TFOptimizer`.,1
This part of the docs says that the cache should be different for each job in our case: https://docs.travis-ci.com/user/caching#caches-and-build-matrices,1
@Dref360 Should be good to go.,1
"For anyone who has read the paper, the meaning of `phi` should be totally clear, so that it in fact is a nice way of parameterizing our EfficientNet implementation.",1
"As the authors said, width and depth multipliers should be generated by phi.",1
"All statement you think should be kept visible to users when they do not configure logging, should be at level INFO.",1
"@fchollet, I think a user should be able to control _any_ events of your library, since it can be used in many different situations, as @mitar noted.",1
"Anyone (including any dependency) could be printing anything, and any log parser that you have (note: cross-app communication via parsing stdout/stderr is generally a bad idea) should be ready to handle it.",1
"I don't know what's your problem @fchollet as obviously any side effects should be avoided (or at least easy to control), especially in libraries.",1
"Module import should be idempotent, so the backend should be initialized only when it's actually used.",1
So I think it should be covered.,1
"If this is a warning, we should not force users to use certain versions of h5py for the only purpose of making their text output prettier, it should be up to the users to upgrade.",1
With that you should be able to build the docs.,1
It should be good to merge once the tests are passing.,1
"- some coding patterns should be revised (again, that's mostly style).",1
"- Squashing: If we are ready to merge, I could open a separate PR with a single commit.",1
Things will get messy.,1
"-  The `Conv1D` class is missing from the layers, it looks like `Convolution1D` is used now.",1
"- `Lambda` is the only layer capable of sitting on top of a `join` `Merge` in a `Sequential` model , so adding an argument to `Merge` which will be used only when a `Lambda` is on top is not a good idea.",1
`Lambda` would be just a  custom activation layer in that case.,1
"If a user wants to structure training in that way, that is on them, and they should write their own training loop.",1
"- The combination of `Dropout` to prevent overfitting, and training until convergence, should yield more stable and much better results.",1
- the docstring should be rewritten.,1
"- The explanations of `num_words` and `skip_top` may be wrong: that words is replaced `oov_char`'s value in [this line](https://github.com/fchollet/keras/blob/master/keras/datasets/imdb.py#L97), not 0.",1
- the fix should be applied in all methods that have callbacks (`fit` and `fit_generator`),1
"- the progbar should not be the first callback, because `BaseLogger` should be the first callback.",1
Basically the progbar should be the 2nd callback,1
"- It is possible to (I added a comment to explain this syntax): 
   * Document only the class: ```classes = [classA, classB, ...]```
   * Document all class methdos: ```classes = [classA, (classB, ""*""), ...]```
   * Document some class methdos: ```classes = [classA, (classB, [""methodA""]), ...]```",1
The methods are listed as string this to save the typing of full signatures. [we could change this],1
- the lines for `_preprocess_symbolic_input` should not be modified.,1
- The link should lead to the editor view rather than the console view.,1
Ideally it should behave like a local terminal.,1
"- The other possibility is that the weights files have random names for the layers, in which case there should be an exception raised when trying to load the weights from imagenet and passing a custom tensor as input.",1
It should be easy too.,1
"I could have added tests, but since keras tests on Travis are really slow, and downloading the weights takes a long time, I chose not to do it.",1
"If the bosses say it's necessary, I'll do it though.",1
"- the plus is that it will be even more flexible, down side is more work for the user.",1
2 - I'll alter when I'm back from vacation,1
- the syntax should be made PEP8 compliant.,1
- This keyword argument would be mismatched with the API of every other built-in dataset.,1
- The use case is not clear; it seems this is for users who already have downloaded the dataset somewhere themselves.,1
- There are many changes that don't seem to be related to test coverage.,1
"- There's a possible confusion in the existing ZeroPadding2D (see https://github.com/fchollet/keras/blob/master/keras/layers/convolutional.py#L1345-L1346) - dimensions are called width and height, respectively, but in all convolutional layers respective dimensions are rows, cols (vice versa).",1
- May be it makes sense to do the same thing for ZeroPadding1D simultaneously?,1
"- Probably it could also be useful for the image processing, but I cannot offer an example.",1
- From my experience it could be definitely useful when using convolutional layers for the time series data.,1
"I was not aware of the `deep_dreams` example, but I believe that my code provides a more intuitive and user-friendly weights object, as well as better-structured hdf5 files, than the current implementation for `Graph`: in contrast with Sequential, which provides a natural segmentation into `layer_{}` and `param_{}`, Graph currently compresses all of the weights in the model into a flat list of `param_{}`s.",1
I felt it's very natural that instead it should carry forward the named-node tree structure in weight representation.,1
- This could modify existing behavior:,1
"Hello, I've tried implementing a generator which relies on this feature, but it seems like this is not possible with the current version of Keras, i.e. steps per epoch are not computed at the beginning of each epoch anymore.",1
I was surprised to learn that this is not possible.,1
- this is ok though the computation of the `num_filters_out` will be done many times over unnecessarily because it was pushed inside the inner loop.,1
- #7072 & deps should also cause this PR to pass.,1
This seems fair enough as sigmoids are centered around 0.5 and are probably the most typical activation function for multi-label classification.,1
@fchollet this seems fine to me overall.,1
- This seems for use exclusively with Theano.,1
@taehoonlee maybe we could resurrect #11265 ?,1
"This would be useful for this PR, #11556 , and also the tests of the new K.clip function since clip can now take three input tensors as arguments.",1
This would be useful data for picking one API or the other.,1
"- This would be useful for example with a CNN, where each unit in a representation has a specific meaning (i.e., first time point, upper left corner an image).",1
:+1: This would be useful for a model I'm working on.,1
- To be: checking whether **only a single backend produces the desired outputs**; so the redundant tests will not perform.,1
"- To be: checking **only a single backend**, so the redundant tests will not perform.",1
"- Training on live data while simultaneously logging it, such as from an RGBD camera, where a python implementation would drop frames.",1
- Users should be able to use this functionality within the callback even if TensorFlow isn't the backend.,1
It would also enable users to switch more easily between backends (less code to change).,1
- Using the `config` dictionary as input doesn't seem very practical to me,1
- we don't expect that more than a handful of users were using these backend methods directly.,1
So we would benefit from a `__init__.py` where we export public definitions.,1
"This PR is to track possible bugs that we would have by upgrading TF, this will allow us to fix those bugs progressively if there are a lot of them (possible since it's a big jump).",1
"By using paths and not hardcoded strings, we'll be able to build the documentation programatically, hence run more tests on it.",1
Since Theano is EOL soon (maybe already? See https://github.com/Theano/Theano) I suppose that we'll have to go this way at some point.,1
We'll only know after a while.,1
We'll need to add a couple callbacks to go with it.,1
"Currently, if we run lstm_seq2seq.py, and then run lstm_seq2seq_restore.py, we'll get different results, because we only pad the input sequence in lstm_seq2seq.py.",1
"After this PR, if we run lstm_seq2seq.py, and then run lstm_seq2seq_restore.py, we'll get the same result.",1
"Executing the example as it is, we'll get
```
the as you with out themselves powerful lets loves their becomes reaching had journalist of lot from anyone to have after out atmosphere never more room titillate ...
```
which is an error.",1
"-  when wanting to construct a bi-LSTM (or any bidirectional RNN) using a graph model and ""go_backward"" to create backward branch, we notice that the backward and forward branches will return sequences in opposite order.",1
- will not add multiple headers,1
"- You have to stick the Layer into a Model, and then call fit(X_train,X_train), which seems a bit unintuitive.",1
"- The line you mention for stacking autoencoders would have to be added into every possible subsequent layer, which goes against modularity.",1
"- you should use the VGG16 network provided at https://github.com/fchollet/deep-learning-models, mostly for performance reasons but also to avoid code duplication.",1
"It looks like this now:
```python
if sample_weight is not None and sample_weight.shape != score_array_shape:
    raise ValueError('Found a `sample_weight` array with shape ' +
                             str(sample_weight.shape) +
                             ' for output with shape ' +
                             str(y.shape) +
                             '. When sample_weight_mode=""element"", ' +
                             'weights and score_array must have the same size.'
                             'Your `sample_weight` array should have the '
                             'following shape: ' + str(score_array_shape))
```",1
"There are a couple of typos which could be fixed before a pr, sorry about that.",1
@fchollet Ok that may be its intended behavior.,1
# Cannot re-create models and pass weights either will get a rank error based on how model was saved.,1
"# Each question will be at most 100 word long,
# and we will index words as integers from 1 to 9999.",1
# It is currently not possible in keras during training.,1
"We could use a metric but we
# would not be able to access the values and we would have to add an output
# not used during prediction.",1
In keeping with the style of having LambdaLayer it could be nice to have a LambdaCallback as well for being able to create inline callbacks without having to breakout into a Class block.,1
"This is a new handwritten digits-dataset, termed Kannada-MNIST, for the Kannada script, that can potentially serve as a direct drop-in replacement for the original MNIST dataset.",1
**Don't use on shallow networks** as there may be an actual noticeable accuracy loss.,1
# This model will encode an image into a vector.,1
I will be working on this all weekend (I hope).,1
Things that are not tests as such but that would be nice to have,1
"I recon if all these are met, we should be pretty close to 90%, which seems like a more presentable number.",1
"If anyone wants to join me, let me know ( @olegsinyavskiy @EderSantana @farizrahman4u ?) and I will give you push access.",1
"Indeed, if you look at `atrous_conv2d` in tensorflow (https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/nn_ops.py#L741), you have:

``` python
    # Handle input whose shape is unknown during graph creation.
    if value.get_shape().is_fully_defined():
      value_shape = value.get_shape().as_list()
    else:
      value_shape = array_ops.shape(value)
```

which could be changed to:

``` python
    # Handle input whose shape is unknown during graph creation.
    # we do not care if the batch size is not fully defined
    # this is necessary to avoid `TypeError: Expected int for argument 'num_split' not None.`
    # when using the Keras layer `Upsampling2D`
    if value[0].get_shape().is_fully_defined():
      value_shape = value.get_shape().as_list()
    else:
      value_shape = array_ops.shape(value)
```",1
"As a result, if we fine-tune the top layers, their weights will be adjusted to the mean/variance of the new dataset.",1
"Unfortunately, we get no guarantees that the mean and variance of our new dataset inside the BN layers will be similar to the ones of the original dataset.",1
"Nevertheless, during inference the top layers will receive data which are scaled using the mean/variance of the original dataset.",1
"If we change the `trainable` property of `layer`, the weights will be updated.",1
# will reset all weights & biases randomly and recompile the model (necessary),1
# Will update workaround once CTNK supports it.,1
# x_train_batch could be any input tensor,1
# You'll see this metadata on the projector's page.,1
"We won't check for a specific type of bug (which to our knowledge, never occurred in Keras), which is that the generated numbers do not follow the expected normal distribution if generated in a repeated manner, using `K.eval(x)`.",1
"- If the user has given arguments that are not compatible with the backend (let's say write_graph with Theano or CNTK), the callback won't throw an error, it will just give a warning saying that the argument has been overwritten.",1
"I could do without, it can easily be changed if required.",1
The code would be a bit longer though because I didn't find a clean way to iterate over the arguments.,1
- I believe all the tests needed were already created.,1
"What could be added easily:
- image summaries
- sparsity measures if the activation is a ReLU",1
"- When giving sparse arrays to keras in fit, predict or evaluate, if the corresponding Input layer wasn't specified as sparse when creating the model, the backend would complain about it.",1
##  This PR is to fix bug in the keras saving logic (which seems to be typo).,1
"Before this change, auxiliary tf tensor data & operations could *almost* be provided to the `session.run()` call, but not quite since the [feed_dict and fetches params end up duplicated](https://github.com/fchollet/keras/pull/6928/files#diff-a18b8c6a1191d6f49303e0d599ca8c37L2268).",1
- This method would allow to easily obtain the configuration of a callback without knowing the arguments of the callback.,1
"Following the code I'm pretty sure I got the order right - [hidden state, cell state].",1
"Frankly, I was disappointed in some way when I'd done, as I expected to see embeddings progress in dynamics.",1
"I thought this way as in TensorBoard documentation I used I saw:
> Periodically save your embeddings in a `LOG_DIR`.

and I did not get it.",1
"It looks like this:
```
model_checkpoint_path: ""embedding_data.ckpt-594""
all_model_checkpoint_paths: ""embedding_data.ckpt-198""
all_model_checkpoint_paths: ""embedding_data.ckpt-297""
all_model_checkpoint_paths: ""embedding_data.ckpt-396""
all_model_checkpoint_paths: ""embedding_data.ckpt-495""
all_model_checkpoint_paths: ""embedding_data.ckpt-594""
```",1
It looks like seeding random globally is not required in Orthogonal initializer.,1
"It looks like everywhere else in the code, masks are of type `bool`.",1
"Here is how it looks like in MNIST MLP training:

![image](https://cloud.githubusercontent.com/assets/1140359/25154945/098285d0-2493-11e7-9757-4d532eec7ed2.png)",1
"Inspecting the `LOG_DIR` I see all saved ?checkpoints?, and it looks like they are just a saved model, not only the tensor I wanted to save.",1
It looks like the tests were intended to do this.,1
It looks like this was a copy+paste bug where neither `random_uniform` nor the theano backend were being tested.,1
See https://github.com/fchollet/keras/pull/8482#issuecomment-344401396 for an example how it looks like now.,1
But it looks like even sparse updating on the moment variable could help.,1
It looks like people aren't running the tests before accepting merge requests or commiting to the repo.,1
I would suggest taking this request anyway  and then continuing to iterate on the test compliance.,1
It looks like two of the commits in this PR don't fit the heading and are related to the earlier autoencoder PR?,1
"Correct me if I'm wrong, but according to these [Theano docs](http://deeplearning.net/software/theano/library/tensor/nnet/conv.html) it looks like Theano does expose some 3DConvolutional methods, at least for 0.7.",1
It looks like we're almost there with tests.,1
"I know nothing about theano, but from the reading I just did it looks like it works roughly the same way: you create a sparse placeholder and then you can pass in a sci-py matrix into the theano function directly: http://deeplearning.net/software/theano/tutorial/sparse.html",1
I'll see if I can hack together a theano version.,1
One thing that could be done to both backends is to have them auto-convert sparse matrixes to dense matrixes per-batch when they see dense placeholders.,1
It might be useful for large data that people don't want to write generators for.,1
"I don't really use them, so maybe it's not even important, but it looks like allowing sparse inputs there would require adding an argument to Model, otherwise it would require changing every class, which seems like no fun.",1
So it looks like I wrote some flakey tests.,1
"In particular it seems that sometimes sometimes sparse multiplication can be slightly off from the dense results:

```
>           assert np.all(k_s == k_d)
E           assert <function all at 0x7fe76ed31140>(array([[ 0.  ...dtype=float32) == array([[ 0.   ...dtype=float32)
E            +  where <function all at 0x7fe76ed31140> = np.all
E             Full diff:
E             array([[ 0.        ,  0.        ,  0.        ,  0.        ],
E             [ 0.        ,  0.        ,  0.        ,  0.        ],
E             -        [ 7.66850376,  6.24425411,  4.40544653,  4.35426092],
E             ?                  ^^
E             +        [ 7.66850328,  6.24425411,  4.40544653,  4.35426092],
E             ?                  ^^
E             [ 2.9856596 ,  2.03145814,  1.55561113,  1.47568619]], dtype=float32))
```",1
It looks like the Travis failure is because `tf.where` works differently in TensorFlow v0.11.,1
Perhaps you can make a fallback option that uses `tf.select` if you get this `TypeError`?,1
It looks like this may be your first contribution to a Google open source project.,1
The CI check is failing and it looks like it is not because of my changes.,1
Although it looks like it will break other models.,1
It looks like this PR reverts the behaviour to always throwing `StopIteration` in the main thread.,1
I'm looking into ways how to implement it with observable pattern and it looks like it introduces way more complexity.,1
"ObservableInt will help to avoid this call 

https://github.com/keras-team/keras/blob/babaec7ae817fc7d0ad3e3f3eeedbe5425f35534/keras/engine/training_generator.py#L276

because callbacks will get new value of steps_per_epoch automatically.",1
"It looks like one of the existing 1d test cases is hitting your error, probably just as the constants for the test were poorly considered.",1
It looks like you are including in the PR many changes that are unrelated to the PR.,1
@fchollet It looks like BN for LSTM is unfinished -- are you still interested in having this in Keras?,1
"Actually, it looks like there are PEP8 issues left.",1
"The git diff looks awful because of tabs, but the big piece of code hasn't changed.",1
This will allow for more readable and informative tests.,1
- Now the `Cropping1D` layer will get an `data_format` attribute.,1
This attribute will always have the value `'channels_last'`.,1
Maybe this can be considered as an API change.,1
This change will avoid some checks on the backend identity before executing operations.,1
This conftest will only affect the tests in the `legacy` directory.,1
We could probably also use a class with an attribute `self.use_learning_phase` and have those inner functions be methods of this class.,1
"Probably more code to do, but it would be the standard python way to do it.",1
"The layer makes zero sense, but I think the example is ok since it's really close to the first code example so readers can easily spot the differences.",1
Lots of people were looking for documentation on this function and could not find it.,1
"This embedding_matrix[i] = embedding_vector creates an incorrect embedding vector, and it should be embedding_matrix[i - 1] = embedding_vector.",1
This embedding_matrix[i] = embedding_vector should be embedding_matrix[i-1] = embedding_vector.,1
The [blog quoting this code](https://blog.keras.io/building-autoencoders-in-keras.html) should probably also be updated.,1
"In Dockerrfile, we should add an pydot module.",1
"```BatchNormalization``` layer, mean/var/beta/gama tensors may be [broadcast](https://github.com/keras-team/keras/blob/master/keras/layers/normalization.py#L140).",1
1 - Suppresses a false warning when serializing models containing RNNs with initial state (makes people think seq2seq models are not serializable),1
Adds more clarification as to what label format/shape the two categorical loss functions are expecting.,1
"As discussed in past issues it would be beneficial to raise a warning, informing the user that class_weight is ignored in case both sample_weight and class_weight are given.",1
"Comparing to numpy operations allow us to know which backend fails in case of unexpected result (let's say the theano backend changes, the failure will only happen in the theano build on travis when comparing to numpy), and have a good ground truth for tests.",1
"Due to a difficult migration to tf2, I plan to disable tf2 behavior for now in our project (using `tf.compat.v1.disable_v2_behavior`).",1
"A better check would be to check if tensorflow is executing eagerly or not, regardless of its version.",1
"There is a limited upside to this PR indeed, I'll advance two points:",1
- I believe it's cleaner and more meaningful for new users who are reading the keras codebase,1
"For certain operations like moving_mean, there will be no gradients.",1
"I believe that it will be simpler to merge #8296 by breaking it down into indépendant, small PRs as much as possible.",1
"Many users will benefits from this PR, and it can save a lot of code (and maths), so I believe that making those small breaking changes are worth it.",1
I believe we can benefit from an unified implementation of the padding layers.,1
I believe we could add them to the docs. It requires very little work since all the code and docstrings have already been written.,1
I believe we should merge this into master and wait until we have the timeout issue again to see a stacktrace.,1
"I believe it's better to group them, for readability and reliability.",1
"- This Pull Request takes my [API Design Review suggestion](https://docs.google.com/document/d/1oU-x3l7wcZYmuk1bopnxMBs1YMyfSjQvX15k4Yn5hdA/edit#heading=h.5ojovhmssrde) a little bit further, and is a bit more clear, I believe.",1
"I believe some refactoring could be done, and it could lead to more readable and less error-prone code.",1
I will replace more code in the future if this PR is merged.,1
"- This PR takes my [API Design Review suggestion](https://docs.google.com/document/d/1oU-x3l7wcZYmuk1bopnxMBs1YMyfSjQvX15k4Yn5hdA/edit#heading=h.5ojovhmssrde) a little bit further, and is a bit more clear, I believe.",1
I believe that we should cover the entier codebase with tests for both python 2 and python 3.,1
I believe Keras should also have `support_vector_regression_loss`.,1
I believe this will have the side effect of solving this issue: https://github.com/fchollet/keras/issues/4018,1
@Dref360 I believe this is consistent with the discussion in `#keras-dev` but am happy to be corrected.,1
"I realize this is one extra depth compared to everything else on the sidebar, but I believe it may be worth it for the added clarity.",1
"Corrected cast function spec formatting which is causing (i believe) the misformatting in backend documentation: Dot hasn't got a title and is embedded in previous cast exemple, see ""cast"" definition here:  https://keras.io/backend


![image](https://cloud.githubusercontent.com/assets/1705336/22339653/0c20b3d6-e3eb-11e6-8013-5d12092d8c85.png)",1
"I discussed this with @fchollet already and he approved in principle, but please let me know if there are any issues with my implementation - I know `tf.ragged.constant` in particular can have a very long runtime if you're not careful with the inputs, but I believe it's efficient when the inputs are Numpy arrays.",1
I believe this is incorrect and it can lead to reduced accuracy especially when we use Transfer learning.,1
"This is far from what I believe to be the most obvious case: sparse segmentation labels and dense output vectors:
   ```py
   >>> classes = 20
   >>> model = Sequential([
   >>>    ResNet50V2(input_shape=[512, 512, 3], include_top=False, pooling=None, weights=None),
   >>>    Conv2D(classes, kernel_size=1, activation='softmax', name='predictions')
   >>> ])
   >>> print(model.output.shape)
   (None, 16, 16, 20)
   ```",1
I believe this is a small change that many people might profit from.,1
I believe K.rnn is really unintuitive to use for simple maps and folds if it can even be used.,1
I believe `loss_weight` in this part of the docs was a typo.,1
I believe Theano works with cuDNN6 and that it is officially supported: https://github.com/Theano/Theano/blob/master/theano/gpuarray/cudnn_defs.py#L13,1
"I believe that all of the textual datasets in Keras already come encoded, and I thought showing the complete process end to end might be nice.",1
"Personally, I believe in ""sane defaults"" idea.",1
`to_categorical` belongs to the `np_utils` file and not a preprocessing one so this addition could be misleading in terms of code structure but I believe it is useful to include in the current documentation.,1
"This is the reason, I believe inbuilt euclidean distance loss, would be helpful in saving time of developers.",1
Neural Turing Machine with RNN controller (I believe we are the first to open source such thing) can be used as any other RNN model.,1
"I believe I covered the contributing guidelines, please let me know if I've missed something.",1
"For example, I'm writing a DRAW model using Keras and I believe this is the only non-standard thing that the model would require to run with Keras out of the box.",1
"I believe the code should validate the l1,l2 values and should raise exception if any of them `<0`.",1
"I believe validating these parameters`(l1, l2)` in this file will also validate these parameters in `L1` , `L2` and `L1L2` classes also.",1
I believe this is similar to what [TensorFlow does](https://www.tensorflow.org/versions/r0.7/api_docs/python/nn.html#convolution).,1
I believe they can be useful for other people as well.,1
"This is not a fully reliable way to check for GPU execution, but I believe this is the best we have now.",1
"I believe that resolves the following issues:
https://github.com/keras-team/keras/issues/9343
https://github.com/keras-team/keras/issues/6794",1
"In case where there are no sub-directories, I believe the code works as it used to.",1
I believe it might help in many more use cases.,1
"By changing the searchbox to always be ""action=""./search.html"""", instead of {{base_url}} /search.html, I believe this issue can be avoided.",1
"I believe the bigger PR requires building a case and thorough discussion, so I decided to split the changes into 2 parts (I will soon document the problem on BN and submit another PR).",1
"The ragged tensors with RNNs are quite a common usage in my opinion, so quite a lot of users will benefit, I believe.",1
"I find the code quite difficult to understand, and I believe it could be considerably simplified :(",1
"By the way, I believe it would be simpler to just convert Caffe models to a Keras config dictionary, then instantiate the model from this config, instead of converting the Caffe model to an instantiated Keras model.",1
I believe it would be consistent to upgrade the convolution3D too before the merge.,1
"In any case: I believe it is useful to print the name of the backend, which is why this line was included in the first place.",1
I believe a simple cast would fix it. Anyone looking at it?,1
"@Dref360 I believe such a use case would result in an exception, right?",1
I believe this commit introduces a regression on `model.save()`.,1
@fchollet I believe I made the necessary changes.,1
I believe most of the code in this example is about data processing rather than related to demonstrating Keras functionality.,1
"I believe this is redundant with the existing CIFAR10 and MNIST convnet examples, and we will not merge it.",1
"I believe it would be more productive to bump the tf version, because we'll have to do it at some point.",1
But it would require fixing ctc.,1
I believe that for Python2 you'll need to wrap the contents of the write in a `unicode()`  statement.,1
"There may be a better solution, though, that would work the same way for both versions.",1
I believe that keras benefits from a feature if it's added in multiple backends at the same time.,1
I believe there could be more explanation of the parts that are designed to work together beyond what is on the linked page and in the regular keras docs.,1
"I believe that there are many use cases where keras is not a good fit, and for those use cases, people can simply fork the project.",1
"If it's not too much trouble to implement, I believe the best option is to recompute the sample and raise a warning for those reasons:",1
"As for why the tests are stalling, I believe this has to do with your Queue.",1
I believe that in the penultimate commit the execution of the `test_generator_enqueuer_threads` test got stack on `enqueuer.stop()` because it's the last test running on `gw0`.,1
I think my comment on the queue size is still valid and the above snippet can help you reproduce the problem.,1
I believe we should no merge it.,1
I believe the test is not running...,1
@gbaned I believe I fixed the issue.,1
"I might have not expressed myself clearly: I figured out what the error was (I believe MultiWorkerMirroredStrategy#run is returning the expected loss value divided by num_workers/two), but I am unsure how to fix it as this code is not part of keras, but tensorflow.distribute.",1
I believe something could be wrong with how reduction is being handed by MWMS.,1
I believe a recent PR may have broken it.,1
It used to work fine (should work in Keras 2.0.8 in particular).,1
@fchollet I believe this is ready.,1
I believe this would not work with Sequential models that include one or several Merge layers.,1
Actually I believe your code could be reused for serializing / loading multi-branch sequential models (and Graph models as well) very easily.,1
It was the integration test that was failing which I believe have been fixed in [latest commit](https://github.com/keras-team/keras/commit/fe35050a8f18dc52304aa8da4e463eececa25240),1
You can break in the middle of the title name I believe.,1
I believe that we have named scopes to do just that.,1
"I believe that was a oversight on our part, not having names there would have been more consistent (no need to change it now though).",1
I believe it has to do with the modifications made to the objective functions.,1
"The test for this behaviour (test_layer_range_value_fail in keras/utils/vis_utils_test.py) was already failing on my build, and this PR is designed to fix that specific behaviour only, so I believe it is covered by that existing test.",1
I believe we are having problems setting _FLOATX with a global.,1
It won't work.,1
I believe it would work it Theano but it wouldn't in TensorFlow.,1
I believe it is better to keep verbose as a bool variable.,1
"Since we are using platform agnostic language, I believe that it won't cause any issues.",1
"If adding it to the code base is an issue(which I believe is not), I can write a bash script to fetch it from the web on demand the first time.",1
"I believe this loss is relatively niche (e.g. not included in sklearn), especially within the field of deep learning (not included in any other DL framework).",1
"As such, we should not merge it into core, and I recommend that you open a PR in Keras-contrib instead.",1
I think another alternative might be to require pickle protocol >=3 (default as of Python 3.4 I believe); I'll test this and report back.,1
"This is the more robust solution of the lot, and I believe it is quite doable -- adding support for the list of objects I mentioned should be enough.",1
"If you try this and it fails, I would recommend falling back to:

> exclude the subclassed parametrization in the new test, maybe manually testing a simple subclassed model like the one in keras/keras/tests/model_subclassing_test.py -> test_deepcopy.",1
This is an acceptable option because for the models that will fail the user will see an explicit error message -- "your model contains these weird objects that can't be pickled.",1
"The user will be left wondering, ""wait, why?"" but hopefully this will only happen for a small set of models.",1
"Re: oddity / validation accuracy, I believe it's performing accuracy over each of the characters in the output sequence.",1
I believe it should be fixed now.,1
I believe the reason is XLA_GPU has the device_type as GPU as well.,1
Otherwise I believe we are ready to merge.,1
"The style is still not conform, so you could fix the style.",1
Otherwise I'll just clean it up myself.,1
"I would recommend you install a PEP8 linter, such as https://pypi.python.org/pypi/pep8",1
I believe there is a slight difference in the way padding works in both cases.,1
@yanboliang I believe you added this code.,1
I believe I did it the other way round. Thanks for clarifying.,1
I'll raise a new PR soon.,1
I believe passing output of encoder to bidirectional decoder using `constants` will streamline the implementation of attention mechanism.,1
I believe it's called `argmax`. We have it already.,1
I believe Lasagne supports it.,1
"I believe in the current form, the CaffeToKeras class creates the network graph based on the caffemodel file instead of the prototxt.",1
I believe @Dapid created this PR to set trainable parameters of submodels once when loading the model for a second time.,1
I believe typical users won't have the resources to train ImageNet weights from scratch.,1
"It sounds like you're fairly certain that GroupNorm will work better for most use cases, you made a pretty strong statement. :-)",1
I believe Keras used to have a parameter called `mode` for Batch Normalization.,1
I believe it's a good idea.,1
"I noticed the final link in the FAQ wasn't working and after some investigation, it seems markdown links must be in lower case to work.",1
I think this version is less error prone and more maintainable.,1
Maybe we could do some subclassing?,1
"If the number of channels is great than 1, we should add a non-zero value at the begin of ```dilation``` to line up with the input channel axis for ```C.convolution```.",1
Ignoring all warnings can be dangerous because there might be useful ones (eg: depreciation warnings).,1
"I'm probably not doing this the right way, but I wanted to watch it fail on Travis (I'm sure I correctly installed only the Tensorflow backend locally).",1
"In certain use cases, load_weights() would cause OSError if called repeatedly on several different files.",1
The proposed addition will now make sure the HDF5 files are closed before exiting the method.,1
It seems code blocks in `multiple_gpu.py` ([Link][1]) are missing after the document is generated.,1
"I don't know what was intended with this check, but it seems that this should not be performed on each layer because it does not depend on the implementation of the layer.",1
"For the moment, it seems that builds roughly fails less than 10 % of the time.",1
"With the new version of Tensorflow (2.0.0alpha), it seems that the Keras module names have changed.",1
Updating the MNIST CNN (and possibly others might need to be updated as well) example to reflect this.,1
It seems that clipnorm parameter is necessary for sgd optimizer.,1
"Technically users could be depending on the buggy behaviour, but it seems unlikely to me.",1
It seems docstring in couples of files in `keras/layers` containing broken markdown hyperlinks.,1
"(though for some reason it seems training takes longer, possibly just because of initialization.)",1
- It seems that pytest doesn't support short-circuit evaluation of subsequent markers.,1
"It seems that github doesn't pick up the changes, even though I did exactly as shown in the documentation: https://help.github.com/articles/creating-a-pull-request-template-for-your-repository/",1
"Unfortunately, according to [this](https://www.mkdocs.org/user-guide/writing-your-docs/), it seems that table cells cannot span multiple lines in MarkDown.",1
"* I have tested it on Mac, Linux, and Windows, and it seems to work fine.",1
Both TensorFlow and Theano support this parameter so it seems convenient to have it in Keras too.,1
"Fixed an np.random.randint() bug https://github.com/fchollet/keras/compare/master...wayaai:cleanup-fit-generator?expand=1#diff-ed7c4d0cc3c2c1334a8e80ec07781927L190 for the fncs, then fixed this bug https://github.com/fchollet/keras/compare/master...wayaai:cleanup-fit-generator?expand=1#diff-ed7c4d0cc3c2c1334a8e80ec07781927L271 where it seems they thought they were passing in `nb_epoch` but really `predict_generator` and `evaluate_generator` dont have this option so it was setting `max_q_size=1` and causing tests to fail",1
It seems in the tests there are some use cases setting `trainable=None`.,1
"Could do with someone checking this over though, as it seems like it's a simple bug fix but I may have misunderstood the intended behaviour.",1
Edit: It seems like another solution would be to change,1
"It seems that tensorflow can be patched, but testing on 12.04 is a bad idea anyway.",1
"Originally I had these just based on existing backend functions (as in the Theano implementation) and thought they could just be helpers in common or something, but it seems Tensorflow has built-in operations for this already.",1
"[EDIT]: Actually, the backend tests are failing on my machine since it seems like the CTC bits are incompatible with TF 0.10.0rc0 so I couldn't check if the backend test works, so hopefully CI can verify this.",1
It seems that batchnorm overhead in theano can slow things down a bit too much for in the context of this toy problem.,1
It seems to have solved the issue for me.,1
"According to the paper this ""Gaussian dropout"" actually works slightly better, and it seems to in the MNIST example.",1
It seems like it's a problem for a current architecture.,1
"I've only tested this fork with Theano + Python 2.7, but it seems to be working.",1
"This seems like the right way of doing things, but the `get_param` function is thrown around a lot with tuple expansion and it seems like a mess to dig into that (maybe a good place for a `NamedTuple`).~~",1
It seems that currently the metric 'accuracy' won't work with `sparse_categorical_crossentropy` loss.,1
It seems that refactoring for multiple backends introduced some typos and some input or output shapes (especially one-dimensional) were not tuples anymore.,1
"It seems that the `TimeDistributed` layer has a similar issue as the `Bidirectional` layer when passed a layer that requires the learning phase as described in:

* https://github.com/fchollet/keras/issues/5940
* https://github.com/fchollet/keras/issues/5975
* https://github.com/fchollet/keras/pull/5985",1
"It seems that when combining two tensor V1 and V2, the cosine merge output is not dot(V1, V2) / sqrt(dot(V1,V1) \* dot(V2, V2)).",1
"Suppose V1 and V2 is (batch_size, dim).",1
"The result should be (batch_size, 1) while dot(V1, V2) / sqrt(dot(V1,V1) \* dot(V2, V2)) is (batch_size, batch_size).",1
It seems to be a mistake and might be unnecessary.,1
It seems to me that there are probably wrongly copy-pasted comments in `binary_crossentropy` and `sparse_crossentropy` so this PR fixes that.,1
It seems we are transferring the batch over to every GPU and then letting them slice out the data they'll use.,1
It seems that Theano doesn't use the `filter_shape` most of the time. (I ran into this problem while computing the gradient of the deconvolution on the old GPU backend.),1
"ps. I tried to do the same for the input, but it seems that `model.input_names` is not yet created at that time (it is created in the line with `outputs = model(inputs)`).",1
"Got any tips to fix this? My issue was with outputs, but it seems other people have the same problem with the inputs (https://github.com/fchollet/keras/issues/8339).",1
"It seems with the current implementation, the **external loss version suffers from 20x performance degradation** compared to `mnist_tfrecord.py` in #6928 which has a more direct C++ backend pipeline.",1
"It seems that these are not usually counted at all, in any case typically a few convolutions account for the bulk of the calculation.",1
"I am not sure this is the most efficient way to do it, but it seems to work.",1
"- In `Cropping1D`, `self.input_spec = [InputSpec(ndim=3)]` exists in `__init__()`, but it seems like this layer needs overriding `build()`as below:

``` python
def build(self, input_shape):
        self.input_spec = [InputSpec(shape=input_shape)]
```",1
"I'm not here to propose breaking changes, but after writing this it seems like `one_hot` has little to offer except a friendlier name.",1
"Not sure if this is a 0.8.0 thing, but it seems to be an easy fix.",1
Now it seems to be a pain point to repeat these image_dim_ordering() tests.,1
When [MeanMetricWrapper.update_state()](https://github.com/keras-team/keras/blob/master/keras/metrics/base_metric.py#L603) is called it is expecting to call the Accuracy classes "accuracy" function and it seems to be expecting a "matches" tensor to be returned where the "matches" tensor is an integer tensor with 1's for positive matches.,1
It seems that those functions have some original functionality that doesn't align with what Reduce is expecting.,1
"It seems that when the user sets a static learning_phase, it is ignored.",1
it seems to be a trivial mistake.,1
It would make sense for us to cache the compilation directory of Theano.,1
So it would make sense to do it for the user and make the API even cleaner.,1
"Given that tensorflow is the new default for keras, it would make sense to switch the `install_requires` field as well.",1
When chaining callbacks it would make sense to also have an average `loss` metric available in `on_epoch_end()` (not just `val_loss`).,1
Looks like the documentation for ReduceLROnPlateau was mistakenly overwritten with the documentation from EarlyStopping.,1
"Looks like RNN layer doesn't set internal `_dropout_mask` and `_recurrent_dropout_mask` to None, whereas LSTM or GRU layers do.",1
"My only issue with this implementation is that the initialization looks like so:

``` python
model.add(SimpleBRNN(5, output_dim=2*10, activation='sigmoid', return_sequences=True))
```",1
"In this PR, I add a inner method `rhasattr(root, attr)` to recursively detecting whether the object has attribute (concatenated by dots in string), and the usage looks like this: `if rhasattr(tf, 'summary.image')`.",1
"The relevant piece of code is in **examples/mnist_cnn2.py** and **keras/layers/core.py** (Merge) the code Iooks like this:

**mnist_cnn2.py**
`path1 = Sequential()`
`path1.add(Convolution2D(3, 1, 3, 3, border_mode='same'))`
`path1.add(Activation('relu'))`

`path2 = Sequential()`
`path2.add(Convolution2D(3, 1, 7, 7, border_mode='same'))`
`path2.add(Activation('relu'))`

`model = Sequential()`
`model.add(Merge([path1, path2], mode='concat', axis=1))`",1
I think this looks very natural.,1
The summary itself looks like the below by default but the format strings are all configurable.,1
"Its output looks like this:

The layer ""xxx has multiple inbound ...",1
Looks like pull request https://github.com/fchollet/keras/pull/2872 added the KL divergence function to [objectives.py](https://github.com/fchollet/keras/blob/85c2d28e992f8f2a752393d7e9f65c8f3cbb7a7c/keras/objectives.py#L51-L54).,1
"This change looks like an obvious improvement to me, BUT",1
I just thought it should be copied into [metrics.py](https://github.com/fchollet/keras/blob/85c2d28e992f8f2a752393d7e9f65c8f3cbb7a7c/keras/metrics.py) as well.,1
"Looks like we need some spaces/newlines in the docstring, documentation looks like this:

![image](https://github.com/keras-team/keras/assets/46622558/91c8ad15-5f8f-4eeb-8608-a83877314fc0)",1
"Looks like we need some spaces/newlines in the docstring, documentation looks like this:

![image](https://github.com/keras-team/keras/assets/46622558/91c8ad15-5f8f-4eeb-8608-a83877314fc0)",1
Here is how the grid(s) looks like now (after fixes in PR https://github.com/fchollet/keras/pull/8383),1
"The current doc on [keras.io](https://keras.io/models/sequential/#the-sequential-model-api) looks like this : 

<img width=""256"" alt=""before"" src=""https://user-images.githubusercontent.com/506602/32023254-f366fe62-b9d8-11e7-8e64-683d19a5ecc5.png"">",1
"For example, this layer looks like it has a surprisingly large number of parameters:
```
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
...
____________________________________________________________________________________________________
convolution3d_1 (Convolution3D)  (None, 100, 13, 13, 132800        input_patch[0][0]
____________________________________________________________________________________________________
...
```
This gets especially confusing if you're looking at a table with many rows. Adding a space between the two columns makes it more readable:
```
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
...
____________________________________________________________________________________________________
convolution3d_1 (Convolution3D)  (None, 100, 13, 13, 1 2800        input_patch[0][0]
____________________________________________________________________________________________________
...
```",1
"The usage looks like this:
```
# instantiate an ImageDataGenerator with a validation percentage
generator = image.ImageDataGenerator(validation_split=0.1)
train_iterator = generator.flow_from_directory(image_dir, subset='training')
validation_iterator = generator.flow_from_directory(image_dir, subset='validation')
model.fit_generator(train_iterator, validation_data=validation_iterator)
```",1
Looks like there is no test unit for set_weights.,1
this looks like a critical bug for anyone working with time series.,1
"Maybe, missing `to_list` method for some places.",1
"Metrics top_k_categorical_accuracy and sparse_top_k_categorical_accuracy should output a vector of accuracies instead of single scalar to be compatible with weighted_masked_objective function:
https://github.com/keras-team/keras/blob/7c7e51ea5ab47b67cd68374400051dd022bdc662/keras/engine/training_utils.py#L398",1
"Similar as #10727, when we serialize a ```Network``` by ```to_json```, we should handle ```numpy.ndarray``` correctly if there is.",1
"Note: ```tf.keras``` should have the same issue, will send a fix if this get approved.",1
"Sometimes when operates on the masks of sequential/time-series data, there will be a small chance that all values in a mask are zeros (e.g. only several positions are chosen at random with a small rate for loss calculation).",1
That should allow a better error reporting by knowing what exactly fails and what does not.,1
"The backend tests should provide valid usages, but now include an invalid usage (invalid target probabilities).",1
The tests with invalid usage may make users confused.,1
I think that we don't need crossentropy tests with random target probabilities (whose sum are not equal to 1).,1
"The default ```data_format``` for ```Conv1D``` should be decided by Keras config at ```~/.keras/keras.json```, so it should be ```None``` in the constructor.",1
I think it makes the codebase easier to read with a function for this.,1
This addition makes it possible to provide a Google Storage (bucket) path as the `filename` arguments of model/weights loading and saving methods.,1
This makes it possible to have a different number of target classes in each batch.,1
This makes it possible to use flow() to feed a model multiple miscellaneous data arguments while still using the Keras image augmentations for the image data.,1
This makes it possible to use a single `Convolution3D` layer with different input sizes (see #5108).,1
This is a possible fix for #13383.,1
"This may be intentional, but the Keras setup.py install requires 'keras_applications==1.0.4',

see: https://github.com/keras-team/keras/blob/master/setup.py#L40

keras-applications version 1.0.5 is out (and is auto-installed when you install tensorflow==1.11.0rc0 because it requires >=1.0.5).",1
This may cause error list index out of range,1
This may lead to confusion and errors.,1
This may lead to few problems:,1
This may be useful for training models with SeparableConv2D layers and FP16 weights (TensorFlow can't train such kind of models).,1
This may also be useful for automated testing in the future.,1
Affects all recurrent layers; ~~this may not fix the issue when Masking is involved (yet to be tested).~~,1
I don't think adding a test to validate the speedup is useful since this may create a flaky test.,1
This PR is a part of the PR #12076 which will be easier to review if splitted into multiple PRs.,1
"Currently, the replacement is able to apply on
all applications except whose fed with framework-native
tensor data, which will be put as a future work.",1
"No visible limitations now. `backend.sparse_categorical_crossentropy` will set the `_keras_mask` property in the loss Tensor, which will be used during the reduction procedure to mask out invalid pixels.",1
"To detect which functions are tests, pytest looks at the name of the function and if it starts with `test_`, then pytest understand that this function is a test and run it.",1
Update the GeneratorEnqueuer logic to follow the Ordered Enqueuer (We could merge them later on),1
We can't expect an error at this point in the code if a layer has the same behavior at training and testing time since we already called `model.predict` just before.,1
"We do operations on very small tensors in the tests, so mkl might not provide a speed benefit.",1
"We have many warnings looking like this: 
```
tests/keras/constraints_test.py:75
  /home/travis/build/keras-team/keras/tests/keras/constraints_test.py:75: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.
    assert not l2[l2 > m * 2 + 1e-5]
```",1
With recurrent attention it is different: we should wrap a core RNN cell with additional learnable transforms with their own weights.,1
The pain-point is this: normally when we want to define complex transforms we should use the _functional API_ and compose it based on the atomic layers.,1
"As suggest in [pep-8](https://www.python.org/dev/peps/pep-0008/#should-a-line-break-before-or-after-a-binary-operator), we should ignore `W503` to allow breaking line before a binary operator and improve readability.",1
We should be able to close #8330 after this PR is merged.,1
"We should find out why, and even if we don't find out, setting a timeout will allow us to make the tests shorter and avoid keeping Travis busy for nothing.",1
This is why we should compare the resulting html.,1
"Once we manage to remove all occurences of `KC`, `KTF`, `KTH` and `BACKENDS`, we should be able to removed unnecessary installs of backends.",1
Improves documentation for `axis` argument (i.e. we should accept a list of integers as well).,1
We should raise error so that user becomes aware of the missing value.,1
"In ```RNN.call```, if ```initial_state``` is a tensor that was returned by a Keras layer, we should get ```initial_state``` from full input spec(including training data, state and constants) which was generated at ```RNN.__call__```, as it could be copied to multiple GPUs.",1
"Otherwise, it would use the original ```initial_states``` which is not be sliced according the number of GPUs.",1
We should try to build the docs in travis to catch document generation errors.,1
We should use an getargspec instead of deprecated getagspec.,1
"When applying ```BatchNormalization``` to ```Conv2D```, TF backend try to use ```FusedBatchNorm``` for optimization(when ```axis=1``` and ```axis=3```), we should cover their equivalent condition(```axis=-3``` and ```axis=-1```) as well.",1
This way we should have the same behavior when using one or the other.,1
We should check the fix without cudnn too (but it should be no problem imo).,1
"In cases that one would want to predict a convolution kernel (an area of research), I think we should use _keras_shape, which works for ""variable"" and ""placeholder.""",1
"We should decide which store to go with by default. h5 is faster, but only marginally so.",1
"But, we should use line terminator of '\n' on all platform. ([Do not use os.linesep as a line terminator when writing files opened in text mode](https://docs.python.org/3.3/library/os.html#os.linesep))",1
"Another solution would be to add `cell_name` argument to all RNN layers, but that changes the API.",1
"The reason we don't typically see the obvious manifestation of the bug is because typically N is larger, and we normalize across the whole feature map (but we should see is for small N for Dense layers).",1
"Note that default `recurrent_activation` (for gates) in Keras is `hard_sigmoid`, while CuDNN uses `sigmoid`, so we should specify that option explicitly.",1
I.e. we should add the actual update in the numerator of the LR adjustment,1
"The problem is that when size of the last batch equals to last_batch, we should set self.batch_index=0 such that in the next batch the index array will be shuffled.",1
"In order to add new models into `keras-applications`,  we should first add those declarations into `keras`. Please refer to the cores (keras-team/keras-applications#26).",1
We should only pass `step_input_shape` to `GRUCell.build` in this case.,1
This PR is not backward compatible with most scripts so we should revert it and think of a better way.,1
I see a difference on a custom accelerator (it's not spectacular because regularization is not compute-expensive but IMHO we should optimize the graph whenever possible).,1
"In the near future, we should enable CUDNN LSTM and GRU as well.",1
"When input ndim > 2, Dense layer should add bias to the last dim, so we should always set  ```data_format``` with ```channels_last``` when calling ```K.bias_add```.",1
Added `relu6` to fix the error. If this doesn't look good then I think we should change the docs.,1
We should use the wheel file for Python 3.6 when installing CNTK since the docker VM uses python 3.6,1
"When we process a docstring with `process_docstring`, we don't really care about the output, we care about the html which is going to be produced after the markdown parser converts it to html.",1
"- Couple of failed tests for Theano, probably not caused by this PR",1
"However, the training could continue as before because learned weights would probably not be too affected in most cases.",1
This solution should be extendable for other external resources such as AWS S3 etc.,1
When using TopKCategoricalAccuracy you will get an error if the prediction matrix has more than 2-dims.,1
The models could be used similarly to other models in `keras.applications`,1
"This way, when calling fit, the class_weight will be computed from the class frequency.",1
"I think it's minor, but calling `super().compute_output_shape(x)` won't return x anymore (not all the time).",1
* We could also do a test with multiple inputs.,1
But it would require more changes to the `layer_test` function,1
"#1582 added a new parameter sample_weight_mode(s) for model, which should be correctly saved and loaded.",1
3. Typically you need to _build_ the attention mechanism (initialise weights etc.) and I see no reason why this shouldn’t be done in the `build` method (triggered by `__call__`) where you get the input shapes of all inputs.,1
#6298 illustrates why this shouldn't need to be overly difficult to implement.,1
TFRecord works pretty much the same way as queue so there is no reason why this shouldn't work.,1
Yeah I'll post some example in keras-contrib if this is accepted.,1
"#6765 4a6f06f changed Exception => ValueError, running the tests locally occasionally it will threw Exception also, but I'm not very familiar with it.",1
I think I investigated briefly and it looked like it was due to multiple workers.,1
"One code path would throw Exception in an underlying python library, the other throws ValueError.",1
Test success/failure could be a race condition.,1
The first one is quite involved and this approach might well have already been suggested but here's my attempt anyway.,1
"6. #7061 yield op unit tests 
    - might need a small tweak once above are merged to pass
    - unit test for #7072",1
"I think a workaround could be to pass a unique name argument to the op in the TF backend (if necessary), or some such.",1
"@ozabluda you might be able to do it with [save_all_weights()](https://github.com/farizrahman4u/keras-contrib/blob/master/keras_contrib/utils/save_load_utils.py#L10) in keras-contrib, which saves both the model and the optimizer weights.",1
You may also want to keep an eye on https://github.com/fchollet/keras/pull/7033,1
"#9343 is likely resolved now, you might be able to close it.",1
"This could cause memory issues, but if you're using predict_generator, I guess you're not outputting images. ( In this case, switching predict_generator to output a generator would help people in the segmentation domain like myself. Quick suggestion)",1
"Hi, the horizontal version in the current version looks like this:

![image](https://user-images.githubusercontent.com/11573780/155073380-5970b357-d59c-4e13-97b1-e4935d3f6473.png)",1
"And in my Pull Request it looks like this:

![image](https://user-images.githubusercontent.com/11573780/155073452-f9a8974b-23fb-4e2d-8d16-03083d635d44.png)",1
* Fix a bug where Sequence wouldn't work on Windows (Need Fariz approval),1
* Fix a bug where you couldn't have two Sequence at the same time. (Added a test),1
* Fix a bug where on_epoch_end would change the current epoch. (Added a test),1
"The best way to accomplish this is with a differentiable non-linearity such as a sigmoid, that maps all incoming values to 0->1. (Also, the `binary_crossentropy` loss-`sigmoid` output nonlinearity is the cannonical pairing as in logistic regression, and should be the clear choice, unless one has a really good reason to do otherwise.)",1
"Maybe you are using an outdated version of Keras? (although as far as can tell, this example is very old and has been working continuously...)",1
Yes I think you're right.,1
I removed the @fchollet so that you don't get spammed. (although I guess you have muted Github by now),1
"Indeed adding a flag to set the enqueuer would be cleaner, but I think it's a bad idea to change the binding of fit_generator (at least I would not do it if I am not the main author).",1
I think that it should be on any exception that you get the error message.,1
"(Basically, we shouldn't break people who are using a slightly older TF version)",1
So trying to use then in another shared layer with `merge_mode='join'` will not work. (Because all of them have name `simesehead` and they will replace each other in the dictionary created),1
"The following example will produce the issue I described. (`base_network` and `euclidean_distance` same as [this example](https://github.com/fchollet/keras/blob/99991779e5234c57feee1723addd5b523acfc852/examples/mnist_siamese_graph.py))

`g.add_shared_node(base_network, name='shared', inputs=['in1', 'in2'], merge_mode=None, outputs=['mid1', 'mid2'])`
`g.add_shared_node(Dense(85), inputs=['shared'], merge_mode=None, name='shared2')`
`g.add_node(Lambda(euclidean_distance), name='dist', inputs=['mid1', 'mid2'], merge_mode='join')`",1
"At best we should mention VE in passing, with a link, but we want to stay clear from opinionated takes on Python package management.",1
"""pip install"" is pretty clear, and people familiar with VE reading this will be able to adapt it to suit theirs needs.

(besides, the new instructions look more complicated and will confuse less experienced users)",1
"I think with this change, the process will never exit then since the non-daemon threads will hang around forever.  (But of course I didn't test that, maybe I'm wrong.)",1
"This will be an estimation of the dice coefficient, since the true dice coefficient will require to round the input to 0 or 1. (But then it will not be continuous anymore.)",1
"In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters",1
"The limitation which I see with this approach is that it will be hard to track the progress of the removal of the other backends (I may be wrong, feel free to correct me it's possible I haven't read the code well enough).",1
However it is not advisable to run _all_ tests in Colab as it will be quite slow.,1
-  It first identifies the "upstream edge" of the model it will be reconstructing.,1
"However for compatibility with old code, this argument is optional, so if you don't change anything it will be the old batch-wise decay.",1
"With this change, it will be much easier to refactor duplicate code portions of verbose=1 and verbose=2.",1
"Sometimes an extra parameter will be passed to `__array__` by numpy methods, in that case, instead of throwing the defined as expected, a `TypeError: __array__() takes 1 positional argument but 2 were given` will be thrown so it will be confusing.",1
I am also thinking to add some more Tensorboard functionalities to display graphs nicely. i.e. I can add name parameter in each layer so it will be easy to display complex models in nice way with proper block names.,1
it will be interesting to implement invertible model (flow model) in keras. it is a very reading-friendly version of glow.,1
"so it will be easier for you to put your channel dimension at the end (
input_shape=(2, 54, 36,1))
and use tf mode for LSTMConv2D and Conv3d.",1
I think this approach would also be useful if training a classification network on more than one type of class.,1
"(Currently I find the image filenames from the database and then load them with Pillow/PIL, but I think this is very slow compared to using .flow_from_directory().)",1
And it is possible that your `caffe_pb2.py` does not work in my environment or other that of people's.,1
It is possible to add an add_input function to the Sequential model.,1
"In such way, we could remove all the input_shape or input_dim argument from all layers' constructor.",1
Also it is possible to have python 2 Keras installations without pathlib2.,1
"@MichaelMonashev, Yes it is possible.",1
We will not add this activation function to the core API at this time (it is possible we might add it later though).,1
The namespace of models.py is kept clean and it is possible to serialize both compiled and uncompiled models.,1
"I also modified the code again so that it is possible that
the user modify the `lahead` and `tsteps` in the script head
in order to make the stateless LSTM converge or not.",1
It is possible that we should have a `frozen` attribute that would both disable trainability and other updates.,1
I think the better solution there is to make sure the Theano tensors always have `_keras_shape` when it is possible to know it.,1
"Plus, I think it is possible to pass relu6 as a param to the Activation, it doesn't need to be a string.",1
"I think relu6 should just be defined locally in the application file, or it should be generalized unless 6 is a fundamentally better max for many wide use cases.",1
In Keras in general it is possible to annotate a tensor with a mask by setting the `._keras_mask` attribute.,1
When using theano backend it is possible not to provide the time dimension.,1
"New commit: now it is possible to document class methods:

- Using strings: ```classes = [classA, (classB, [""methodA""]), ...]```
- Using qualified names: ```classes = [classA, (classB, [module.classB.methodA]), ...]```",1
Probably the second is easy to use during refactoring.,1
"It is possible to make due with the [mode.compile(input_tensors)](https://keras.io/models/model/) parameter and I don't have the free cycles to keep merging with master on an ongoing basis, so I'm closing this.",1
It is possible to weight losses and samples.,1
"Specific comment: make sure it is possible for the user to specify the exact seed which is used, so the randomness source used does not change if they change the data size or # of workers",1
Yes it is possible to customize `train_step/test_step` instead of `compute_metrics` but this increases the maintenance cost for the user.,1
It is possible to have dummy/empty methods but I think its too much.,1
"To make things more complicated, it is possible for TF tensors to have an undefined ndim, which makes the transposing more complex.",1
It is possible to break a sufficiently complex model with `None` in input shape by providing a numpy arrays with unexpected shapes irrespective of this PR.,1
"So it is possible to do it again thanks to this commit, by checking the number
of timestep everytime that there is a new input.",1
"- I am not too familiar with the keras tests setup, so the test I added may need editing",1
"- there are several tests around my new additional test, it is possible that one may want to add extra ""invert"" tests corresponding to each of these.",1
"Since each time step of the rnn is independent of the previous time step (no state involved), instead of looping through the sequence, it is possible to obtain the output in one single huge matrix operation.",1
"- I don't really understand the role of backend.epsilon, it is possible something should be changed (I think it is needed only when dividing ?)",1
"From these parameters, it is possible to reshape between 1D, 2D, 3D (and possibly to ND, although I am unsure on that).",1
_This lambda should return a tuple._,1
"Additionally, it is possible to use `np.rot90` over the `transform_matrix` for more exact rotations when the angle is precisely in [0, 90, 180, 270].",1
In my experience the current setup yielded images with slight black border (depending on the fill mode) when rotating by 90 degrees.,1
"With this layer it is possible to build more types of RNN architectures (one-to-many, many-to-one, many-to-many, etc)",1
"With these additions it is possible to implement all of the models from this paper in keras:
http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003143",1
"You could send the summary directly to python logging, which is what I normally do:
```python
model.summary(printf=logging.info)
```",1
"You could also send the summary to a file:
```python
with open(""summary.txt"",""w"") as f:
	def printf(s):
		f.write(s)
		f.write(""\n"")
	m.summary(printf=printf)
```",1
"After all, if the files were already placed in class-specific subdirectories, you could pass `labels=""inferred""`.",1
"After the fix, we can get the original sentence
```
[START] this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being ...
```",1
"As a result of this PR, you could delete any docstrings in theano_backend that are not intentionally meant to indicate a difference.",1
You could use this as a bootstrap.,1
"Because the CNTKv2.0 is not officially published, you could use the wheel below to have a first try:

http://cntk.ai/PythonWheel/ForKeras/cntk-2.0rc3-cp35-cp35m-linux_x86_64.whl
http://cntk.ai/PythonWheel/ForKeras/cntk-2.0rc3-cp27-cp27mu-linux_x86_64.whl",1
@asampat3090 Maybe you could add a test to perform the check you did automatically?,1
"As I am quite occupied recently, so it would be great if you could create a new PR!",1
"Hey @EderSantana, I'm actually working on this as we speak, so if you don't mind I could take over this one and you could focus on your awesome VAEs instead.",1
It would be great if you could take a look at it! (https://github.com/fchollet/keras/issues/2259),1
"So that turned out to be relatively straight forward to get TF parity; one thing I noticed is that Theano has many more sparse operations, so there were 3 kinds of different dot products you could choose from.",1
You could add a `K.ifelse` or something similar to handle the scalar-condition case.,1
"You could potentially submit it to Keras-contrib, though.",1
"...and of course, you could extend the solution above to allow passing a list of ′initial_states′ that is _shorter_ than the total number of states as well, and append default initial states internally for those not specified.",1
"@todiketan Perhaps you could ask that question in the thread you mention (just reply to my message there), as it's off-topic here? (This is an issue about adding an element-wise weighting feature to keras).",1
But you could imagine a similar situation in any sort of recurrent neural network where inputs had a variable length.,1
"Furthermore, you could probably solve these issues by adding additional tensor axes and padding (originally --- I had quite complicated code that masked inputs, outputs, and losses) but it's less clean.",1
"If you do not wish to early stop, I supposed you could initiate it with `patience=epochs` as well.",1
"You could also apply the same fix (and test) to `tf.keras` in the TensorFlow repository, that would be very helpful.",1
"Alternative, you could set utf-8 encoding at the start of execution using `setdefaultencoding`.",1
"You could just try using `encode`/`decode`:

```python
print('?'.decode('utf-8'))
```",1
"It'd be really great if you could add this as a test, too @salmituukka.",1
"To be clear, I was suggesting that since this class is maintainable as a small subclass of the original callback, you could easily maintain it as part of your own code with pushing it into the Keras API :)",1
"In general, if that's a desired property one should use `Sequencies` not `Generators` (you could also use a priority queue using the circle number of the generator but that's slower and messy).",1
"You could use your code in the tensorflow
back-end.",1
"The second would be a tree search -- if you weren't interested in the whole distribution and were rather interested in simply the most likely output, you could probably come up with a smart way to traverse the tree from the root to the most likely leaf without evaluating each time.",1
"For problem 2, you could dynamically find out the batch_size to pass to h_softmax by doing input.shape[0](or similar) - afaict all the Theano backend functions should work just fine with a Theano variable.",1
"Till I find a fix, you could switch to predict instead of predict_generator inside your callback and only predict some examples and not the entire sequence.",1
You could have just edited yourself instead of waiting on the submitter ;).,1
It would be nice if you could open a new PR.,1
Maybe that will fix the travis issue.,1
"Also, in general, to avoid messy git history commits, you should not use your master branch for PRs.",1
You should keep it to have a copy of the remote master branch locally. (lots of unrelated commits in this pr as you can see because of the merge).,1
"What you should do:

1) Delete your fork (but keep a copy of the changes somewhere)
2) Create a fork of keras again
3) Clone your fork
4) Add keras as the upstream repo `git remote add upstream https://github.com/keras-team/keras.git`
5) Update your master branch frequently by doing `git checkout master && git pull upstream master`
6) To make a PR create a new branch from your master `git checkout -b branch_for_PR_42`
7) If you want to update your PR branch, update master with `git checkout master && git pull upstream master ` first and then merge master into your branch `git checkout branch_for_PR_42 && git merge master`.",1
You'll be able to do multiple PR with one single fork and also avoid the many many commits added when merging like what happened here.,1
"Also it feel like a bit of a niche use case, and one for which you could roll out your own layers. But I'll leave it open and consider later on.",1
"Alternatively, it might be better to make it a parameter specifying which axes _aren't_ shared, in which case you could call it `unshared_axes`, and default it to the channels/features axis.",1
"So that you could implement the layer in this PR as:

``` python
model.add(TimeDistributed(Highway(Dense(32))))
```",1
"We won't merge it, but you could write an example script based on it if you're interested.",1
"You could just iterate over `dir(tf.keras.initializers)` and retrieve `x.__name__` for functions, or `x.__class__.__name__` for classes.",1
I would recommend that you keep this functionality as a utility function outside of Keras.,1
@kemaswill the repo is ready you could open a PR [here](https://github.com/farizrahman4u/keras-contrib) :tada: !,1
You could take a look at the errors [here](https://travis-ci.org/fchollet/keras/jobs/107955300#L780-L789).,1
"* You could build a version where the ht0->ht1 function is shared between the encoder and the decoder, or not.",1
I could imagine advantages and disadvantages to both.,1
It would be useful to me.,1
"Besides, this wouldn't scale to more than a one-time download --you couldn't train a model like that.",1
"If the goal was only tensorflow support, you could always call `tf.range()` within a keras model on the tensorflow backend.)",1
Maybe you could rewrite it along these lines?,1
"Alternatively, you could look for a solution, on the Theano side.",1
Very easy for a user needing this to set that up (you could set verbose to 0 everywhere and either call logging in your own code or from a custom callback).,1
"For your case you could as well do something like:
    ```python
    if self.model.uses_learning_phase:
        feed_dict[K.learning_phase()] = 0
   ```",1
Until this is fixed here you could use my branch and see if you get the expected results (it's based on v2.7),1
"Alternatively, you could get rid of `embeddings` and use the batches (in numpy array format) returned from a `sess.run(...)` in `on_epoch_end` to build up the overall (n_samples, n_hidden) array for each embedding layer and then assign to the `embedding_vars` in one shot with e.g. `K.batch_set_value`.",1
"Yes, precisely you could set `layer.params = []` before calling `.add(layer)`.",1
The effect would be the same.,1
"For fine-tuning, you could do something like:

```python
# Set up inference-mode base
K.set_learning_phase(0)
inputs = Input(...)
x = layer1(...)(inputs)
x = layer2(...)(x)
...
x = layerN(...)(x)

# Add training-mode layers
K.set_learning_phase(1)
x = layerNp1(...)(x)
x = layerNp2(...)(x)
```",1
"As for suggestions, maybe you could pre-compute a bunch of augmented vectors as well?",1
Or it might work to create a generator (to train with `fit_generator`) which does both augmentation and creating the vectors.,1
"You could use something similar to the following:

```
import copy
tf.keras.layers.BatchNormalization._original_call_function = copy.deepcopy(tf.keras.layers.BatchNormalization.call) # We potentially need this to be a different object to avoid recursion
def non_trainable_call_function(_self, inputs, training=None):
    return tf.keras.layers.BatchNormalization._original_call_function(_self, inputs=inputs, training=False)
tf.keras.layers.BatchNormalization.call = non_trainable_call_function
```",1
"Alternately, you could recurse through only your frozen model and individually set the call functions of the layer if it is an instance of `BatchNormalization`, rather than changing the global behaviour.",1
"Alternatively, you could also create your own logger callback.",1
"The feature visualization example in Keras does this, you could just copy from there.",1
"I was thinking something like this..

``` python
class OptimizerScheduler(Callback):
    def __init__(self, schedule_func, param_name='lr'):
        super(OptimizerScheduler, self).__init__()
        self.schedule_func = schedule_func
        self.param_name = param_name

    def on_epoch_begin(self, epoch, logs={}):
        getattr(self.model.optimizer, self.param_name).set_value(self.schedule_func(epoch))
```

.. and if there's more than one hyper-parameter, you could add multiple callbacks.",1
"You could try training a network with the old implementation, then saving it to disk and verifying that the outputs are the same at test time after loading it and running it with cuDNN.",1
I'll let you add the `test_callbacks.py` so you could impose some structure.,1
Perhaps another way you could implement this is to check for `self.output` and if it is set you can use `self.output.dtype`.,1
It would be a much smaller change confined to just the `base_layer.Layer` method.,1
"Without going into too much detail, you could imagine factorizing a matrix into three matrices using SVD.",1
Similarly you could implement them as deferred-execution functions.,1
Note that you could easily support 1D convs by implementing them as 2D convs.,1
"If you're willing to go all out, you could internally modify `model._compile()` to create a whole new network with input tensors by copying the existing network and weights over (and then back).",1
"edit: failing a pep8 test, I'll take a look in a bit and push again",1
"If @fchollet ask to expose this variables too, then I will do that.",1
But I think the best is to give meaningful comment in documentation about these values. (I actually will do that in doc-string I guess).,1
"It is, however, possible that I completely misunderstood the concept of nodes and that is what lead to the insertion of this condition regarding the multiple 'inbound_nodes'. 
(I also thought of checking if a node has multiple outputs but that seems to never be the case so I only inserted the check with the 'inbound_nodes')",1
It is however very interesting that the get_config() output always has 'inbound_layer**s**' (even if there is only one element in the list) and always has **one** 'outbound_layer' (even though the result of the node could be used multiple times in the network).,1
"Can you evaluate NASNet large with the current weights on the ImageNet validation set to confirm this? (I dont have the validation set, else I would run it myself).",1
"Also, another update, tt will take 3 more hours to finish building all of the weights.",1
"Edit: Since Keras version will not be supporting the CIFAR variants of NASNet, it is probably ok to drop the `skip_reduction` flag entirely.",1
"If evaluations locally on some sample images work out properly, I will upload them to my repo after that, which will probably take another hour.",1
"While I am currently building the weights again, I believe the current NASNet large weights are correct with this fix.",1
"For now it's not a big problem because Keras will just use the current version, but I might have to come back with a new PR if the Theano interface does change before it is merged. (I don't know if it will. I obviously think it's very good the way it is now, but it hasn't been thoroughly reviewed.)",1
"It raises an exception which is probably what should happen. Printing out a warning instead would work too, I guess.",1
I guess it is typo.,1
I previously had a PR open for this but I guess it got automatically closed when I reverted my commits...,1
"According to this, I propose either add extra requirements for testing (I guess, vast majority of devs already has this anyway), or tune tests skipping with respect to available modules.",1
- This would disambiguate floats from integers I guess,1
I guess the correct one is https://www.tensorflow.org/guide/estimator#create_an_estimator_from_a_keras_model,1
"If you want to follow the paper more closely, I guess you should also weight decay.",1
"This would also be nice to show in an example as it's important, but only described in the documentation (not in the examples afaik).",1
so that's another `keras-extras` function I guess,1
I guess this is already being tested?,1
I guess we're basically waiting for relevant reviews/reviewers...,1
It's the big model I guess.,1
This is merged so I guess it can be added in a separate PR.,1
I guess in subclassing API there are fewer loops as they are only stacking blocks (e.g. STEM might be treated as a single layer).,1
"I'm glad there is a solution for those of us with models that have variable input output sizes, but I guess it's too niche to justify an API change",1
"I guess we could try to diff the passing tests [here](https://travis-ci.org/keras-team/keras/jobs/421671864) with the passing tests on a successful run, and try to figure out which tests could be causing this.",1
"I guess 1 if all the timesteps are equal, 0 otherwise?",1
I guess the travis server was busy.,1
So I guess we should stick with just contributing to keras-team/keras and the TF guys will port it to tf.keras.,1
"For the standalone example, this makes sense I guess.",1
_side note_: I guess a similar problem would also occur when wanting higher `beta` values in the newly introduced [`fbeta_score`](https://github.com/fchollet/keras/blob/4de7eaa6a80fd4257b866a6b695450c40b72dd28/keras/metrics.py#L96) metric.,1
I guess that also solves the issue with security?,1
@PavlosMelissinos There is one more issue regarding multiple masks I guess..,1
"While the tests seem to pass, the code is ugly so I'll just push a new PR following your suggestion (something like the tests for the merge layers should be enough I guess).",1
I guess the blog's value (95%) needs to be updated to 71%.,1
2) I guess the problem may lie in callbacks and commented out the callbacks.,1
"I guess I'll subclass, though there is something to be said for having ""batteries included"" when it is to allow a common task like including the learning rate.",1
"I guess we won't include tests to be run on Travis, but we should at least have one test script that we can run manually on a multi-GPU machine (e.g. a EC2 instance).",1
It isn't autogenerated I guess.,1
I guess we can go ahead and merge this PR.,1
"First let me specify in detail. (I guess you actually ran `example_new.py`, right?)",1
"So I guess send a pull request, and we'll see what fchollet says. :)",1
I guess this is not a logical error. It is as it should be.,1
"On adding `topN=2`, I got `RuntimeError: Node 'ClassificationError325' (ClassificationError operation): Expected MBLayout in Input 0.` so i guess its broken.",1
So i think its best to skip cntk backend in the test for now. (Unless you want to re write the in_top_k impl :p),1
"@udibr , I was trying to find out is there any better way to do updates, and I guess I'll have to use similar way you used.",1
"So far since the PR author is not cc'ed on the PR, so I guess @haifeng-jin also missed your comment.",1
But I guess if the goal is to match the tf.keras behavior then that's fine with me.,1
@rchao I guess this can be closed since #17366 is a better approach.,1
"I haven't had any luck setting up a `test.py` to test manually in pdb or otherwise, it seems that some protobuf compiling and such is needed which I guess Bazel does automatically.",1
"That is what we were doing, but `object.__reduce__` doesn't support models that have those weakref-based wrappers (which I guess are part of the parametrized tests but no the existing `copy.copy` test that is now failing), which is why back at https://github.com/keras-team/keras/pull/14748#issuecomment-867237966 we had decided to only support unbuilt models.",1
"I like what you did with the regularizers, @fchollet , I guess I was too worried about compatibility, keeping the gradient-updating regularizers :-)",1
@kenterao's suggestion sounds good to me.,1
"Yes, I guess you are right.",1
"Maybe for the example of Add()
```python
sum = Add()([x1, x2])
# sum = add([x1, x2])
```
and the other way around for add().",1
"But I guess there's a reason you keep both of them, so better examples would contain the most suitable cases.",1
PS. will replace `sum` with `added`.,1
I guess this change will solve almost all of problems in the PR.,1
"Theano and Windows is a dark art, 14th times a charm I guess.",1
"Step had actually referred to your code: `step = min(self.batch_size, n_samples - i)` I guess. Long story short, assign as many samples as you have in your current batch.",1
"@fchollet Thanks, I guess I finally learn how to do this.",1
I guess for now I will freeze everything at training and test time in BN layers from pretrained conv nexts and hope that the optimization process can fix this weirdness.,1
But I guess from your blog that your fix actually "freezes+locks" all the BN layers during the training phase in transfer learning.,1
"I guess that on Windows, using a `multiprocessing.Manager` is not good?",1
I know it's 1D but the input shape is handled differently and still looks like it has more than one dimension. (I guess I should just play with it more).,1
I guess the errors may happen when framework doesn't run in eager mode.,1
"I guess a bird in the hand is worth two in the bush,
IMO in future PR the embedding data callback parameter should be removed, the embedding writing  should be done the same way the histogram writing logging is done, i.e. without calling sess.run directly from the callback.",1
I guess a similar solution could work for that too?!,1
That was a little bit too radical I guess.,1
"I guess it is because `self._inbound_nodes_value` is only applicable in symbolic mode, but I am not sure.",1
"Is looks like `timeseries_dataset_from_array2`, which I guessing is the new version, is actually performing noticeably worse. Is that correct?",1
We will probably not be able to land this with a performance regression.,1
"A 'min' or 'max' mode (string), without automatic `None` option would be more intuitive for me (but less flexible and fool-proof I guess).",1
"And for the name, You are right, I prefer the one I choose, but I guess it was a personnal choice",1
For the name I guess it is better to use the name which is widely used.,1
I will change it tomorrow.,1
"For the statefulness, I added the same tests than for the classical RNN, so
I think it works fine.",1
Maybe I could try to use it in the example to confirm that it works.,1
"@bstriner I think that your patch is way better than the current system, which has obvious shortcomings (and your patch in fact is easing my pain in a current project to write a new keras layer).",1
I guess the real question is what kind of short and medium term solutions keras wants to live with.,1
"This way it can be turned up to help avoid over-saturation, without making everything darker. (I haven't seen this before, but it could be good to swap L2 or add an additional loss with absolute difference in chroma where chroma is the max across channels minus the min across the channels.)",1
"Should it really be a parameter of Layer ? (I still thinks, this is more Optimizer related, than Layer related)",1
(I will submit a PR for the demo if/when time distributed merge is pulled),1
"I can't see any reason why we append `constants` to `states` inside `rnn`, this case is not motivated by ""flat list"" requirements from Topology linking. (If completely ignoring legacy, I'd rename `step_function -> cell_function` as well).",1
"@jonilaserson You're right, Generators won't go away anytime soon. (Will remove the warnings and change the docs).",1
"If @fchollet approve the optional dependency, I'll remove the warning and make `GeneratorEnqueuer` the default.",1
(I'll try to make it work with a `Pool` from `multiprocessing` this would remove the dep),1
"Do the aliased functions still show up in the generated documentation?

(I'm not familiar with MkDocs, and I couldn't quite get it to work, so I'm asking here).",1
"In my opinion, the performance of the current version is not bad in terms of both memory and speed.",1
I double checked my bidirectional RNN code and looked closely to the theano scan implementation and i found an error where the return sequences flag is active. (it actually return the reversed sequences that may cause failure in particular where stacking Bidirectional Layers.,1
I also added `target_transform_save` to be able to save the output result if necessary. (it's maybe not necessary since the function can be integrated in each `target_transform`).,1
"Are there any examples of loss functions that are not averaged across all datapoints? (keep in mind that if such a loss existed you would not be able to calculate it by averaging across minibatches as we do now, external to the loss function).",1
Perhaps the difference between th and tf is bigger than we expected.,1
And I think this difference would be the souce of many unexpected bugs.,1
"If what you're doing is significantly different from that, then rolling out another function would seem reasonable.",1
"Your `Masking` return something of the same shape as X, but it should return something of with one less dimension, i.e. (nb_samples, nb_timesteps, nb_dims) -> (nb_samples, nb_timesteps)",1
"I can't look at it more closely right now, but this is a signal that something might be wrong.",1
"I did try to return a mask of (nb_samples, nb_timesteps), and it seems to return the same results (see the branch for the change, results are in file padding2.log).",1
"But this part seems quite complicated and difficult to follow:

``` python
network = make_network(layers, phase)  # obtain the nodes that make up the graph
if len(network) == 0:
    raise Exception('failed to construct network from the prototext')
network = acyclic(network)  # Convert it to be truly acyclic
network = merge_layer_blob(network)  # eliminate 'blobs', just have layers
reverse_network = reverse(network)  # reverse, to obtain the network_input
network_inputs = get_inputs(reverse_network)  # inputs of the network - 'in-order' is zero
network_outputs = get_outputs(network)  # outputs of the network - 'out-order' is zero
network = remove_label_paths(network, network_inputs, network_outputs)  # path from input to loss layers removed
reverse_network = reverse(network)  # stores the 'input' for each layer
```",1
I'll look into it.,1
"I haven't looked at the issue and at potential fixes in detail, but I think the fix is potentially bug-prone because of the use of `id`.",1
This would only work with symbolic tensors.,1
"Maybe in `def losses(self)` we can keep track of the origin of the losses, and de-dupe at that stage.",1
"No output has been received in the last 10m0s, this potentially indicates a stalled build or something wrong with the build itself.",1
"The
>   messiness potentially derives from both my own coding skills, and from the
>   limited set of functions supported by the backend (see below).",1
"The c2c loss looks like the same as the mean identity loss that was part of this PR way back -- so, that's an option, potentially.",1
I think the method consisting of getting the shape and instantiating a new ones tensor from it would be a lot cheaper than reshaping a potentially large tensor then instantiating a ones tensor from it.,1
"Getting the shape is free, reshaping a large tensor will involve a memory copy and some compute.",1
"From the CI:
```
No output has been received in the last 10m0s, this potentially indicates a stalled build or something wrong with the build itself.
```
Seems like a timeout.",1
I really don't see how the piece of code I have written can potentially break this test,1
But I think it would potentially result huge memory usage when `batch_size` or `output_shape` is large. **EDIT**: ~~`batch_dot` doesn't fit this situation.~~,1
I will do some experiments to see if aggregate multiple `K.dot` can speedup computation.,1
"To do so, I introduced a very simple `convert_weights` method in `Layer` that takes a list of weights and the backend that the weights originated from and is expected to return a potentially updated list.",1
This allows other layers that might have similar needs in the future to implement this behavior rather easily.,1
This is also a potentially breaking change.,1
Potentially conflicting (but also very useful) PR of note: https://github.com/keras-team/keras/pull/7617,1
Potentially this can easily blow the memory of the machine if sequence has a lot of information and you a lot of processors.,1
"Also, a potentially relevant generalization of trainable: perhaps we could have a parameter for each layer containing a multiplicative factor associated with the parameter updates at that layer?",1
"I also agree that overwriting objects is _potentially_ a feature; non-explicit substituion of implementations is however, a little scary to me.",1
I feel like you probably more often want to just edit the code and do it explicitly.,1
`X` is always a list of inputs (potentially of size 1).,1
"`len(X)` is **not** the batch size, it will typically be 1, or 2, etc.",1
Two things we could potentially do:,1
The directory potentially doesn't exist.,1
"I could potentially move this to the get_gradients function and loop over zip(params, grads, regularizers) so the get_gradients function returns the regularized gradients, somewhat similarly to what you have now.",1
"The only exception would potentially be string values, where it matters less, but even in this case backquotes are still better.",1
It allows users to have control on metrics collection within `compute_metrics` (by potentially removing them) while being safeguarded by the epoch level collection.,1
"I understand that this warning is to potentially spot channels_first/channels_last mixups, but the false positives [are causing problems](https://github.com/keras-team/keras/issues/11538).",1
"This DCGAN example code structure is also very different from ACGAN example (which is far from perfect), but it makes unnecessarily harder to understand both and to potentially have the same code structure for many/all GAN examples in the future.",1
"This is a potentially valuable feature, but since Keras layers are interoperable with TF layers, we could only introduce it in Keras if it is also standard in TF.",1
I.e. it should be supported in TF layers and `tf.get_variable`.,1
This is a potentially breaking change.,1
We would need to resolve the concern about this being a (potentially breaking) behavior change before we can merge.,1
"It would also be a breaking change (it would potentially change convergence behavior), so I think we should avoid it.",1
Sounds like a potentially serious Theano bug.,1
"The reason why the fix proposed here is reasonable is because:

> I do realize that this is not optimal since this means that we encode a potentially high-dimensional vector into the configuration.",1
In general it will be rather small.,1
"This is potentially confusing though, so a warning would be great!",1
"This is also compatible with `GeneratorEnqueuer`, since every generator could potentially raise `StopIteration`.",1
With full access to the internet and the ability to execute potentially long running code on our servers people can certainly do a lot of harm.,1
This could point to implementation correctness issues with LSTM (and potentially other layers as well).,1
My initial thought is that making our objective polymorphic will potentially create issues where we can't tell whether or not inputs are expected to be expanded..,1
"Another solution would be to translate the ones from PyTorch, potentially forcing the bias to 0 for the original implementations with bias.",1
"I advise the reviewer to be very careful, as this PR can potentially break many pages in the docs.",1
"The messiness potentially derives from both my own coding skills, and from the limited set of functions supported by the backend (see below).",1
Edits are allowed for maintainers so a patch fixing the bug could potentially be added directly to this pull request.,1
We want to avoid using the global numpy random generator as much as possible because it could potentially modify the behavior of other methods calling it as well.,1
This will potentially generate wrong order between the ops after the pass.,1
"Before implementing: ``AUC``, ``Confusion Matrix`` (``FP``, ``FN``, ``TP``, ``TN``) and potentially the rest of https://www.tensorflow.org/api_docs/python/tf/metrics, I wanted feedback on the first 2 metrics.",1
"E.g. if `iterations` is read before it is updated, two threads running the code concurrently would end up with the same value of `iterations` before each incrementing the variable once, and thus potentially computing the EMA update twice or not at all.",1
I am not using flynt's `--aggressive` to avoid _"conversions with potentially changed behavior"_.,1
I do realize that this is not optimal since this means that we encode a potentially high-dimensional vector into the configuration.,1
* `if self.seen < self.target` is checking for training iteration being not finished but in case of degenerate case with zero length it will not be called and `log_values` will stay not initialised but i don't see any explicit logic preventing using it on exit from 0-length training cycle and potentially it is the bug of some kind that is prevented on caller logic level,1
"This PR is intended as a discussion of the function of masking in the `TimeDistributed` wrapper, with some code to potentially demonstrate a different way it could work.",1
"It's certainly possible that we have mis-used `TimeDistributed` in a way that you have not intended - if this is the case, please just say and close this PR.",1
"- everything, modulo a few things that were overlooked and a few potentially remaining bugs (only one is currently known, fix pending).",1
**TL;DR**: The second bug would cause a `GeneratorEnqueuer` instance to stall potentially causing a deadlock.,1
Updated ISSUE_TEMPLATE.md to potentially help cut down on the github issues that are just implementation questions.,1
"However, RandomStreams does not take 0 as an input for seed and using numpy.random.randint(10e6) can potentially generate 0 as an output (even though it is very unlikely) and it will result in the following error:

```
ValueError: ('seed should not be 0', 0)
```",1
"So I modified the code to be

```
    if seed is None:
        seed = np.random.randint(1,10e6+1)
    rng = RandomStreams(seed=seed)
```

and seed will have a new range [1,10e6] compared to the previous range [0,10e6-1] and we can avoid running into ValueError.",1
It's necessary to make ```GlobalAveragePooling1D``` support masking as the sentences are very likely to be padding with zero.,1
"This is problematic for any schedule that uses functions from `numpy`, which will most likely return a learning rate of one of numpy's dtypes (`np.float32`, `np.float64`).",1
Note that accuracy for ResNet1001v1 is likely a typo in the v1 paper (in reality it's probably for ResNet1201v1),1
"Therefore, it's likely that the mismatch between TensorFlow 2.10 and Python 3.10 is causing the error you're experiencing.",1
"In MobileNetV3 docstring, the model is often referred to as `ModelNetV3` which is most likely a typo.",1
"Reason for this is that by randomly sampling from a dataset with relatively large number of classes (specially if balanced) and a small batch_size, it is highly unlikely to produce any positive pairs in most batches.",1
The NotImplementedError now describes two likely root causes of the problem.,1
Note: It'd be a good idea to add a subsample / stride example in the near future as there are no tests / examples of that within Keras and it's non-trivial but that's likely a separate issue.,1
"2. For example, if `shift_range=2`, it is sampled from `[-1,0,1]`, but 0 will be oversampled (which is likely a good thing).",1
Or I suppose the layers could not be connected up correctly but that seems unlikely.,1
"As long as you are not overfitting, then deeper nets are likely to help.",1
But I can't really tell if it's sorta improving (a bit more likely) or simply suppressed earlier random spike(s) (a bit less likely).,1
You'll likely have to declare it with `def` then.,1
"Note that we aren't likely to add new MNIST-like datasets, since we already have MNIST and FashionMNIST.",1
"In other words, any value within the given interval is equally likely to be drawn by uniform.",1
"I think it would be useful to restart on timeout the tests that are causing the timeout, which are most likely tests related to `Sequence`/etc.",1
I think the problem is likely not *all* tests related to multiprocessing. There's probably a small number of tests that cause the issue.,1
"If we think about future research leveraging EfficientNet, it is very likely that such papers will refer to the B0-B7 mappings instead of reporting any `phi`.",1
"Thus, the vast majority of users will look for one of these 8 variants and never choose any other `phi` than the 8 fixed ones.",1
"I unfortunately got too involved with other issues in life and haven't had
the time/priorities for this particular task, and likely won't any time
soon.",1
"I presume, when I'm working on another Keras model again, the output
will bother me and I might return to it at that time...",1
"I tried, but couldn't.",1
"Its diminishing returns at this point, so its unlikely that I will spend more time on this.",1
"* Changing the order of the batches can cause users to wonder what is going on (silent unexpected behavior) if they overlook the warning, but this is unlikely to happen in practice.",1
"You can submit the same PR in this repo and it's much more likely to get merged:

https://github.com/keras-team/keras-contrib",1
(Note that such a change will likely syntactically conflict with #5049),1
"After looking at (what I called ""apparently"") bug where https://github.com/fchollet/keras/pull/704 logic is missing from verbose=2, the ""bug"" seems to me like a convoluted feature, likely not used by anyone, except the original author @rodrigob.",1
"Maybe it's best to remove it from verbose==1, rather than introduce it into verbose=2?",1
But it would be an API change.,1
"The CONTRIBUTING.md file states:

> Please note that PRs that are primarily about code style (as opposed to fixing bugs, improving docs, or adding new functionality) will likely be rejected.",1
I'll close this PR.,1
"See CONTRIBUTING.md:

""""""
Please note that PRs that are primarily about code style (as opposed to fixing bugs, improving docs, or adding new functionality) will likely be rejected.
""""""",1
"Here's the error:
```
ImportError: cannot import name 'layers' from partially initialized module 'keras' (most likely due to a circular import) (/home/kbuilder/.cache/bazel/_bazel_kbuilder/31d6f47147b75c35404d734345be7323/execroot/org_keras/bazel-out/k8-opt/bin/keras/utils/data_utils_test.runfiles/org_keras/keras/__init__.py)
```",1
"If you want to force-change the dim ordering setting within a script, it's safer to use `K.set_image_dim_ordering('th')` at the beginning than to specify a `dim_ordering` everywhere, you're less likely to miss something.",1
I'll do that,1
I suspect it is a bug in the test file which is likely caused by the messy code. :),1
I will look into it when I have a little more time on my hands.,1
You likely get the same error if -1 is replaced with some positive integer.,1
And the performance benefit will likely be only a few percent.,1
I don't think this is going to be implemented anytime soon.,1
I think it's a good idea to actually benchmark my solution against #6928 to see what the difference really is.,1
@fchollet NLP-related tasks are the most likely to have int outputs (at least during test/generation).,1
It also seems likely you'd want to understand the relationship between the performance of the weighted and unweighted metrics as you tinker with your sample weights.,1
It's more likely related to TensorLikeDataAdaptor setting `check_all_flat=True` when it calls the function.,1
Now it would be neat to have tests for these two modes: most likely a new method in `test_sequential_model.py`.,1
"That should most likely fix the failing test (if it doesn't, there might be a deeper issue).",1
"Having the keys ""text"" and ""sequence"" in the namespace is a problem, because they are likely to collide with other variable names (esp. ""text"").",1
"Yes, possibly a version error.",1
You are supposed to be able to import preprocessing directly: https://github.com/keras-team/keras/blob/master/keras/__init__.py#L10,1
"Also, we are generally unlikely to merge PRs that are solely about code style.",1
I don't think it makes the code more readable or Python.,1
"Interesting refactoring, but using generators of generators will likely confuse newbies and make the final code less readable.",1
"I would recommend:
- move `test_caffe_conversion.py` to `tests/auto`. You can put the auxiliary file on S3 and fetch it with `get_file` (if you want I can put it on S3 for you). 
- remove the `keras/caffe/test` folder and its contents.",1
The cleanest way would most likely be to generate it from `caffe.proto` at installation time.,1
"Batches may be very small, so only sampling `batch_size` worth of data points is likely to lead to very inaccurate histograms.",1
It would be safer to go with the first solution you mentioned: iterated calls to `sess.run`.,1
Code will be released most likely this Friday and it will become the master branch in a couple weeks.,1
"@mhajiaghayi ,  I can't say for sure but it's very likely related to this issue.",1
"Because it's most likely not desirable to create the `tf.train.Saver...` and the `ProjectorConfig` over and over again, I don't see a way to simplify the interface.",1
"Best I can tell, it's likely just a matter of checking for empty arrays and skipping those.",1
"Besides, since `fit` support some special cases that `fit_generator` doesn't, it is not likely that users can easily migrant their `fit` implementation into `fit_generator` when `fit` is declared as replicated.",1
"In this case, merging training procedure will be necessary to meet every needs.",1
I don't know if the speed is currently your main concern for reopening this but I would say that this is unlikely to affect the majority of the users of Keras.,1
Just updating the applications API will not fix the problem as most likely you need to apply the same patch on load_model().,1
At any case I hope someone will patch this on the future as the effects of the problem are likely to affect lots of people and they might not be aware as it has similar symptoms as overfitting.,1
"Although I read @fchollet 's explanation multiply times, this exceeds my comprehension (although it is very likely that I'm just too stupid).",1
I will try to setup keras with the patch - unfortunately have not managed to get it to work just yet.,1
If your training accuracy is high while the validation one is low and you use a pretrained network and freeze large number of layers then you are likely to be affected.,1
"The problem masquerades itself as overfitting, but it might be caused by the BNs.",1
"I think the best way to confirm is either to set a static learning_phase to 1 one the very top of your script (that's not a solution just a way to confirm the problem) or install the following patch and retrain: 
```
pip install -U --force-reinstall --no-dependencies git+https://github.com/datumbox/keras@fork/keras2.2.4
```",1
"Though I've been maintaining this fork for some time now (and I plan to continue doing so), please note that you will be messing with custom forks which is always suboptimal.",1
"@george-gssy Based on your description, you might be affected.",1
"That this ""can't be changed after model compilation"" isn't a serious limitation, as models can be easily saved/restored [uncompiled](https://github.com/keras-team/keras/blob/master/keras/engine/saving.py#L568), and you're likely loading models for transfer learning anyway.",1
"Another alternative is to modify `K.epsilon()` so that the following works: 

`self.epsilon = K.epsilon(epsilon)`

but this would preclude combining K.epsilon getter and setter in the future (not likely to happen anyhow). On the plus side, `K.epsilon(epsilon)` could warn about nonsensical `epsilon`.",1
"If Multi-input-output layers get implemented in the future, they will likely replicate `Graph` API, so it will work with those layers too.",1
I think in [#302](https://github.com/fchollet/keras/issues/302) someone suggested that Sequential should be the introductory model for new people but experience users will most likely use Graph models.,1
"The use case for Rx seems to be high-throughput event-based concurrent applications, whereas training a Keras model involves only a few event types (unlikely to increase) which are not called that frequently, and are not called concurrently.",1
"The following API

```python
model.compile(..., weighted_metrics=['accuracy'])
```

could be a good solution. But the initial proposal is likely to be more user-friendly.",1
"I'm pretty sure the keras nasnet model still has some problems, in other words they are most likely extremely inaccurate on keras compared to tf!",1
So it is unlikely that I can get some tests setup for this in next few weeks.,1
"Commit af46ab0d4dc981b899fe6c82c1712e95f251a118 appears to have broken the Kaggle Otto example, most likely at optimizer level.",1
"@codekansas your changes have likely modified the behavior of the RNG somehow, so a deterministic test went from passing to failing (it's not really failing since it reaches the expected accuracy...).",1
"Folks are likely to very purposefully be using symbolic vectors with keras models, so a separate function call might make sense",1
"However, we will keep the array-based and generator-based implementations separate for the time being.",1
"They may merge eventually, but that is unlikely, and if it happens it won't be until some extensive refactoring of the Keras engine that are in the plans.",1
This PR will most likely be closed anyhow,1
If you have unequal batches this is likely to be a big issue.,1
"Also, it would be interesting to know which of your many changes actually fixed all-black generated images.",1
That is likely the most important one.,1
This is quite likely.,1
I think you could simply change that line to do a manual casting.,1
"Previous failure is a sign that Theano versions before were likely using a buggy implementation of max pooling, and that it is fixed in the current version.",1
This is all in line with Theano's manual (which was likely written before @yaringal's paper).,1
"This is most likely due to the labels, which are 0 and 1.",1
I don't think we want to take a dependency on the pre-commit package.,1
This is a quite heavy weight solution to fix something we can likely do with a simple shell script.,1
I think it is highly likely related mix usage of local keras workspace and pip env.,1
I think we might as well implement a general and extensible system from the start.,1
That sounds good.,1
"It seems like the weights for the fully connected layers were transposed incorrectly, but otherwise the weights and biases for the convolution and fully connected layers all matched up with caffe.",1
"It probably isn't the group parameter since I checked the weights against caffe's after the model was imported, but it could be an issue with pooling or relu layers (made changes [here](https://github.com/asampat3090/keras/tree/caffe)).",1
It probably does have to do with how the image is interpreted though since I've verified the weights matched up with the caffe blobs for each layer.,1
"It's probably unrelated, but I'm reverting until we figure it out.",1
"This probably also needs a sparse input layer, but I thought I would get some feedback on this before throwing too much time into it.",1
"Theano also supports more sparse formats, though for batch training I expect columns > rows for cases where you actually want a sparse matrix, so I think that using a CSR representation by default in a sparse input layer is probably fine.",1
"you should probably move this to the keras-2 branch because of the keras-1 PR freeze, and of course fix the CI test failures",1
The Merge layer does not look like anyone has created a conversion yet and will probably be a bit more messy since it looks a bit different in Keras 2 from what I can tell.,1
"Still, the situation in which you need to change this value is probably rare, so I do not have problem with staying with `1e-12`, if there are some reasons to do so.",1
"Agreed, it does not seem crucial to have it in the API.",1
You're probably right.,1
Thanks! I'll probably try to implement some other things first since beam search is not super critical for the numpy backend.,1
"Sadly that probably means no Python generators, nice as they are.",1
Looks good to me.,1
"I do think it makes sense to update the API of `GeneratorEnqueuer` to reflect the fact that parallelism isn't really possible at all, but that is probably out of scope for this PR.",1
"I checked on other failing CIs and it seems to be present in a lot of places, so it's probably not due to a bug introduced by this PR, but rather by something that slipped through (see [here](https://travis-ci.org/keras-team/keras/jobs/567810637#L2978), [here](https://github.com/keras-team/keras/pull/13191#issuecomment-518377540) or [here](https://travis-ci.org/keras-team/keras/jobs/568396840#L2935)).",1
We should probably only have `EfficientNetSmall` and `EfficientNetLarge`.,1
Probably the best thing to do is to attempt to bisect the test codebase until we find which tests are linked to the timeout.,1
EDIT: RAM could cause this as well and this is probably one of the reason.,1
"But for those power users who want to control where thing are and probably do more with those logs, we can configure logging to do better things.",1
ETA is probably around January.,1
Then we should probably update the documentation for the other backends.,1
"I do see this bug with ResNet18 and MobileNetV2, although they are probably still too heavy for testing purposes.",1
"No sure what the best solution is, we should probably change the behavior of save model.",1
But right now you should probably avoid double nested model with both trainable and non-trainable params (e.g. BatchNorm),1
It seems a fair number of items like this probably exist but could be easier to discover in the [tf.keras docs](https://www.tensorflow.org/guide/keras).,1
But we should probably leave that for another pr.,1
"This is missing, I’ll add it.",1
"I suspect you'll need to both open a new issue (since this old and merged PR is probably not the place to discuss this new issue) and also provide a lot more detail, such as keras library version, operating system, and ideally a runnable piece of code that reproduces your issue for the maintainers to look at.",1
"Without this additional information, it is impossible for anyone else to have any insight into what is causing your problem.",1
"When you call stop, these threads wait indefinitely and that's why probably your tests are stalling.",1
"Mean identity error is good for hierarchical softmax,
>   because the layer outputs the negative log probability of the correct class
>   -- this is something that should probably be minimized.",1
"Batch norm seems to deal with this by having an extra set of functions in the backend that are highly specialized, but that probably isn't ideal in this situation.",1
"However, your symbolic HSM could probably be translated into keras backend code, and used from there.",1
"The takeaway here is that using multi-character splits is definitely slower, but probably just as a result of building/reading longer strings rather than as the result of these changes.",1
"Users should probably prefer to use single-character `split` values where possible (and seeing as this issue wasn't previously discovered, I suspect most already are).",1
"There's a bit of weirdness (I expected the `replace` implementation for multi-character `split` on Python2 to be slower, not faster, than the `translate` Python3 implementation), but I don't suspect it will have user impact.",1
This was released 2 days ago so probably reflects the most recent changes.,1
There is probably no cost about doing that (Would need tf team to validate).,1
There is probably no cost about doing that,1
It sounds like it would be a reasonably reliable way to do it.,1
"Would probably break the model reading, writing.",1
"However, I think that currently, stop signal will not be sent to these threads if fit_generator() raises an exception in a bad moment - so the patch should probably setup a try-finally within the generator functions and move _stop.set() to a `finally` block.",1
Though just throwing NotImplemented is probably not the right approach for that; maybe making the Theano implementation a no-op?,1
Looks like Travis is failing again.,1
We will probably have to update the Travis config to fix that.,1
I'll look at it later today / tomorrow.,1
"Maybe, an option in the example would be a good idea.",1
but it's probably not worth it.,1
You should probably squash the commits.,1
"It would be too verbose to put melgram into name, but probably something like `music_cnn_tagger` and `music_rnn_tagger`?",1
"The new training is almost done now, will PR in 1-2 days.",1
"I can just update the keras on my server to 1.0.8 and run it again, but probably you also wanna fix it if there's a problem.",1
"This is probably the commit we need to look into: https://github.com/fchollet/keras/commit/97d2a73dd36e90a3502c575a8ea93125e894c84a
and follow-up: https://github.com/fchollet/keras/commit/05883934f1b9a13e09a46ec6845927d9397f3540",1
First we would need to know if and when the problem arises...,1
Probably the `std`(in weights learned in 1.0.6) should be changed to `std ** 2` to be used in 1.0.8?,1
I'll test it.,1
I will train it again anyway.,1
"To make sure we have separation of concerns between trainability and updates, it's probably best for this attribute to *only* act on updates (no effect on trainability) and to explicit mention updates in the name. Like, `freeze_updates`.",1
I'll probably try to tackle this `TimeDistributed` layer business in the next few days.,1
I use these guys a lot so some abstraction would be nice.,1
"Yeah, I think `invert` as an argument make sense.",1
"We should probably also show an example of this in the docstring, taking some data, first normalizing, then inverting.",1
"As long as the docstring is explicit about what it does, either name seems fine to me. `reduction_axes` is probably the best.",1
"This suggests that you probably need to return (Y, updates) tuple from the 'call' in the general case.",1
Most of the time you probably don't want to use `K.repeat`.,1
Maybe we should rename it to `repeat_vector` for added clarity.,1
Probably we could first have layer and backend and then discuss how to deal with the examples.,1
"So if you need to post any comment on the PR, probably just put an @ for the PR author which will notice us via normal github notification.",1
"if mask is not None, I can get out of the loop the exand_dims and tile operation,
but it will probably require a little bit of extra memory.",1
Its probably temporary though.,1
Instead we are probably going to have a `Variable` constructor that could take either a numpy value (making it similar to `floatX`) or a `init` function and an `input_shape`.,1
This constructor would be handling the naming.,1
Under the hood it would be calling Theano/etc.,1
@fchollet No response from OP in 3 months so probably safe to close it.,1
"3) Not sure Theano is smart enough to merge the two computes into one, though loss functions are usually so fast it's probably negligible.",1
It's probably the first entry.,1
"Mean identity error is good for hierarchical softmax, because the layer outputs the negative log probability of the correct class -- this is something that should probably be minimized.",1
This was possibly a bug first introduced in TF backend and the logic was probably copied when writing the CNTK backend.,1
"Probably this comment doesn't matter
to people as each epoch won't take much time anyway.",1
"`scipy` could probably be made optional because all of its usages in `np_utils.py` can be replaced with `numpy`, and the remaining usages are all image-related.",1
"Also, Scikit-learn's GridSearchCV and RandomizedSearchCV (and probably Scikit-optimize's BayesSearchCV) automatically infer the most appropriate CV folding (stratified or not) from the base_estimator.",1
"I wasn't sure exactly what to do here so I left it alone, but the same issues probably apply.",1
"I did not update the non_trainable_weights method, but probably with them the same thing should be done.",1
This probably isn't everything.,1
Most people are probably using float outputs and are unaffected.,1
"If you have int outputs, they will now be predicted as ints.",1
"Although, in terms of overall design, solution (1) is probably better, but since I didn't want to introduce back-compat issues, I figured solution (2) was a cleaner approach.",1
Only one configuration but probably a large user base.,1
- The dream_l2 loss component would probably work better if it was based on the difference between the input image and the current dreamed image.,1
"For now I left it in `keras.utils.training_utils`, but that probably isn't the best place for it.",1
"2. Another minor issue is that the user is expected to maintain the same number of samples for all epochs, but could input a generator with variable number of samples per epoch, which although pretty cool probably wouldn't make much sense in most applications, but who knows.",1
If so I'll make sure that `evaluate_generator()` and `predict_generator()` work the same way before a merge.,1
"All of the callbacks, except for the `DrawActivations` one in `test_callbacks.py` (which I will probably fix) don't have a copy of the model object anymore.",1
Note : I'll probably submit a pull request for it.,1
It is probably possible with a callback metric but that seems like a lot of work for something that is in popular demand and should be supported as a first-class option.,1
This will probably be the messiest part of Keras.,1
"5. Finally, probably the largest (by size) and controversial change was to include the `caffe.proto` file _IN_ in this repo.",1
"As far as I can tell, masking is only required for the `'sum'` and `'ave'` modes (and lambda functions as well probably, but those are a case of their own).",1
"If restore_best_weights=True and the last epoch of training was reached without triggering the early stop (probably because to a very high patience), the best set of model weights should be restored anyway.",1
There are probably ways to make this code more clean and efficient.,1
But I probably replied it in some places where it's not needed and neglected to replace it in places where it is needed.,1
It would probably make sense to pull most of this out into an abstract base class and create derived classes for classification and regression instead.,1
"I don't think this will cause any problems, but I'm not positive.",1
I'll leave that to a future enhancement though.,1
"I would consider once per second a reasonable threshold, but for short-duration calls it's probably nice to see sub-second progress updates.",1
"`interval=0.2` gives 5 updates per second, that should be sufficient and reasonable for both real-time local execution and web-based IPython notebooks.",1
Probably other places a similar change should be made.,1
"Although #5812 could probably be fixing this problem, it seemed way too complicated for what it introduces (broadcasting) and thought that a simple PR as this might be better while the case of broadcasting is dealt with separately.",1
"Specifying the initial hidden state of a recurrent layer is necessary for sequence to sequence models, and probably for other architectures as well.",1
This also probably has the benefit of saving some memory on the GPU side.,1
Probably we can pass all `mask` as constants to `K.rnn()` but I was expecting better solutions.,1
This PR is probably useful for implementing (some variants of) attention RNNs.,1
"Also opened this in the tensorflow repo, before noticing this probably belongs here:
https://github.com/tensorflow/tensorflow/pull/53457",1
This argument should've only been part of the Adam optimizer and probably was added to SGD by accident.,1
We found a possible bug in the implementation of the *Softmax* activation.,1
But this is not possible (or at least not straight fwd) when defining a RNN cell transformation.,1
"# also possible with Embedding, TimeDistributedDense, Convolution1D",1
There are two possibilities:,1
"However, the previous fix had been to escape these characters in the code_snippet method, which made it impossible to add any intentional newlines before this point in the the method headers' rendering.",1
Possibly we could craft such data that both tests can be merged and parametrized.,1
"If a reviewer wants me to split this PR, it's possible.",1
"For tests where it's possible, I'll split them, making them smaller, and making them easier to debug. (Idea taken from https://testing.googleblog.com/2017/04/where-do-our-flaky-tests-come-from.html).",1
"But for me to do a PR, I'll need the build to pass.",1
"When testing different learning rate annealing schemes, it would be very useful to have the possibility of using parameterizable schedule functions that takes other various keyword arguments as inputs.",1
Argument `unroll` is not supported in `ConvRNN2D` as it is written in the docs that it's not possible with Convolutional RNNS.,1
We have two possibilities:,1
Also I think we could remove the backend injection stuff with this PR,1
"For tensorflow backend, if there is not ```_keras_shape``` for mask values, it calls ```tensor.get_shape``` to get static shape in most case, but it still not guaranteed, it's also possible to return ```None```.",1
"_Note: as opposed to other PR:s with ""saving to binary"" in the title, this PR goes one step further and extends the api to write and load directly to file-like objects, thus making it possible to also load models from binary data (without first having to store it on disk)._",1
"For TF backend, it will try to call the optimized ```tf.nn.fused_batch_norm``` if possible.",1
"- It's possible to (de-)serialize non-standard optimizers, constraints and regularizers.",1
- make it possible to use RNN dropout with TensorFlow without specifying a batch size,1
There are two possible ways to fix this :,1
"2) Do a pre-check for `input_shape` (if provided), check it is one of the possible sizes supported by MobileNet, and then change the `default_size` to match this input size.",1
If #171 is merged then a callback based animation of the loss curves would be possible.,1
"With a mode=0 layer, I get the possibly expected ""Exception: You are attempting to share a same `BatchNormalization` layer across different data flows.",1
"Ideally there should be BatchNormalization layers in the net, but I was unable to get it to run with those layers.",1
This is not possible.".,1
"Added the possibility to create 5D tensor in theano,
correction of a bug in rnn which prevented output shape to
be different from input shape. (for 5D tensors)",1
Adding the possibility to ModelCheckpoint to set the last best monitored quantity.,1
Flags add cognitive overhead and should thus be avoided when possible.,1
"However, I suspect that weight conversion is common, but much less common than accidental changes to model shape where a failure to load is correct.",1
"2) TODO: automated testing of TFRecord input, including possible edge cases",1
Possible issues:,1
Adding this possibility however makes possible to implement a Bidirectional LSTM using a Graph model.,1
"On worker nodes, it might possibly we don't have writing permission for the `_keras_dir`.",1
"In this case, the running will be failed.",1
I think we can check its permission and assign it to temporary directory in this case.,1
Possibly this is rather a problem of gym than of keras...,1
"Possibly using it's context manager:

```python
with keras.preprocess.image.load_img(...) as img:
    # do something with the image
# image closed...
```",1
Possibly the same problem appears with other models.,1
"Spelling errors could possibly block CI pipelines e.g., if it has a spell check set up to check even warning messages that come from notebooks.",1
Note: very possibly not the best solution.,1
"An empty .h5 file with that path would also be silently created, possibly corrupting workflows based on loading checkpoints.",1
"Without a default placeholder or a fixed value the `keras_learning_phase` must be either fed as part of a prediction request (exposing it and adding unneeded complexity to the interface), reprogram the serving endpoint to transparently feed this (essentially a hack, and possibly not possible), or have the pleasure of performing TensorSurgery to convert the placeholder to a constant on the fly into the SavedModel protobuffer (a laborious and unpleasant hack).",1
"However, another solution would be to make utility metric functions (possibly in metric_utils.py) that reflect the behaviour that Reduce expects.",1
"Multi-threading on the other hand is an execution model, possibly for ""tasks"", that actually runs parallel in practically any languague other than python since the days of multi-core CPUs (~2005).",1
"Possibly, but first we should make a decision: what's the best way to implement attention models in the Keras API today, and would this PR provide a better API?",1
Possibly related to the recent TF 1.9 upgrade on CI.,1
We seem to be having test flakiness issues with TF currently.,1
Goals and code look good to me.,1
"Maybe someone with more experience on the topic can help, but I would say this question should be treated in a different issue and possibly discussed with the Sklearn team.",1
"Possibly because it's easier for the model to learn than a zeros vector (which stands out) stands for nothing, whereas a mean vector is still a point in the embedding space, and therefore has a meaning (and you don't know what it is until you lookup nearby words).",1
"The main issue here, is that this change would break backwards compatibility and possibly break people's trained models (expecting a different normalization scheme).",1
I think this is possibly a case of flaky test. Let's try rerunning the tests.,1
We can discuss whether `where` should be added to the backend. Possibly.,1
"The results for Prisma and this network will probably never match, for the simple reason that they are using pre trained Texture Networks, possibly similar to the ones from the paper Perceptual Losses for Real-Time Style Transfer and Super-Resolution.",1
"So in other words what I ran was mostly inconclusive (and possibly misconfigured), because I forgot to try locking random fractions of the imagenet weights and so `trainable=True/False` was either on all imagenet weights or none.",1
"Something to store training progress to a file (possibly on the fly, not just on the end) to analyze it.",1
Possibly together with a plotting callback (I haven't submitted a PR yet) to quickly determine if it is overfitting and how each variation behaves.,1
We can possibly get more contributors.,1
"eventually, if we want to allow contrib modules to work seamlessly I imagine we might want to so something similar to other projects that have plugin systems, which is to use ``importlib`` to import objects from module path strings, (e.g. [Django](https://docs.djangoproject.com/en/1.10/ref/applications/)), and possibly allow said modules to register their own names by module import path, e.g. ``module1.custom_object``?",1
"Another difference is that responses are handled also via messages and the model does not have to parse through, possibly, a list of commands to execute and take action immediately.",1
"The main training loop would then check these flags at every loop, possibly even every batch, and take action",1
"Please run a PEP8 linter on your code, as there is at least once PEP8 issue and possibly more that I missed.",1
"The API would then be the same as with Numpy arrays, but with tensors.",1
"In this case we should not require people to pass any data to `fit`, because that is redundant.",1
"Currently, you can do the following (and this will always be an option):

```python
x = Input(tensor=tf_record_tensor_input)
y = Dense(1)(x)
model = Model(x, y)
model.add_loss(tf.nn.sigmoid_crossentropy_with_logits(tf_record_tensor_target, y)
model.compile(optimizer=tf.train.AdamOptimizer())
# Ok, actually we need more work to make that last step possible, but close enough
model.fit(steps_per_epoch=10000, epochs=10)
```",1
On might say that `model.add_loss` is not intuitive for people used to specifying the loss in `compile`.,1
But I'm not sure if this could cause breaking repercussions for users who possibly have built their own custom training functions expecting the model to be compiled.,1
"@fchollet I believe the case 2 you described in https://github.com/fchollet/keras/pull/6928#issuecomment-312115383 works with this pull request, at least the second code example and possibly the first one too.",1
I think the only item I know of that specifically needs to be addressed would be the changes in https://github.com/fchollet/keras/pull/7113.,1
- many unwarranted style changes (possibly made by an auto-formatter that doesn't follow PEP8 conventions?),1
- private methods should be prefixed with `_`,1
"Breaking as in, it modifies training behavior (and possibly inference, for those who use data augmentation at inference, which is common) in a significant and unexpected way.",1
A basic example would be someone using a Keras model in production where predictions are computed by averaging 10 predictions made on 10 randomly augmented versions of the same image.,1
This PR would impact this behavior in unexpected ways.,1
"We won't merge it, because as pointed out this would be a ""breaking"" change to a widely used feature.",1
"Fixed all, plus some collateral fixes, except, possibly, one (see comment above).",1
"@fchollet, the downside is that you couldn't use the exactly correct RNN dropout, but rather might get worsened regularization (and possibly other side effects) because all gates need to share the same dropout, because of the GEMM concatenation.",1
There appear to be at least two main differences (though possibly more):,1
The Keras add layer will only add tensors of the exact same shape.,1
The tensor `+` operator will broadcast scalars/tensors w/ fewer dimensions.,1
"If yes, I would adapt the implementation of the remaining objectives accordingly and possibly if needed, add an uniform weight vector to the test functions to remove the if conditions in the objectives.",1
The tests and possibly the Model constructor logic will need to be updated. https://travis-ci.org/keras-team/keras/jobs/392231240,1
Possibly due to recently added tests that weren't wrapped in the `keras_test` graph cleaner.,1
"Now Travis tests pass, except a [failure on a possibly unrelated out-of-memory error](https://travis-ci.org/keras-team/keras/jobs/337251772) when forking in `tests/keras/utils/data_utils_test.py::test_finite_generator_enqueuer_processes` in python2.7/tensorflow:

```
>       self.pid = os.fork()
E       OSError: [Errno 12] Cannot allocate memory
```",1
"By running the test code, I notice that, the loss value from each epoch is different when I run on GPU and CPU, I think it could possibly because the precision difference of `conv3d2d.conv3d`, but not sure if it's normal for a layer to give different result on GPU and CPU.",1
"So I think we should keep the current implementation, even though it has issues, so as not to break anyone's code.",1
We can feel less bad about it by advancing that the PyTorch official implementation has the exact same "issue" (possibly because it was ported from Keras).,1
"We have made progress faster than expected, and are we fast approaching a maturity level sufficient for a first release (possibly within the end of April).",1
Having Py3 + 2.7 compatibility would be one of the milestones on our way.,1
"That's also a reason why 0 (or possibly -epsilon) might be a better masking value, combined with strict enforcement of downstream masking support as per above, since in that case a random error would only have a tiny impact.",1
"I tried to think of ways in which it could matter, but I couldn't find any, other than possibly a performance difference.",1
"Okay, I will look over them.",1
I noticed for example (at least with addition_rnn.py) that slice_X was moved from keras.models to keras.engine.training so possibly its just some simple things that I can help with.,1
I feel like it can't possibly stay on par forever without ongoing work in the upstream library.,1
"Haven't investigated yet, but these exist on master and ""someone"" (possibly you) should be running py.test before committing to master.",1
"The primary reason for not merging it here is that it involves niche features (which I generally wouldn't recommend using other than as a workaround) and isn't as straightforward as the base version -- our goal is to make examples as simple and obvious as possible, possibly at the cost of performance.",1
It has two possible string values: `"gpu"` or `"cpu"`.,1
"For 2D image data, we often have RGB channels, so the actual size of a 2D, 256 pixel image would be (256, 256, 3). For 3D data, is it possible to have multiple channels for the convolution?",1
"To make this work with both backends, it might be possible to rewrite Theano's conv3d2d (https://github.com/Theano/Theano/blob/master/theano/tensor/nnet/conv3d2d.py#L170) using Keras's backend-agnostic operators",1
@MinhazPalasara (cc @oeway @evanfeinberg): It would be great to get some reasonable implementation of this PR merged into keras as soon as possible without waiting for conv3D support in tensorflow/theano.,1
It's not possible for me to ensure the correctness of the `tensordot` lines just by looking at the code.,1
That would prevent you from knowing the specific commit when a bug was introduced.,1
"In our case, tests are heavy so it's simply not possible to run tests after every commit.",1
"It's now possible, thanks to stateful layers, but in lieu of an explicit weight sharing between training and test models, requires saving/loading the model from disk.",1
So far a) has been possible to work around since code has mostly just wanted the rank rather than the full shape; I wonder if I should make the code in TF_K.concatenate call into TF_K.ndim for this?,1
"b) has been possible to resolve, but only to the extent that code only really needs the rank",1
"@fchollet I addressed your comments as best I could; though using all() wasn't possible since it gets shadowed by K.all, so I copied it to py_all, hopefully that's better than before, lmk if you have a preferred solution.",1
"[Theano already relies on nose-parameterized for testing](https://github.com/Theano/Theano/blob/master/setup.py#L168) so adding that would not be a big change, but I'm aware that requiring sklearn for running tests is a bit excessive (but very convenient!).",1
"Theano already relies on nose-parameterized for testing so adding that would not be a big change, but I'm aware that requiring sklearn for running tests is a bit excessive (but very convenient!).",1
"An interface which implies to do something impossible without actually doing it does more harm than good, I think.",1
"On the other hand I feel that it could be possible to compute this approximation accurately during training, only one would need to aggregate false positives, true positives etc and use those to compute the f-score (and other metrics that rely on them).",1
I could attempt to implement this if you guys think it would be useful.,1
"For example if one wants to implement a callback for an early-stopping rule (a basic rule ""if the average loss on the latest epoch is <0.001 then stop learning""), it is obviously possible to retrieve the latest average loss with the whole history but that would be even easier to get the local information.",1
That was not possible with this approach.,1
"As I wrote, the most ""urgent"" feature that is missing is to be able to feed the attention encoding inferred from a first layer to later layers in a stack of RNNs, but I think this should really be solved by making it possible to return ""state sequences"" from the base RNN - which does not affect the API of the attention mechanism itself.",1
"As far as I understand the only possible solution now is to predict each symbol with the new run of entire model feeding it previous output label and state, am I right?",1
Also I think it would be beneficial to add that prediction part to the example if you don't mind,1
"Since it seems that it's not currently possible, I'll close this PR.",1
I think it's better to make a separate page in the doc for everything related to Tensorflow.,1
"Don't worry if what you make is not perfect, make a PR and we'll work together to make it as nice as possible :)",1
"I think that it was the official way to use the wrapper, but it has been possible to use a native TF optimizer since some point.",1
Maybe we need to investigate a Keras version that enables us to remove the wrapper.,1
We'll run the test at each commit to ensure that the bug doesn't appear again.,1
"Once you provide this, I'll include it in the PR myself and resubmit it for merging in master.",1
I think its ok accept this PR. (after any possible refactoring in its current form).,1
"I think this is LGTM, this would give the user ""some"" information and we can move forward with using ""spawn"" when possible on Travis.",1
I would also recommend adding some debug messages when the queue consistently gets empty and warn users for possible GPU starvation.,1
"Think that is possible here, or do you think a separate PR will be better?",1
I'm going on vacation for a week so I won't be able to review.,1
"In the end, I think that we don't want to add too much complexity whenever possible hence why the observable pattern that inherits __int__ would be the best in my opinion.",1
I think that it may be possible to use the hdf5 serialization and pickle at the same time.,1
That would explain why we are getting loss/2.,1
"I think the following could be possible:
- `HierachicalSoftmax`, as a layer, returns `[input] + weights` in train mode, and returns probabilities in test mode.
- a `hierarchical_softmax` loss function takes as input the labels and the output of the `HS` layer (`[input] + weights`), and computes a loss value.",1
"I'm not sure whether Tensorflow has similarly optimized sparse dot backend ops, but it should definitely be possible to obtain some speedup from decomposing a single large softmax into two smaller softmaxes.",1
"This should be relatively easy to do purely in the backend, but it does mean that HS on Tensorflow might be a lot slower.",1
"If so, then I think it would be possible to do what @fchollet mentioned.",1
"Regardless, I'll keep the current configuration for now and see if I can replicate Theano's hierarchical softmax in the keras backend.",1
"for testing, I used this for my own problem, which is emoji prediction and it is much better than the recurrent_dropout (I'll open source it as soon as possible)",1
"@fchollet  Thanks for the response, and sorry to bother you, but I still have some other questions and a possible feature request.",1
Would it be possible to support an operation only for one backend (this would allow for the use of theano's optimized implementation)?,1
Also fixes a possible bug with np.load()/f.close() pair not being exception-safe.,1
Problem is that a variable number of timesteps should be masked out and be excluded from the metrics (same as was done for the objective function). Looking at `training.py` I saw two possible ways to fix this issue:,1
"1. Take the same approach as for objective functions (see `weighted_objective()`). _Pros:_ more consistent with existing approach, enables metrics to be scaled by weight as well; _Cons:_ requires rewriting of metrics functions to return values per-timestep, possible back-compat issues for users who have written custom metrics",1
"As pointed out in #2294 the one_hot function does not really implement a one hot encoding, but a hashing-based encoding, with possible collisions between words.",1
"Before the faster implementation of RNN and Timedistributed layers,
 it was possible to create a layer with Recurrent and Timedistributed layers with a number of timestep
specified (for example 200) and then to use this layer on inputs with 
different number of timestep such has 20 or 400 (for theano backend)",1
It was not possible after the faster implementation.,1
"e:\toolkits.win\anaconda3-4.4.0\envs\dlwin27cntk23kerasmaster\lib\site-packages\cntk\core.py:361: UserWarning: your data is of type ""float64"", but your input variable (uid ""Input23"") expects ""<type 'numpy.float32'>"".",1
"/media/EDrive/toolkits.ubu/anaconda3-4.4.0/envs/dlubu27cntk23kerasmaster/lib/python2.7/site-packages/cntk/core.py:361: UserWarning: your data is of type ""float64"", but your input variable (uid ""Input23"") expects ""<type 'numpy.float32'>"".",1
I'm running couple parameter server training on google cloud ai training and tensorboard metric curves are being produced middle epoch as expected.,1
I've also tested locally with in process cluster that metrics get plotted as expected.,1
This is because the final model has more layers than expected and the loading of the weights is based on the topology of the model.,1
"But `Sequential` derives from `Model`, so in fact, if layers work in `Model` they're expected to work in `Sequential`.",1
"weighted_masked_objective function expects to receive a vector with separate accuracy for every sample in batch, it's needed to properly reduce accuracies when sample weight is 0:
https://github.com/keras-team/keras/blob/7c7e51ea5ab47b67cd68374400051dd022bdc662/keras/engine/training_utils.py#L446",1
"This lead to an error when calling `load_wrapper` with `filename=foo` (when not using gcs), as it expects to continue working with the original variable `kwargs`.",1
"Previously in PyCharm, it would print a new line every update to the progress bar and with this change it works as expected, clearing each previous update to the line and removing the annoying bug of many, many fast printing lines to the console.",1
"I enforced them to run against both input and output channels are great than 1 which is more common case, and check output as expected given an input.",1
"I have run all these unit tests on a machine with 2 GPUs, they produce expected output and exactly same as TF and TH backend.",1
"As a consequence, if we pass `KerasClassifier` to `GridSearchCV()` with numeric `cv` argument
```
clf = KerasClassifier(...)
...
grid = GridSearchCV(estimator = clf, param_grid = params, n_jobs = 1, cv = 10)
```
the `KFold` splitter would be created instead of expected `StratifiedKFold` because `KerasClassifier` contains no `_estimator_type` and, therefore, treated as regressor.",1
"This behavior has been introduced in TensorFlow 2.0, in order to enable layer.trainable = False to produce the most commonly expected behavior in the convnet fine-tuning use case.",1
"`ValueError: Error when checking target: expected lambda_1 to have shape (10,) but got array with shape (1,)`",1
"ValueError: Error when checking target: expected lambda_1 to have shape (10,) but got array with shape (1,)`",1
"With some re-shaping to suit tf's expectation, the existing function is used as-is.",1
A simple test function has also been added to demonstrate expected operation.,1
"- Tougher enforcement of input formatting expectations for `dot_axes`, because the format is complicated and not obvious.",1
Errors will be common and need to be catched.,1
The dense gradient tensor expected by tensorflow should be extracted with the .values function.,1
ValueError: too many values to unpack (expected 2),1
The current example shows the result of using the stateful parameter by comparing the error between two models to the expected signal.,1
"This pull request instead compares the expected signal to the predictions, and also compares the errors to the errors.",1
Seeding the global generator may introduce unexpected behavior in the applications that use Keras and also rely on its state.,1
"- On the other hand if I visit Japanese docs https://keras.io/ja/preprocessing/text/ , I can find the class and the methods listed as expected.",1
"These 3 APIs will allow user to disable and switch back to legacy behavior if they prefer. In future (eg tf 2.10), we expect to totally remove the legacy code path (stateful random Ops), and these 3 APIs will be removed as well.",1
I tested it on latest TF and theano and it works as expected.,1
"This is caused by a 1-indexed word_index, since sequences_to_matrix expects 0-indexing.",1
"The reason for doing this is so I can annoy colleagues on [Gitter](http://gitter.im) with the following callback (Gitter expects the HTTP POST data to be named `message`, and not `data` like Slack :no_mouth:):

``` Python
RemoteMonitor(root=""https://webhooks.gitter.im"",
              path=""/e/..."",
              field=""message""))
```",1
"**I think there's a case to be made for removing RemoteMonitor entirely, but on the other hand it provides some inspiration for what the callbacks could be used for so perhaps it makes sense as documentation.**",1
This was giving `TypeError: mel() got an unexpected keyword argument 'hop_lengthgth'` error.,1
Was expecting a numeric data.`,1
"I noticed that `Merge()([input1, input2])` didn't work as I expected.",1
Fix: TypeError: Unexpected keyword argument passed to optimizer: learning_rate,1
"This will convert the (5, 1, 50, 3) to the expected (5, 50, 3).",1
This gives the expected behaviour and allows sample_weights to be applied without issue.,1
Consider the fact that we can't expect all keras users to know caffe entirely,1
"I'm talking about files taken from the master branch of the Caffe repo, I would expect them to be up to date.",1
Expect `subsample_length` to subsample steps,1
"That would definitely be necessary, for consistency with the API of `Convolution2D` and `Convolution1D`.",1
"This is just a suggestion, and perhaps @fchollet or other keras maintainers would have more insight into the correct input format.",1
I would expect it to go away; if it doesn't we may have to update our Travis config.,1
"Without  `pytest.raises(ValueError):` I get a valueError as expected:
https://travis-ci.org/fchollet/keras/jobs/301847000#L2148
https://github.com/Danielhiversen/keras/blob/c7914011003f4a787c958622ab95738efd7a44aa/tests/keras/backend/backend_test.py#L726",1
I'll try to reverse engineer them but it is not clear what the expected inputs are so I am not sure I'll write very good tests...,1
"- The expected output of the beam search is a list of np arrays (the list length: `top_paths`, the np array shape: `(number of samples, maximum decoded length)`.",1
An imprecision of 1e-7 is to be expected when working in float32 precision.,1
"We should not add extraneous ops such as `clip` to enforce artificial value ranges like this, because that adds computation overhead for everyone.",1
"So I modified convolution layers unit tests, but I don't understand how (or where) I can add expected test results.",1
Turns out the other case also doesn't really do what you would expect.,1
Having to provide additional states like this is a bit redundant and unexpected IMO (especially if the attention wrapper is simple enough where `attention_states` is nothing but `[attention_h]`).,1
"Imho, when doing subclassing API, we can expect the user to take care of the types, but I don't know how you feel @fchollet .",1
"As you can see, in my first commit, travis detects PEP8 errors which were in master and fails as expected.",1
It seems chaining instructions with `&&` did the trick.,1
"It has quite some more parameters, but if users expect something in the dimension of NasNetLarge, judging by the Large suffix, they might be surprised that B4 has just as many parameters as a ResNet-50.",1
"This PR, in contrast, is mainly about which variants to provide in the `keras.applications` namespace, which is expected to be used by a variety of less advanced users as well.",1
"We should expect planes crashes, banks going bankrupt and some earthquakes here and there.",1
@MrinalJain17 The blank lines don't look as bad as one might expect.,1
"I think, though, that we can balance minimal-size, visual appeal, and consistency, though.",1
I followed your suggestions and changed all inputs to random numbers and clarified that expected outputs are the same for `unroll=True/False`.,1
"There is no need for the Numpy reference implementation for this PR, the tests are self-contained and verify the expected behaviour.",1
* The new implementation adds some fair amount of non-trivial code (80+ LOC) for an optimisation that we maybe could expect tensorflow to perform.,1
We also have to consider TF eager which we'll have to support in the future where TF can't perform this hypothetical optimisation.,1
It's also the expected behavior by the users.,1
I think the user would expect this behaviour.,1
2nd epoch is longer then expected (7 batches vs 4 expected).,1
"In these conditions, using `tf.nn.compute_average_loss(loss_value, global_batch_size=global_batch_size)` seems to result in the expected loss value being divided by 2 (the number of workers):
```shell
AssertionError: 
Not equal to tolerance rtol=1e-06, atol=1e-06
Mismatched value: a is different from b. 
...
 x: array([1.5, 1.5])
 y: array([3., 3.])
```",1
"If I replace `tf.nn.compute_average_loss` by `tf.reduce_sum`, I would expect it to return `batch*loss=32*3=96`.",1
"Yes. Based on the numbers I'm getting, I \*\*believe\*\* MWMS is either discarding half the values or performing `ReductionOp.MEAN` here, with the former being incorrect and the second being incompatible with `tf.nn.compute_average_loss` (which expects ReductionOp.SUM).",1
"The backend softmax functions expect 2d tensors, so the objective function doesn't work for sequences in theano.",1
`y` is a list of two tensors but `K.dtype` expects a tensor as input so how should we go about this?,1
Could you add some tests to validate the expected behavior?,1
"Error is as below:
Error in py_call_impl(callable, dots$args, dots$keywords) :
ValueError: Error when checking target: expected dense_9 to have shape (1,) but got array with shape (5,)",1
"my model structure looks like this : 
 Model
________________________________________________________________________
Layer (type)                    Output Shape                 Param #    
========================================================================
lstm_1 (LSTM)                   (20, 5, 50)                  11000      
________________________________________________________________________
lstm_2 (LSTM)                   (20, 50)                     20200      
________________________________________________________________________
dense_1 (Dense)                 (20, 1)                      51         
========================================================================
Total params: 31,251
Trainable params: 31,251
Non-trainable params: 0
_________________________
and error : 

Error in py_call_impl(callable, dots$args, dots$keywords) :
ValueError: Error when checking target: expected dense_9 to have shape (1,) but got array with shape (5,)

(i am running keras on R)",1
#works as expected,1
71% accuracy is the expected value (after the header removal).,1
"This should be expected as most of the work will be done by `translate` in both the new and old versions, while this change only affects the input to `maketrans`.",1
I'll update shortly with a comparison for using multi-character `split` values vs. single-character on both versions.,1
But I don't expect breaking changes at this point.,1
I didn't expect it to be such a long PR so I didn't do it "by the book".,1
"Without looking at the code, I expect https://github.com/fchollet/keras/pull/5049 is a better solution than mine.",1
"The dropout makes the model non-deterministic, so I would not expect the same predictions.",1
"On my server (keras 1.0.6, theano, linux) the prediction is fine - as expected.",1
"Pragmatically, what most people want/expect is that setting `bn.trainable = False` will run BN in inference mode, i.e. without updates.",1
"I was expecting from the [documentation](https://www.tensorflow.org/api_docs/python/tf/summary/histogram) that tf.summary.histogram has to have a normal Tensor, but your solution seems to work fine for the problem in #7397.",1
We expect users to read the documentation at least once before starting working.,1
"Maybe not obvious, but it's the expected behavior and this behavior is desirable in 99% of use cases, it allows users to do the right thing without thinking about it.",1
"Of course users are expected to read the documentation, but arguably some of the most valuable features behind keras's popularity are its intuitive design and pythonic style.",1
In my opinion the fact that validation set isn't shuffled when `shuffle=True` is unintuitive and could be clarified with a short warning.,1
"It would be great to add a code comment explaining the use of a mean embedding vector, and stating what the expected improvement is over a zeros vector.",1
I think it's worth clarifying the expected types of all arguments in NumPy-style docstring parameter lists and explaining when/why an argument can be of multiple types.,1
expected behaviour: Saves model,1
expected behaviour: Doesnt save model,1
In my knowledge this would a good sample from all the possible combinations.,1
Doing so will lead to add a lot many cases.,1
"The potential problem is located in the following lines of code (see line 92 in module *softmax.py*):

```
adder = (1.0 - math_ops.cast(mask, inputs.dtype)) * (
          _large_compatible_negative(inputs.dtype))

...

inputs += adder
```",1
"A way to create an incentive for the neuron to fly toward potential problems through their weights, is to add a regularization term that implements this attraction.",1
"A potential downside of merging this PR is the following test failure, related to upgrading to the current master branch of tensorflow:",1
Address potential vulnerability in which a malicious tar archive could be extracting files outside its target directory.,1
Fix potential concurrency issue in updating/using `iterations`.,1
This seems like a pretty severe potential issue so anyone doing sequence to sequence learning should take note.,1
Potential use case: For stacking after a MaxPooling1D Layer,1
Potential use case: For stacking after a MaxPooling2D Layer,1
"There is no great need to accept this merge request, but it demonstrates a potential layout on disk allowing for both manual and automated tests.",1
"Getting the structure right beforehand seems useful, though.",1
"The potential problem is located in the following lines of code (see line 92 in module *softmax.py*):

```
adder = (1.0 - math_ops.cast(mask, inputs.dtype)) * (
          _large_compatible_negative(inputs.dtype))

...

inputs += adder
```",1
Many times it's better to know about GPU memory consumption for DL models to avoid potential out-of-memory errors either at the beginning of training or in the middle,1
"Remove duplicate logic, reduce line count, fix potential bug if reporthook is convertible to bool by checking ""is not None"" - i.e. what PR https://github.com/fchollet/keras/pull/8320 title promised, but didn't really do :-)",1
"Replaced the divide with the safer: tf.math.divide_no_nan, as denominator has the potential to be 0.",1
"The following - rather artificial - example shows a potential flaw in the current masking approach:

``` python
X = np.asarray([[[1e+30]]])
y = np.ones((1, 1, 1))

model = Sequential()
model.add(Masking(mask_value=1e+30))
model.add(SimpleRNN(1, 1, init='one', activation='relu', return_sequences=True))
model.compile(loss='mse', optimizer='sgd')

logs = model.fit(X, y, nb_epoch=3)
```",1
"The language in the CONTRIBUTING.md file of the repository has been significantly improved, making it more clear and more concise for potential contributors.",1
* Some potential bugs with same nature are prevented and covered by manifestation checks.,1
Current potential problems (all could be fixed):,1
Potential downside: not providing the input shape makes it slightly harder for Theano to optimise the convolution.,1
"If the input shape is known, Theano will sometimes choose to use `GpuCorrMM_gradWeights` instead of the `GpuCorrMM` if this is faster, for example. In practice, however, Theano will mostly use the cuDNN version anyway and this should cause problems.",1
"Nonetheless, I fixed a potential bug for the ""generator"" part.",1
I'll focus on getting the theano HSM working with keras so we'll have two potential solutions.,1
"In general, it's not possible to check the correct rendering of the docs via unit tests: there are many potential issues at many levels.",1
"Would be super helpful feature, I think!",1
"If any potential users would like to chime in in this thread, that'd be great :)",1
Maybe this would be a better fit for `keras-contrib`?,1
2) There's potential for bugs in using different code for training loss evaluation.,1
The loss functions shouldn't live in two different places.,1
Only potential issue is that this requires Protobuf to be installed before running setup.py.,1
Or else Caffe import won't work (Keras can still be installed though).,1
One initial reason why you would see different result (independently of any potential bug in the PR) is that the networks are in different phases; the Keras net is in test mode and the Caffe net is in train mode (which is why Dropout is being applied).,1
"Please also refactor `ConvLSTM2D` in the same PR, since it is difficult to write unit tests or identify potential issues when we only have the cell.",1
"You could use the current PR, or create a new one.",1
There are two ways we could introduce a potential HSoftmax layer:,1
"- it could work by adding a loss via `self.add_loss` in `call`, require targets to be passed as a model `Input`, and require a `None` loss argument for the corresponding output",1
"- we could try to make it work as a loss argument, by making it possible to have layer-like losses",1
"To mitigate the potential confusion we are discussing, best_estimator_ isn't available unless we've set that argument to refit the model on all of the training data.",1
"At least in the case of concatenation, your normalize_dims function has the potential of resulting in length `m` on the last dimension in `x` if all of the merging layers are from embeddings and there are `m` layers.",1
- potential conflicts with regular Lambda layers,1
The potential for user error is just too high.,1
"This PR enables the refactoring, which should eliminate all current bugs due to divergence and potential for future ones due to divergence [1].",1
"It might also help reduce potential NaN/Inf's in DNNs, as well as generally increase perf a bit.",1
"Also to put things in context, one full batch (1Gbytes in my case) takes up to half a second to transfer to gpus, so the potential gain if we do this right would be about 150-200ms per batch.",1
"I think my main issue at the time was that I couldn't immediately verify that it worked, due to the lack of test.",1
But I'll check it out.,1
I think I had addressed this issue before.,1
The only error I can think of is that the weights had to be transposed.,1
Anything else would lead to dimensionality errors.,1
"@fchollet For a measure of complexity, I think the above two repos might give an estimate.",1
I think I said the other way around.,1
"@asampat3090, I think the error could rather be due to preprocessing not being applied.",1
- I think you made an `if...else` decision with `prototxt` or `caffemodel`.,1
"As you can see from the discussion above, people would want to change `prototxt`s to obtain modified models",1
"@entron I think the problem is that you put `self.pooling_function.__name__` into the config, which is something like `T.mean`.",1
"Your constructor takes a string, not a function, so you should rather put `average` there, instead.",1
By default conv2d would be called.,1
I think the [modelnet](http://modelnet.cs.princeton.edu/) database would be a good open-source example of 3D data.,1
"@fchollet 
https://github.com/fchollet/keras/blob/master/keras/layers/core.py#L844
I think this also needs to be removed.",1
"Sorry, I think it's already decently clarified in the existing docs.",1
I'll leave the subsample -> stride modification out of this.,1
"Also, I'll keep the hand defined `output_shape` while we think of an automatic inference way to do this.",1
"I'll make the PR as soon as the vae conv example finishes running (its much slower on TF, is it because of the transpose operations?)",1
"Also, I'll
> keep the hand defined output_shape while we think of an automatic
> inference way to do this.",1
I think I know where it is...,1
I'll make a PR to your PR,1
"@yaringal I made you a PR,I think it should fix it",1
@lukovkin I think you can do a pull request at https://github.com/yaringal/keras/commits/master which I can merge into this PR,1
"I could try to catch the import error and don't allow sparse input creation if the dependency failed to load, let me know if you think it's worth it.",1
"Yep, looks like the nose-parameterized dep causes travis to fail.",1
@DingKe: That looks better.,1
"I don't really understand why you think Theano's `switch` is much more powerful than `tf.select`, but I'm not a TensorFlow user.",1
"I don't really
> understand why you think Theano's switch is much more powerful than
> tf.select, but I'm not a TensorFlow user.",1
I'm thinking I can get through those tonight.,1
"P.S I personally dont think small stand alone numpy functions need tests - once proven working, they will work for ever without breaking.",1
@ozabluda yes I was also thinking about that since we are sharing so much code...,1
@ozabluda It seems there is a lot of new code and I think there was a mistake somewhere (1000+ new LOC).,1
I think the current way is there because of CNTK compatibility.,1
We think writing to `stderr` is preferable.,1
"@fchollet I think we should use ```embeddings_initializer``` to initialize weights for embedding layer, rather than set ```weights``` directly, because in the current [API](https://github.com/keras-team/keras/blob/master/keras/layers/embeddings.py#L37), no explicit argument named ```weights```.",1
"For later, I think it would be nice to link the `reference_operations.py` in https://keras.io/backend/ .",1
I think the best would be to use it in the tests to make sure it works.,1
I think the problem was that I did not add edit the BUILD file and I edited it.,1
@amueller  I think we just need to get someone from keras to re-run tests on this PR.,1
"I would like to point out that modifying the switch function would not change the backend API as the change applies to this specific case only
so I can do that too if you think that is better",1
I think it will be only when building the graph.,1
"I think that could be cool, but it's not straightforward how such a function could fit into metrics.py without major refactoring, aside from using a stateful closure which I think would be frowned upon.",1
"What I'm thinking is something similar to how the base logger does it now, but it would require the use of some ""hidden"" metrics to compute the values that can be aggregated over an epoch (true positives, false positives, etc).",1
I'll come back with a pull request if I ever manage to write this with not too much refactoring.,1
This looks great!,1
The animations look really cool.,1
I think the callback pattern was definitely a step we had to take in order to bring about the visualization tools we're planning for.,1
On the API side: I think the callback system should not affect the default logging system (accessible with  the verbose flag) and the returning of the history by the `fit` method.,1
"We could re-implement these with callbacks, but I'm even sure that's necessary.",1
"On the implementation side: for generality I think it would be better to pass values to callbacks as a dictionary where keys have explicit names, rather than as a tuple of arguments where the meaning of each value its determined by its position.",1
I removed the returned history in `fit()` but to be honest I can't think of anything replacing it.,1
"So I agree with you, I should revert this change, add the `keras.callbacks.History` callback to the default callbacks in `fit()` and return the history again.",1
"But as it is right now (with the `keras.callbacks.History` callback), the history is no longer a dict but it is an object: it changes the way to access the infos and it may break existing code using keras.",1
"I think callbacks should only have access to local statistics of the training, and leave it up to the callback creator to keep the history according to her needs.",1
"I agree that it was out of the scope of this PR but I think it would make sense to call `on_batch_end()`, `on_epoch_end()` and `on_train_end()` if one manually stops the training.",1
"I've thought about it, and I think you are right.",1
"I agree that it was out of the scope of this PR but I think it would make sense to call on_batch_end(), on_epoch_end() and on_train_end() if one manually stops the training.",1
...I think it would be just silly to merge the base class `RecurrentAttentionCellWrapperABC`with the specific implementation `MixtureOfGaussian1DAttention` as it describes and implements a highly relevant and general abstraction level for attention mechanisms.,1
"I think this may be a bug, but the test doesn't show it clearly. Please update the test.",1
I also made 3 different functions because I think that there are 3 main cases to be tested.,1
TL;DR: I think it's safe to say that results matched.,1
This is most consistent with original repo I think.,1
"As I read it more, I think the original is correct!",1
I think so.,1
"@gabrieldemarmiesse, I think it is better to leave them as they are.",1
So I think this is it :),1
"I think the problem comes from this line:
```python
mask = ((idxs < f_active.dimshuffle(0, 'x')) &
            (idxs < b_active.dimshuffle(0, 'x')))[::-1, ::-1]
```",1
"I think this feature is very interesting, and I will be using it a lot.",1
"I think something is going wrong around those lines:
```python
# reduce weight array to same ndim as score_array (needed for
# sample_weight_mode='element')
if weight_ndim > K.ndim(score_array):
      weights = K.reshape(weights, K.shape(score_array))
```",1
"And because the element-wise weighting would be dealt with internally in the loss function, and the `score_array` would have the same size it already has, I think no further changes would be necessary in keras.",1
"I think we just need to wait for the build, and if it passes, for a review from another member of the keras team.",1
This feature can't be supported by CNTK I think right now.,1
I'll think about where it could be documented.,1
"I think it would be better to remain them as just special cases, rather than targets of generalization.",1
I think this should finish resolving this [issue](https://github.com/keras-team/keras/issues/16173).,1
I think one could motivate something like a `MultiLayerWrapper` class that takes care of the boilerplate for these cases (`get/set_weights` etc.).,1
"I don't think CNTK supports multiple dynamic axes, which arise frequently in code enabled by this PR.",1
I think it was since #11163.,1
I think chaining the instructions with `&&` will solve the issue.,1
I think it will also increase the coverage. (maybe?),1
"@taehoonlee , I think you're the right person to ask for review.",1
I think a if-else was supposed to be there.,1
I think this should be clarified.,1
I think it's a better option than to disable them.,1
"This PR adds a to_ordinal function for multi-hot encoding ordinal values, as most (I think ?) neural network libraries lack ordinal values support and often use standard one-hot encoding which loose the ordering information of the target classes.",1
I think it belongs there rather than in the activations tests.,1
I based this on moby/moby PR template which I think is quite good.,1
"I've read the guidelines, but I think many of them don't apply here.",1
But I think it doesn't have effect of the code structure at Keras.,1
I think it is because conda's default channel does not contain `mkdocs`.,1
We already found out the origin of the 10 minutes timeout on travis (see #11461) so I don't think this timeout is needed anymore.,1
I think it makes sense for the implementation to be there overall since it's tightly connected to the data_format given by the backend.,1
"Further, I must mention that I think there is a small error in TF implementation: [in this line](https://github.com/tensorflow/tensorflow/blob/320dc4913f94a679790d90f5c577037276aa9599/tensorflow/python/keras/callbacks.py#L187) the `_t_enter_batch` attribute, which measure the batch processing time, is set at the beginning of the method.",1
"However, I think this is wrong (since in that case the execution time of `on_batch_begin` would also be included) and as it is [currently implemented in Keras](https://github.com/keras-team/keras/blob/7bee9a18d83899ce6dfd50c4883afc678139f4ad/keras/callbacks.py#L99), it must be done at the end of the method.",1
So in this PR I would set this attribute at the end.,1
I think ```InputLayer``` should support masking and it can use the default ```compute_mask``` function in base layer(just carry over the input mask).,1
"Because users don't add this layer explicitly, it should transparent to users.",1
"I think we can do a prototype with Cropping1D and after when everything is perfect, copy the same pattern to Cropping2D, Cropping3D, etc.",1
For very large vocabulary scenarios (think 1M word vocab) the normal softmax is computationally expensive.,1
I think the purpose was for it to be a 2-point average.,1
I think basically all workers using Keras will be beneficial from this.,1
"Here's a small example why I think there's a small mistake in the code.

![Example Code](https://i.imgur.com/jZVO97d.png)",1
I think it would be useful to also set `inter_op_parallelism_threads` using this variable.,1
"I think it would be more flexible to have the metrics computation completely separated from the model, inspired by [what scikit-learn is doing](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics).",1
So I think the following parts of files should be modified.,1
I think it might be useful for others too.,1
"Once the model is included into Keras, I think it's better to move the weight files here.",1
"I'm not sure this is the best way to do it, but I think it fixes the issue.",1
"I, and I think others, would like to be able to know what each example does quickly from the github ui.",1
I think the flexibility here is nice.,1
"- We need to check the normal operation of the modules `keras/applications/*` and `keras/datasets/*`, but I think it is a little unreasonable that they affect a test coverage because they are not core functions.",1
I think it would be a plus to support this layer in Keras.,1
"2. I did not use preprocessing layers, as I thought some users might experiment with different preprocessing.",1
We’re looking for ways to let Keras users know this is available and thought a badge to show Optuna integration is available would be helpful.,1
I'm still looking around for improvements but thought we could merge it along the way.,1
We use both a lot and thought it might be a welcome contribution for anyone who would like to use them.,1
"This version is thought to be efficient for GPUs, in particular, because it decomposes the softmax into two reasonably sized matrix multiplications.",1
Hierarchical softmax can be thought of as a tree -- each leaf node of the tree is a class of softmax.,1
"This happened to me, and I found it confusing that layers that I thought were outputs were referred to in the error message as ""inputs.""",1
"When I encountered a bug in my code that triggered this, I thought that my network was overflowing somewhere, resulting in hours of debugging the network.",1
"Following the PR request (https://github.com/keras-team/keras/pull/10256) I raised form my work github, I thought it would be useful to cleanup the last occurrence of the deprecated ``model.model`` in the code base.",1
Fixed some (what I thought be) mistakes in the variational autoencoder example,1
Attempt at reusing the validation enqueuer (I thought we were already doing that).,1
This is a callback that I've been using and thought other people might find handy.,1
This is just a small thing that I've been using and I thought others might find it helpful.,1
Thought this was simple enough that I'd take a stab.,1
I needed this constraint for my own application and thought it can be useful for others.,1
"Unit tests are still missing, but the paper has recently gained some attention on the machine learning subreddit, so I thought it might be a good idea to open the pull request right away in case someone wants to experiment with it.",1
"I thought maybe adding an `output_mask` parameter that takes a list of (normalized) masks and returns the output mask, but this seems clunky.",1
Thought it would be useful for keras to implement atleast a few of those quantiles as shown below in objectives.py.,1
@TimZaman maybe you have thoughts about how to improve it?,1
"They're quite different, so this could be due to some other factor, but I thought it was worth mentioning in case I'm inadvertently using an operation that's unsafe for the GPU.",1
"For instance, for a timeseries [1., 2., 3., masked, masked], an accumulator RNN would return [1., 3., 6., 6., 6.].",1
"For this to work I've had to add a new argument to `model.compile`, so I thought I'd see if this would be useful to anyone else, or if anyone knew of a better way to achieve this.",1
This could cause confusion for beginners reading the examples so I thought I'd bring it up.,1
"Also since `pop()` is sort of a hack, I thought it would be good to have a test.",1
"With the self-imposed requirement of doing as little refactoring as possible, I thought this was okay given that step is relatively fast.",1
"I think to use a condition, something like `if self.write_grads and weight.is_trainable (something in that spirit)` would fix the issue you are mentioning without affecting the behavior of `write_images`.",1
"For that reason, I think adding more functionality is a bridge too far because we'd put at risk a large set of interdependent code that may ultimately be rejected.",1
"I think you should use the Theano HSM for Theano, otherwise Theano will be
much slower then it should.",1
"For very large vocabulary scenarios (think 1M word
> vocab) the normal softmax is computationally expensive.",1
"This
> version is thought to be efficient for GPUs, in particular, because it
> decomposes the softmax into two reasonably sized matrix multiplications.",1
I thought about the simple implementation but it may be more problematic then this.,1
I tried with a simpler `if output_shape[1] == 1` but it opens more cases where we want to operate on more dimensions so i thought to this solution to cover the simple case.,1
He thought the code was fine,1
I'm not sure why the caffe model would be in training mode - I did specify the phase to be test (or so I thought) via: `net.set_phase_test()`,1
I thought it was because of the 'narrow and deep better than wide and shallow' thing.,1
"So, I thought it would be reasonable to use dynamic shapes for TF as well.",1
"The docs say that epsilon is _fuzz factor used in numeric expressions_ and `epsilon()` is actually used in Theano's `l2_normalize`, so I thought that the TF default value was left here by an oversight.",1
"I always thought that `stderr` for errors, not for debugging information.",1
I thought that I should import it by adding `keras.utils` but it seems that it cannot find it. Is there any other file I should edit to include `audio_dataset` ?,1
This is something I thought I might need to do myself at some point.,1
I thought we got rid of those timeouts a while ago.,1
"I thought one of reason is that we have to add following commands in `Dockerfile`.
because default preferred encoding is not `utf-8`.

```
export LC_ALL=C.UTF-8
export LANG=C.UTF-8
```

and I have no idea about other reason.",1
"I thought it's not easy to complement static shape inference for all Theano backend functions in short time, so fall back to the imperfect solution.",1
"That's ok, I will close this one and send another PR to add static shape inference for relevant Theano functions.",1
It will make it easier to add in other types of attention such as the Multiplicative Attention from Luong's 2015 paper.,1
"In regards to the code generally, I have a few thoughts:",1
I thought it would be preferable to go all the way and use the existing infrastructure but the result ended up being worse.,1
"I thought you'd get a notification but I should have pinged you anyway, my mistake.",1
I just found a work-around for #4392 and thought I'd post it.,1
I thought your PR had something to do with thread shutdown.,1
"My bad, I thought the Conv1D is older, since I was looking at this part of the [documentation](https://keras.io/layers/convolutional/) that uses `keras.layers.convolutional.Convolution1D()`",1
Thought I'd post the background for posterity's sake.,1
So the timing is the issue. Im planning to add more tasks (IT tests) and I thought I'll make infrastructure changes before moving on.,1
"I thought the easier fix would be to provide `steps_per_epoch` to the `model.fit_generator` call - i.e.

`    # Compute quantities required for feature-wise normalization
    # (std, mean, and principal components if ZCA whitening is applied).
    datagen.fit(x_train)

    steps_per_epoch = x_train.shape[0] / batch_size
    # Fit the model on the batches generated by datagen.flow().
    model.fit_generator(datagen.flow(x_train, y_train,
                                     batch_size=batch_size),
                        epochs=epochs,
                        steps_per_epoch = steps_per_epoch,
                        validation_data=(x_test, y_test),
                        workers=4)

`",1
I thought I could just pass it from the layer's `call` method,1
I thought I could just pass it from the caller,1
I'm going to merge the current PR as soon as the tests pass (as far as I can tell it is good to go).,1
I thought it would make sense to have the validation at the epoch level and maybe make the progress bar work around it.,1
"On the other hand, I thought about another option, but it will imply more changes to the codebase:",1
I think simply having the content of the current `def _update_trackables(self):` get called in `trainable_weights` / `non_trainable_weights` should be sufficient.,1
The overhead does not seem to be significant.,1
@old-school-kid I think that might need more thought.,1
"I thought batch_dot was only used to do 3D tensor operations, but in some cases it is used for 2D.",1
"I thought the PR comment will be sync back to our internal system and notice us, but it didn't.",1
"Or, as a thought, we might throw this in as an advanced_activation layer  https://github.com/fchollet/keras/blob/master/keras/layers/advanced_activations.py",1
"My thinking is that the tensor3 requirement may only be for RNNs of different flavors, which need to utilize 3 dimensions for both correctness and speed.",1
"@fchollet I thought i did, or do you mean a test somewhere else?",1
Not sure why @mthork thought it was not a good idea.,1
"Note: I thought maybe I need to set histogram_freq=1 or something like that, but then I get an error upon calling the .fit() method:

```
Traceback (most recent call last):
  File ""/home/magda/Documents/powroty/ModelDL_001_OffersSuccess/joint_model.py"", line 231, in <module>
    epochs=1, batch_size=64, validation_split=0.2, shuffle=True)
  File ""/home/magda/envs/offers2.7/lib/python2.7/site-packages/keras/engine/training.py"", line 1507, in fit
    initial_epoch=initial_epoch)
  File ""/home/magda/envs/offers2.7/lib/python2.7/site-packages/keras/engine/training.py"", line 1117, in _fit_loop
    callbacks.set_model(callback_model)
  File ""/home/magda/envs/offers2.7/lib/python2.7/site-packages/keras/callbacks.py"", line 52, in set_model
    callback.set_model(model)
  File ""/home/magda/envs/offers2.7/lib/python2.7/site-packages/keras/callbacks.py"", line 662, in set_model
    tf.summary.histogram('{}_grad'.format(weight.name), grads)
  File ""/home/magda/envs/offers2.7/lib/python2.7/site-packages/tensorflow/python/summary/summary.py"", line 203, in histogram
    tag=scope.rstrip('/'), values=values, name=scope)
  File ""/home/magda/envs/offers2.7/lib/python2.7/site-packages/tensorflow/python/ops/gen_logging_ops.py"", line 139, in _histogram_summary
    name=name)
  File ""/home/magda/envs/offers2.7/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 494, in apply_op
    raise err
TypeError: Expected binary or unicode string, got <tensorflow.python.framework.ops.IndexedSlices object at 0x7f577a114a10>
```",1
I propose that we consider the numpy backend as a true backend for the tests (without gradients of course).,1
"2nd can be solved by removing the exception catching in that function (I checked), but would want an opinion (Because the check _is_tf_1() has been used multiple times in that script, dont know why, considering it is a tf-2 branch).",1
"To my understanding, what's missing is the ability to specify a value to reach for the monitored quantity before considering to stop training.",1
"To address this issue, we introduce a new tag `oss_excluded` for platform exclusion design. `no_oss` will now be considered to disable broken tests, while `oss_excluded` will be used to permanently exclude a test from running on OSS.",1
ReLU is considered to be dead if it did not fire once for entire training set,1
"As of now, the following model is being considered as a ""Sequential-like"":

```python
from keras.layers import *
from keras.models import *

a = Input((5,))
dense = Dense(5)
b = dense(a)
c = dense(b)

model = Model(a, c)
model.summary()
```",1
This would fix that.,1
Alternatively it could be addressed within preprocess_weights_for_loading(),1
Following the contribution guide I consider this a simple bug fix which does not require an issue before?,1
There isn't a test written for this specific functionality but considering it's pretty straight forward I wasn't sure if new tests were necessary.,1
One should consider to rename the `MaxPooling` layers.,1
I consider this as a bug.,1
"Updating 100 times per second by default is crazy anyway, considering most monitors can't refresh that quickly.",1
The sorting algorithm is as defined by PEP 440 with the addition that any version which is not a valid PEP 440 version will be considered less than any valid PEP 440 version and the invalid versions will continue sorting using the original algorithm.,1
"If we want to add it as a parameter, it should be considered as part of the `update` variable in order to accumulate it into the `delta_accumulators` variable, if not, when it reaches a local minimum it starts bouncing and no total convergence is achieved.",1
"lease also consider my alternative external API proposals in https://github.com/fchollet/keras/pull/6928#issuecomment-309595218, but that should be kept separate from these internal improvements.",1
"I haven't tested it extensively, so I would consider it work in progress for now. I would also like feedback for further improvements & options.",1
this is considered to be [good practice](http://stackoverflow.com/a/32513360) and also used by other packages like [iPython](https://github.com/ipython/ipython/blob/master/setup.py#L192) or [lasagne](https://github.com/Lasagne/Lasagne/blob/master/setup.py#L32),1
"with regards to evaluating next generation AI algorithms, VQA is considered a compelling ""AI-complete"" task.",1
"Your layer will look like this:

``` python
class GlobalPooling2D(Layer):
    """"""
    By @entron
    Borrowed and modified from here: https://github.com/fchollet/keras/pull/522
    """"""
    def __init__(self, pooling_function='average'):
        super(GlobalPooling2D, self).__init__()
        if pooling_function not in {'average', 'max'}:
            raise Exception('Invalid pooling function for GlobalPooling2D:', pooling_function)
        if pooling_function == 'average':
            self.pooling_function = K.mean
        else:
            self.pooling_function = K.max
        self.input = K.placeholder(ndim=4)

    def get_output(self, train):
        X = self.get_input(train)
        return self.pooling_function(self.pooling_function(X, axis=-1), axis=-1)

    def get_config(self):
        return {""name"": self.__class__.__name__,
                ""pooling_function"": self.pooling_function.__name__}
```",1
"Looks good, just merged it.",1
@fchollet maybe we want to consider adding a small constant to the denominator of `cos` mode to avoid division by zero.,1
I would not have opened this PR if I had known that fixing minor errors in the documentation was not a desired contribution (the document currently suggests otherwise). Thanks again.,1
I'll fix that. ??,1
"@carlthome I hadn't considered the impact of dropout and similar things, good point, it would just be an approximation anyway.",1
You should consider upgrading via the 'pip install --upgrade pip' command.,1
"With regard to the large variant, I would also take EfficientNetB5 into consideration, since there still is a notable performance gap (0.7%) on ImageNet between B4 and B5.",1
"I'll just run the tests on monday on a gpu, but you can consider this PR merged. Thanks for the work.",1
It _seems_ that the PR would not add an unreasonable amount of new complexity.,1
"Your change doesn't affect the display of the markdown file in github, adding a second empty line can be considered a style change.",1
"The Code to realize that module would be:

```
# The bottom block where the module starts
model.add(MaxPooling2D(poolsize=(2, 2), name='base'))


# 1st row after MaxPool
model.add(Convolution2D(64, 64, 1, 1, name='conv11', prev='base')
model.add(Convolution2D(64, 64, 1, 1, name='conv12', prev='base')
model.add(MaxPooling2D(poolsize=(3, 3), name='pool1, prev='base'))


# 2nd row after MaxPool
model.add(Convolution2D(64, 64, 1, 1, name='conv21', prev='base')

model.add(Convolution2D(64, 64, 3, 3, name='conv22', prev='conv11')
model.add(Convolution2D(64, 64, 5, 5, name='conv23', prev='conv12')
model.add(Convolution2D(64, 64, 1, 1, name='conv24', prev='pool1'))


# DEPTHCONCAT [Green Box]
model.add(Merge(prev['conv21', 'conv22', 'conv23', 'conv24' ], mode='concat'))

# Used one standard number of filters (64) for simplicity. The actual inception module has varying number of filters for each type of convolution.
```",1
We could consider `reduce_axes` or `reduction_axes`.,1
We might also want to consider whether resizing a 3D input before applying softmax makes sense.,1
Maybe something like this could work?,1
Might be overkill but more code analysis than you would ever need.,1
"After consideration of the proposed API change: will not merge, sorry.",1
I think that would help many users!,1
- I don't think we need a new keyword argument.,1
"- I don't think we should log the post-scaling losses (after `loss_weight` has been applied), rather the user is going to care about the raw loss value.",1
"We can just look at `self.outputs`: if there are multiple outputs, then we will name the main loss ""total_loss"" in the `metrics` list, and we will add add each separate loss to the `metrics` list under the name `output_name + '_loss'`",1
"For example, it might be the case that you are choosing weights that perform really well on your weighted metric but your unweighted metric tanks, which could raise red flags and cause you to reconsider your approach.",1
I think you need to consider modality-wise batch processing for 3D data.,1
It's probably a bit complex.,1
"In some 3D cases, modality-wise transformation is important and otherwise, it may not.",1
"# result is nan, but should be 1.0",1
"# result is 1.0, but should be 0.5",1
And we should consider `model.trainable = True` may break the untrainable layers inside.,1
I think it'll be better if setting only container's `trainable` works perfectly.,1
Maybe we can consider it.,1
"That would be a breaking API change, though.",1
"There are ways to enhance the performance by feeding input directly into the graph, but this is going to mean a LOT of work to decrease training time perhaps a few percent.",1
"I also included other options (oov_char, etc), though they are rather niche, so perhaps their lack of inclusion was intentional.",1
This fixes it using the same trick in `Layer.__call__` to get the output tensor (suggests that the `super().__call__` perhaps should be called instead??).,1
Not sure if you'd rather have such configuration in a separate config file (perhaps helping to ensure any commits to master don't accidentally change where the documentation is built from).,1
"Perhaps we could centralize the location of useful data generators in `generators.py`, like the random image transforms, to make it easy to find?",1
"The exact implementation is perhaps confusing, and is due to overloading of `sample_weight` to be both a weight and a mask.",1
"I personally only use it as a mask, so perhaps anyone using it for weighting should make sure that this is appropriate for their use as well.",1
# Perhaps this aspect of API usage can be improved?,1
Perhaps the documentation should be updated to indicate the desired behaviour more clearly so that the functionality could be compared to that.,1
The variable `num_predictions` was perhaps confusing too in addition to being unnecessary because:,1
Maybe the variable is vestigial?,1
ERROR: Analysis of target '//keras/layers/convolutional:conv_test' failed; build aborted: error loading package 'keras': Label '//tools/build_defs/license:license.bzl' is invalid because 'tools/build_defs/license' is not a package; perhaps you meant to put the colon here: '//:tools/build_defs/license/license.bzl'?,1
Perhaps someone could check TensorFlow support as well?,1
However I wasn't sure how to use it and found out it's not included in the documentation perhaps because it was added quite recently.,1
"Perhaps add a comment with that information around the if switching, in case TensorFlow ever becomes available? :+1:",1
Perhaps your questions point to a larger interface design issue.,1
"If not, perhaps such a fix could be included?",1
"Perhaps in `fit()`, in the call to `self._standardize_user_data()`?",1
"Having the sparse block dot operation really seems to be key, but perhaps you've found a way around it?",1
Perhaps @farizrahman4u's implementation could be used instead?,1
"Perhaps the random number generators are being called in a different order, and so produce slightly different numbers?",1
It seems to be working fine.,1
Perhaps you aren't using Python 3?,1
"We should either introduce a notion of ""control dependency"" in the backend (best UX), or perhaps remove `__call__` from the API since it cannot be used correctly.",1
Perhaps you are using an outdated version of Keras?,1
Perhaps this use case could be covered in a simpler fashion by also adding `invert` to the `Normalization` layer?,1
Also the graph you produced did not show any advantage for using BN in LSTM so perhaps you need to find a different test program,1
Perhaps the simplest example I should try is Hinton's 'binary addition' example.,1
"EDIT: wait actually, if I just used some random tokens in pickles, this perhaps would not be a problem?",1
"I personally only have a CPU, so perhaps someone with a good GPU can try too.",1
And perhaps there's a way for metrics to be refactored to not copy the code of all the loss functions in metrics.py,1
"@fchollet Since there doesn't seem to be other reviewers, perhaps you can mention some general guidelines to follow, to which I can adhere to?",1
But perhaps I am missing some of the finer details.,1
Perhaps I need to run a few tests with 1000 epochs for VGG-19 and 16 to see if I can differentiate between them.,1
Perhaps CuDNN is the deciding factor here ?,1
I will try and disable CuDNN to see if I can replicate this issue.,1
Perhaps it would make more sense to move the fix into preprocess_weights_for_loading() then unit tests could just work with weight tensors that are constructed in the old style?,1
Would you be open to discuss a solution that would make the training variable changeable after the network definition (or perhaps another property)?,1
"Wouldn't it be less computationally intensive to pad with zeros before
calling conv2d and then use a _valid_ border_mode (perhaps by using the
newly ZeroPadding2D Layer?",1
"Interesting what you mention about the 5% slow down, I would love to see the benchmarks; perhaps it can be resolved.",1
It will not work for the pretrained models of Keras or when a model is loaded from disk.,1
1) Again this will work only if the network is defined based on code.,1
"2) After setting the learning_phase(1) in your example, the learning_phase will be static for the remaining of the session.",1
This will overwrite all the nice mechanisms that keras has for switching between phases depending on whether it trains or predicts.,1
Or perhaps some other longtime contributor of the BatchNormalization layer has an opinion or can offer a more elegant solution on this? @ozabluda @taehoonlee @farizrahman4u @Dref360,1
"Currently there is no straightforward way to do what I describe (the current API doesn't cover it), nevertheless if you provide specific guidelines on what tickboxes the update should check it would be useful.",1
I wish I had provided on my PR the example that you posted on the issue #9214; perhaps this would have built a stronger case for this patch.,1
At the very least perhaps someone could make a PR with an example which demonstrates fine tuning correctly with the current API?,1
"I think this all still indicates there is an issue: the keras API could be more clear and easy to use when fine tuning, with an explicit and easy to use choice between the options mentioned by @ppwwyyxx (plus perhaps Group Normalization).",1
Perhaps that's an opportunity to resubmit this fix for consideration.,1
@fchollet Perhaps the DenseNet models (not FCN type) should be added to core Keras since they offer more functionality?,1
"@EderSantana perhaps we could team-up on this one too, I've got some ideas that I think can be quite usefull.",1
"I've added `output_ndim`, but perhaps there's a more compact api for graphs by specifying both in the same dictionary?",1
It's supposed to give you control over both (perhaps the naming could be better).,1
"Perhaps it would be better to default to using `class_weight` on the validation data and allow people to not weigh their validation data by explicitly passing in `None` as the third part of `validation_data`, e.g. `validation_data=(x_test, y_test, None)`.",1
"Perhaps that is a matter for a separate pull request, but AFAICT we could easily have name collisions - would one notice that they had inadvertently masked some non-descriptive name such as ``ELU``?",1
perhaps just read an env variable to check if the user wants it printed or not?,1
"Side question: any interest in merging a small hyperopt class, perhaps in a file next to multi_gpu, which calls [GPyOpt](https://github.com/SheffieldML/GPyOpt)?",1
It'd be a couple weeks before I can submit it.,1
I would suggest putting it in Keras-contrib.,1
"Though some of the same concerns we had about what value to use as the mask signal apply, and perhaps there's a completely different approach that solves that.",1
Perhaps the following example will demonstrate what I mean:,1
"Suppose I have defined the model, then I will compile it, train it and finally save it.",1
Perhaps the labels aren't actually being used in the loss function?,1
Perhaps you could even create a separate `fit_tfrecord` function just as there is a separate `fit_generator` function.,1
This would allow us to add the functionality without any changes to the API for existing users.,1
"Until then I have it on github it so others could leverage and try the code, perhaps even improve and fix features that I'm trying to implement.",1
If this is merged the documentation must be updated and perhaps include the example that you gave.,1
Perhaps you had a git issue somewhere along the ride?,1
"I'm unsure of the dimensions of x, W and U though so perhaps this is just mumbo jumbo.",1
Perhaps we can revisit the semantics of `Add` layers in the future and make them more consistent with the `+` binary operator.,1
At that point we could apply this change.,1
"@anerirana if you're still interested in contributing something around this, perhaps you could contribute unit tests that mean we wouldn't have to run the full internal tests if we ever did want to revisit applying this change?

(e.g. use the above examples that work for `+` but not `layers.Add`",1
@neggert I like the fact that the api would work consistently between both theano and tensorflow backends...,1
can you perhaps try to use average pooling to downsample which should also do the trick for the residual layers?,1
Keep in mind I haven't tested it with any new keras version since the latest when this code was written - perhaps some APIs changed.,1
Perhaps there's something wrong in my build procedure?,1
"Overall, though -- I think it would be really nice for keras to have alternative softmaxes for high-dimensional output spaces.",1
"I think in a lot of other APIs, there's no option for PReLU to have a tensor of slope parameters across more than one dimension, so your only choices are to have one shared slope parameter for all neurons in an entire layer, or to have N different slope parameters, where N is the dimension of one of the axes (usually the channels axis in a convnet, or the features axis for dense layers).",1
"I might be misinterpreting the Torch source though, so I could be wrong.",1
"An alternative would be to
use `np.ceil()`, since np is already imported (removes one extra line in example)

AND

1a. cast denominator to `float` first
OR
1b `from __future__ import division` (adds one extra line in example)",1
"For test_data_utils, as an alternative that wouldn't involve large whitespace-only changes, I could write a decorator that runs the function in a temporary directory",1
It was my best guess at what it should be doing.,1
"The default value for this is {} so I'm guessing it wants dict input, rather than a list of tuples or something that would otherwise work as-is.",1
guess it was copy-and-pasted,1
I'm guessing you mean using the same caffemodel file and slowly building up the prototxt one layer at a time?,1
My guess is when calculating the "gradient of a strided convolution".,1
My guess is that it may be that Travis made a change that resulted in builds timing out after ~20-25 min (exact timing is non-deterministic).,1
my best guess for what a numpy implementation of batch norm should be.,1
We can only just guess that it will lie on somewhere between the `N`-th and the `N-p`-th.,1
"In my guess, the eight variants are for the performance curve with respect to the proposed scaling rather than practical uses.",1
"We would have to make it very clear, for which 8 values we have pre-trained weights.",1
"It is a problem to guess not only phi but also alpha, beta, and gamma.",1
"@taehoonlee Having a single hyper-parameter is a very nice option, but I am afraid that the ""valid"" values for `phi` are a bit hard to guess, given that it is continuous.",1
"In my guess, the three numbers have been updated since the official implementation was released.",1
I am guessing that you still want to provide support for theano and tmp dir in the backend section right?,1
1)  Will hop on this ASAP.,1
"But to not even point to the SWWAE, Deconvnet, or Res Net papers is silly, so will add that and a better explanation soon.",1
I'm guessing after loading the prototxt and caffemodel we can directly predict?,1
"Learning to work with the Applications module of Keras I bumped into this same issue. In the beginning, I thought I was overfitting, but when I tried to finetune VGG16 it did not overfit, so I started guessing that the problem could be the same as you are trying to fix.",1
I suppose we can't merge this as-is right?,1
The function `_test_no_grad` is supposed to test that a `ValueError` is raised when there is no gradient.,1
"After this fix, the argument `period` does what it is supposed to do.",1
"With a mode=2 layer, compilation failed with ""ValueError: Dimension 3 in Rebroadcast's input was supposed to be 1 (got 8 instead)"" when running the first training batch on the discriminator.",1
I chose to start by implementing a Highway LSTM layer in order to get a feel for the problem and because I wanted to see if they really are as good as they are supposed to be.,1
"I noticed that the clip_norm variable was unused, and I think this is how it was supposed to be used.",1
I suppose that's the intended behavior.,1
I suppose one possible use case would be the careful construction of the `X` and `Y` tensors such that they contained all training examples followed by validation examples with precise use of `steps_per_epoch` and `validation_steps` to make sure the right data is read at the right time.,1
It feels like this would be tricky to pull off at best,1
Solution to this is decreasing the learning rate with rmsprop as I supposed or changing the optimizer like Adam or SGD.,1
Supposedly latent vector encodes "style" or something.,1
"It turns out that sklearn should only see the get_params from the wrapper class, but not the get_params from the keral model itself, as the latter doesn't follow the sklearn API (and it is not supposed to).",1
Those changes are suppose to work with CNTK v2.0 GA.,1
"fix for #170, including constraints. Nothing fancy, just copied the code from the dense layer, but I suppose it should work the same.",1
"Oh, actually, you're not supposed to import from within tensorflow directly.",1
Nothing about it is supposed to be "trainable params only".,1
"It should *not* report just trainable weighs, and it shouldn't change based on the `trainable` layer property.",1
The output of a model will never be binary (achieving it would involve non-differentiable operations).,1
A `keras_test` is already supposed to tear down the TF graph after running.,1
But I suppose it's fine since we can put comments in the code.,1
"Users are supposed to do `import keras.backend as K`, not `from keras.backend import *`.",1
I think they are supposed to be metrics.,1
@gabrieldemarmiesse  Its supposed to be a module from a package rather than a standalone file.,1
Ok I suppose that we can suppose that we have a backend called `my_package.my_backend`.,1
"Suppose we have a Tensor of shape `(None, 10, 5, 4, 3, 2)`, reshape it to `(None, 10*5*4*3, 2)`, ie. collapse all the axis in the middle.",1
I had completely missed the point that the function is supposed to work on batches of input and not individual vectors.,1
This is supposed to be used with stateful RNNs,1
"@fchollet, maybe this PR and https://github.com/fchollet/keras/pull/8233 are good candidates for the upcoming Keras 2.1.0, since they are supposedly API and docs improvements.",1
"Short term, I suppose we could either merge or create something like `timedistrib.py` (or something of that ilk), or hold off on the time distributed version of the `Highway` and work on a generic `TimeDistributed` layer.",1
"I suppose for that, we would just need a `step(x, states)` defined for each non time-distr. layer, then internally we can call `K.rnn(self.step, X, [], masking=False)` inside `TimeDistributed`, similar to what we have now.",1
I suppose it would make sense to put the code from this PR into one utility module for graphing with #172.,1
I will add documentation if you want to merge this.,1
"It also seems very weird that a string is expected here, since that's supposed to be the shape argument (you'd expect integers).",1
"In the case of the BGR channels order I suppose so, but for the mean pixel maybe it should be integrated in the ImageDataGenerator.",1
"In the case that `keras.backend.truncated_normal` is really supposed to have a lower standard deviation than the one provided as argument to the function, the correct Theano function to use, would be [`rng.normal(shape, mean, stddev, dtype, truncate=True)`](https://github.com/Theano/Theano/blob/master/theano/sandbox/rng_mrg.py#L1051-L1053).",1
Normally in such situations what you're supposed to do is merge the master branch then resolve any conflicts by hand.,1
so I suppose the embedding should be fine too.,1
"I suppose a simple layer e.g. `Dense(input_shape=X))`, where `X` is the shape of the input tensor, including the batch size.",1
PR: https://github.com/fchollet/keras/pull/6387 was supposed to address the use_learning_phase but still suffers from when model has submodels.,1
You're not supposed to modify it during training.,1
I think not seeing the CI/CD output before you allow it to run is making it harder for me to catch this kind of stupid mistakes that the CI/CD would have reported to me at once otherwise :) . (I suppose CI/CD does not run automatically when I push so that you cannot get ddos:ed or something like this?),1
"Can't think of any examples, if there isn't any I suppose it could just be inferred by subracting one.",1
No one is supposed to know that this internal `model` attribute even exists.,1
"Sounds good, thank you for the effort.",1
`sample_weights` are supposed to be all positive values and never sum to zero.,1
"@bstriner if I'm not mistaken we need this also to allow custom e.g.  `Layer` classes to re-use keras test infrastructure as well as contrib, since, e.g. `keras.utils.test_utils.layer_test` also does not accept custom_objects parameters, so I suppose what contrib layers there are currently use the global monkey-patching solution.",1
"When I was going through the docs, I thought the following lines weren't too clear on the format of the generator output, and thought that x and y were numpy arrays to be returned, while x is actually supposed to be a numpy array wrapped in a list:
`# create Numpy arrays of input data
        # and labels, from each line in the file
        x, y = process_line(line)
        yield (x, y)
`",1
"If my understanding is right and you're ok with it, I'll go ahead and submit a PR :)",1
"This was no visible from the GH PR interface, and since tests are supposed to fail at this point, I didn't even check them.",1
And i suppose that it doesn't work in sequential models since they are not named.,1
The performance of the actual Keras model may vary slightly from reported results even if the weights are supposed to be the same.,1
Suppose you are doing video captioning.,1
"So currently you are supposed to be able to:
- build models on top of tensors
- train with `fit` with partial Numpy data (i.e. any tensor input will no expect Numpy data), e.g. `fit(x=None, y)`",1
"@fchollet, maybe this PR is a good candidate for Keras 2.1.0, since it is supposedly an API improvement.",1
I think that making `trainable_weights` return only trainable weights might solve all regressions - is that what `trainable_weights` is supposed to do?,1
"@tleeuwenburg the above could be used as a fallback when h5py is not available, I suppose.",1
@fchollet I will be sure to review those changes. It's ironic because those changes were supposed to improve PEP8!,1
"Adding batch normalization to the Discriminator breaks training so badly, that I suspect a bug (maybe https://github.com/fchollet/keras/pull/5647 is fixed incompletely or something).",1
Layer attribute tracking was introduced in 479fc3a978221bb835f7e2781dcef0db66c96e1c by @fchollet and it included what I suspect to be a debug print statement that wasn't meant to be merged.,1
"On the categorical_crossentropy function at the theano_backend (I don't have the TensorFlow installed, but I suspect the same fix must be applied there...).",1
I suspect the errors in the failing Travis CI build are unrelated to the changes made in this PR.,1
I suspect the various `INTERNALERROR`s in the failing Travis CI build are unrelated to the changes made in this PR.,1
"Is so, we'll need that before we can proceed with a change here in Keras.",1
The `loss` of the result of `Model.fit()` should not change with the strategy being used.,1
"I suspect its a result of the silent fallback on https://github.com/keras-team/keras-preprocessing/blob/master/keras_preprocessing/image/iterator.py#L15, but I don't know why the `get_keras_submodule('utils').Sequence` would throw since this example starts with `import keras`",1
I suspect that the reason we have different logic in Layer and Model is to preserve weight ordering backwards compatibility.,1
I would love to know if you can reproduce my results and whether you can observe any speed degradation that @fchollet suspects.,1
@fchollet I did not run Imagenet evaluation as I suspect the models are unchanged.,1
I suspect it's the impact of `KTF._set_session(session)`.,1
"So, I decided to just save your processed images and use the same minibatch generator as I suspected the discrepancy could be in the keras on the fly image data augmentation as it applies all transforms in to single transform homography matrix.",1
I suspect that keras's SGD is a bit different from the lasagne momentum and weight decay.,1
We will see when they finish.,1
I suspect it might also fix the aforementioned bugs.,1
I'll put tests in #7061.,1
TF 1.3 will be a couple months.,1
I'll put tests in a separate PR. Would you prefer them on master,1
"1. I'll focus on https://github.com/fchollet/keras/pull/7046 which drops `Model()` API changes, but includes `is_placeholder()` and the internal fixes.",1
"I may be mistaken, but I suspect that something like ~80% of these changes will prove necessary in practice.",1
But I suspect that it's not the internal developers that are usually introducing them.,1
And when next person with hooks touches that file the issues will be fixed automatically.,1
I suspect there might be issues with the dataset that would cause results to be semi-random.,1
"Maybe just the very small size of the dataset (especially the test dataset), coupled with the quantized metric (accuracy).",1
An easy way to check this would be to look at the variance between different runs with different random initializations.,1
I suspect this will introduce code duplication but I agree this is motivated by avoiding adding any additional complexity to the `RNN`.,1
"This PR was still open because it is a suspected bug for which no fix exists, perhaps this is expected behavior or I misunderstood something?",1
You should do IP-based rate limiting.,1
I suspect it is related to this change.,1
Perhaps you can spot an easy fix?,1
"I suspect the issue would be with:

```python
if self._use_multiprocessing:
    traceback.print_exc()
    setattr(e, '__traceback__', None)
elif not hasattr(e, '__traceback__'):
    setattr(e, '__traceback__', sys.exc_info()[2])
```",1
I suspect the `Pool` class also uses one internally (didn't check though).,1
"I suspect that with 2 samples and `validation_split=0.2`, validation set was empty.",1
In the future I suspect that we will move some layers outside of `core.py` too.,1
Can't believe this wasn't already done!,1
I've only received positive feedback so far and believe the API is pretty solid and general :D,1
Closing this issue because we believe the path forward is to use `tensorflow.keras.backend.rnn` for the implementation of this function.,1
I do believe that such an arbitrary-connectivity scheme would be very valuable to have in Keras.,1
"Thanks for the PR, but I don't believe this is a necessary change.",1
Previously the description led you to believe that all values for a given timestep had to be the mask_value (across all samples).,1
"I have forked keras, and believe that I have a somewhat functional version of [two-layer hierarchical softmax](https://github.com/jmhessel/keras/blob/master/keras/layers/advanced_activations.py#L268-L395).",1
"I asked some questions about graph rewriting on the slack channel a while back, and the feedback I got from there has led me to this pull request, implementing what I have come to believe is the most fundamental operation required to perform ""net surgery"" within Keras.",1
But I don't believe it's important.,1
I don't believe this can be avoided in a truly parallel solution.,1
We believe it is an acceptable breakage because:,1
I'm afraid that would be against duck typing.,1
"Yes, I'm afraid this is true.",1
"@Callidior, I'm afraid too.",1
"And I'd also fear breaking something that might not even be tested, these fixes start to get deep into implementation details which I'm afraid may only be obvious to those with extensive experience in the codebase.",1
"Because some people asked about it and also otherwise, showing `Add()` and `add()` could be a bit confusing I'm afraid. (+Those functional interfaces resemble backend functions..)",1
So I'm afraid with current tooling we won't get there.. :(,1
I'm afraid `attended` wouldn't be sufficiently explicit.,1
"I'm afraid I have to retain these layer names because only when names of model layers and names of corresponding weights get matched, the weights could be set correctly.",1
"Presumably this was an error when copy/pasting, causing only the last input tensor to be checked.",1
"As a result of this confusion, instead of (as I presume was intended) encoding the bytes as Unicode escapes, the code was _searching the bytes for anything that looked like a Unicode escape and parsing it as such_.",1
"Presumably, the reason this mistake was made is that marshal returns bytes, which needed to be converted to a string, and decode is the method used to do that, despite the fact that semantically decoding is the opposite of the operation that needs to be performed.",1
"~~This does not go as far as to implement an `evaluate_generator` method (which would allow, presumably, to use validation generators in other fit methods as well).~~",1
"I presume there's some reason that the `normalize_legacy_config` function is defined in `from_config` and not `get_config`, although it isn't immediately clear to me what that is.",1
"That's where I was looking for it, and I presume other would. input/hidden/output layer is standard terminology (with industry finally mercifully settling on not counting input in the number of layers).",1
"That test passed in most other commits, so I presume it is a bad randomization?",1
"Presumably, a new technique that does result in meaningful gains would be broadly adopted after a few months anyway (like ResNet), and that’s when we would be adding it to the core API.",1
3) It should have an owner committed to maintaining it in the long term.,1
"1) It should be broadly useful to our users, rather than a niche feature that is only relevant a specific vertical of researchers.",1
2) It should be widely recognized as a machine learning best practice.,1
"Closing (since there will be a new PR, presumably)",1
"(presumably the reason why I missed it is because I initially skipped it to due to failing tests, then forgot to check back on it)",1
"still, I think there is an underlying issue, which is that  the entire way the namespace is access in keras is a little strange if we want to allow contrib modules; presumably this underlying object access system will change eventually?",1
"Given the algorithm used, there should be no presumption of bug at this level...",1
I presume changes in example script can be auto merged without human review?,1
"I had this issue and it manifested in an infinite loop using fit_generator(presumably because it was running on a different thread), proving difficult to track down but this fix worked for me",1
"Presumably you are submitting your changes against some internal tool, which is then making PRs for this repo.",1
"From the minimal facts included, my idea is that they fed the entire input into a single RNN, including the query, presumably then running a dense layer on the RNN output.",1
"Most of them already exist in `keras/tests/keras/test_sequential_model.py`, I just added a few which look like what we tested before.",1
"This fixes it to look like this

<img width=""272"" alt=""after"" src=""https://user-images.githubusercontent.com/506602/32023261-fab4927e-b9d8-11e7-8b25-b12ad6067de1.png"">",1
"If we add delimiters, it will look like this:
```
__________________________________________________________________________________________           
Layer (type)                   | Output Shape     | Param # |Connected to                                 
===============================|==================|=========|=============================                
noise_input (InputLayer)       | (None, 100)      | 0       |                                              
auxilary_input (InputLayer)    | (None, 47)       | 0       |                                               
concatenate_1 (Concatenate)    | (None, 147)      | 0       | noise_input[0][0]                             
                               |                  |         | auxilary_input[0][0]                          
dense_1 (Dense)                | (None, 1000)     | 148000  | concatenate_1[0][0]                           
batch_normalization_1 (BatchNor| (None, 1000)     | 4000    | dense_1[0][0]                                 
leaky_re_lu_1 (LeakyReLU)      | (None, 1000)     | 0       | batch_normalization_1[0][0]                   
...                            |                  |         |                                                
batch_normalization_4 (BatchNor| (None, 400, 1)   | 4       | conv1d_3[0][0]                                
activation_1 (Activation)      | (None, 400, 1)   | 0       | batch_normalization_4[0][0]                   
=========================================================================================

```",1
"@dilipajm that does look like another backwards compatibility issue, but I don't think it's related to the bug I was fixing in my PRs...",1
"Does not look like an assertion error, but rather a CUDA launch issue.",1
"Also, I believe it will remain tricky for users to understand what the legal permutation list look like when just using the API.",1
"Sure, It would look like this:

![195469866-dbb40180-f2b7-4b82-8536-32eedeaa59d4](https://user-images.githubusercontent.com/18636378/198835709-d9649436-7e80-4b0f-aff9-40a4ee71cf37.png)",1
"For example it can look like this:
# --- metadata file begin ---
# super
# cool
# metadata
# file
# --- metadata file end ---",1
"So it would look like:

```python
def _preprocess_numpy_input(x,...):
    ...


def _preprocess_symbolic_input(x,...):
    if data_format == 'channels_first':
        if K.ndim(x) == 3:
            ....


def preprocess_input(x,...):
    if isinstance(x, np.ndarray):
        return _preprocess_numpy_input(x,...)
    else: 
        return _preprocess_symbolic_input(x,...)
```",1
"This is starting to look like it duplicates the resnet model functions in keras_contrib, perhaps it would make sense to move that into keras/applications as part of this PR or as a separate one?",1
There are also several functions in theano backend that look like they have old documentation that could be deleted so it will be replaced by the current tensorflow documentation.,1
I do think I should put epochs parameter back.,1
"Now epochs does look like a weird exception, as in ""we pass everything, except (for unclear reason) epochs, which is hard-coded'.",1
It seems cleaner (at least to me). Also using `exec` for putting a function (called func in this case) in the global namespace doesn't look like a very robust solution.,1
these look like nice changes,1
"Ah also I had only been running the `test_recurrent.py` tests, look like some other stuff broke.",1
"It's not working yet, but yes, it looks interesting to me.",1
So now I have to copy-paste more than 40 lines of code – does not look like a good idea.,1
"The return strings will look like this:
```
>>> from tensorflow.python.client import device_lib
>>> l1=[d.name for d in device_lib.list_local_devices()]
>>> l1
[u'/cpu:0']
```",1
"So the return strings will look like this:
```
>>> from keras import backend as K
>>> l2=[d.name for d in K.get_session().list_devices()]
>>> l2
['/job:localhost/replica:0/task:0/device:CPU:0']
```",1
"Also, I think you'd better to check this comment by @datumbox on the code that #8567 changes.",1
But now it's starting to look like a `Graph` =),1
"That is a very different type of API, but it would look like this:

```
branch1 = Sequential()
branch1.add(Dense(10,10))
branch1.add(LSTM(10))
branch1.add(Dense(10))
branch1.add(Dense(1))

branch2 = Sequential()
branch1.add(Dense(10,10))
branch1.add(Dense(10))
branch1.add(Dense(10))
branch1.add(Dense(1))

model = Sequential(inputs=[branch1,branch2],merge_mode='sum',shared_tuples=[(branch1.layers[0],branch2.layers[0]),(branch1.layers[2],branch2.layers[2]))
```",1
"2. The ""see installation instructions"" are unqualified and on lines of their own, and they look exactly the same, so that they look like they point to instructions within the keras documentation.",1
It doesn't look like there is currently a way to weight different indices within a particular output layer.,1
"Apologies for not documenting the code (and not following any relevant coding standards), feel free to comment any changes that might be necessary to make this better.",1
I don't feel very confident with this as I don't fully understand the internal working of keras.,1
"Or maybe I'm just dumb and there's an easy way to do this (tried ""loss"" as the metric in the multi_output dictionary, didn't work, would have had to respecify each function by name)",1
"However, I feel it can be easier to declare custom objects by adding them a decorator, something like:

```Python
from keras.utils.generic_utils import custom_object

@custom_object
def myloss(y_true, y_pred):
    return (y_true - y_pred)**2.0
```",1
"I wanted to discover the progress of my network, just to feel that things goes as I expect, and I found such a thing as TensorBoard, which helps us to visualize training process.",1
"I don't feel like I understand what exactly name scopes do very well, so I might have done this incorrectly, but in my tests, this fixes #5820 (you can't save models with bidirectional layers, because there are overlapping names; I only ran into this with theano, incidentally; tensorflow worked fine).",1
"I have a feeling that having `DeprecationWarning` and `Exception` later would be better, but that's up to you.",1
"If there's interest I'll clean up according to the guidelines, otherwise no hard feelings :-).",1
"Feels pretty hacky, though, and it doesn't fix the real problem, which is Keras doing unexpected transformations to the model predictions ""behind the scenes"" without the user's knowledge.",1
"Whilst this is not a task where the RNNs is expected to win, I still feel it provides a good demonstration.",1
"Overall I think this is better 1) because I feel it aligns with what users would expect out of categorical accuracy, 2) reuses already functional code and is more maintainable since in the future the team would only have to worry about making changes to sparse functions and categorical accuracies will be covered.",1
I'll be waiting to see community consensus in order to include a new loss/metric.,1
"Closing for now, feel free to reopen if you want to make a case for this feature (preferably you'll need a simple example, which doesn't have to be packaged with the PR, and you'll need unit tests as part of the PR).",1
"Hi @adriangb I'm going to go ahead and close this PR, because it seems to have stalled.",1
"Will give you write
permission on the fork as well as toynet, if you like.",1
On the other hand I feel that the current implementation has a major drawback because it ignores the way Keras aggregates metrics internally.,1
I will close this PR once I port it to keras-cv (unless you want to close now).,1
"This PR is stale, I'll close.",1
The thread will then die and kill the `mp.Pool`.,1
I have a strong feeling that it's just the usual OOM from tensorflow since 1.9.,1
I'll investigate the stateful metric test.,1
"When we call `stop`, the enqueuer shouldn't be used and the data shouldn't be trusted.",1
"This still feels suboptimal, but seems to be one of the best ways to get this to work while still keeping inside the Keras architecture.",1
I'll close this.,1
"I can understand not wanting to alter `models`, but I feel like this could easily benefit people by being in the keras repository --- ideally, it should take one extra line to visualize your experiment, not integrating a whole third party library.",1
"It will be closed after 30 days if no further activity  occurs, but feel free to re-open a closed issue if needed.",1
"So if you feel like doing it, it would be great.",1
My feelings aren't particularly strong on this.,1
"I'm very interested in adding this feature, and as I feel this is a significant change I will take a little bit to review this PR.",1
"I feel like someone could accidentally output the wrong type of float and want it to be automatically converted to the right size, so the existing behavior makes sense.",1
I feel like they can also serve as an additional sanity check.,1
I've thought about the problem some more and came up with a slightly different implementation in https://github.com/fchollet/keras/pull/3345/commits/b715ecc744b115d3328b0d5a68c1d2e0b8a2c9de that feels less hard-coded to this specific problem.,1
I feel like there is a use case for both copying and not copying the results so I would suggest leaving the option there and setting the default to `False`.,1
I will make a new commit to this PR tomorrow.,1
But indeed I feel uncomfortable with having sum_values being the holder of the "BaseLogger values" (since the name implies some kind of sum.,1
"For the record: overall I feel weird about `class Progbar` existing at all, instead of delegating that to the `progressbar` library.",1
"I feel the use-case of multi-input models deserves more discussion, though.",1
"The repo you linked was last updated 9 months ago... still more up-to-date than the other versions, but I feel like this one is going unmaintained as well.",1
I felt it was generic enough to be useful to other folks so I decided to submit a PR.,1
"Its pretty bare-bones and does not implement the restore-best-weights feature of the early stopping callback, but I felt it was better to submit the version that I've used and let others decide on what features to add.",1
"Shuffling of imports seems critical when dealing with large datasets that might be started/stopped irregularly, and this felt like the best way to handle shuffling with HDF5.",1
I _do_ think this behaviour would need documentation.,1
Every time I read the documentation for this I felt it was unclear.,1
"I felt that the removed lines were redundant, given the new example.",1
"I did this partially as this felt naturally to me, partially as I wanted to use the Merge API, and finally as I feel it's a fairer baseline.",1
We just haven't had the time to tackle this yet as we felt the other improvements had to come first.,1
I felt that here it was not too much of a problem since we were going to squash eventually so the heavy commits would not be in the git history.,1
"This sounds exotic but this happened to me in a generator that rendered PDF files and in the initial testing, epoch size was just a small multiply of batch size (and similar to validation set size).",1
"From this comment it sounds like there is an implicit
`Flatten` layer before the dot product with `kernel`.",1
"However, this seems misleading to me, as the output
shape of this layer is the same as the input shape
with the last dimension replaced by `units`.",1
Sounds good!,1
"If it is used at least 2 times, then sure it sounds like a good idea to make it part of the backend.",1
Sounds great.,1
It sounds like it's indeed best to keep this issue open then.,1
@gabrieldemarmiesse This sounds useful to me.,1
"4. It seems to me that tf.images.resize_images are designed for image pre-processing, not for intermediate layers (in early days, this op only runs on CPU, not GPU) are too generic for the simple goal of scaling the tensor by integer times, and tf.tile+tf.reshape sounds more reasonable for nearest, and tf.tile+tf.reshape+tf.conv2d (with pre-defined kernel) seems more reasonable for bilinear option.",1
Sounds like a good idea.,1
Sounds like we'll have to do a new release.,1
Sounds great!,1
"Sounds good on investigating the OOM, let us know your findings.",1
"If you don't spot anything there, we should look on the order of the data that I describe above.",1
Sounds good. :-),1
@PavlosMelissinos that sounds reasonable.,1
"3. It would be useful to record which device we places an op on; TF has <tensor>.device we could wrap, but for Theano it sounds like we'd have to keep track ourselves.",1
Sounds good to me.,1
"@fchollet I agree, `freeze_updates` sounds like the best of your suggestions",1
Sounds like something useful,1
And achieving it using unique identifiers for each layer sounds reasonable.,1
"Ok, sounds good.",1
"I chose `shared_axes` because `reduction_axes` sounds to me like a reduction operation is being applied along certain axes, which is not the case.",1
"@fchollet 
Yeah sounds good.",1
"That sounds like a good, pragmatic solution to me.",1
@lunardog This sounds good.,1
Sounds good.,1
This should be added to the BN test.,1
That sounds good!,1
"Sound reasoning, thanks for the explanation!",1
That sounds like a great idea - let me know if I can help.,1
"It's not as crazy as it sounds, but still very inefficient.",1
"I finally read through this in detail, and it sounds fantastic!",1
"Sounds great, I'll have a look this weekend.",1
This sounds like a good idea.,1
"It seems to be specific to the 4D tensor case with `dim_ordering=tf`, so I think we should just specialize for this case and use the less efficient but more generic current solution for others.",1
I'll give it a shot after Christmas.,1
"But this sounds like a hack to me, my prediction time increases.",1
"This discussion is at a good decision point, @titu1994 that sounds reasonable.",1
"OK, sounds reasonable.",1
"In theory it sounds good, but in practice all tests are failing.",1
Sounds reasonable,1
"This sounds ok at a high-level, but it should not be part of the public API.",1
"Otherwise its role is so tied to the dynamic use of `trainable` as not to make sense in the bigger picture (what would be some other use cases in which one would want to call `rebuild`? What is the _UX_ justification for having both `compile` and `rebuild`, as they sound conceptually similar?).",1
Then again... it sounds complicated.,1
That does sound like a good plan for now.,1
That sounds very reasonable.,1
"Yeah, sounds good.",1
@roywei Sounds great!,1
"Yea, following option B sounds good to me.",1
"@EderSantana this PR is too old, but adding a Recurrent-Convolutional layer sounds good to me.",1
"Sorry, didn't mean for that to be as rude sounding as it was @kirk86 .",1
It sounds much cleaner.,1
It seems to be an issue with the input layer being 'conv1_1' instead of 'data'.,1
Doesn't seem to match up.,1
@fchollet I'll have to delve deeper into the code to figure out next steps.,1
There doesn't seem to be any simple linear relation.,1
It does seem like it could be a relu issue given that the keras result has no zero values and the caffe one does...but not sure how to check it.,1
`network.get_config()` could offer some insight.,1
"Also, it would be great to have your code so we can reproduce these results and investigate.",1
"Dropout will only be applied in 'training' mode, i.e. using `model.train`, etc.",1
"Layer objects have _a lot_ of attributes (I count 132), and I can't seem to find any documentation for them.",1
That doesn't seem right.,1
It seems like that may be out of my control if I am using the pycaffe wrapper then.,1
"i was having a look at convolutional.py, but it seems that all layers require the explicit definition of the ""pool_size"".",1
"I don't know much about the internal of theano, and it seems this problem has been there for quite some time.",1
"Additionally,  I was hopping to add the dnn conv3d to the functionality, but it seems conv3d in dnn is not exposed to theano as yet.",1
"So, I would commit the support for cpu and gpu(without dnn backbone) right away.",1
"For the most part it seems to work, though I had to make a few fixes:",1
"3. Moreover, the method `get_config` should also include the following two lines:

```
base_config = super(Convolution3D, self).get_config()
return dict(list(base_config.items()) + list(config.items()))
```

to include fields for super class `Layer` (like `Convolution2D` does).",1
"It would be awesome, @MinhazPalasara  and @fchollet , if this PR could be merged soon.",1
"As you can see, `conv3d2d.conv3d` seems the best on both GPU and CPU.",1
"Ok, it seems like the coveralls job doesn't wait for Travis tests to be completed before outputting an error.",1
So by definition it will always start by failing --then it fixes itself.,1
It seems there is a softmax for match in the paper.,1
There seems to be various git issues with this PR. Please sync with master.,1
Maybe create a new PR.,1
"In my experiments I found that it can be very important to add regularisation over the embeddings (without dropout over the embeddings the loss seemed to decrease and increase in a snake like shape, which was resolved by adding embedding dropout).",1
Seems good to me,1
"Theano code seems to be working, but I can't debug the tensorflow code",1
"the failure looks weird, doesn't seem related to the PR, does it?",1
"Build still seems to fail with error 
`The command ""if [[ ""$TRAVIS_PYTHON_VERSION"" == ""2.7"" ]]; then wget https://repo.continuum.io/miniconda/Miniconda-latest-Linux-x86_64.sh -O miniconda.sh; else wget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh -O miniconda.sh; fi"" failed and exited with 8 during .`
`Your build has been stopped.`",1
It seems the tests are failing due to an issue with Travis.,1
"Yeah, seems reasonable.",1
"When I created a non sequential model using the Flatten layer with Keras with tensorflow backend, I got an error whereas the old version seems to work (see below).

```
>>> pool2_bis
<tf.Tensor 'Reshape_894:0' shape=(?, 2048, 1) dtype=float32>
>>> [-1, prod(shape(pool2_bis)[1:])]
[-1, <tf.Tensor 'Prod_5:0' shape=() dtype=int32>]
>>> [-1, np.prod(pool2_bis.get_shape()[1:].as_list())]
[-1, 2048]
```",1
"It seems, that during compilation loss function doesn't know what are the dimensions of its parameters.",1
"However at the layer level, it seems too confusing for users.",1
"c) I've been replacing calls to len(mat) with calls to mat.shape[0], but I've also filed a sci-py ticket where people seem responsive.",1
Changed seed and current run seems to be generating stuff well.,1
"And if you really want optimize `K.switch`, I'd suggest making it check whether the input is a scalar and use `switch` or `ifelse` depending on that (but this seems like an optimization that should be included in Theano).",1
"So should we leave it that way (as the new PR).
or should we try to make tf backend does as much as theano backend, which seems nontrivial (th swtich support broadcast of arbitrary dimension).",1
"Can't seem to fix the conflict, should I start a fresh PR ?",1
"- I've added a `preprocessor` argument to  `generate_legacy_interface`, seems to be working.",1
Doesn't seem to work though :(,1
Will close for now since there seems to be problem when putting it on Travis.,1
So this seems to be just a code simplification.,1
"My final conclusion is that we will not include this in Keras for now, since there seems to be low demand for it.",1
"But ""a same"" seems completely wrong (or at best extremely exotic):
https://www.google.com/search?q=a+same+vs+the+same",1
There seems to be no tests for `np_utils`.,1
close/open to restart the tests (Travis seems to be up again),1
This seems to save ~30 seconds on average.,1
"seems a bit like an overkill - the function would be : 
```
def stack(x, axis=0):
    return np.stack(x, axis=axis)
```",1
1) only tests shape and inputs two tensors - which seems lacking.,1
I'm curious as to why it seems to be a duplicate of #15433?,1
I'm curious as to why it seems to be a duplicate of #15430?,1
"It seems there are test failures, please take a look.",1
"It seems your commits aren't signed with an email address, which can lead to loss of authorship tracking in the git history.",1
It seems to work nowadays?,1
Maybe it's new from tensorflow 1.10.,1
"It seems like the test failure is a flake, but we are not sure.",1
"As well it seems that `K.conv1d` is using the new API, however, I am still getting a warning from tensorflow which is warning that `data_format` is using the old api.",1
"Maybe, but that seems overkill given the context.",1
It seems to me that your valid concerns really apply to all platforms and I wasn't attempting to address them with this fix,1
The real underlying issue here seems to be that python generators simply aren't suitable for multi-threading or multiprocessing.,1
"The first thing I've noticed when I'm trying this implementation is that, under an encoder-decoder setting, it seems that we need to provide additional `initial_state` for the states used in the attention wrapper.",1
"By the way, example provided worked without that warning, so the problem seems not to be related to keras version.",1
"We could do bookeeping but since there seem to be a unique identifier for each tensor, maybe we could use this.",1
"Also, it seems partially redundant with the exist addition_rnn example.",1
"As such, we will not merge this one.",1
It seems flaky tests invaded Travis land.,1
"Seems that bug is not in keras,  but in keras implementation of tensorflow (https://github.com/tensorflow/tensorflow/issues/22697)",1
Seems like there is this timeout issue again.,1
"Anyway this seems to be bug on TF side since it works on latest version of TF, and it has gotten too niche at this point for me to put more time into it.",1
It seems flaky with very low probability of failing.,1
"For history purposes and in case we need it later since it seems strange, here is the stacktrace:",1
"@fchollet @gabrieldemarmiesse bumping this up, as it seems to have been forgotten",1
"The code structure seems to be different to regular keras, although the filenames are the same.",1
"Because currently this parameter is inaccessible without subclassing Model which doesn't seem great, especially because everything works perfectly for my use case after knowing about that parameter.",1
It doesn't seem to make the build take more time than before.,1
"Seems quite a straightforward thing to fix, not sure why nobody has committed patches.",1
"In my opinon, adding `ConvRNN2D` and other missing important layers seems better to be done in advance, especially in case not all methods are necessarily noted on the documentation pages.",1
"Seems it mas a mistake from code cleanup commit e6d685b1, where this parameter was removed.",1
Adding such an attribute to `KerasClassifier` and `KerasRegressor` seems be a reasonable improvement solving this problem.,1
"It was a bit of a pain to write, and seems a bit inefficient, and I had to do some things in a relatively round-about way (e.g. the indexing operations are strange and messy).",1
"* As ugly as it is to access internal _feed_X variables of Model,
  copy&pasting all of the logic seems worse",1
"The history dictionary for the model seems to be wrong for accuracy, when I tried the visualisation example, the correct key was `accuracy` and `val_accuracy` not `acc` and `val_acc`",1
I observed a seemingly useless self-assignment inside the function pool2d from the cntk_backend.py file.,1
The issue seems to be dead so I am hoping this PR can bring some attention to this.,1
"A comment seemed a little out of order in the `TimeDistributed` docs, and led to some confusion (see https://github.com/fchollet/keras/issues/6190).",1
A first implementation has been tried through a fork and seems to work;,1
"The performance of this model seems comparable to that of the LSTM in imdb_lstm.py, reaching an acceptable 83.16% on the test data at epoch 10.",1
I also added a testing script with what seems to be the standard layer tests.,1
"up to code review, this pull request seems good to merge on my side.",1
"Another option would be to check  `isinstance(self.model, Sequential)` and use `model.model.total_loss` instead of `model.total_loss` for `Sequential` instances but this seemed dirtier to me.",1
"Seems like keras uses cudnn batch-norm ""spatial"" configuration, which normalizes over axis (0, 2, 3).",1
"Because people seem have some problem understanding this new API, I added an example code.

https://github.com/fchollet/keras/issues/3921#issuecomment-308597601",1
"This seems, to me, more intuitive behaviour.",1
Both `conv2d` and `conv3d` seem to be failing tests with `same` padding,1
"Doing `model.trainable = False` doesn't do anything, since its layers seem to still be trainable.",1
"- The original Deep Dream only uses normalized gradient ascent, whereas lbfgs seems fairly intensive.",1
But the previous error message was only suggesting solution 3 which seems unintutive.,1
"Another PR (#5175) was opened+closed but it seemed to be doing a bit more than necessary: this just does exactly what was discussed in the issue (namely, trying the more recent `tensorflow` API first).",1
`globals()` seems to be local at the module level and the custom function is not visible inside the `objectives.py` module.,1
"The speed gain is going to be very small, but if we can reduce the number of lines in the codebase, It's not a bad thing.",1
Now the message is going to be something like `Early stopping conditioned on metric 'accuracy' which is not available.,1
"In order to keep it lightweight, quickly trainable, and not download a new text dataset, I was just going to create 4-5 body/headline pairs myself (2 of which are in this PR as an example), and then work through the entire sequence to sequence process.",1
"If you were in this situation, you need to update your Sequential input shape so that it has the same rank as the data you're going to pass to the model.",1
"Since this is going to be quite a big upgrade, I'm doing it in smaller steps at a time to be sure not to break anything too horribly.",1
We need to make sure that the numpy backend is very readable since it's going to be displayed in the docs.,1
"We used nonzero() on the weights in order to ensure that if there
happened to be a NaN or an Inf in the output that was going to be masked
about by the weights anyway, it wouldn't propagate (because 0*inf = NaN)
however this was causing interaction issues if you also used a mask,
because that wasn't using nonzero() properly.",1
"I tried setting up a testing environment from the code in `.travis.yml`, but the keras tests didn't work straight away with it, so I must have missed something, and I'm going to have to deal with my deadline, and then revisit.",1
I'm going to try to push some commits on this branch (hopefully without breaking everything).,1
"There are also advantages of having everything in one file: if I'm looking for the code for `binary_crossentropy`, I don't have to ask myself if it's going to be in `nn` or `elementwise_ops` (both are technically correct), if I'm looking for `transpose` I don't have to ask myself if it's in `linear_algebra` or `shape_operations` (you put it in `linear_algebra` but it seems more like a shape operation).",1
Having debugging information going to logging is in fact the main way how those statement would be able to be captured and stored into a central logging facility for the whole cluster. Intercepting stdout/stderr is ugly and tricky and it is hard to know where the source is. (So filtering and debugging in a complicated app is tricky.),1
"Indeed, compatibility is going to make a lot of things harder.",1
I would vote against adding options for those reasons:,1
I am not going to fix the remaining issue of handling multiple input and multiple output submodels in this PR.,1
"@farizrahman4u cool, I was going to do the same thing.",1
I'm going to make a new release and I want to include this (it's a significant bug).,1
Merging now and I'll make edits myself.,1
I'm going to get my head right ..,1
"I was going to write batch norm for RNN and read an old PR for it, so I realized that my zoneout implementation is bloating the code, and this way of implementing it is wrong.",1
Most variables are going to be global to the script. It is nicer not to have ALL_CAPS variable names everywhere.,1
"I can't remember right now where I encountered this, but I should have an example somewhere and am going to try find it.",1
The reasoning here is that unittest are going to cover platforms and validity of components and IT tests are going to catch bugs in components interactions that independent on python and backend.,1
The documentation is going to become awesome really quick.,1
Sorry! I'm going to track few pulls to see if my changes break other people code..,1
Example that comes to mind is RBM that might be implemented with theano.scan that is going to return non-trivial 'updates'.,1
"Yup, that should work.",1
It's going to be tricky keeping compatibility I think if it makes sense to trade off for breaking changes for logical consistency.,1
Might be worth abstracting out supervised/unsupervised types.,1
"Because we already have a ""First contact with Keras"" section in this README, and pip installation instructions are a bit out of scope for this repo, I think what this PR adds isn't necessary in our README page, so I'm going to close this PR.",1
"Easy enough to build something like that in Keras proper, but the unit is going to be custom.",1
Something like @farizrahman4u recurrentshop might be a good way to build the unit out of something reusable.,1
"If you are going to set up bash script, I think fetching the latest `caffe.proto` from the official and run protobuf compiler in local environment requires less maintenance cost.",1
I'm going to close and re-open to re-run,1
We're going to set up automated testing going forward to avoid this kind of issue.,1
"That's going to break people's code, though.",1
"Another reason could be, Convolution2D is going to abstracted away, in the future it's not going to inherent form Convolution2D, so it's should have a standalone keywords list.",1
"I find that the loss value improvement flattens out pretty quickly, with very little improvement after about the 60th epoch, and the image is pretty much as good as its going to get by about 20 iterations.",1
I'm going to close the merge request and open a new one with only the relevant changes.,1
"Hi @FancyXun  I'm going to go ahead and close this PR, because it seems to have stalled.",1
"I like the idea seriously, it is more intuitive then the current API even the MultiLayer is a good idea since we are going to have lot of them (At least all the layers i have implemented in my library follows this idea :D )",1
I was going to add the tests but couldn't find `test_pooling.py` in `tests/keras/layers`.,1
"FYI, you're almost certainly going to need to follow the `API Design Review` process explained in [CONTRIBUTING.md](https://github.com/fchollet/keras/blob/master/CONTRIBUTING.md#pull-requests).",1
A really great example would be transforming an [imagenet vgg16 to segmentation vgg16 like this example](https://github.com/aurora95/Keras-FCN/blob/master/utils/transfer_FCN.py#L19) without going to disk or regenerating the network in different modes.,1
If you think that it is going to cause more problems than it will solve I understand.,1
@phreeza @fchollet @EderSantana I'm going to setup testing of some examples.,1
"If there are no objections, I'm going to start with mnist mlp this weekend.",1
"By the way, I fix several bugs in `fit` and I am going to temporally keep those codes and wait for next refactor to replace them.",1
"We don't know what we are going to need, so we might as well reserve ourselves the possibility to do absolutely anything.",1
They explicitly tell you what messages they are going to react to.,1
"We don't know what we are going to need, so we might as well reserve ourselves the possibility to do absolutely anything. Unless there is a solid reason not to.",1
"I'm going to integrate the validation split idea, it seems convenient to have as an option, rather than leaving it be to handled manually by the user.",1
I am going to submit another PR that branches correctly (shame on me) and then maybe before these changes get incorporated you can run the examples to let me know what timing was on your machine.,1
"@nouiz I  believe I am using recent Theano + Cudnn, but will double check.",1
When dealing with classifying images it is easy to images scenarios where deforming the images id going to be a problem.,1
I'm going to remove `cos` mode until we sort it out.,1
"According to the official document and my experience of training process,
I found out that the value of ""steps_per_epoch"" should equal to the value of
`Total # of samples of training dataset / batch_size`.
(it's same with the api documentation [here](https://keras.io/models/model/#fit_generator))",1
"In my experience, using pixel jitter doesn't do much, but roll/offset jitter helps a lot.",1
"I don't think this is a bug, but I don't have much experience so I'm giving it the benefit of the doubt.",1
"In #6299 better support for slicing was added in HDF5Matrix. kielnino in the PR and I experienced an AttributeError code caused by line 65 in this commit, where the `start` and `stop` attributes would be requested for inputs that can include integers and lists.",1
"This PR adds a current percentage display to the right of the progress bar, I would say this improves the user experience since most users are accustomed to seeing a percentage number besides a progress bar.",1
I personally think this is a very urgent issue to be dealt with since people without coding experience can only rely on the documents for doing project.,1
"If any meaningful improvement was to be obtained, it would have been glaringly obvious in the output using the 5_2 layer, since this layer is much more susceptible to different style weights in my experience.",1
"However, this would be very surprising to see (i.e., never the case in my experience) right after 1 or 10 epochs on CIFAR 10/100 for ResNets or Wide ResNets.",1
In my experience masking makes everything very slow without much benefit.,1
"@gabrieldemarmiesse, In my opinion, we can already see useful warnings in TF and TH environments.",1
"The motivation is reasonable, however in my opinion, there might be no significant difference between N-th epoch and (N-1)-th epoch.",1
"In my humble opinion, functions that are not primitive and combinations of NumPy operations need to be documented as NumPy codes.",1
Keras is in my opinion lacking adequate and consistent logging for the level and  breadth of functionality that this module is now at.,1
Maybe adding blank rows only around layers with multiple inputs could work.,1
It's a bit more readable in my opinion.,1
In my opinion this is really nice to have so let me know what you think!,1
"In my opinion, whether the `input_length` should be static or not should depend on if the `input_shape` has static length or not, which is what my modification does (`input_shape + (output_dim,)`)",1
"let us wait for @fchollet's opinion, but I'd also suggest some documentation and examples like this one you just gave me in the PR.",1
The test also doesn't seem to capture what you are proposing.,1
"The good thing about keras in my opinion, is the hiding away symbolic manipulations from the user.",1
I'll start a new PR.,1
I see that the PR wasn't formally reviewed and that contributor opinions seem to indicate the functionality might not be needed.,1
"The couple of people, who have used Caffe through pycaffe I spoke with regarding this also had the same opinion.",1
"In my opinion, the existing test is not great; it is testing an API that only partially works, and was never explicitly supported/implemented.",1
"I would remove that test and only explicitly support _built_ models, as discussed in https://github.com/keras-team/keras/pull/14748#issuecomment-867237966.",1
"Importantly, I don't expect the discrepancy to be detrimental, it should actually be an improvement over the reference implementation -- the rational thing to do in this context, architecture-wise, is global average pooling before the Dense layer. 7x7 average pooling with no subsampling makes no sense in my opinion.",1
"As a side note, I will note that the official PyTorch ResNet50 implementation follows the same pooling behavior as Keras.",1
"In my opinion 2) is preferable, and doesn't clutter the API.",1
Here are the two main points that in my opinion remain not addressed:,1
"This time, in my opinion, semantically meaningful word (s) which attempt to describe what that mode will do should be used.",1
"All are good choices, in my opinion.",1
"2. my opinion doesn't matter, @fchollet is the keeper of the style, the original is his, I predict it won't be merged.",1
"The value, in my opinion, is that someone checked that the two backends provide the same functionality.",1
But I guess that might be different if you regularly switch backends.,1
"Thus, I my opinion:
- Merge #8920 after replacement of `len(x.shape)` by `x.ndim`.
- Merge #8892 for further optimizations and readability.",1
"In my opinion, it's more general to always broadcast all dimensions before batch normalization.",1
In my opinion adopting the syntax from theano is not a bad choice in this case.,1
"I'm doing the coding review, I just needed your opinion to avoid giving suggestions that won't get ultimately accepted.",1
"My opinion is that this new style can be better to read for examples like this:

```python
    >>> keras.backend.epsilon()
    1e-07
    >>> keras.backend.set_epsilon(1e-05)
    >>> keras.backend.epsilon()
    1e-05
```",1
"And in my opinion, the `g` and `m` are local variables, so they do not need to be changed.",1
"In my opinion, this is not just for who had downloaded data alreay, but the workflow would be 'check if extracted file exist' -> 'if archived file exist' -> 'download it'.",1
"In this way, we won't care where the data come from.",1
"But maybe for archive is the usual state of data, when we use it.",1
Will make the above graphs reproducible.,1
"In my opinion, it is okay to keep Rescaling inside but I'm not sure about Normalization.",1
As pointed out by @innat there might be some cases where users may want to use some custom preprocessing.,1
"yes, i think using 2 arguments below will be the best: model_relocation='/cpu:0' and merge_location='/cpu:0', and your opinion?",1
In my opinion it's the first one that seems most useful to skip.,1
As a temporary workaround having explicit declarations of the time step is adequate enough in my opinion.,1
I think I will stick with my opinions unless you have other reasons beyond this.,1
In my opinion it should be added another argument called _zca_epsilon_ with the default value 1e-6.,1
"But the _zca_epsilon_ argument is better in my opinion, because it depends whether the data is scaled or not.",1
"If this change is dependent on another PR, then in my opinion it isn't atomic enough and constitutes bad design.",1
In the meantime I'll take a look at your API proposal.,1
"Then you will get:
```
A:
[[0.        0.5722787 0.        1.1026295 1.4389379 0.8462129]]
[[0.        0.5722787 0.        1.1026295 1.4389379 0.8462129]]
B:
[[1.3929384 0.        0.4537029 1.1026295 1.4389379 0.       ]]
[[1.3929384 0.        0.4537029 1.1026295 1.4389379 0.       ]]
```

Which in my opinion is the intended behavior.",1
"That said, I just made the change you requested, and I'm happy to push it if you prefer, I don't have a strong opinion about this: perhaps it's the `Attention` layer that should be updated to use `use_causal_mask` in the `call()` method.",1
We are also of the opinion that degraded performance is a better alternative to catastrophic failure in execution (as is the case right now).,1
"Maybe a different behavior is desired, but Keras, in my opinion, shouldn't crash like this (especially without any warnings).",1
`first_or_list` isn't very pretty in my opinion.,1
So in my opinion the library must be more careful when printing unavoidable messages.,1
"In my opinion, since it is relatively rare for a single model to be trained on different image sizes, I prefer option 2.",1
"In my opinion, calling functions should not alter the global random state.",1
In my opinion such triggering of `fit_generator()` callbacks makes more sense.,1
"So if a layer has multiple input layers (""inbound_layers""), the entire model is in my opinion no longer sequential...",1
"In my opinion if any `input_shape` is None on the `concat_axis`, then this means that
the actual shape is unknown on this axis, which implies that the `output_shape[concat_axis]` should be `None` as well.",1
"In my humble opinion, I think the current build matrix may be a bit waste of resources, because the two tests usually take 3~4 mins and the initialization of environments (`conda create`, `pip install`, ...) consumes at least 2 mins.",1
To my understanding flipping filters or not are two different operations: convolution and cross-correlation ([see picture to the right](https://en.wikipedia.org/wiki/Cross-correlation)),1
"But if I try to actually randomize the inputs again, which is -to my understanding- done in each layer's `build` function, it doesn't work.",1
"From what I understand, non-picklable objects can't be passed to children processes easily.",1
It's an extremely useful (necessary as far as I understand) option for time-series problems and I think it could really lead to an explosion in adoption of convs.,1
"As far as I understand, `init` argument of all layers accepts only str type, isn't it.",1
Because then the loss function does not match reparameterization from 2.4? (As far as I understand it),1
Also the point of RegNets as far as I understand is that they are efficient and scalable.,1
"As far as I understand, the average should be over the statistics of each epoch rather than iteration.",1
"If I understand it well, the orderedEnqueuer is protected by the fact, that steps_per_epoch should be <= len(sequence).",1
"In my view, despite having similarities that are convenient for inheritance, they are conceptually different and thus should be independent of one another.",1
"As far as I know, the layers are treated in the standard way.",1
"Again, as far as I know, this is pretty much standard.",1
As far as I can tell I have used the correct Keras code.,1
...and wrt. the current implementation of [`MixtureOfGaussian1DAttention `](https://github.com/keras-team/keras/pull/8296/files#diff-9c4188ddc4dd173d80f64feed5b89412R370) as far as I recall it supports what you're asking for by reading the shape [here](https://github.com/keras-team/keras/pull/8296/files#diff-9c4188ddc4dd173d80f64feed5b89412R505).,1
"In particular, for logging aggregation in distributed computing, best practices state the opposite as far as I know: always pipe stderr to the log aggregator (opposed to using a Python logging handler).",1
"??  hello, this code has been removed from keras as far as i can see, does that mean that loading from models from in memory h5 file is no longer supported?",1
"As far as I can tell, daemon mode is not necessary.",1
"I didn't have them in mind, but as far as I know, Sklearn is not designed to operate with any object that fits on generators.",1
"Indices in the parameter list do not encode information (each layer generally contributes several indices, and in the case of graphs, the order is basically random as far as the user is concerned).",1
"As far as I can tell, the only activation function that wouldn't work out of the box on a tensor3 is Softmax (http://deeplearning.net/software/theano/library/tensor/nnet/nnet.html#tensor.nnet.softmax).",1
"As far as I know, the cntk 2.3 we  integrated in Keras does not have float16 support.",1
As far as I can see the issue it addresses is not fixed yet.,1
"I looked into the failing CI build and as far as I can tell, it's referencing something I didn't modify.",1
The current text copy is correct and accurate as far as I can tell.,1
"And as far as programming languages go, it is probably easier to write this as a hard constraint and avoid infinity.",1
"As far as I observed, norm-clipping dose not make a beg difference.",1
I guess that It's because the architecture of the network shallow so the gradient vanishing/explosion problem is not that serious.,1
The changes all look good as far as I can tell (though from the GH PR interface I couldn't tell if they cover everything).,1
`K.ndim` wouldn't work for Numpy tensors as far as I can tell.,1
"As far as I can tell, current_batch_size is not a user-facing parameter but is the first element of the shape of the input hitting the layer at the current iteration.",1
"As far as I could tell the overhead from the identity function was measured in nanoseconds, so basically just the same as an assignment.",1
"As far as I can tell, the issue is that empty lists for constraints are messing up the zip() happening in the main loop of every optimizer.",1
I'll look at it in more detail later.,1
Both would only involve changes in training.py as far as I can tell.,1
I would expect these changes to end up at ~30-50% of the total size of this PR.,1
Additionally as far as I know in case of NumPy dumps there would be multiple files (one for each array).,1
@fchollet You could check the file extension (eg. `.h5` vs `.pkl` vs `.npy`).,1
"By the way, this solution works great in terms of compatibility with single-output / single-input layers (unnamed), but as far as I can tell it isn't compatible with multi-io layers (i.e. `Graph`, with named inputs / ouputs).",1
"This might be true for normal programs but for example in Jupyter notebooks as far as I know, the only way to interrupt a running cell (e.g. a model that is trained) is with the interrupt command which normally will throw a SIGINT signal.",1
"SIGINT has the intention to actually do exactly what would be useful here, like going as far as saving a file before terminating.",1
"@fchollet, as far as I can tell, this PR makes Keras **consistent** with current fused (default) `tf.layers.BatchNormalization`.",1
There were several attempts to create `keras-extras` such as [Seya](https://github.com/EderSantana/seya/tree/master/seya) and [seq2seq](https://github.com/farizrahman4u/seq2seq) but as far as I know currently both repos do not work because of changes in Keras 1.,1
"The PR only changes a specific implementation used for LSTM and GRU on a GPU for RaggedTensors -- as far as I know, it is not straightforward to write a test that the cuDNN implementation is now used.",1
So that would be the cause of the failure.,1
"As far as I can tell there is no existing (tested) behavior of V1 that is newly failing here, so you can simply exclude your new test from running in V1 and you'll be done.",1
Not Keras-related as far as I can tell.,1
As far as I know I was the only one to use this naming pattern (which is why I dropped it in Keras 2).,1
"If the test completes now, it can be merged as far as I'm aware.",1
"As far as I know, the docs are auto-generated, yes.",1
We are good to go as far as I can tell.,1
"I will keep fixing any issues you can find, but otherwise development is done.",1
"@phreeza  As far as I can see, we can tick 'unit test removal'.",1
This just refers to the dataset as far as I can tell.,1
Seems fine to port them.,1
"But as far as I known,these structures cover almost all well performed inceptional deep network architectures such as GoogLeNet , BN-Inception,Inception-v4....",1
"Yes as far as I know from doing weight transfers, ""shadow variables"" are lost when a model is saved in both TF and keras.",1
"As far as I could see, it was the only test that tests a callback that calls self.model.stop_training in on_batch_end.",1
"In principle all test of callbacks should check if results are equal when using fit or fit_generate, but then again, maybe all tests that call fit should also test the fit_generator case...",1
"1. `self.lr_epsilon` doesn't do anything meaningful as far as I can tell, but may prevent `lr` from becoming exactly equal to `min_lr`.",1
"As far as W_regularizer can be equal only to a single function, one should be able to mix L1 and L2 regularizations",1
"As far as I can tell, theano doesn't seem to be a requirement when installing keras.",1
"As far as I can see, the tests all pass.",1
"I think it's general case, as that's the way embeddings work as far as I know them.",1
"The alternative as far as I can tell is to load the weights into the _original_ architecture, then surgically alter the layers.",1
"As far as I know, Theano owner knows this issue but won't implement the asymmetric padding:

- https://github.com/Theano/Theano/issues/2118#issuecomment-282332804.
- http://deeplearning.net/software/theano/library/tensor/nnet/conv.html#theano.tensor.nnet.conv2d",1
We provided a few updates on the saving.py python script and expected outcome was achieved as far as we tested.,1
The `output_dim=2*10` is meant to imply that the forward recurrence has 10 outputs and the backwards recurrence has 10 outputs.,1
"The outputs were named as `*_loss` implying that they held loss values, whereas they in fact held the outputs.",1
"However, on line 846, deg2rad() is applied to the argument, implying that the argument should be given in degrees",1
"""Connected to"" does not imply a direction, just a link.",1
"To be clear, I in no way meant to imply that your results are not reproducible when I wrote that I 'somewhat' reproduced the results of the paper.",1
I am not implying the restart is not helpful.,1
"3. One last comment for the change: since we have removed the 'epochs' (and should it be better named `n_epochs`?) out of the parameter list, it might imply to readers that all those methods should be using the same # of epochs, which is not true.",1
"Unless I'm missing something, `sum` can be used for `MirroredStrategy` and **will not** imply in behavioral changes:",1
"Again, a transpose might be in necessary.",1
@lireagan @phreeza you might want to see https://github.com/fchollet/keras/pull/921,1
"To maximize code reuse, we might need an abstract dropout layer, too.",1
"Someone in reddit also reported about the unstability, so without any bug it might be still like that.",1
"Someone in reddit also
> reported about the unstability, so without any bug it might be still like
> that.",1
I might have accidentally removed the request for review from @haifeng-jin - I did not mean to do that.,1
We might as well make this (`self.model.something`) be the unified mode of communication between callbacks and models,1
That might explain some things.,1
"The simplest for your PR might be to just do:
```python
assert z_shape[1:] == z_np.shape[1:]
```
and it would work across many TF versions.",1
"@yoks might be interested, too.",1
"If you do investigate on the matter, you might want to start with this merge commit https://github.com/keras-team/keras/compare/6096ded90df9...1336cdb14ff0",1
If it does it might be worth patching also `ReduceLROnPlateau` to follow the same logic.,1
I'm thinking we might want to editorialize them a bit first to make them more readable (more tutorial-like).,1
I'll be away at NeurIPS for the week but I'll start reviewing more PRs after I'm back.,1
Maybe reading the numpy implementation is faster than reading the function description?,1
So users might wonder if `K.max` does really correspond to `np.max`.,1
For my logging aggregation process to skip the "first" line (which might not be the first)?,1
"Straight up flattening 3D inputs might not help: the metric shape for an input of shape `(batch_size, time_steps, dim)` would be `(batch_size * time_steps)`... which doesn't seem right.",1
We should return only 1 scalar per sample.,1
`categorical_accuracy` and `sparse_categorical_accuracy` should have the same behavior.,1
"For 3d input, just flattening the second part might not be the solution.",1
"That being said, maybe a markdown-compatible one would facilitate online clean-looking user interactions with markdown compatible sites; HOWEVER, their table implementation might vary.",1
"However, I am not sure of the complexity that such an implementation might induce.",1
"They might load up some arbitrary model and print the summary(), so a nice default, but then the user can set an option:
   Markdown-table compatible, CSV, force-full-fields (ie. no truncation of batch_norma).",1
"1. @gabrieldemarmiesse For normal terminal output, the width might quickly cause a wrap, destroying the clarity.",1
"1. If we can have some keras.options [for output format] in the future, it might be convenient (csv? full-width)?",1
You might need to modify the numpy implementation of `rnn` if the implementation have the same bug.,1
"People may not always want to save the graph created by plot_model, they might just want to see it displayed.",1
"Also, some people might want to save the graph for later use and not display it directly.",1
I might be wrong but it seems unrelated to my changes.,1
"More over, using elem wise and reduce sum works for our case, but might not be a generally useful solution.",1
* We don't take the risk of breaking things since other keras components might crash/behave in a weird way if the Sequence doesn't yield the right number of batches.,1
"I might be wrong on certain points, as I don't know much about all this.",1
"So I'll be able to review, but the merging might be delayed as only @fchollet can merge PRs which have a failing build.",1
This is because a thread might get blocked while adding stuff in the queue (if it's full).,1
Might be related to TF as @fchollet said but personally I think it might be a side-effect of the way the data land in the Queue.,1
"If that's the case, it might be worth increasing the tolerance because I'm not sure you can force the order of addition (or have the property of seeing all the data within an epoch) without locks.",1
This object will go to custom callbacks and might be confusing for their authors.,1
"This is not hard to do, but I have quite a lot of things on my plate, so it might take a while.",1
"The ""right""
>   solution might be to have models that require no labels (e.g. it could
>   become legal to pass ""None"" as the target when using mean identity error;
>   this could be useful for a variety of models outside of hierarchical
>   softmax).",1
"It might be too brief though, it took me more than a second to find it.",1
"There might be a much cleaner way of doing this with layer wrappers and I think that's the way to go, so I close my current PR and if I wrote the wrapper version, I'll make another PR (or reopen this one)",1
Note that any changes we might make should be backwards-compatible.,1
Note that any changes we might make should be backwards-compatible. We don't make breaking changes to public APIs.,1
Agreed with @carlthome that the names might benefit from being more specific (names are important since they will stick forever).,1
"I might be misunderstanding this commit, but I think this introduces a regression.",1
"If we see good performance, which we do, we don't necessarily need it, but just raising as people might question now that I think about it.",1
"In fact, you might update the example script yourself (either with a different learning rate or a different optimizer), run the script and ensure it learns, and then update the docstring and whatnot.",1
I'll close this PR for now.,1
I might take a stab at it again in the future but it's not certain.,1
I think we should prioritize this use case over "Keras should not modify the global random state".,1
"I think it might be possible to have both, if we use the global random state to generate a local one?",1
Also you might want to add an option to widen the residual block layers (more channels per convolution) as done in https://github.com/szagoruyko/wide-residual-networks .,1
"Basically, I created a method that is called in `build()` and that updates variables contained in wrapped objects (that might have changed after the creation of the container, a dict or list):  

```python
    def _update_trackables(self):
        """"""This method loops over tracked objects to update tracked variables
        for wrapped lists/dicts that may have been updated after initialization
        (Issue #16797)
        """"""
        for trackable_obj in self._self_tracked_trackables:
            if isinstance(
                    trackable_obj,
                    tf.__internal__.tracking.TrackableDataStructure
            ):
                self._track_variables(trackable_obj)
```",1
The gzip is broken which might be caused by a failure download.,1
"On the other hand, I understand that maintainers might want to elevate this specific message to an ""info"".",1
"The output might be unclear on complex models, but it's up to the caller.",1
"For example, a researcher might want to add the seconds per epoch, an identifier (same for every epoch) and the learning rate of each epoch (especially useful when using a learning rate scheduler).",1
It is under review/discussion what parts might make it into the core api.,1
"Errors might slip in giant PRs, so breaking it down might be a solution.",1
"For example, a researcher might want to add the seconds per epoch, an identifier (same for every epoch) and the learning rate of each epoch (especially useful when using a learning rate scheduler):

```
    import numpy as np
    from keras import backend as K

    def get_learning_rate(epoch=None, model=None):
        return np.round(float(K.get_value(model.optimizer.lr)), 5)

    custom_csv_logger = CustomCSVLogger('training.log',
        additional_columns={'seconds': None, 'learning_rate': get_learning_rate})
    model.fit(X_train, Y_train, callbacks=[custom_csv_logger])
```",1
The "right" solution might be to have models that require no labels (e.g. it could become legal to pass "None" as the target when using mean identity error; this could be useful for a variety of models outside of hierarchical softmax).,1
This method might affect all keras users if they want to use it.,1
So this might be our biggest source of issues.,1
"I found some compatibility problems in your use of TensorFlow APIs, which might lead to crashes in a low version of TensorFlow.",1
Using the same input parameter but having a different output might be misleading.,1
"When a user runs in Colab env or in script, the user might try to start / stop the `TimedThread` instance multiple times.",1
"I have kept the default value to 0, to maintain existing behavior in any place it might be used.",1
"First, one might wish to run multiple instances of keras concurrently on the same machine, which would be impeded by a process that consumes all of the available computational resources.",1
"As suggested in #2473, here's an implementation for a kullback-leibler divergence objective function as it might be useful for other users.",1
"Avoid concatenating too many tensors (~100) when the actual logic is to tile, as this might cause `Blocks nested too deeply` error in large models (theano backend, Windows).",1
"Reasons like this were some of the initial pushes for the automatic shape inference functionality in the first place, so if shared variables using .eval() for shape inference are floating around in other places, it might be wise to convert them (unless of course there are very stringent cases when the variables can DEFINITELY only be shared).",1
"This might not be the most efficient way to do it, but at least it works.",1
"It might also be reasonable to move these and the upsampling and zero padding layers to a new section, since they're not ""convolutional"" per se (although they're most often used with convolutional layers)",1
There might even be some way to avoid the swap to CPU if there is an equivalent to np.roll on the GPU.,1
"1. **ignore_class**: In segmentation problems, some pixels in segmentation maps might not represent valid categorical labels.",1
#NAME?,1
"Here, my rationale was that the std of the noise might be a hyperparameter you want to optimize, and that to be able to do that the loss functions have to be comparable.",1
"Hypothetically, could delete large portions of the backend after this pull request, but might cause performance and documentation issues.",1
So I might be wrong but I think it's misleading to display this class in the docs.,1
"This might get the network stuck at a local minimum, because it moves the weights suddenly in a direction that might be incompatible with the gradient.",1
"Because this might not be the case for other problems (larger images for example), I have added the option in the convresblock function that allows the choice of ELU or BN + RELU.",1
"There might be a better/more proper way to fix this, but it has been working flawlessly so far.",1
"I don't think there's any real reason for them to be required, though I might be missing something.",1
"In the future it might be possible to auto-resize to the nearest factor, but another variable will need adding to ensure we can disentangle the model from the preprocessing.",1
"I'm new to markdown, so the formatting might be a bit off.",1
"Also, if some of the weights are converted in `preprocess_weights_for_loading`, the returned list could be a mix of h5py datasets and numpy arrays, which might not be a desirable behavior.",1
In multi-task learning one might also want to monitor loss functions of specific outputs.,1
"It might incur some performance difference, but will greatly reduce the variable created if we use one tf.random.Generator per initializer.",1
"This example demonstrates how to construct them, a few common tricks, and a few exercises that might prove educational for newcomers to RNNs for NLP.",1
Noticed some things that might improve the readability in the `activations.py` file,1
"One might want using the ImageDataGenerator interface to do custom transformations (such as dropout, elastic...).",1
"In practice I redefined load_model in my own code, but still I think it might be a non absurd addition to the code.",1
"Usually, this is what a user wants, but there are edge cases where one might want to do this (for instance, projection shortcuts in Residual Networks).",1
- it will break any existing code using `x_generator` in a nontrivial way,1
- it might be simpler to simply get rid of `nb_worker` and say that if the user wants parallelism he must implement it within-generator,1
"However, there might be some tensor shapes for which the second test works on Theano but not on Tensorflow, but I couldn't think of one immediately.",1
Vanilla SGD might run faster.,1
"I have traced the problem to https://github.com/keras-team/keras/blob/5d2993b78603bda911f0a4912d08b1e5f36eb633/keras/layers/recurrent_v2.py#L616-L623 -- the problem is that even if `mask` can be `None`, `sequence_lengths` might not be `None` -- and in that case the CudnnRNNV3 is used https://github.com/keras-team/keras/blob/5d2993b78603bda911f0a4912d08b1e5f36eb633/keras/layers/recurrent_v2.py#L655-L664 and the inputs **should not** be transposed.",1
"Functions were moved to the
end of the module in few cases because or the order of function or class definition (but after thinking about it might not have been necessary).",1
"The doc string leaves out the write_images arg, which might be a little confusing for Tensorboard beginners.",1
"The new formula is compatible with torch.
and might be fix  https://github.com/fchollet/keras/issues/21",1
"The most frequent usage of such layers with masking support might be a hierarchical RNN on a sentence with words with characters, or a paragraph with sentences with words. (E.g., models like [this](https://github.com/keras-team/keras/blob/master/examples/mnist_hierarchical_rnn.py)).",1
"I explored some possible solutions, and think this might be a concise solution.",1
This solution should fix the issue with BatchNormaliztion and also with any other wrapped layer that might have update ops conditioned on its inputs.,1
"2) If  the dimension of the inputs is changed by the encoder, create a mask which is all ones unless for a given dimension, the input mask is all zeros (this addresses the fact that an entire sentence might be masked).",1
An alternative might be to search each layer from `model._output_layers` in the nested structure and then select its name.,1
"To elaborate on my future vision on the ImageDataGenerator: my plan is that eventually it would be able to process a list of inputs and a list of outputs, some of which might be images and some which might be something else.",1
"It would also take, as a constructor parameter, a list of transformations that need to applied to each of the inputs and outputs.",1
"Edit: while looking at this function, I noticed it might also make sense to explicitly allocate the array as `dtype=np.float32`, to help avoid a common error.",1
This might lead to deadlock if the only thread popping from the queue is the thread calling `stop()`.,1
It might be worth putting in some kind of warning or something like that in the future to let people know.,1
"So, that might be something that could be removed if this PR is accepted.",1
"This might be specific to Python 2.7, but the some exceptions that pass through `Model.fit_generator`, for example, are not very useful because they are first caught and then re-raised by `raise e`.",1
This might solve #4881.,1
This might be useful when the generator actually depends on the current state of the model itself.,1
"There might also be other layers where this should be done, but I changed the ones I could easily find.",1
"To make it easier to build an  Inceptional or Inception -like deep network such as GoogLeNet or BN-inception,Sequeeze-net et al by using Keras built-in Sequential model,here I add  an Inception class and FireModule class which might be useful for keras users.",1
"For example, users might want to make predictions rather than continue training, or to make surgery on the loaded network to build a new one.",1
Would be nice if `K.zeros_like` used the parameter's dtype but that might break a lot of other things. May be worth updating the other optimizers but those are the two I use the most.,1
"Using `IfElse` should allow Theano to [perform lazy evaluation](http://deeplearning.net/software/theano/tutorial/conditions.html) of the training and testing branches, so in theory it might be faster.",1
"TBH, the merge modes could use a bit less hard coding, since all the checks seem to group into element-wise operations (sum, mul, ave, max), reductions (dot, cos) and concatenation. (Except for [one line](https://github.com/fchollet/keras/blob/master/keras/engine/topology.py#L1330), which might be a bug.)",1
"Here are some details of this PR to discuss, which might have better solutions:",1
"@EderSantana , it might have been my first pull request, so I might be blamed for that:)",1
Layers might have states.,1
"States might be updated during call (even if its not training mode), for that reason you have to put 'updates' argument into theano.function.",1
keras-contrib makes a lot of copy and paste duplication with keras but a nice way to make updates that might not have a wide amount of usage (yet).,1
"That question is highly dependent on what the dimensions stand for, so it might be better to leave that call to the user and have them use a Reshape layer before applying softmax.",1
"It's worth including hashes for internal file downloads that we might want to update in the future, e.g. datasets and downloads from the `applications` module.",1
"Ok, while working on the docs I realized it might make more sense to add a 'causal' option to the padding argument, rather than this extra flag I've proposed.",1
"if `data_format` is `""channels_last""`.
        `rows` and `cols` values might have changed due to padding.",1
It might be burdensome to add this to the codebase indeed. It's not clear that it belongs in the Keras codebase.,1
As an associated metric it might be worth showing what proportion of `y_pred` values are greater than the associated `y_true` value.,1
"I am dealing with a theano issue, might take some time to think up a workaround.",1
Unit test for convolutional layer might need same modification as well.,1
I am sure there are other scenarios where something more than additive cost functions might be useful?,1
"It also makes sense to me that it's controlled by a parameter instead of a separate class, as the filter_dilation is basically like subsampling on the input, whereas the subsample parameter does the same on the output, so in that sense, if there was an AtrousConv2D layer, there should also be a SubsamplingConv2D layer, which might not be a useful thing to work on.",1
"The footnote on page 2 of [the paper](http://arxiv.org/abs/1511.07122) states that this is not the ""à trous algorithm"" used on wavelets, so using this name might lead to confusion.",1
"So I thought, is might be processing forward pass on respective gpus and backward pass on the default GPU 0.",1
i might try on OSX without gpu to see if i can isolate the issue there.,1
I was thinking it might be useful to get a `user_info` param that allows the user to pass arbitrary metadata to be stored in the saved model.,1
This could be used to save (for example) information about the training dataset.,1
"Also, I might be wrong, but the failed test with CNTK on Python3.6, I don't think it has anything to do with the changes or even CNTK.",1
"@asampat3090 You have to compile the network manually (for now, that might change).",1
Hence performing the forward passes in blocks of `self.batch_size` might be necessary.,1
"@dschwertfeger: as the data processing in batches is still open, I have an idea that could maybe work and might even simplify the code and interface: isn't it possible to extract the embeddings (i.e. the hidden layer activations) and create an `embeddings` tensor from the hidden layer activations stored in a numpy array or alike in the very end only?",1
"That presents another challenge because the last batch might (and very often is) smaller than the `batch_size`, in which case the reshape operation complains.",1
"It might no longer be an issue, though (and the dataset path issue has been fixed with Nagadomi's recommendation).",1
Now if someone could also make use_learning_phase recursively so I can use TimeDistributed with BatchNormalization & Dropout I might finally get my model to work lol.,1
@fchollet: maybe in future version of Keras a redesing of how models pass meta-data between child and parents models might be needed?,1
"Additionally, your proposed PR adds a computational overhead (which might amount to a ~5% slowdown for a BN-heavy model like InceptionV3) to every single convnet that uses BN, fine-tuning or not.",1
"(This behaviour seems a bit strange, as it has as a consequence that the
first column of the weights of the embeddings will never be used or
updated. The resulting network thus has a redundant set of parameters).",1
"Also for GRUs, tanh seems to be the default:
see http://arxiv.org/pdf/1412.3555v1.pdf Section 3.2",1
At least it seems possible to avoid running IT tests (like datasets) on every backend since these are independent of the backend.,1
"I have run the tests with both python 2.7 and 3.5 and tensorflow 0.12.1 and tensorflow 1.0.0rc1 (so four times), they seem to pass.",1
Google indicated that only Scipy seems to support that...?,1
"Hi,

I noticed that the abstract base class `keras.preprocessing.image.Iterator` was seemingly missing an abstract method definition for `_get_batches_of_transformed_samples` so I added it.",1
"The tests seem to run fine, code is correctly reformatted, and I verified in Tensorboard that after the change the update operations are indeed in a name scope.",1
"I haven't benchmarked the Theano backend to see if this is an ideal implementation, but it at the very least seems consistent with tensorflow, so at least they're accurate.",1
"Also this line seems to confirm that its used the way I have described above:
https://github.com/tensorflow/tensorflow/blob/r1.8/tensorflow/python/ops/nn_impl.py#L830",1
In this custom layer I use what seems to be the correct interface to instantiate my custom initializer (`initializers.get`).,1
"My net of LSTMs compiles and runs, but during training it outputs `loss: nan` and the net doesn't seem to output very much of anything.",1
Keras2 changed *_generator arguments (and seems like a smarter way to do things) but I didn't notice it.,1
"I should have used named arguments at everything would been fine :P Quick googling resulted that maybe others have done the same mistake but its hard to know if its about this or something else:

https://github.com/fchollet/keras/issues/6445 , https://github.com/fchollet/keras/issues/6117 , https://github.com/fchollet/keras/issues/2730#issuecomment-290204054 , https://github.com/fchollet/keras/issues/6406",1
"I was having difficulties with the `keras.utils.plot_model` function, specifically that pydot no longer supports the `find_graphviz` function, and installing `pydot-ng` instead does not seem to fix it.",1
Argument for the outright removal of these lines: this information seems not very useful and easily accessible through other means.,1
The way I have it below seems clearer and easier to work with and is similar to the way the dropout rate is specified.,1
I've seen a couple other people who seem like they need masking in merged layers.,1
"Although a far too small example, the metrics seem to remain comparable.",1
"Anyway, with the refactored metrics in Keras 1.0 the implementation seems straightforward.",1
"Sadly, gym seems to pack the dict into arrays, so I need to unpack it again.",1
"Upon closer inspection I noticed `validation_steps` was already specified, but the current behaviour seemed strange.",1
It would seem if your specify `validation_steps` without setting `validation_data` the input `X` and `Y` in the example above would be read `validation_steps` times.,1
"Since this function is defined in only TensorFlow backend, this comment seems to be clear for docs.",1
"This pr borrows idea from https://github.com/keras-team/keras/commit/cb3469215ab78219a0ae58f566ddeba2fe6242fb, which seems to be a appropriate method.",1
"Using current_name_scope in self._name_scope() seemed to be difficult to
handle because it is a deep value managed by python's threading through
tf.__internal__.get_name_scope",1
"It also, seems we may need a shuffle function inside the Sequence call.",1
Seems many image stacks may have different number of channels.,1
Also seems that the transformations will work no matter the number of channels.,1
This seems to work fine though for "live augmentation" feed to a network.,1
Right now there doesn't seem to be a way to have this information displayed.,1
"The first line seems correct, where I would understand

> Size of the vocabulary

as

    input_dim = len(vocabulary_indices)

and

> 1 + maximum integer index occurring in the input data.

as

    input_dim = max(vocabulary_indices) + 1",1
"On Mac OSX, the filenames seem to be sorted lexicographically, but on Ubuntu 17.04 with ext4 filesystem, they seem to be given in an arbitary, non-lexicographic order.",1
This seems to run faster than the old theano.sandbox.cuda backend.,1
So seems like there is a bug due to the modification if the dictionary in the iteration loop.,1
The history.history dictionary seems to have changed in the meantime,1
The implementation of bAbi [End to End Memory Network](https://arxiv.org/pdf/1503.08895v5.pdf) in the example seems to be missing the Softmax Layer.,1
"Also, the question encoder [here](https://github.com/fchollet/keras/blob/0df0177437ce672d654db6d7edfdc653aaf67533/examples/babi_memnn.py#L186) seems to sum over the probabilities and the question vector as suggestted in the original paper.",1
The link to the under https://www.tensorflow.org/api_docs/python/tf/keras/estimator/model_to_estimator pointing to _Creating estimators from Keras Models_ seems to be broken.,1
"The style seems to be to just use range. In fact, this is the only place in the whole repository where xrange is used.",1
"This night seem minor, but it introduces issues when trying to match behaviour from botch backends when rounding numbers that end in .5 (note that even when working with 32bit floats, many numbers of this form can be represented with full precision).",1
"I do not fully understand the ""C Magic"" behind the slowdown, but there seems to be a lot of time wasted copying the Sequence to each worker.",1
"As of the CNTK 2.5 release, users can now install CNTK via PyPI. The 2.3.1 release seems broken.",1
Tensorflow seems to ignore additional arguments.,1
"The width corresponds to the ""temporal"" domain in the RNN, so narrower images means less backprop through time and convergence seems to be much easier.",1
I will showcase in the following code snippet what is proposed but the main goal is to create a discussion because nobody seemed interested to counter-argue with the issue.,1
That strategy seems more complicated but would be independent of the way how `model._output_layers` is created.,1
Behavior with different padding and strides seems okay.,1
"`KerasClassifier.predict(X)` though seems to return an array of shape `(n_samples,1)`.",1
"I noticed that the wrapper tests are not executed (methods not prefixed with ""test_""?), so  I've changed the tests a bit and now `py.test tests/` seems to pick them up.",1
The usage of `Activation('tanh')` followed by `Activation('softmax')` does not seem to be normal.,1
Unfortunately the `tensorflow.python.client.device_lib.list_local_devices()` method seems to create of a new TF Session and to register of all the available GPUs on the system.,1
"BTW, current test seems working in my environment.",1
"I'm not sure if this is the best solution, even though it doesn't seem to break anything here.",1
"It does, however, also eliminate what seems to be the only purpose for the function.",1
But the test seems to pass locally.,1
There seems to be a problem in the gradient Theano's `IfElse` that is triggered by giving it GPU variables as input.,1
"This seems like a good place to use the on_epoch_end callback to print the generated text, instead of explicitly performing iterations with epoch=1.",1
this just seemed a bit easier than threading the rest of the code.,1
Only one unrelated Python 2.7 test seems to be failing.,1
"This is fixed by having `AutoEncoder.connect` call `self.encoder.connect`, which seems like the correct thing to do.",1
"It is a confusing issue because dictionaries do seem to work for fit, but are not supported, and they break evaluate in a weird way.",1
"Using the optimizer's own gradient aggregator seems a better choice here - the default one handles corner cases the previous documentation does not, and if the user wants to conditionally process aggregated gradients, there is greater consistency with the standard path.",1
"Note: I didn't include SumPooling, bc there seems to be no implementation in TF (that I know of), but I included a suggestion for Theano in comments.",1
Binary Accuracy fix raised one concern but also helped me realize what seems to be the root of these metric accuracy issues so I discuss that after.,1
The root of what seems to be the issue.,1
Passing `batch_size` seems irrelevant as `None` is its default value in `test_loop`,1
`categorical_crossentropy`  is another term for multiclass log loss. Which seems to be necessary information about `categorical_crossentropy` as `sklearn` has it as `log_loss` hence its beneficial for people migrating from `sklearn` and other people who learned it as `log_loss`.,1
"`preprocess_input()` throws an exception if used with NumPy arrays containing `int`s (which, to me, seems like a completely reasonable thing to do when processing images).",1
it seems the h5f.open() not support Chinese characters.,1
"The alternative would be to catch a type error, but this would seem pretty broad to me.",1
"Also, I'm not sure how to go about adding support for lambda functions, since this also seems useful.",1
"Common usage seems to be one flop, eg ResNet paper.",1
"This way seemed cleaner to me, but what do you think?",1
I still believe this would be valuable to have.,1
I have addressed your feedback and believe we can move this forward now.,1
I am certain that the majority of people who face this believe they have overfitted the model while in reality this is just a side-effect of how Keras implements the Batch Normalization layer.,1
"If @fchollet believes that this can done with the current API, he should update the documentation.",1
Cannot believe that this patch hasn't been merged after 1.5 years!,1
I can't believe this is not fixed yet,1
"@visionscaper, I believe it's now working in tf-nightly:
```py
import numpy as np
import tensorflow as tf
print(tf.__version__)
print(tf.keras.losses.sparse_categorical_crossentropy(
  np.random.randint(-1, 10, size=[40, 1]),
  np.random.randn(40, 10),
  ignore_class=-1
))
print(tf.keras.losses.SparseCategoricalCrossentropy(ignore_class=-1)(
  np.random.randint(-1, 10, size=[40, 1]),
  np.random.randn(40, 10)
))
```
```shell
2.11.0-dev20221011

<tf.Tensor: shape=(40,), dtype=float64, numpy=
array([17.46086028,  1.64064914, 16.93660172,  2.25964914,  3.02902916,
        2.38092942, 16.97059782, 16.5225091 ,  0.        , 17.21726741,
        1.47735013, 16.65561627, 16.58555793,  0.        ,  1.94407448,
       17.10451514,  2.04504283, 16.77500514,  2.10482156, 16.75909515,
        1.45206898,  1.36361875, 16.52289682, 16.88043939, 17.54349066,
       17.05594301,  2.36618914,  1.87394029, 17.44958865,  1.42225717,
       17.27105659,  0.        , 17.47401625, 17.47470669, 17.42965694,
       17.33150152,  1.03149344,  1.56646177, 16.54211899, 17.32527626])>

<tf.Tensor: shape=(), dtype=float64, numpy=10.997069327410369>
```",1
"Hmm @fchollet Im very dumb, I believe this has to do with any system not using utf-8 which is apparently more to do with any of the keras text examples that have utf-8 while using docker (docker run -it ubuntu:latest locale prints POSIX stuff) or certain foreign languages.",1
It is probably worth fixing for all of the examples and probably better way to do it (or at least any texts that may have utf-8 chars) or not at all.,1
"My pull request passed the Travis CI build too, which I believe includes pep8 testing.",1
I believe this isn't tested due to our PEP8 config,1
"I believe the changes you made would break a number of features, such as model saving / loading.",1
"This solves the problem for `Sequential` models since, I believe, we can always get the mask from the last layer.",1
I'll work on that next.,1
I believe `sample_weight` affects an entire sample.,1
That's all that is needed I believe.,1
I believe the issue is similar.,1
"The K.Conv2D data_format default value is None, it's same as ""channels_last"", but I've tested it with keras 2.1.5, found that it's default value is ""channels_first"", so, I believe Keras internal team also feel confused with ""channels_last"", ""channels_first"" and None.",1
"I believe the test `test_sampling_rate` (that I edited) was indeed also faulty, because if `data = np.arange(100)` (i.e. `0, 1, ..., 99`), then there are 84 such sequences of length 9 with sampling rate 2 possible, not 83:
```
0, 2, 4, 6, 8, 10, 12, 14, 16
1, 3, 5, 7, 9, 11, 13, 15, 17
2, 4, 6, 8, 10, 12, 14, 16, 18
...
81, 83, 85, 87, 89, 91, 93, 95, 97
82, 84, 86, 88, 90, 92, 94, 96, 98
83, 85, 87, 89, 91, 93, 95, 97, 99
```
which results in 17 batches of size 5, of which the last has 4 elements, not 3.",1
"I think the last sequence of that example should be
> [81, 83, .... 99], and I believe the error of this example is also caused by the current issue.",1
I do not believe that changing to block4_conv2 will cause the change in the commit to have much effect.,1
"As discussed, I believe this is the right choice.",1
I believe that merely running a model that has the callback (in a test restricted to TensorFlow) would be enough.,1
"I think this is a typical example of something that is useful for some users, and benefits from being shared on Github, but where there is little justification for including it in the master codebase.",1
I don't believe this is 1) useful to a sufficiently large fraction of the user base and 2) tightly related to the core functionality of Keras.,1
"I believe these is a chance that these tests failing was an anomaly:

line 1681: `Exception: URL fetch failure on https://s3.amazonaws.com/img-datasets/mnist.pkl.gz: None -- retrieval incomplete: got only 956412 out of 15296311 bytes`

and 

line 1468: `EOFError: Compressed file ended before the end-of-stream marker was reached`",1
These lines seem to indicate that it was just a matter of transferring this pickle from s3 which failed.,1
"Actually, I strongly believe that every function shouldn't use the global random state except for convenience.",1
"However, I also believe that new dependencies should only be introduced if they absolutely must.",1
I believe we can achieve message passing with minimal changes to the current setup.,1
I believe `Conv2DLSTM` would be in need of a similar fix.,1
@antonmbk I believe you can now do the unpooling with tensorflow.,1
"The code is very straightforward, and I believe many other have the same issue. (Well, I do :raising_hand_man: )",1
I believe this will create bugs in the 'model' since the actual vocabulary size is now `num_words+1`.,1
I believe it is a plan to make all models named.,1
I personally believe tests > docs sometimes because they give working examples.,1
I think that anybody not lazy enough always go to tests to learn about the library.,1
"I believe this is not a problem since any user experienced enough to be able to use `join` and write his own Keras layers should be able to calculate an `input_dim` or whatever is necessary to build the layer after `join`, don't worry too much to complain with the shape inference if you can't.",1
@fchollet I believe @dbonadiman had a neat and simple solution for naming conventions that is independent of the way we do it in Theano.,1
"@fchollet I believe by FCN he means support for dense prediction tasks like image segmentation of which the FCN paper happens to be one implementation, right or not the two terms are often used interchangeably.",1
I do believe that `image_dim_ordering` is the depreciated way to use `image_data_format`.,1
It would be strange that someone forgot it.,1
"I think the main thing is to work on separate files so as not to step on
eachother's toes.",1
I don't think it's critical to work using Trello.,1
"All in all, I believe this table helps users to have a general idea of what the networks are capable of, and to compare their complexity.",1
I don't think it is a big issue if the numbers are not exact since 99% of the users are not interested in a 0.1% deviation with the official results.,1
"Support for previous format will of course continue, but I believe we can afford to redesign something from scratch then route the parsing of the files to a different function based on the presence/absence of a file format version indicator in the file.",1
At that time I believed that this is how people do it.,1
"However, it seems that most of them (not Lasagne guys) use 50k.",1
"At that time I believed that this is how
people do it.",1
"However, it seems that most of them (not Lasagne guys) use
50k.",1
@kracwarlock Concat mode is supported I believe?,1
I believe this strictly adheres to the following principles:,1
"I figured out another solution, which I believe can be implemented in just a few lines of code with essentially no change to the Keras API:",1
"I believe the most correct behavior of `is_keras_tensor()` should be to simply return `False` if the parameter is not a keras tensor, eliminating exceptions.",1
"I believe it would be a tf.Tensor instead of an int:

```
import tensorflow as tf
import numpy as np

y_true = [[0, 1, 0], [0, 0, 1]]
y_pred = [[0.05, 0.95, 0], [0.1, 0.8, 0.1]]
cce = tf.keras.losses.CategoricalCrossentropy()
cce(y_true, y_pred, sample_weight=np.array([0.3, 0.7]))
```",1
"I believe this should be a note inserted in the `objectives` page: ""`categorical_crossentropy` expects categorical binary labels, here's a way to convert your integer labels to categorical"".",1
"I believe that having a full blown file for both CIFAR's is a good idea, especially since in both cases, the official testing data is left aside. (the test archive is never deserialized)",1
I believe you're right.,1
"@gabrieldemarmiesse I believe the ci failure is not due to my code, can you retest it?",1
I believe that none of the failing tests are caused by this PR.,1
"I believe GAN in Cifar-10 result is not as good as Human face, ImageNet cats and so on.",1
Ahh yes - cant believe that didnt cross my mind.,1
Will do so!,1
"@elanmart The multiple heads are really necessary for MLP controllers, here we have RNN controllers (and I believe we are the first to open an NTM with RNN controller).",1
I believe we do not currently have a correctness test for the CSVLogger callback.,1
I believe you can implement this functionality in a cleaner fashion by using `sample_weight` and setting a weight of 0 for any 0 values.,1
I'll send you a PR for the first change.,1
"I believe it would involve some minor changes in any layer, but maybe there are better ways.",1
"@fchollet @gbaned 

I believe all build issues are resolved now.",1
"Finally, the shared variables add no visible overhead and I believe it is the correct way to ensure a random shuffle and no duplicates.",1
"I believe we should include the performance profile of recurrent layers in the documentation, on CPU and GPU, on a variety of tasks.",1
That would be very useful to users.,1
"If it is 0 or lower, I believe the model will simply return without any training, which is a reasonable behavior in this case.",1
I believe the current behavior is fine.,1
I believe this would no longer be the case?,1
"Testing a single epoch or a smaller data set led me to believe `0.2` would work, but for longer work items or more epochs in a single cell it still ends up killing the browser.",1
Closing this PR since I don't believe it implements what it intends to do.,1
I do believe we should merge it.,1
I'll consider this as your good to go and start training the models.,1
"@farizrahman4u Yes, I think these are good points and it is valuable to have a `Bidirectional` wrapper.",1
"I believe the fixed I outline in https://github.com/fchollet/keras/pull/1282#issuecomment-165243334 would solve it, what do you think?",1
I removed some of the usual BN parameters from the interface because I believe there is no need to touch them and they would have made the LSTM API even more complex.,1
"I understand it might be too late, but I believe the benefit (large speedup on GPU) is considerable, given that we just reuse an existing cuDNN implementation, which is already used for masked tensors.",1
I believe I've fixed all the outstanding items.,1
@fchollet I believe all the `get_file()` docs changes should be addressed and I added a dataset dir & keras directory FAQ at https://github.com/fchollet/keras/pull/6030,1
I believe the current design was due to previous limitations with TF.,1
"Also, you should add a unit test demonstrating the limitation that is being lifted.",1
I believe this should be left to the user's discretion.,1
"However, I don't believe this would be a widely useful feature.",1
I believe a simpler solution is more desirable.,1
I believe the test failed because it couldn't download some data.,1
"Yes, we should upgrade.",1
"I believe our CTC utils will stop working with 0.10, so we will have to fix that when we upgrade (in a way that is still compatible with 0.9.0).",1
You could attempt to open a PR for this if you feel like it.,1
I believe this is too advanced and would not benefit a sufficiently large fraction of the user base.,1
I believe this PR is ready to merge.,1
I don't believe the complexity of the fix is an issue.,1
It's used for when making RNN cells stateful for I believe remembering the hidden state between batches.,1
"Overall, this is a niche feature, and we do not believe we should add it to the core API.",1
I believe a long time ago @EderSantana did something like this.,1
"However this would only be useful for testing purposes, since it would have poor performance, and couldn't implement convolution and autodifferentiation.",1
"I believe RNN cells that need specific constants should be managing their own constants, e.g. what we do for dropout (the parent RNN is agnostic to dropout constants).",1
I am pretty sure Attention wrappers would be implementable with the current API,1
"I believe people should move to the sequence class anyway, but that will be more lines written than my solution I've been using locally (~8 lines of code in the Iterator class).",1
"While I am open to alternative names, I believe that changing them could create confusion for users who are already familiar with these naming conventions.",1
"Therefore, it seems like a trade-off between renowned names and more intuitive names.",1
I strongly believe that this new layer will be helpful to people working with audio data.,1
"By the way, I just noticed that you are computing mean and std over axis 0 (samples); I believe it should be the last axis instead (dimensions).",1
"If it's meant to be added later, I believe you should provide a placeholder example because I honestly don't understand the PR...",1
"Also: sanity checks and programming flaws that should not reach runtime should be dealt with with assertions, whereas exceptions should be used to handle runtime faults.",1
I believe it is done!,1
I believe that if we we would grant anonymous users the right to launch executions then these executions would also have to have a very limited execution time (just enough to see if the code works. Rather seconds than minutes) and also should not have the right to access the internet or just limited access to white-listed sites ton consume public data sets.,1
But that would certainly degrade the user experience a lot.,1
And I believe this is the most efficient way to do this.,1
"In fact, the solution is incorrect, since iterations may not equal to ```INIT_EPOCH*steps_per_epoch```, it may be ```INIT_EPOCH*steps_per_epoch+100```, but your solution only set init epoch(only works when ```iterations=INIT_EPOCH*steps_per_epoch```), which restores a wrong optimizer state when the optimizer state saves when ```iterations=INIT_EPOCH*steps_per_epoch+100```.",1
I believe they are always divisible regardless.,1
"I believe this series of cascading issues could be avoided by reverting to the initial plan of a hard-coded mask value of 0., non configurable.",1
"Still, I believe anything in Keras that processes sequences should support masking.",1
"I believe we want to instead have the loss functions return a (nb_samples \* nb_timesteps, 1) array of the loss for each row, and then calculate the weighted mean on that, i.e.

```
train_loss = (self.loss(self.y, self.y_train) * self.w).mean()
```",1
We could do that step inside the loss function.,1
I think there must be a better way.,1
I will look into it...,1
In the same way I believe we should check for `previous` here...,1
In the same way I believe we should check for previous here,1
I'll dive deeper into this as soon as I get some time.,1
Yeah we could check for previous and return `None` if it is not there.,1
Can't believe @fchollet merged this!,1
"I don't have too much time to look into this now or fix it, but I believe it should be addressed.",1
I believe the two formulations of weight decay are equivalent up to some constant factors and maybe order of operations.,1
I believe this speeds things up a bit.,1
I believe that is the issue here.,1
"Also, I believe it was fixed in IPython?",1
"@souptc I spotted the problem, I believe that if we expand the definition of int_shape to handle int and floats we should be OK. Something like this:

```
def int_shape(x):
    if type(x) in {int, float}:
        return ()
#...
```",1
"I do believe this is very valuable code for anybody who does their computation on a desktop with a GDE (e.g. most people who use their own GPU), but I don't think it belongs in master.",1
Closing this as we won't merge it.,1
"At this stage I believe it would be preferable to create a separate repository for Caffe conversion, which will allow to provide more extensive tooling (command line utilities, etc).",1
"I believe it is. Happy to help you set it up, if you're interested!",1
"Overall, I don't believe such a layer is sufficiently widely in use or would be sufficiently useful to justify adding in to the core Keras API.",1
"After some time to think about it, I believe this is a good feature to have.",1
"However, `targets` would need to support single tensors, tensor lists, and tensor dictionaries, much like `fit`/etc.",1
"If you are interested, you can reopen a PR, otherwise I will handle it.",1
This is actually a great merge (I believe).,1
"I believe that this new layer will allow this, although I have not tested it as a first layer.",1
"So i believe if these layers can be stacked by using Sequential model,it will save a lot of time for building prototype and make the model itself more concise.",1
"Also, I believe we can implement these new merge modes without `scan`.",1
"I believe that conceptually the `dtype` argument of a layer should be the dtype of the weight matrices of the layer, not that of its input. Input dtype can be specified in input spec for validation checks, if needed.",1
I believe there is a TF dtype method that will return the "vanilla" dtype name in every case.,1
"Oh, I suggested this fix in the original issue, but I thought it would be used only in the graph mode -- in eager mode the original `.numpy()` should still be used, I believe.",1
"If inheritance is believed to create more harm than good, `type(obj) is Convolution1D` would be more robust.",1
"I have merged the changes but am not able to test due to an error I believe is unrelated, during imports:
```
  File ""/home/david/.cache/bazel/_bazel_david/104f66e67d3126a47418c58ff2542bf8/execroot/org_keras/bazel-out/k8-opt/bin/keras/utils/vis_utils_test.runfiles/org_keras/keras/mixed_precision/loss_scale_optimizer.py"", line 257, in <module>
    class LossScaleOptimizer(tf.__internal__.tracking.DelegatingTrackableMixin,
AttributeError: module 'tensorflow.compat.v2.__internal__.tracking' has no attribute 'DelegatingTrackableMixin'
```",1
I also just discovered this bug and I believe eliemichel is correct.,1
You could also do something like `batch_size = X.shape[0]`,1
I believe we should implement this feature differently.,1
I believe your description is accurate based on what I saw on the code of the other backends.,1
I believe the only operation that wouldn't work both on tensors and Numpy arrays would be the axis reversal op.,1
"@farizrahman4u I believe I intended to merge it, but it got further down the stack as other things piled up.",1
"I personally
believe so.",1
"I believe that **we should not treat** `(None, None)` with `(None, None)` to be broadcastable.",1
"Afterwards concerning the transposition, I believe that you should be expanding all the dimensions in `axis=1` until all inputs have the same number of dimensions and then simply call the merge function.",1
"`Model.fit()` takes care of the loss scaling, and upon some investigation I believe this change (of allowing different reduction method) is not needed for the following reason:",1
"It's very difficult to do research in Keras and I believe part of this is because we are always on custom environments (custom train_step, multiple GPUs) that require an understanding and care over a million tweaks.",1
"This would be one less thing to worry about, and thus helpful to researchers.",1
"1. The list of depencies is visually broken into parts, so that one would believe it to end before the first ""When using …"" line.",1
I believe this PR should be merged directly rather than via Copybara.,1
I believe the LSTM decoder should have `stop_gradient` when consuming its own output.,1
I believe this was fixed in an earlier PR relative to legacy Theano weight loading.,1
"I hope I am not coming on too harsh, it's great code but I believe it tries to do too much.",1
"The parameters passed would then be expected to follow the Layer API, but they wouldn't have to be single layers, they could be arbitrary containers (such as a stack of layers).",1
"If a BRNN has to be used in conjunction with CTC to be useful, then it would be very valuable to 1) add both the BRNN layer and CTC at the same time, and 2) provide an example script with a model leveraging both, so that users have a reference point of what to do with BRNN and CTC, and what kind of performance they should expect.",1
First of all we should fix the current error message:,1
It seems that this layer doesn't work with the current tensorflow version.,1
"On calling the layer following error is returned:

`TypeError: Expected binary or unicode string, got -1`",1
"@EderSantana , looking at you ipynb, it seems that you might just use predict_classes, predict_probab without compiling the network yourself.",1
Something like recurrentshop is maybe a good approach but that code might need some work.,1
"@datumbox Ok think I see what you are saying, I might try this out on my dataset.",1
"One thing that might help with getting this through is a few improvements to the PR, variable names, and description.",1
"I did have other models including resnet and densenet that didn't perform as well as vgg that use pretrained weights, and the fix in this PR might be why.",1
I will try them out but can you confirm the following steps will make use of your changes?,1
I might also do a third pair of runs where a random fraction of each network is trainable.,1
"I looked at a few specific examples such as inception resnet v2 weights with training locked and either a densenet or resnet block on the end, and they might have done ~1-2% better, but they didn't suddenly become the best models found in the search because of this change.",1
If you think it'd be worthwhile to re-run with random proportions I might be able to give it a try.,1
"That might help other users deal with the current API, then if a PR like this eventually gets merged the example can be updated accordingly.",1
Imagine that you might have trained a classifier from scratch on one domain and now you want to use it as initial weights on a different problem.,1
It's fair to say that you might as well have saved the entire project that I'm currently working on.,1
A note about this issue in [the documentation's fine-tuning example](https://keras.io/applications/#fine-tune-inceptionv3-on-a-new-set-of-classes) might save others confusion like this in the future.,1
"If and when the contrib DenseNet makes into keras/applications, I can make changes and a new PR. For the meantime, end users might want to see how densenet is implemented in keras on a dataset like cifar10 that can be easily understood and ready to run.",1
This PR would be useful in that case.,1
I think it might be best to create a new issue to increase visibility over this problem.,1
@visionscaper I thought these two synchronized automatically...,1
Maybe this has something to do with PR #16851?,1
I think I can't do more in this PR.,1
Probably close this one and open a new one might help?,1
I described their different behaviour (mostly concerning the way other callbacks might change `Function.fetches`) in [this comment](https://github.com/DavidAriel/keras/pull/1/files#r192450599).,1
"But because now the engine functionality is used, a better solution might be to check the `do_validation` property of the callback, which is set in all cases, and remove the test.",1
"If we can achieve the same thing, we might just close this PR.",1
"I realize the whole squashing thing might not be clear, so I've updated CONTRIBUTING.md with a link to http://rebaseandsqua.sh/.",1
"A lot of transfer learning works better with decreased (but nonzero) learning rates applied to pretrained layers, so it might be worth keeping in mind...",1
"In short, I would say that atm the shape inference is not that useful and it might make sense to remove it (but say explicitly in the doc string that the output shape is not arbitrary and should be inferred from the input e.g. using a dummy variable).",1
"Also, inserting some other stopping flag like `self.model.stop_training` in `_fit_loop` might help you achieve your purpose without changing codes so much.",1
"Please do not use it for now, and we might expose it later once it is mature enough.",1
You might want to actually call `model.fit()` and make sure the weights are not changing.,1
I got to look a bit closer and it seems nice!,1
"Rebase/switch fork, etc looks like it might be perfect for connecting new inputs for the input tensor API.",1
They might quit with the keras if it doesn't work out of the box.,1
I marked a few points that might be causing the ci to complain.,1
Sometimes network might fail.,1
Also might be useful for logging...,1
The modification you wanted to make might end up in Keras as part of the PR for Caffe model importing.,1
We'll see.,1
I think a solution might be to make an optional dependency.,1
It might also be hard to reproduce if the user does not set a seed at the beginning.,1
"`sample_weights` for all samples, e.g. used to call `fit()` or `evaluate()`, might have positive values, but the `weights` vector used to call `weighted(y_true, y_pred, weights, mask=None)` can have only zero values anyhow due to batch-wise computations as described above.",1
"I would imagine a contrib module `keras_contrib.regularizers.mymodule` like this:

```python
class L3Regularizer(...):
  ...
custom_objects={'regularizers.mymodule.L3Regularizer': L3Regularizer}.
```

I could use it like so:
```python
from keras_contrib.regularizers import mymodule
with custom_object_scope(mymodule.custom_objects):
   reg = regularizers.get('regularizers.mymodule.L3Regularizer')
```",1
"However, I'd be interested in any other ideas to fix current issues with custom objects that might be helpful for implementing contrib.",1
Most won't be useful but some like jacobian or arcsinh might be useful.,1
"This might be what I'm leaning towards, because it isn't too radical but gets the job done:

```
#theano_backend.py
arccos, arcsin, arctan = theano.tensor.arccos,  theano.tensor.arcsin,  theano.tensor.arctan
```",1
"Having a bunch of automatically copied functions that may or may not work consistently removes most of the value, then I might just as well call the Theano function directly.",1
"The above wrapper might improve reproducibility, but it might harm training.",1
"In my programs I don't consume any global randomness, so if I were about to use this wrapper, my models would be trained with the same permutation of training data all the time.",1
"I accept that this is settled as won't fix, but for the unfortunate landing here through search engines I want to point out a last point.",1
"We might be able to implement it with `ndimages`, but it might be slow.",1
"The advantages I see for layers that are independent of tensor dimensions are:
- work with any tensor a user might want to use
- easy to develop, just one case
- less clutter in namespace",1
I have concerns that the use of `set_subtensor` might be quite inefficient (since it is copying entire tensors).,1
"This behavior can be achieved with boundary methods as well, but I find it less intuitive (I also find weight decay more intuitive than L2 regularization, so it might be just personal preference).",1
"It would be nice to inform users (e.g. see https://github.com/fchollet/keras/issues/6545) somehow about the required version of tf, it might be tricky since it's not written in setup.py and on the web page.",1
"Output shape: 5D tensor with shape: (nb_samples, timesteps, nb_filter, nb_row, nb_col). nb_row, nb_col might have changed due to padding.",1
"Might feel a bit unnatural at first, but its better this way than have 2 function with same name. (keras.backend.sum and keras.layers.sum).",1
Similar updates for the `objectives.py` documentation might be better done separately.,1
You probably right and util would be better place for these methods.,1
It might be nice working together though -- more motivating :),1
I would still want to give it a try but might need quite some clarification and help to make things right.,1
"Yeah, a test might help indeed.",1
"I feel this is especially important in light of pushing to make Keras a more ""ready-to-use solution for applied machine learning"", where users might be concerned with data traceability and long-term interpretability.",1
"I might look into using a different data set as well, but that might take some time.",1
Might want to reduce sensitivity and seed the RNG.,1
"Other features of Keras have issues with older versions of Theano (specifically, a Theano bug causes layer concatenation to fail on GPU --there might be other problems as well).",1
"If you experience a faster convergence, then an overfitting might naturally occur earlier.",1
The transfer to your own dataset might requite some validation-based adjustments of the initial learning rate and .the weight decay factor.,1
"So, it might not be an equal comparison to begin with. In short, the early loss reduction could be only attributed to the restart scheduling if you start with the original resnet with all preprocessing and params the same and show that you can reproduce that and then by only changing the learning rate scheduling to show the difference.",1
"It might happen that there is a difference already there, i.e., with the default approach, and so it is expected for restarts.",1
"I would also suggest to
check the original step-decay of the learning.",1
"It might happen that there
is a difference already there, i.e., with the default approach, and so it
is expected for restarts.",1
It might not make a whole lot of difference.,1
"I guess that the clipping should be optional, otherwise depending on parameters it might be harmful like you just found.",1
"Adding anything to the codebase has benefits (the functionality it brings), and it has a cost: it might hinder usability, it might complicate future development, it creates maintenance liability, etc.",1
"We are going to write tests for all features sooner or later, so we might as well start writing them for any new functionality being added now.",1
it might be worth separating out the merge PR from the RNN PR if the merge works for normal cases.,1
"By the way, I've been using this merge implementation for some merging stuff and it seems to be working well.",1
The return path of the [`updated`](https://github.com/fchollet/keras/pull/6928/files#diff-a18b8c6a1191d6f49303e0d599ca8c37R2280) variable might still need some tweaking.,1
Might be a few days before I can address further code fixes.,1
"This error looks like it might be due to flaking, but I'm not super familiar with `TimeDistributed`.",1
"Note: There might be typos above, I checked it carefully but it isn't fully implemented yet.",1
Also: doing everything in vanilla Keras if you have a specialized TF workflow might not be optimal.,1
"TF has a [high performance models guide](https://www.tensorflow.org/performance/performance_models) you might wish to take a look at, I've quoted a key paragraph below:",1
2. Patches to the relevant PRs that implement discussed changes might help with getting the outstanding items merged.,1
"One could set `steps_per_epoch` to batch_size to avoid this but it might be worth adding a shape attribute to the input tensor if possible or alternatively, check for the existence of a `get_shape` function in `_test_loop`.",1
As a code developer my concerns with this PR 6928 is it might be too extensive.,1
"Even when these are good in terms of DRY principle, it still might be too much.",1
I might do this. Thanks for the help.,1
Might have missed it when we changed the naming convention. :+1:,1
Maybe a solution to avoid those conflicts might be to do smaller PRs?,1
@yongzx might then be able to do one PR per file and avoid this type of problems (and it would make the review much easier).,1
"This might be one way forward, alternatively one could imagine a `fit_tensor` which would reduce the number of changes needed for `fit` and might match workflows better anyway.",1
the mask in TimeDistributed might need to be handled differently than just putting it in there..,1
"I've updated the code upstream, which might remove the need for this PR.",1
"I think for the pr here in keras it might be wise to consider explaining how the usage of this model is different from using other models in the docs, particularly w.r.t. the aux network.",1
"Additionally, `softmax` in `keras/activations.py` might be cleaned up.",1
In the next revision version they might try to reproduce their analysis and the results will not match.,1
"Also, I haven't tried this with `mask_zeros` in the `Embedding` layer, which seems like the most common use case.",1
References to the specific meaning of each dimension should be avoided if it isn't relevant to the computation -- the second dimension might not be time.,1
"Besides, it is not clear what ""rotating"" a `(time, features)` tensor actually means (I had to read the code to get it), so that should be clarified.",1
"Finally, the choice of the names `1D` / `2D` might be problematic, since they are actually applied to 2D and 3D tensors respectively.",1
"I hope I've explained clearly, if not trying out variations of [test_model_with_input_tfrecord()](https://github.com/ahundt/keras/blob/b7d44a54ffee3391135abd3a3566a9c0d20a2fa8/tests/keras/engine/test_training.py#L515) on master might help.",1
I'm also available on Slack or I could email you my phone number from ATHundt@gmail.com if a call might save you time.,1
I know I could implement my own model or loop that does TFRecords & yield_ops.,1
"- The above crashed, and while there might be steps might be missing in your description, I think it'd still be a problem for the reasons above",1
"However, I might have misunderstood how StagingArea works, please correct the following if I have a misunderstanding.",1
I think it's more of like a bug.,1
"I think the results will be same or better in all (?) cases, except, maybe, where there was a bug in user code specifying zoom range or something (like having a zero or negative number there).",1
Such a scheme might come roughly at the same time as the future abstract backend.,1
"Let me review this in detail, then we will merge.",1
It might be a few days until I find the time.,1
This might make possible a workaround.,1
I might not get to it until the weekend and maybe not even then,1
"A naive approach would be to zero out parts of the rows of the large matrix, but there might be a more efficient way of doing this.",1
"Still, **a GPU performance increase of roughly 40%** at the expense of requiring the same RNN dropout for all gates is useful in many cases, especially considering many don't even use dropout, and considering some might be looking to [RNN batch normalization](http://arxiv.org/abs/1510.01378) in the future.",1
`consume_less='gpu'` sounds good.,1
"I think there might be some value to keeping the previous two modes, because of the dropout, but I guess it really should come down to what @yaringal quantifies in his experiments.",1
Maybe it doesn't make much of a real-world difference?,1
That might incidentally give @joelthchao what he is looking for as well.,1
The PR is complete from a code-wise perspective although you might want to change the above mentioned special case.,1
When I get the training working with the hinge losses I think this PR might be finally finished.,1
We might take a bit to get back to you on this given it's the holidays and a lot of the team is out.,1
"I get that it's a lot of work to use custom types everywhere in the codebase and to maintain them, but for the public API, it has a direct benefit to the user through Mypy and IDEs, so it might outweight the cost of maintenance",1
I think that Noise can have its own module.,1
Having the entire family might be useful.,1
Intertwining these loops would complicate the code and might affect performance by switching the executed functions.,1
"Depending on the version, it might store each and every update to the screen, or in the newer (4.3.1 I think) it accumulates ""\b\b\b\b\b\b\b\b""s, which are ""backspaces"" that serve to clear the screen.",1
@fchollet I think there might be some value in making this a command-line executable script with default arguments (using `argparse`).,1
"These trailing spaces might have nothing to do here, but removing them along with your commit makes your commit quite hard to read...",1
We could try using that here but it might not be able to handle some of the custom stuff done in here.,1
"given wild-west status, I think it might be nice.",1
Reproducibility is [Sacred](https://github.com/IDSIA/sacred/)'s goal and something like it might complement Keras examples and datasets well.,1
It might work there as well.,1
4) I think I stretched it to 200epochs just to see any further reduction.,1
We feel that this feature is overly specialized.,1
It is not scalable to add more new arguments to the visualization utility covering every possible bit of information that one might want to display about a layer.,1
"Alternatively, I could do it, but I haven't contributed to Keras before and the work might take me a while.",1
User might need to update the code with tf.compat.v1.disable_v2_behavior() to force the test run in v1.,1
The tf_api_version flag will not work since the TF binary is imported from PIP and the flag is only consumed when we build TF.,1
So I thought it'd not be a too narrow use case and that other might be interested and that I could share some of my implementations.,1
I might be missing something.,1
If you're testing with 2d data you might want to rescale your images to 1450x1450 and make sure to use float and increase the stride on the first Conv to have reasonably sized feature maps.,1
"I have an alternative proposal to solve this problem, which would also extend to the needs of other layers that might run into a similar problem in the future.",1
The previous solution might have be better.,1
"If there were a long string of weights in their, it might make the files a lot more tedious to inspect.",1
"Seems like vanilla definitions are going to be the easiest for people to understand and maintain, so this PR should be the right way to go.",1
"Alternatively, it might make more sense to put all of the extra functions into the contrib repo depending on how that pans out.",1
"I can see a future use case where someone might want to initialize with convolution filters, will a situation like this break the implementation without raising an appropriate error?",1
http://rebaseandsqua.sh/ might be worth doing before the review process begins,1
"@fchollet yeah it's fine for me, but figured it might be something that would be a nice fix for Keras.",1
"I could only find custom defined formats, but then it might as well be a computed by hand since it's not rocket science.",1
"There are also interesting issues with the dataset ([duplication of some of the (story, query, answer) tuples](http://smerity.com/articles/2015/keras_qa.html#dataset-issues)) that I've discovered that might have had an impact on all the systems that have used this data.",1
"If you don't have the ImageNet validation set, the following codes might help you:
```python
import numpy as np
import tensorflow as tf
import tensornets as nets
import tensorflow_hub as hub

from keras.applications.imagenet_utils import decode_predictions
from keras.applications.nasnet import NASNetLarge, NASNetMobile, preprocess_input

url = 'https://tfhub.dev/google/imagenet'
model_name = 'nasnet_large'

img = nets.utils.load_img('cat.png', target_size=378, crop_size=331)

inputs = tf.placeholder(tf.float32, [None, 331, 331, 3])
tfhub = hub.Module(""%s/%s/classification/1"" % (url, model_name))
features = tfhub(inputs, signature=""image_classification"",
                 as_dict=True)
model_tfhub = tf.nn.softmax(features['default'])

model = NASNetLarge(input_shape=(331, 331, 3))
model.load_weights(""/home/taehoonlee/.keras/models/NASNet-large.h5"")

preds = model.predict(preprocess_input(img.copy()))
with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    preds_tfhub = sess.run(model_tfhub, {inputs: img / 255.})
np.testing.assert_allclose(preds, preds_tfhub[:, 1:], atol=1e-4)
```",1
I'll give this updated version a try.,1
It might confuse some people.,1
"In this example, the condition to move to the next phase of training might be `val_los <= -2.0 and examples_seen > 5000`.",1
"Could make the Travis output clearer, and could make the system more easily extensible as well (in the future we might want to extend this exclusion system to more heavy tests -- `ConvLSTM2D` for instance).",1
"If it is made publicly available, others with the same use case might also benefit from it.",1
Otherwise it might be good to add an if statement for that case.,1
That would be a Theano PR though,1
"It could be that it's just too complicated to make a single `TimeDistributed` class handle all possible ways that someone might want to use it for masking, and we should handle this variable-length encoder masking as a subclass of `TimeDistributed` (this is what we already do; I work with @DeNeutoy).",1
One option would be to just return `None` if the child layer returns `None` at any time step.,1
Different backends might want to optimize the way they manage constants.,1
Here is an expanded example with how a more complex segmentation train/test script might work.,1
"# TODO generators defined in this PR would become YieldOp implementations
# might utilize PythonFunction for that",1
"- `thread.terminate()` call in GeneratorEnqueuer::stop() might corrupt the queue, why not `thread.join()`?",1
"For instance, people developing in Python 3 might use integer divisions that would result in a hard-to-spot issue in 2.7, like you just did : )",1
"BTW, `datasets/cifar10.py` might need a bit more work, since the original cf10-pickle files aren't straightforward to load in Py3.",1
I took a look at the code and I think the best fix might be a nonlocal class like I did in get_file(). https://github.com/fchollet/keras/pull/6535#discussion_r115638225,1
"Now that I think of it, this might be slightly nicer way of doing things.",1
"I will make a new commit to change it, but this will take a few days because my schedule for the next days is a bit busy.",1
I'll check again on a different machine but it might be worth rerunning them tomorrow on Travis in case they have an issue today.,1
@fchollet I would still be more comfortable if the tests actually pass on Travis.,1
This might have all sorts of side-effects.,1
"If it did, it might cause problems when using keras as a layer library for Tensorflow / Theano.",1
"Instead of tracking constants through the computation graph, it might be easier to see that ""wait, I didn't expect 'height \* width' to come out of that node"".",1
"It might, however, be sufficient just to see the all the constant shapes (bypassing the complexity of building up symbolic computations).",1
But it might be worth it as it makes it easier than my solution to get the shape of a specific layer.,1
"It would be nice if Keras handled sparse matrices for all of the methods that might take in sparse data (fit, train_on_batch, predict, etc), hence all the lines of code.",1
"Seems useful indeed! Until now I was doing this stuff very much by hand, but I imagine the average user might want to stay within the Keras interface.",1
"I haven't done any profiling to see what this cost might be, though it should be small relative to computing the actual convolutions.",1
This might be useful in a multi-task learning setting.,1
"In that case, the function skips an unnecessary step, so you might want to change the `skip_standardizing` parameter into `num_skip_standardizing` or something like that and just specify the length of the list (like len([p]) ).",1
1. checking if the input is a numpy array is not good enough because it might be converted to a numpy array later,1
PS. I am not extremely familiar with the checkpoint mechanisms that you might be using.,1
"It might have something to do with [_fixed_padding](https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/conv_blocks.py#L24), but I have yet to figure out how to make ours match.",1
"The epsilon approach might work, would need to think about some more.",1
I'm also nervous because I know GPUs sometimes are a bit loose in their implementation of IEEE floating point and NaN is exactly the kind of corner case where we might see strange behaviour.,1
I think a potential problem would be that it might hide problems where your fit wasn't converging.,1
With NaN as mask you might not notice this explosion.,1
Yes. That was my main motivation to consider NaN so at least you might notice.,1
Modifying every loss function might not necessarily be a big issue.,1
I just thought this might be more clear.,1
For applications like that of @kgzy wherein `return_sequences=True` it might be nice to use the input mask as an output mask as well (basically multiply the weights matrix by the mask matrix in the last stage).,1
Right now you would need to explicitly mask your labels as well.,1
"I might implement this for my purposes, though I acknowledge that it introduces a kind of ugly/confusing API around micro-batches vs. mini-batches.",1
"Yes. If you're not on Linux, then it might be a difference in your TF build.",1
"Though there is a seed setting in `test_optimizers.py`, some other unexpected randomness might exist.",1
That might make things a bit more clear,1
"I've reorganized things a bit so the sequence of patches might make more sense now. (And I changed a bit in the code as well, so it's slightly different from the previous iteration.)",1
"This patch also deprecates the existing `K.batch_normalization` function, which might be useful to keep around for external code that depends on this.",1
"I do think that it is useful to have a separate method for batch normalization during training, since there are also separate training and testing functions in cuDNN that you might want to use.",1
"In TensorFlow the function for both is called `tf.fused_batch_norm`, I think, with a parameter to specify the training/testing.",1
This might be related to the generator problem #2225,1
There seems to be memory overflow somewhere,1
"If so, docs might be wrong.",1
"I was initially imagining it might be useful for other custom objectives, but I don't have a clear idea of what they would be, so removing it sounds good. For the second point, the theano source for [categorical_crossentropy]",1
Edit: I might try to simplify nested `if` statements but that seemed the cleanest way to me.,1
"As for coverage, I just realized that it might be tricky to make it work with travis parallel test matrix..",1
I'm not sure what goes wrong with dropout following a `Bidirectional` but it might help to see an example of something that actually works.,1
"Yeah, feed in the same images will nail it down.",1
"It might be desirable to allow things such as rescale to be different for mask vs image without affecting the synchronized generator, for obvious reason.",1
This is another use-case but might not be very common.,1
"For example, with gradient noise, users might want to configure the mean and variance of the Gaussian noise.",1
"For example, with gradient noise, users might
> want to configure the mean and variance of the Gaussian noise.",1
"However, because `T.nnet.conv2d` accepts any `**kwargs`, older versions will not give an error but will just ignore the new parameter (they might say it is deprecated, which isn't really helpful).",1
"However, because T.nnet.conv2d
> accepts any **kwargs, older versions will not give an error but will just
> ignore the new parameter (they might say it is deprecated, which isn't
> really helpful).",1
"I'm going mostly offline for 3 days, I'll review and answer this weekend.",1
"My initial feeling is that we are likely to merge this, as it provides
useful functionality.",1
"Unfortunately I don't have a Windows 7 machine right now, but I think the error might be somewhere else.",1
"You can reopen a PR with the setup classifiers, although this may be of limited interest since we're not distributing the library on pip at this point.",1
"There is pep-0427 reading also, which may be a little more factual.",1
"There may be another error, now it works.",1
"First, I had a dataset that had mostly positive values, but maybe 10% small negative values.",1
This may have the effect of increasing memory usage but can also reduce the overhead introduces by using Scan.,1
Maybe PR https://github.com/tensorflow/tensorflow/pull/13561 fixes it.,1
"Maybe the problem is/was triggered by -1 in reshape
https://github.com/tensorflow/tensorflow/blob/r1.3/tensorflow/contrib/keras/python/keras/backend.py#L2091",1
"Basically, we may want a flexibility in encoding categorical features during network construction.",1
So I am not sure whether the API is the same and maybe @lukedeo can verify is there any problems for my training results.,1
Could add more info maybe ?,1
Since it inherits from dropout we may not have to do anything --but let's add a test.,1
Maybe Theano doesn't need to be run for certains module?,1
Maybe we can set this mode for `keras.applications` only?,1
"It allows parsing custom objects that are nested dicts or lists (instead of stopping only on the second level), but I can't find an example where a 3-level custom object is used (may exist, I am just not sufficiently familiar with everything).",1
Maybe even `vhat*` can be calculated unconditionally (if performance difference is negligible) and only `p_t` calculation would differ between the two.,1
Maybe this could become an option in `Adam`?,1
In general - It may be a good idea to split this function into at least two functions - greedy / beamsearch.,1
"As you may know, the greedy is a special case of the beam search when `beam_width=1, top_paths=1`.",1
Maybe it's a flake and re-running will pass?,1
"There may also be a problem with the ""trainability"" of
the alpha parameter.",1
In that sense the whole training history may not be a proper property of `model` since it is only used inside `fit` (besides for callbacks at the moment of course).,1
"So let's start with the base class (made private, i.e. `_` in front of the name -- we may make it public later on), and let's add a single attention cell wrapper that subclasses it (as a proof of concept and API example).",1
Therefore we may need a better error message.,1
Maybe it's not so random after all?,1
Maybe changes in TF.,1
Maybe it's related to #11034 ?,1
You may need to adapt it if it throws an error.,1
"Which may not be the case, for example with a loss like this, it needs to be minus two:

```python
def dummy_loss(y_true, y_pred):
        return K.mean(mae(y_true, y_pred), axis=-1)
```",1
"This PR requires support for multiple dynamic axes, i.e., in addition to the batch size axis, other dimensions may be defined at execution time, too.",1
"@fchollet, Recently, as you may know, the timeout has been arising even in CNTK and Theano.",1
"I'll make the code public soon, but in the meantime, you can maybe investigate this.",1
"@fchollet maybe a noob question, but what's the benefit of having K.where when we have K.switch?",1
Maybe we should have migration tests to ensure that we don't break the loading of saved models.,1
"If you want to try different sets of arguments across different runs, you may simply do:

```python
callback = LearningRateScheduler(lambda epoch, lr: my_schedule(epoch, lr, **schedule_args)
```

Or

```python
callback = LearningRateScheduler(functools.partial(my_schedule, **schedule_args))
```",1
"Since tensorflow is used in the cntk build (for tensorboard with cntk for example), there may be a memory leak somewhere.",1
Maybe they should go in their respective op files.,1
"@MarcoAndreaBuchmann, Maybe we need @fchollet's comments.",1
"Maybe, we need a discussion about which functions are useful to inform their NumPy equivalences.",1
Maybe that's why you are confused.,1
"@fchollet, maybe this PR is one of the temporary solutions for the recent build errors.",1
"As you said, it may be related to the RAM.",1
I'll try to play around with jobs.,1
"If it's just a memory issue, we could upgrade to a VM based environment.",1
We would gain 3.5GB of RAM. And I think it's free because we are FOSS?,1
"We could try to run the docker locally. 
https://docs.travis-ci.com/user/common-build-problems/#Troubleshooting-Locally-in-a-Docker-Image",1
This seems related to multiprocessing.Manager not being started.,1
This may be GIL related.,1
We may want to update this code to a Pool (similar to Sequence).,1
"Anyway, I created this pull request and spent some effort in writing this comment to contribute back to the open source community, and even if this pull request has been closed I hope that this discussion can be useful somehow, maybe in future.",1
This test is therefore non deterministic and may fail randomly in rare cases.,1
"Maybe, Travis build is failed because of other problem.",1
"The solution for that is to either: 1. Preface line with a pipe (see example below), or 2. Put a placeholder in blank fields (a dash maybe) (no example shown, but you can imagine it).",1
"You may still use it, by importing directly from `layers.wrappers`.",1
This change is only relevant to few users (maybe only your own use case).,1
"so, changing symbol  is a simple solution.
or, maybe Adding  PYTHONIOENCODING=utf-8 to Dockerfile?",1
"However, I may mis-judge that it could be fix very easily.",1
"After some inspection I think it may need a clearer indication where it shall be fix, and that may involve implementation decisions.",1
You may also find Keras bugs that you can fix.,1
It maybe still necessary to open with 'a',1
"* Some logic is applied to both x and y, maybe we could move some logic in a separate function?",1
Maybe let's move this discussion to an issue to avoid stopping this PR from being merged?,1
Maybe someone else can give some insight?,1
Maybe it can help you.,1
"This worked perfectly, well you may not need to base64, for me to store in the database I did, everything in-memory, no touching disk",1
Maybe there are others too.,1
The model file is 2 Gigs so maybe it's too large.,1
Maybe having a "deterministic" model is something we should look for.,1
"Maybe, I should solve with inspect.getargspec in autogen.py until the latest version of keras in PyPI is updated.",1
It may be that the same fix needs to be applied in `tf.keras` as well.,1
"One may just use:

``` python
def top_10_acc(y_true, y_pred):
   return top_k_categorical_accuracy(y_true, y_pred, 10)
```",1
Maybe it should be fixed that way?,1
I agree -- it seems silly to not use the optimized Theano implementation.,1
Maybe I could add a warning that prints if you try to use the tensorflow backend with HSM?,1
I can fix problem 3 tomorrow (or very shortly) and maybe @farizrahman4u can comment on problem 1?,1
To emphasize -- I do think this implementation is too messy to be merged as is; I mostly am just looking for feedback about the best direction to go from here.,1
Maybe that's why tf.keras couldn't be a simple fork :D,1
So this may explain your slowdown?,1
It could be beneficial to replace it with something more standard - e.g. maybe just leave the default batch norm momentum value?,1
maybe we can fix this with the `KerasCV.models` refactor?,1
"If we want a mapping from one image to a set of classes, we may be better off using something like TFRecords...",1
Maybe the fastest thing would be to try a new fork and add once functiona at a time and take the loss?,1
"Maybe we need a big try/finally block around the whole thing. And we could wrap up the data_queue/stop_event/generator_threads into a class for cleaner syntax:
```py
data_generator = None
try:
    data_generator = DataGenerator().start()
    # run loop
finally:
    if data_generator is not None:
        data_generator.stop()
```",1
Maybe it's a good idea to add "depth" to the model summary?,1
Maybe list both - trainable depth and total depth.,1
"This message and its attachments may contain confidential or privileged information that may be protected by law;
they should not be distributed, used or copied without authorisation.",1
"As emails may be altered, Orange is not liable for messages that have been modified, changed or falsified.",1
I think this shows that maybe something needs to be fixed in this model with this particular example,1
Training happens in maybe 5 seconds but compilation takes about a minute.,1
Maybe we should discuss this feature first?,1
"@kretes fyi I suggest a PR which includes your feature ""ability to add static values to output file"" - for me it works well, maybe others find it helpful, too: #12266",1
Maybe it's related.,1
The one place I could see this *maybe* helping is if people want to adapt this script to CIFAR10 or that ilk.,1
"With recent fixes to the BN, maybe I'll try it again later.",1
"Most It comes from sampling latent noise. Which is not what we want, but may not matter much in practice, depending.",1
"Without smart re-shuffling, the net will see row number `i` of the data, update its hidden state, and then proceed to use this hidden state at row `i + batch_size`, which is not what we want.",1
"tests/test_multiprocessing.py::test_multiprocessing_training
  e:\toolkits.win\anaconda3-4.4.0\envs\dlwin36tf140kerasmaster\lib\site-packages\keras-2.1.2-py3.6.egg\keras\engine\training.py:2023: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data.",1
"tests/test_multiprocessing.py::test_multiprocessing_training_from_file
  e:\toolkits.win\anaconda3-4.4.0\envs\dlwin36tf140kerasmaster\lib\site-packages\keras-2.1.2-py3.6.egg\keras\engine\training.py:2023: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data.",1
"tests/test_multiprocessing.py::test_multiprocessing_predicting
  e:\toolkits.win\anaconda3-4.4.0\envs\dlwin36tf140kerasmaster\lib\site-packages\keras-2.1.2-py3.6.egg\keras\engine\training.py:2375: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data.",1
"tests/test_multiprocessing.py::test_multiprocessing_evaluating
  e:\toolkits.win\anaconda3-4.4.0\envs\dlwin36tf140kerasmaster\lib\site-packages\keras-2.1.2-py3.6.egg\keras\engine\training.py:2251: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data.",1
"tests/test_multiprocessing.py::test_multiprocessing_fit_error
  e:\toolkits.win\anaconda3-4.4.0\envs\dlwin36tf140kerasmaster\lib\site-packages\keras-2.1.2-py3.6.egg\keras\engine\training.py:2023: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data.",1
"tests/test_multiprocessing.py::test_multiprocessing_evaluate_error
  e:\toolkits.win\anaconda3-4.4.0\envs\dlwin36tf140kerasmaster\lib\site-packages\keras-2.1.2-py3.6.egg\keras\engine\training.py:2251: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data.",1
"tests/test_multiprocessing.py::test_multiprocessing_predict_error
  e:\toolkits.win\anaconda3-4.4.0\envs\dlwin36tf140kerasmaster\lib\site-packages\keras-2.1.2-py3.6.egg\keras\engine\training.py:2375: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data.",1
"tests/test_multiprocessing.py::test_multiprocessing_training
  e:\toolkits.win\anaconda3-4.4.0\envs\dlwin27cntk23kerasmaster\lib\site-packages\keras-2.1.2-py2.7.egg\keras\engine\training.py:2023: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data.",1
"tests/test_multiprocessing.py::test_multiprocessing_predicting
  e:\toolkits.win\anaconda3-4.4.0\envs\dlwin27cntk23kerasmaster\lib\site-packages\keras-2.1.2-py2.7.egg\keras\engine\training.py:2375: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data.",1
"tests/test_multiprocessing.py::test_multiprocessing_evaluating
  e:\toolkits.win\anaconda3-4.4.0\envs\dlwin27cntk23kerasmaster\lib\site-packages\keras-2.1.2-py2.7.egg\keras\engine\training.py:2251: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data.",1
"tests/test_multiprocessing.py::test_multiprocessing_training
  /media/EDrive/toolkits.ubu/anaconda3-4.4.0/envs/dlubu36tf140kerasmaster/lib/python3.6/site-packages/Keras-2.1.2-py3.6.egg/keras/engine/training.py:2023: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data.",1
"tests/test_multiprocessing.py::test_multiprocessing_training_fromfile
  /media/EDrive/toolkits.ubu/anaconda3-4.4.0/envs/dlubu36tf140kerasmaster/lib/python3.6/site-packages/Keras-2.1.2-py3.6.egg/keras/engine/training.py:2023: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data.",1
"tests/test_multiprocessing.py::test_multiprocessing_predicting
  /media/EDrive/toolkits.ubu/anaconda3-4.4.0/envs/dlubu36tf140kerasmaster/lib/python3.6/site-packages/Keras-2.1.2-py3.6.egg/keras/engine/training.py:2375: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data.",1
"tests/test_multiprocessing.py::test_multiprocessing_evaluating
  /media/EDrive/toolkits.ubu/anaconda3-4.4.0/envs/dlubu36tf140kerasmaster/lib/python3.6/site-packages/Keras-2.1.2-py3.6.egg/keras/engine/training.py:2251: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data.",1
"tests/test_multiprocessing.py::test_multiprocessing_fit_error
  /media/EDrive/toolkits.ubu/anaconda3-4.4.0/envs/dlubu36tf140kerasmaster/lib/python3.6/site-packages/Keras-2.1.2-py3.6.egg/keras/engine/training.py:2023: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data.",1
"tests/test_multiprocessing.py::test_multiprocessing_evaluate_error
  /media/EDrive/toolkits.ubu/anaconda3-4.4.0/envs/dlubu36tf140kerasmaster/lib/python3.6/site-packages/Keras-2.1.2-py3.6.egg/keras/engine/training.py:2251: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data.",1
"tests/test_multiprocessing.py::test_multiprocessing_predict_error
  /media/EDrive/toolkits.ubu/anaconda3-4.4.0/envs/dlubu36tf140kerasmaster/lib/python3.6/site-packages/Keras-2.1.2-py3.6.egg/keras/engine/training.py:2375: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data.",1
"tests/test_multiprocessing.py::test_multiprocessing_training_from_file
  /media/EDrive/toolkits.ubu/anaconda3-4.4.0/envs/dlubu36tf140kerasmaster/lib/python3.6/site-packages/Keras-2.1.2-py3.6.egg/keras/engine/training.py:2023: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data.",1
"tests/test_multiprocessing.py::test_multiprocessing_training
  /media/EDrive/toolkits.ubu/anaconda3-4.4.0/envs/dlubu27cntk23kerasmaster/lib/python2.7/site-packages/Keras-2.1.2-py2.7.egg/keras/engine/training.py:2023: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data.",1
"tests/test_multiprocessing.py::test_multiprocessing_predicting
  /media/EDrive/toolkits.ubu/anaconda3-4.4.0/envs/dlubu27cntk23kerasmaster/lib/python2.7/site-packages/Keras-2.1.2-py2.7.egg/keras/engine/training.py:2375: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data.",1
"tests/test_multiprocessing.py::test_multiprocessing_evaluating
  /media/EDrive/toolkits.ubu/anaconda3-4.4.0/envs/dlubu27cntk23kerasmaster/lib/python2.7/site-packages/Keras-2.1.2-py2.7.egg/keras/engine/training.py:2251: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data.",1
May be a callback could be a better approach.,1
"For some reason, the theano tests are not faster with python 3.6 which is very strange (caching maybe?).",1
Maybe we could use subclassing later on?,1
Note that novice developers may be confused as the depth is just slightly different from `len(model.layers)`.,1
Maybe it's a memory issue.,1
Maybe it will help.,1
"In fact I faced it when I'm using `multi_gpu_model` as mentioned in my earlier issue，so maybe it's a better idea to do some more test on 
`multi_gpu_model` instead (but I have no idea about that...)",1
"`import keras` may cause error like this:

>  /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated.",1
The proposed change doesn't break the existing code base but it may change the produced results.,1
Maybe `test_no_grad` should not exist at all?,1
It would make more sense if this test was in the TensorFlow test suite and not in the Keras one.,1
"#10108, #10513, #11957 maybe?",1
May effect the accuracy results of some papers.,1
"- It is known that keras object are not pickleable, adding a get_config method to optimizers may enable to share different optimizers configuration without the need of sharing the object themselves.",1
"Since I want to make small PRs, this one may not look useful, but it's actually a necessary addition of test to ensure that I don't break things during the refactoring.",1
"This would also allow the user to define her own metrics of interest (maybe she is not interested in the accuracy but in the precision per class, F1, BLEU, etc... motivated by https://github.com/fchollet/keras/issues/254#issuecomment-114418526).",1
- ~~The progress bar in `verbose=1` does not update for the last batch of every epoch (it may appear as computational _lag_ but everything is fine)~~ (see tristandeleu/keras#1),1
"That logic turns out to be too restrictive - it chooses the fallback path in cases where it is not really needed, which may result in significant performance degradations.",1
"- It also runs in #7046, (equivalently #7072) but it may be slower.",1
"In some cases, sys.stdout is replaced and may miss this attribute.",1
"It is revealed by global presubmit that `variable()` method is heavily called. Although `tf.Module` has a built-in `variable` property, it may not worth the effort to let people write code changes.",1
"For now this information is ignored when loading weights from a file, but it may be useful for reconstructing a model in case a user loses the corresponding source code.",1
Maybe people can help with that?,1
"Input may optionally be inverted, shown to increase performance in many tasks in [Learning to Execute](http://arxiv.org/abs/1410.4615) and [Sequence to Sequence Learning with Neural Networks](http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf) theoretically as it introduces shorter term dependencies between source and target.",1
Maybe all regularizers could be handled like this in the future?,1
"As name suggests, added the tilted loss function so that Keras may now do quantile regression.",1
"As with the theano backend, when using multiple GPUs, one may set gpu by theano.sandbox.cuda.use instead of via config.",1
You may also want to see this issue here: #2978.,1
"Although this is a minor mistake, it may be a slip of the pen, but correcting it will help beginners understand.",1
"- when validation_data is smaller than batch_size some samples are going
  to be used multiple times and some others may not be used at all",1
"However the benefit is worth it, Tensorboard callback won't lead to huge
memory footprint and won't cause OOM crash when whole validation_data
doesn't fit into GPU memory.",1
"- histograms will slightly vary even if weights didn't change between
  epochs just because each time Tensorboard callback is engaged it will
  pick a different set of samples to process",1
"- histograms won't be 100% accurate since not all data is taken into
  account",1
"I think the random tests are enough because `layer_test` is called multiple times for each conv layer, but let me know if you think something may be wrong.",1
"Due to https://github.com/tensorflow/tensorflow/issues/50467
(users may be not aware of how does keras.layers.Masking work)",1
"Between epochs, we update the Sequence since it may get modified by the `on_epoch_end`.",1
"Even we do not mask zero, we may has other mask from previous layer. Return None directly is not very rigorous.",1
"My exact use case is I have created a custom callback which may also trigger self.model.stop_training, just like EarlyStopping .",1
If my custom callback triggers self.model.stop_training then the EarlyStopping callback will have stopped_epoch set to some value from a previous train.,1
"The argument to layer.Rescaling is passed as EagerTensor which is not serializable, because tf.math.sqrt() may return EagerTensor.",1
"For sparse category, a top k metric may be helpful.",1
Maybe that deserves an in-code comment...),1
"As you may find on PyPI: <https://pypi.python.org/pypi/keras/json>, keras is reported with an empty list of classifiers which can cause a lot of problems to anyone using the PyPI API to retrieve information about Keras (e.g. most CI tools).",1
Maybe you guys can help in that direction?,1
Maybe there is way to measure it with the streams too.,1
"I made a few changes to your code, maybe you want to reuse them.",1
Maybe you just forget to add this part in 'autogen.py'?,1
If someone has the compute power maybe can help on this issue. Or maybe someone has already pre-computed them.,1
"I also reused the function `get_layer_index_bound_by_layer_name` by importing it from `keras.utils.vis_utils`, im not sure if it's ok, maybe mantainers prefer to move this function to a separate file where both modules can import from.",1
"- I searched a bit and this is the only place I found where this problem, but I don't fully understand how this change will fully fix this problem, maybe another similar change is needed elsewhere ?",1
"- There is no test for ""invert = True"" in normalization_test.py, maybe it is an issue ?",1
"If it is proven to be useful, then maybe we can add it to Keras library.",1
"I may have missed something, but I don't really see other way around that would preserve a unified way to get initializers.",1
- May be it's better to add a separate layer for asymmetric zero padding instead of changing the existing ZeroPadding2D?,1
"This cannot happen and it is only logical to have our own version on it somewhere (as suggested before, @fchollet's S3 storage maybe)",1
I was also thinking of adding an example to https://github.com/fchollet/keras/wiki/Keras-2.0-release-notes and maybe the warning could be a link there instead of trying to explain what has changed.,1
"Decided to go deep into keras and maybe contribute, let this typo fix be the start point :)",1
Overall I think it may be nice to migrate to fine grain unit tests across the board with python `unittest` and only keep around a few integration tests.,1
Maybe a short explanation is needed.,1
It may be a good idea to add a warning when the user uses a multiclass target (y) with binary loss and vise versa; binary class target (y) with multiclass loss.,1
"In either case, a model will train without raising any exceptions or warnings.",1
It may be minor details.,1
"Does it make sense to add a warning in the documentation below ""Note on using statefulness in RNNs"", something like `The hidden states of stateful RNNs are not saved in save_model(), which may lead to differences in predictions before and after model serialization.`?",1
"Maybe _to_tensor() should be renamed and exposed (made public) as K.convert_to_tensor(), with API changed to match (will be backward compatible)?",1
"Maybe there's a reason these layers were left out, but I think it doesn't hurt to let the world know.",1
"Maybe we can relax the constraint in the load_weights, and loading weights in a more current-model central way.",1
"I had to answer a question about how to build these in Keras maybe four times in the last month alone, I really see a lot of interest and the github issues of Keras contain scattered, obsolete and misleading information.",1
Others may want to try that as well. But let me know.,1
"I figured as long as I'm fixing it, I may as well make it feature-complete.",1
"The reason is that the MNIST task is too simple compared with ImageNet(60, 000 samples and 10 classes v.s. 1, 280, 000 samples and 1000 classes) so that the a much more complicated model such as ResNet may not help to improve.",1
"ResNet will get excellent experiments results on ImageNet, CIFAR or COCO.",1
Sometimes it may be desirable to use multiple regularization penalties on model weights.,1
It may not be necessary anymore.,1
"Cause by defualt, people may want to organize their weight list as [Mean, Std, Gamma, Beta], this is just the computation order of BN.",1
I think this doc will be helpful.,1
The wrong-order list won't get any warnings or errors cause the shape of these 4 parameters are exactly same.,1
But maybe this needs to be handled also internally in Google somehow?,1
"For instance, in a Memory Network, you may want to embed background knowledge in the form `(batch_size, number_background_sentences, sentence_length)` and specifically, this implementation allows a mask to be propagated which is 3D.",1
These objects may be compared to each other and sorted.,1
"Any feedback is highly welcome, maybe someone has a better idea than somewhat misusing the config like that.",1
The set of valid layer depths may be a strict subset of the set of valid node depths when the computation graph involves non-trivial layer reuse.,1
This is not a bug for now but since this is an example and many people may write more code from here.,1
"Although these two terms mean the same thing, the discrepancy disrupts the document's general format and may cause confusion for newcomers.",1
"I could add a unit test for this, but it wasn't clear whether they should go in `test_model_methds` found in keras/tests/keras/engine/test_training.py or `test_io_utils` found in tests/keras/utils/io_utils_test.py.",1
Maybe it's worth merging the tests found in `test_io_utils` into test_training.py for maintence?,1
"If this proposal is adopted, then some of the example scripts may need to be updated.",1
"This PR adds a new class mode, `custom` which may be used with `flow_from_directory`.",1
The tests may be conflicted with #9359.,1
I may not be able to have a perfect one either but am willing to improve it.,1
"1) `K.int_shape()` may not be available for some `mask` with `Theano` backend, especially when the inner layer is `Embedding` or `Masking`.",1
"I'd imagine that having this option may be useful in other instances, as libraries that are sensitive to their threading context are not uncommon.",1
"This PR fixes the case when using small batch sizes in `evaluate` and `predict`, the final update may be randomly throttled and the total elapsed time is not displayed.",1
"This PR can significantly reduce warning messages (`/home/taehoonlee/.conda/envs/taehoonlee/lib/python2.7/site-packages/cntk/core.py:361: UserWarning: your data is of type ""float64"", but your input variable (uid ""Input103"") expects ""<type 'numpy.float32'>""`), and may bring slight speed improvements.",1
This PR is adds a new layer to Keras to allow people to build more complicated LSTM networks where someone may want to adjust the input to the network at a later step and/or act on the states returned by the LSTM immediately.,1
"For repeatable flags, repeats are counted twice and may lead to unexpected behavior.",1
Probably some refactoring would be needed (maybe the doc strings could be stored in single files for clarity) but I think having some tests here could help saving time in the near features.,1
"Also, my change may decrease memory peak usage on some accelerators (no need to use ""Tile"").",1
1. We may now need to get gradients with respect to several variables to get the update expression for a single parameter.,1
"A train only Keras graph may be faster but it's also useless except in the rare circumstance that training features (BN, dropout, etc) are desired at evaluation and prediction time.",1
"Note that to keep the `GeneratorEnqueuer`'s external interface the same, I had to define two ""private"" classes that redefine the queues' `get()` method to actually return `ApplyResult.get()` (which may block if the result is not ready yet).",1
"Maybe someone could add that, since I don't have it set up on my machine?",1
"When a Lambda layer is serialized as JSON, `defaults` may be serialized as a list, e.g. [None].",1
"* If you want to keep current behavior, maybe we could add a flag to switch between casting to float32 or using the returned dtype.",1
"When switching between backends and Keras versions, different `keras.json` files may be required for different installations.",1
"Plus, `rnn` is handle things like an RNN, but you may need a loop for something like, compute cumulative sum, or sliding windows, or even a new tensor operation that saves memory.",1
"These may be avoided by using `venv` or `virtualenv`, and their use should be encouraged.",1
"resolves #15715. Removing assert y_pred in range [0, 1] in metrics because they may be logits.",1
Maybe I'm missing something?,1
This example using 20_newsgroup dataset works with or without this fix but I think it is good to update the code as people may reuse it for other datasets.,1
So add an option of bias_correction for Adam may be a better choice.,1
Maybe someone can guide me...,1
"This fixes #4916,  #4302 and probably #2487.",1
"It's working, but could use a bit more documentation and there are probably a few tests missing.",1
For some reason (probably oversight) it was reverted in the merge at commit 1f87cff.,1
EDIT: Ended up going through the codebase and [probably] fixing all the obvious cases,1
"In general, there should probably be a way to turn the bias off.",1
There're also some low hanging fruits for test speed up (TF only though) - test_convolutional along can probably be sped up ~2x.,1
Haven't taken a look at tensorflow backed (I only use theano) so if similar adjustments could be made there that would be helpful.,1
"visualize_util.py 
could probably use a better way to keep track of names but still allow directed edges in sequential mode without names",1
"While @EderSantana pointed out that this difference in behavior is properly documented in the Wiki, I think we can do better.",1
"I think the two commits are right (unable to use BN as a shared layre), but we can use BN as a shared layer for some cases.",1
"As more Tensorflow users come in, I think it would be great to add that instruction.",1
"Correct me if I am wrong: I think the code in the current example:

```
def compute_accuracy(predictions, labels):
    '''Compute classification accuracy with a fixed threshold on distances.
    '''
    return labels[predictions.ravel() < 0.5].mean()
```

is not accuracy over all the samples, but over samples with negative prediction.",1
"Disclaimer, I'm new to the library but I think it's great.",1
"If you think this is a good addition, I'll change the examples, add some docs, and a test.",1
I think it is more intuitive than `join` mode inside a `Merge`.,1
Also it would be better if the argument of Reshape was a tuple.,1
I think a simple change to `Graph` container API would make it easier to create arbitrary connections.,1
Hey I made what I think is a fix for this (it crashed for me when I tried verbose=2),1
"As a side note, I think
```python
for cls_key in custom_objects:
            globals()[cls_key] = custom_objects[cls_key]
```
could be replaced by `globals().update(custom_objects)`",1
"i think i found a typo in the first example of the recurrent layer documentation:

``` python
# as the first layer in a Sequential model
model = Sequential()
model.add(LSTM(32, input_shape=(10, 64)))
# now model.output_shape == (None, 32)
# note: `None` is the batch dimension.
```",1
"Because of `return_sequences=False` (default value), i think only the last output is returned.",1
although keras offers the new LambdaMerge layer I think extending the "regular" Merge and especially the TimeDistributedMerge layer by a "max" mode is a good idea.,1
I think the Recurrent layer should treat a part of the inputs as `initial_states`.,1
I think this is also what you want to do according to the API doc.,1
But I think the right relationship is add : sum = multiply : product.,1
"I think in most cases with a recurrent network you prefer to truncate the beginning of the sequence rather than the end, since the beginning is ""furthest"" from the label.",1
I don't think the message is coherent with the if just before and what is written in the documentation.,1
I realize this is not a major focus for what is primarily a research library but I think it's helpful to expose keras to a wider audience (i.e. kaggle competitions etc.).,1
"User needs to check the number of input themselves, which I think should be done by keras.",1
"In other words: I don't know whether the test failure is caused by cuDNN version change or not, but I think not.",1
Therefore I think it will prevent gradient vanishing problem.,1
But i think that for the moment is dispendious and useless.,1
I think it's a pretty general constraint and I'm sure their are other useful uses which I didn't think of.,1
I think the consistency here is nice.,1
All these decisions can obviously be changed and improved but I think PR could serve as a good base for future improvements.,1
I think we can simply add a typecheck and if a tensor is passed then we wrap it in a list.,1
This will fix both the slowdown as well as make sure the functions is checking that sample_weights correspond to inputs and outputs instead of checking every single sample in the tensor.,1
I think it is better to use "binary_crossentropy" instead of "mse" as those metrics are for classification purposes.,1
I think it is better use `prefetch()` after batching.,1
I think it is significant for 1d sequence processing.,1
"I think it makes a lot of sense to mirror the [contributing page on GitHub](https://github.com/fchollet/keras/blob/master/CONTRIBUTING.md) on the doc site, as many other projects do.",1
I think it more makes sense since the connected_to shows from which layer(s) the current layer is connected from -- so that it specifies they are the inputs.,1
I think it's almost completely conceptually wrong to train discriminator to produce class labels for generated images (except as a way to handicap generator).,1
The rest follows because of this (I think).,1
I think model serialization with a deconv layer + tf backend causes a bug.,1
I think adding this tuple cast fixes it.,1
I think this part should be float type annotation.,1
"With that in, I think it should all work just fine.",1
I think the original PR tried to do a _lot_. Both `caffemodel` and `prototext` are mandatory now.,1
I think this should do it.,1
I think it would be great to have that upstream.,1
"I don't think it makes sense to have the regularizers and constraints specified by strings, i.e. W_constraint='maxnorm' , since the user will usually want to specify the parameter and it's not clear how to do that with the string convention.",1
"However, I think \`""xxx""\` looks a bit strange.",1
"In the paper, the first item of loss is -KL(q(z|x),p(z)) and -KL(q(z|x),p(z)) = 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1), so I think if you define kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1), you should use loss = xent_loss - kl_loss",1
"Also note, `numpy` and `scipy` has a more complicated `__version__` string but i think it's an overkill for now =):
- https://github.com/scipy/scipy/blob/master/scipy/__init__.py#L105
- https://github.com/numpy/numpy/blob/master/numpy/__init__.py",1
I think the ideal behavior is to serialize the states as well to make results fully reproducible.,1
"I think it would be better if the order was:
1) shuffle
2) batch
3) prefetch",1
I think it is better use `prefetch()` after batching. In a pipeline we would want the next batch ready (t+1) while processing current batch (t).,1
These are all bug fixes that we think are important enough to cherry pick into the initial release of preprocessing layers.,1
This example will lead to raised error the size of the total array does take into account the None dimension size and thinks it's and error.,1
Sorry I think I used wrong method for squashing commits.,1
I think the only problem (although I haven't looked very deeply) is that now a ValueError will be raised in "array_to_img" if the transformed images are being saved to disk.,1
I don't think so,1
"However, as a follower of the open source movement, I think it should be made available for others to test / use. I hope the Keras community can find a good use for it.",1
So I think it should add this change.,1
"The `deconv2d` method in the Theano backend applies a dimshuffle to the `kernel` variable, but I think it should also reorder the values in `filter_shape` to match the new `kernel.shape`.",1
I think EarlyStopping should work fine with ProgbarLogger.,1
I think printing in on_train_end callback is safe with ProgbarLogger.,1
"In principle, I think all the activations could (or should) also be layers.",1
It think it makes sense to provide access directly through Keras.,1
"I think it would be better if the order was:
1) shuffle
2) batch
3) prefetch",1
I think it is better to clean up the current tests first in order to write new tests for increasing test coverages.,1
One issue here is there is no way (I don't think) to check which dimensions have been reduced.,1
"This would be a possible reason to not implement this part of the PR, but we think that the first point certainly is relevant.",1
"I've included it as a discussion point and if others can see a way to specify the dimensions which are reduced, I think this would be a good feature.",1
I think the `test_rnn` needs to be improved with the same way because it is often seen in the slowest 10 test durations.,1
I think testing datasets are the same.,1
"Other choice would be just a list or tuple of the values, but I think this way is more generalizable in the future if we want e.g. custom transformation functions (for image segmentation coordinates)",1
"</s> **Edit:** This was just because of the default `batch_size`, so I don't think is an issue",1
I know there's been some discussion in the issues here about masking so I think this could be helpful to some other people as well.,1
"I think the parameter dimshuffle can be removed, since it should be handled by the Theano functions.",1
"I think there should be some non-symmetric cropping cases. (At least I need it but I am not working on image, so..)",1
"I wrote more or less the same example [with a sequential model](https://gist.github.com/mmmikael/0a3d4fae965bdbec1f9d) but I think the network definition with a graph is easier to understand:

``` python
g = Graph()
g.add_input(name='input_a', input_shape=(in_dim,))
g.add_input(name='input_b', input_shape=(in_dim,))
g.add_shared_node(base_network, name='shared', inputs=['input_a', 'input_b'],
                  merge_mode='join')
g.add_node(Lambda(euclidean_distance), name='d', input='shared')
g.add_output(name='output', input='d')
```

compared to:

``` python
input1 = Sequential()
input2 = Sequential()
input1.add(Layer(input_shape=(in_dim,)))
input2.add(Layer(input_shape=(in_dim,)))
add_shared_layer(base_network, [input1, input2])
lambda_merge = LambdaMerge([input1, input2], euclidean_distance)
model = Sequential()
model.add(lambda_merge)
```",1
"I think the next phase is adding a validation datastream, but I want to know what's you take on this code and in which direction to advance",1
It makes the code simpler and more maintainable I think.,1
"I'm not certain whether that refers to what I've done here (I think yes, but it's in the `random_transform` method).",1
"Theano 0.8.2 does show a warning that the `filter_dilation` parameter is ""deprecated"", but I think having a more explicit check would be helpful for cases such as #5024.",1
"I think there was some discussion of datasets API in tensorflow, but can't find it now.",1
another approach will be to use this function instead of standardize but I think this is better.,1
One possible option would be to add a `legacy=True` argument to `Sequential.get_config`?,1
I _think_ it's right now though.,1
"For now, this only changes `Dense.__init__`, but if you think this is an interesting change, I'll add the same parameter to other layers.",1
"I think this is pretty standard, it is also described in the [Deep Learning Book](http://www.deeplearningbook.org) [1], page 247, Algorithm 7.1.",1
"I think this fixes a bug in TF backend, because int_shape(x) returns x.get_shape() only if x._keras_shape is not set, for example if x is np.ndarray, or a sparse tensor/ndarray.",1
i think this will do it,1
I think it runs both on Theano and Tensorflow,1
"Also happy to do this in a separate Container layer, but I think that would include some duplication.",1
"I merged 5defe21 from #6035 directly into the test that validates the bug in #6034, so perhaps if that succeeds this pull request #6035 could be closed and #6034 merged since it includes both the fix and the test to verify the fix?",1
"With formatting, docstrings, and perhaps cleanup could it become viable for merging?",1
"Perhaps we should add 3 arguments, `key_mask`, `value_mask`, and `query_mask`, mutually exclusive with `attention_mask`.",1
"I did have a case where it was trying to convert an on-disc bcolz array if I didn't do this, but perhaps it's only with that.",1
Rather than thinking of all these as tf only functionality perhaps changes like this and/or some improved version of #9121 could be considered a way of simply improving support for the tf backend without taking away from the others?,1
Perhaps there some way we can really address this sort of thing?,1
Perhaps that's still papering over the real problem.,1
"I agree with you on the warnings, perhaps it's better to remove that option.",1
"In Tensorflow case, I'm only warning that `kwargs` will be ignored instead of raising an exception (perhaps it's advantageous to allow the same code to be switched between backends without changing these?).",1
"Perhaps it was a bad merge, I had created so many branches.",1
"Maybe other people have better ideas about how to define it, but before we find a good one, perhaps, it would still be reasonable to use ""time"":",1
"4. Theano should be more general than Keras, but it still uses ""time"", ""movie"" and ""spatio-temporal"" for 3D signal.",1
"#print(""Expected error:"", sys.exc_info()[0])",1
"What's inconvenience for me is that if I do training in 40 epochs with frequency of saving histograms and embeddings of 10, I expect to visualize 10-th, 20-th, 30-th and 40-th, but it comes to visualization of 1-th (I'm not sure it does make sense), 11-th, 21-th and 31-th.",1
"After this fix, I got the much more useful error message about incorrect input data dimensions:
Error when checking model input: expected input_1 to have 4 dimensions but got array with shape (0, 1).",1
E ValueError: Unexpectedly found an instance of type `<class 'theano.gpuarray.type.GpuArraySharedVariable'>`.,1
Expected a symbolic tensor instance.,1
"/Users/nicole/.virtualenvs/theano/lib/python3.5/site-packages/Keras-2.0.4-py3.5.egg/keras/engine/topology.py in assert_input_compatibility(self, inputs)
    454                                      self.name + ': expected min_ndim=' +
    455                                      str(spec.min_ndim) + ', found ndim=' +
--> 456                                      str(K.ndim(x)))
    457             # Check dtype.
    458             if spec.dtype is not None:",1
"ValueError: Input 0 is incompatible with layer dense_1: expected min_ndim=2, found ndim=1",1
"i tried this script 
`from keras import optimizers
from keras.models import load_model
from keras.preprocessing import image
import numpy as np
import scipy.misc
from keras.wrappers.scikit_learn import KerasClassifier
# dimensions of our images
img_width, img_height = 313, 220
# load the model we saved
model = load_model('hmodel.h5')
sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)
model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy','mse'])
test_image= image.load_img('/Images/1.jpg',target_size = (img_width, img_height))
#x= scipy.misc.imread('/Images/1.jpg').shape

test_image = image.img_to_array(test_image)test_image = np.expand_dims(test_image, axis = 0)
test_image = test_image.reshape(img_width, img_height*3)
result = model.predict(test_image)`
and i have got this error :ValueError: Error when checking : expected dense_1_input to have shape (36,) but got array with shape (660,) i couldn't touch to my  model cause it's generated  using  GridSearchCV!!!",1
"However, the expected input data type for `preprocess_weights_for_loading` is a list of numpy arrays, as stated in the docstring.",1
This causes the following error when using dnn: `TypeError: dnn_conv() got an unexpected keyword argument 'image_shape'`.,1
"In order for `import keras` to work as expected in `autogen.py`, the script should look for `keras` in the parent folder.",1
"My attached example code shows how a Sparse Autoencoder trained on natural images fails to obtain the expected oriented edge filters using SGD (or any other Keras optimizer, trust me I tried) but works perfectly when trained on the L-BFGS-B routine.",1
"Modified ImageDataGenerator.flow_from_directory to fix a bug:
image.py uses PIL to load images, and PIL expects image dimensions to be specified in
the format (width,height), however load_img(...,target_size) takes target_size in the
matrix-format: target_size=(num_rows,num_columns). We need to specify width=num_rows and
height=num_columns rather than passing target_size directly to PIL.",1
NumpyArrayIterator is expected to conditionally performance image check and 4D-image transformation.,1
"On Keras 2, loading ResNet50 models saved with Keras 1.2.2 throws a ""got an unexpected keyword argument 'input_dtype'"" exception.",1
TypeError: __init__() got an unexpected keyword argument 'input_dtype',1
Previously check was expecting target to alway be two dimensional.,1
"Previously, `Graph` inherited `__call__` from `Layer`, which doesn't work as expected.",1
This fixes BinaryAccuracy metric class to function with sample weights and refactors metrics.py and metrics_utils.py such that metrics_utils.py has new methods with behaviour that better reflects what [MeanMetricWrapper.update_state()](https://github.com/keras-team/keras/blob/master/keras/metrics/base_metric.py#L603) is expecting.,1
"Binary accuracy is the only one that has an additional process, this allows it to behave as expected from the public-facing side.",1
# This gives an unexpected output shape,1
I was expecting the momentum will cripple sparse updates.,1
"The `IndexLookup` layer doesn't persist its `sparse` attribute which makes a layer with `sparse=True` produce dense tensors after deserialization, which breaks model loading in cases where the output of `IndexLookup` are expected to be sparse.",1
This occurs because the documentation renderer expects there to be some text explanation between the name of an argument and a list of possible options (e.g. see the `output_mode` argument in [tf.keras.layers.Hashing](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Hashing)).,1
"The `stop_gradient` documentation states that the argument should be a list of
variables. The Theano implementation crashes if the argument is a list of
variables and the CNTK implementation crashes regardless but expects a list anyway (since it passes it to combine).",1
The TensorFlow implementation expects one variable but in case a list is passed it doesn't crash as long as the shapes are all the same.,1
"By replacing all the values which are to be masked with `0` in the output of the `Masking` layer, everything works again as expected.",1
"The method `__len__` returns a `numpy.float64` but the class' `__iter__` method expects it to return an integer, which is not obvious from the example alone.",1
The parameter `units=0` of `tf.keras.layers.Dense` should raise ValueError.,1
Since `Units` expects Positive integer.,1
"Note, there are some failing tests due to changes to the master repo which broke some of the api expectations in already-existing tests.",1
"* If you set keras to tensorflow and do not have tensorflow installed, importing tensorflow_backend will fail with an import error as expected.",1
"Theano expects Python int for the argument of tile().
https://github.com/Theano/Theano/blob/rel-0.8.2/theano/tensor/basic.py#L4918",1
"ValueError: The model expects 0 input arrays, but only received one array. Found: array with shape (32, 299, 299, 3)",1
"``` py
TypeError: __init__() got an unexpected keyword argument 'dims'
```",1
"This PR allows the users to directly read the images that are mapped with the CSV files (or any other file that can be read as a pandas/dask dataframe) and also enables the users to use the flow_from_dataframe for regression problems, multi-label classification problems or any problem that expects data from the dataframe.",1
"This PR fixes a version number, which is expected inaccurately by me :).",1
"This ensure that both Theano and TensorFlow return the expected shape:

```python
from keras.layers import Embedding, Reshape, Merge
from keras.models import Sequential
import numpy as np

left = Sequential()
left.add(Embedding(1, 2, input_length=1))
left.add(Reshape((2,)))
right = Sequential()
right.add(Embedding(2, 2, input_length=1))
right.add(Reshape((2,)))
model = Sequential()
model.add(Merge([left, right], mode='dot', dot_axes=1))

print model.output_shape
print model.predict([np.array([0,0]), np.array([0,1])])
```

With TensorFlow:

```
Using TensorFlow backend.
(None, 1)
[[-0.00155337]
 [ 0.00074518]]
```

With Theano:

```
Using Theano backend.
(None, 1)
[[ 0.0001435 ]
 [-0.00048947]]
```",1
"Note that the slightly lower performance of mnist_tfrecord.py #6928 is expected, because it is a pipeline designed for quickly loading large datasets that don't fit in memory, and writing the records and graph setup takes several extra seconds.",1
"The RNN will pass on the tensor(s) to the call method of the RNN  Cell which (_if_ constants are passed) is expected to implement the signature:
```call(inputs, states, constants)```",1
"Output:

```
Exception: Invalid input shape - Layer expects input ndim=2, was provided with input shape (None, 1, 1)
```",1
"In the example in #6302, Keras expects `(1, 1, 18, 18)` but Theano produces `(1, 1, 19, 19)`.",1
"This PR raises an exception if ndim is < 3 in batch_dot, to avoid unexpected outputs, as described in #5131.",1
"This adds a test that illustrates a bug in TimeDistributed, where dropout does not appear to match the expected behavior for inputs with large dimensions.",1
"This turned out to be much simpler than I originally expected, due to
the nicely componentized design of the new RNN backend.",1
"Note: Tests to come, I just wanted feedback on the scaffolding - I'm expecting a lot of feedback/revisions.",1
This is a tentative export for an expecting failing test for https://github.com/keras-team/keras/issues/14086.,1
To workaround this bug and prevent users from unexpectedly losing their model:,1
"This issue is due to an unexpected loss of dimensionality when
composing the backend tensor operations ""reshape"" and ""squeeze""
when there are dimensions of length 1.",1
"For example in Sequence Labeling, when evaluating a model with text that contains unseen words, converting the input text into a sequence and then padding it could inadvertently change the sequence in an unexpected way.",1
This won't affect the first layer declared in the ResNet class (as expected).,1
Update error message format and provide expected value for keras/callbacks.py,1
"We are getting error ""ValueError: The model expects 0 input arrays, but only received one array."" by passing x and y data as validation_data.",1
"However `FunctionType` expects `argdefs` to be a tuple or None, not a list.",1
"The rest of the Keras code expects the shape to be `None` if the dimension has unknown length, and so setting `_keras_shape` without converting `-1` back to `None` leads to some bugs.",1
"InvalidArgumentError: {{function_node __wrapped__Squeeze_device_/job:localhost/replica:0/task:0/device:CPU:0}} Can not squeeze dim[1], expected a dimension of 1, got 4 [Op:Squeeze]",1
"This results in expected behaviour:
```python
y_true = [[1, 1, 0, 0],
         [1, 1, 0, 0]]
y_pred = [[1, 1, 0, 0],
         [1, 1, 0, 1]]
sample_weight = [[1, 1, 0, 0],
                  [1, 1, 0, 0]]
m?=?tf.keras.metrics.BinaryAccuracy()
m.reset_state()
m.update_state(y_true,?y_pred, sample_weight)
print(m.result().numpy())
``` 
Returns
```python
1.0
```",1
model_fom_config expects a dict... --> model_from_config expects a dict...,1
"the previous example code cant get the expected result，it get a ValueError
so i  fix this problem",1
"It errors out saying: ""TypeError: Expected binary or unicode string, got None""",1
"I tested on my original issue code to see if it passed and that worked fine, and I ran it on all the documentation examples for the function and they also worked as expected.",1
"This results in expected behaviour:

```python
y_true = [[1, 1, 0, 0],
         [1, 1, 0, 0]]
y_pred = [[1, 1, 0, 0],
         [1, 1, 0, 1]]
sample_weight = [[1, 1, 0, 0],
                  [1, 1, 0, 0]]
m = tf.keras.metrics.BinaryAccuracy()
m.reset_state()
m.update_state(y_true, y_pred, sample_weight)
print(m.result().numpy())
```
Returns
```python
1.0
```",1
Although returning a list and expecting a list would be more consistent with the previous documentation it wouldn't be consistent with the code's behaviour which could result in breaking others' code.,1
"After this the parent class [Reduce's update state](https://github.com/keras-team/keras/blob/master/keras/metrics/base_metric.py#L410) is called and it expects sample_weight to be the same shape as the ""matches"" tensor, or broadcastable.",1
The fixes change the behaviour of these methods to align with what Reduce is expecting but this alters their public-facing behaviour as well.,1
Then the original public metric accuracy functions can also be changed to call the util functions but if need be do some extra processing after the fact to match the expected behaviour for the public-facing documentation.,1
"However, #7064 is obviously more lines, and probably a touch slower.",1
"If your output is an int, it is probably intentional, so it shouldn't be converted automatically.",1
"If the dtype is bool, int, unsignedint, or complex, that was probably intentional and the type is left alone.",1
"I should probably add a test for this use case, actually.",1
"As you say above, this is probably a bad idea.",1
"Below are some pointers, however, it probably doesn't guarantee the same transformation yet, maybe need some [same seed settings](https://github.com/tensorflow/tensorflow/blob/a4dfb8d1a71385bd6d122e4f27f86dcebb96712d/tensorflow/python/ops/image_ops_impl.py#L404-L408).",1
"But as it will probably also speed up computation, I think it is good.",1
"urrent default is highly unexpected, since we have fractional shifts, rotations, zooms and whatnot, and probably makes things worse vast majority of the time.",1
"A slightly less exotic case is `order=3` for, say, superresolution autoencoder, but even than moved to `order=1` AFAIK, probably for the reasons in my description above.",1
"I did some tests about the performance and probably the biggest problem with copying the images is the doubled memory cost, which can be a problem when processing large images (or large batches).",1
Probably the Pypi package is outdated.,1
That's probably why the error got by testing.,1
Most probably my implementation is wrong.,1
I will keep working on it to see if all 3 can work in tandem.,1
Once I get a gtx 1060 I should probably be able to enable CNMeM properly too.,1
"you should probably move this to the keras-2 branch because of the [keras-1 PR freeze](https://github.com/fchollet/keras/issues/5299), and of course fix the CI test failures",1
"Now everything apart from CNTK errored, probably due to some network error. :/",1
GitHub probably changed your tab indents into 8 spaces.,1
"Also, we should probably have test coverage for this!",1
Let me know where you think is most appropriate and I'll add it.,1
"I wasn't able to reproduce that running the tests locally, but that's probably my fault!",1
"I've made a change that should fix it, and I'll see if I can get the tests working too.",1
"This example would probably answer some questions that many newcomers to DL seem to have about AEs and pretraining, but I have an issue with ""endorsing"" badly outdated techniques by including them in the examples folder.",1
This is encouraging people to use methods they definitely should stay away from unless they really know what they are doing.,1
I can't say I follow fully your setup but if the run was misconfigured then this is probably why the results were inconclusive.,1
"Fran?ois may not notice this again unless again unless he is pointed to the discussion through some other channel, he probably gets 100s or 1000s of @ mentions each day at this point.",1
"Probably there is something not so user friendly or under documented for Keras expected average usability:

@ppwwyyxx made a good analysis in https://github.com/keras-team/keras/pull/9965#issuecomment-398183440",1
"even with with only 400 images, the difference between 92% and 97% is probably statistically significant (depends on the confusion matrix).",1
Here is a very clever trick that works for tensorflow 2.0 in eager mode (otherwise probably wont work),1
End of semester is crazy but I can probably setup a cygwin test over the summer.,1
"We probably need to write an example in the docstring of how to handle these in custom training loops, right?",1
I was probably running the test in a wrong way on my end which is why I did not catch it.,1
I think it is probably an test infra flaky when running the GPU test. We can ignore it here.,1
"This utility is really meant for strings. It does a cast to string (so would probably support a wide set of types than what you are listing), but that's not something we plan on documenting.",1
"As for the single core being used, it's probably that the queue is full so the other workers are not doing anything.",1
"It should probably end with `compile`, and should do more, such as offering an option to reinitialize the weights.",1
"But yeah, there are probably more pressing matters.",1
You should probably report that in the header of imdb_cnn.py.,1
You are probably right about this.,1
"Adam gives 1 point improvement there, probably task related with the default parameter, i will add this value soon, thanks.",1
And the cause of this is still opaque (probably it is due to the unittest itself).,1
"Thus, I will delete that part from functional_test.py.",1
"Probably, we should just click ""Merge pull request"" here since copybara missed it.",1
BTW the errors are probably the need of a little rewriting of the tests to this new API.,1
"A name like `mode` would probably be more meaningful than `cmp`, though.",1
This seems quite reasonable.,1
There is probably some space for optimisation.,1
"It would probably be useful for logging, visualization, and debugging (eg. we can annotate the Theano graph with names).",1
"For the simple functions, of which there are probably a good number, this should be an efficient implementation.",1
"I think it would make this component too complicated to use, probably you can make a comprehensive example to illustrate how to do proper data augmentation based on Imagenet",1
"ok, I think it works but I am not sure how to fully test it in a Sequential model.",1
"I also included a file that will probably not make it into the final commit but I'm wondering why don't we have more automated tests like this, where the output of the computation is actually checked?",1
We won't merge this.,1
I think such layers would probably benefit from being listed in a library of Keras extensions.,1
"Another thing in this line that I used recently was - (p - abs(p) / 2 to extract the negative component of a tensor, which I'd seen reading some PRs that I would have probably been scratching my head for a bit coming up with an alternative.",1
"So a proper version would require some documentation to reach this goal, but lmk what you think.",1
Maybe the error message could suggest this issue which is probably fairly common among those who try making stateful RNNs using the functional model.,1
"I could make a new pull request, but probably is more correct to push the changes in this pull request (I only solved some conflicts, the real work is made by the author of this pull request).",1
"A decorator like that (probably better):

``` python
def check_output(func):
    def func_wrapper(self, *args, **kwargs):
        X = func(self, *args, **kwargs)
        if list(X.shape)[1:] == list(self.output_shape)[1:]
             X.name = '_'.join([self.name, 'output')
             return X
        else:
             raise Exception('the output shape of the layer is not the one expected')
    return function_wrapper

```",1
I think that is an elegant solution to solve the output naming problem and checks on the output_shape that are currently missing from keras.,1
I don't think it will works directly on all the layers for instance the merge join outputs Ordered dicts that can't be named so i need to verify.,1
Probably they should be added,1
Probably we should remove them (as in the original commit).,1
"Probably, only thing you need to write is a util method to copy an old generator?",1
"sure, probably tonight (Italy time) out of works hours.",1
"I have a minimal inception net, probably with just 2 inception modules.",1
"Edit: on second thought a test for ReduceLR.. is probably desirable, I'll give that a shot.",1
"So these 3 lines probably belong in the parent class, not in every descendant.",1
"Like layers, optimizers should be easy to build, and free of boilerplate (as much as possible).",1
This is looking very good.,1
"We were probably going to need this sooner or later anyway, as we add default layer functionality.",1
"Also I removed a unicode dash in one of the comments (probably came from a copy and paste somewhere), hope you don't mind :)",1
"@RaffEdwardBAH I guess there isn't a test for when a mask is `None`, should probably be `enumerate` instead of `zip` here although I'm not sure what the point of the `[:-1]` part was either",1
"This change is probably the correct way

```
masks = [K.ones_like(inputs[i]) if m is None else K.expand_dims(m) for i, m in enumerate(mask)]
concatenated = K.concatenate(masks, axis=self.concat_axis)
```",1
"@wxs you are correct, it will make a change to `fit()` which we probably don't want.",1
"# The part below is semantically ugly and reflects the fact that
# it would probably be better to `fit` with something else than
# the build-in loop",1
We probably won't be talking a few percent but instead be concerned with decreases as large as an order of magnitude.,1
"Yeah, `QueueRunners` will probably be going away in TF 2.0.",1
"Indeed, hooking up a ResNet50 with some ~256x256x3 images would probably make the tfrecords & multigpu shine!",1
"@avolkov1 Wow, that looks great, I'll probably make use of your examples myself!",1
Theano probably not as straightforward and I would need to use Theano-MPI to make it worthwhile for multigpu+distributed training.,1
"Well, I figured this is too specific, so it would cause more people more problems than it actually solves.",1
"Even more, the added lines should come after the first checks, but in case a dict was really uncovered, the dict should still be checked and standardized - I guess for an overall solution, this should be addressed in the gym framework, though personally I will probably stick with this.",1
This approach seems reasonable to me but someone with more expertise on this should probably take a look.,1
Maybe @rchao or @qlzh727 ?,1
"I probably don't have my machine setup correctly or the time allocation at this moment to get setup properly, make the changes, and manually test.",1
"But RNNs with memory is the topic of my PhD research, so I'll probably update this implementation to be faster, more efficient and have multiple heads.",1
As it stands a limitation of doing two large GEMMs is that the same dropout will be used for all gates but this could probably be remedied.,1
You probably can submit it again and hope the error won't happen again.,1
Also "resampling" would probably be a better name?,1
This is probably a question for @fchollet.,1
@jingzhehu probably you can use condition on tensorflow version to fix the problem.,1
I guess tensorflow does the same thing to maintain compatibility.,1
You'll probably want to squash those commits into one but the code is ??.,1
"Nothing mind-blowing, and probably very similar performance factoring in margin of error, but they are nonetheless cool to have as alternatives.",1
It is often very annoying to do it that way as this ends up in a large exception and is probably also not very clean so I would totally agree to have such a interuption handling callback in Keras.,1
"Currently (and it would be very interesting to find out what changed since the original implementation) within 7 mini-batches of the first epoch, discriminator gets so far ahead of the generator, that the generator can never recover (probably gets zero gradients).",1
"Agreed that a regression wrapper would also be a nice addition, and that it would probably make sense to have both wrappers inherit from a same class.",1
"We probably need to add more such examples, though.",1
I will try to add inception v3 soon.,1
This pull request should probably be closed since fixing just this trivial issue in batch_fix is pointless if it otherwise doesn't work as intended.,1
Otherwise I'll probably do it myself during the weekend.,1
It would be cool if this was possible with a `fork` but that's probably way more work =),1
"Probably some of the more regular contributors to Keras would have a lot more to say, but as it is I would find immediate use for it, and so would many others I bet.",1
10. Probably bilinear interpolation vs nearest.,1
"This is probably better - if you like, we can change the docs to suggest that instead?",1
"The point of me making the issue is that I ran into a very confusing issue, and I think others should be at least warned about it.",1
It's difficult to say how that got there; there is probably a sequence of optimizations that introduces it.,1
"Also, for future reference, do note that the current PR has some file formatting issues -- perhaps you're using a code autoformatter, which is creating issues.",1
I agreed to your suggestion to put this logic in a new separate class with (as I wrote) the main motivation being "avoiding adding any additional complexity to the `RNN`" and perhaps to move forward a bit faster ;).,1
Perhaps we should have an option to just go through a single epoch and yield a StopIteration when over?,1
"- This step needs more thought, `keras.Model` and perhaps [tf.contrib.data.Dataset](https://www.tensorflow.org/versions/r1.2/api_docs/python/tf/contrib/data/Dataset) can provide inspiration.",1
Perhaps the assertion doesn't work the way it appears to?,1
"So, perhaps the smoothest option would be to merge this and update #1683 to rather move the averages computation outside of the callbacks.",1
"@souptc @chentaMS I'm trying to add an is_placeholder attribute to the output of `K.is_placeholder()` in CNTK, however it does not appear to support runtime attributes (or perhaps just public ones?).",1
"Would it make more sense to have a single image representation (perhaps at the end of LSTM that has seen all the ""slices"" of image features) and use RepeatVector to feed this image information to each timestep in the RNN? (e.g., something a simple captioning model would do)",1
Perhaps there are still some issues during weight loading.,1
perhaps `mask_zeros` or `zero_mask`?,1
"However I don't know if there are other concerns with using NaN, perhaps performance or otherwise.",1
"Just like how I think ""0"" is an unsafe mask value because there's a much higher probability of inadvertent 0s than anything else, perhaps NaN is a problem as well.",1
Perhaps you have better ideas for testing patterns.,1
"Unmasked still seems to have a slight edge, which is interesting.",1
"It could be a bug, or perhaps just an idiosyncrasy of this particular architecture?",1
Will think about it a bit more.,1
Perhaps there will be some good news when you wake up tomorrow.,1
Perhaps we should cut off the dependency between input dim_ordering and the shape of conv layers.,1
In this case a single version of weights could be loaded in a model no matter what the image dim_ordering is.,1
Perhaps we should cut off the dependency between input dim_ordering and the shape of conv layers. In this case a single version of weights could be loaded in a model no matter what the image dim_ordering is.,1
"Perhaps the Theano patch will be changed to handle this in a nicer way, but at the moment `epsilon=1e-5` is an unlucky default value.",1
"When 1e-5 is converted to float32 the value is actually smaller than 1e-5 in float64, which will cause Theano to reject it.",1
Perhaps each metric can be a class instead?,1
I agree with @Dref360 perhaps The code causing those if statements could also be moved to the backend?,1
"Oh now that I see this again, it is just like my original version of the input tensor api proposal google doc (perhaps this came first?).",1
Perhaps as you suggested they only worked with custom losses.,1
"Perhaps this is out of bounds for this PR though, I should ask this question elsewhere.",1
"But it would take much longer and it seems like no one is keen to spend much time on this part of keras. Which is fair enough, perhaps it could be split into a separate package to shift the burden of keras maintainers.",1
"I could look into writing them again, but is there any interest in merging this fix, or would it be a waste of my time?",1
"@de-vri-es That's true, my fix is not ideal, and your proposal would be much cleaner.",1
"Note that the problem disappears if you call `super(...).build(...)` at the end, or if you use `import keras` instead of `from tensorflow import keras`, so perhaps it's more a TensorFlow issue than a Keras issue, but I still think it's best to encourage people to set `self.built=True` at then end, I don't see any reason why users would want to do this earlier.",1
"Perhaps the most practical option 1, profiling + vectorizing, is a good one for the projects board! :-)",1
perhaps it can be a stand-alone example.,1
@jrao1: Perhaps you could change the code to use `theano.sandbox.cuda.dnn_available()`.,1
Perhaps it was too early to move to PRs but on the other hand it is the only way to really show the implications and feasibility of the suggestion.,1
Checks appear to be failing.,1
Tests appear to be failing.,1
Tests appear to be failing? https://travis-ci.org/keras-team/keras/builds/351115876,1
Unfortunately it doesn't appear to be adding much value.,1
"`np.random.shuffle(index_array)` does not modify the global random state of `np.random` (unlike, say, `np.random.seed()`), so this PR does not appear to change anything other making the shuffling follow the same pattern every time (which is not a desirable behavior).",1
"As such, this function does not appear to be a valid loss function.",1
This does not appear to be standard markdown.,1
"I rewrote the tests. Loss weighting does not work well with hinge and squared hinge, but that does not appear to be an implementation issue.",1
These errors appear to be connection issues on the Travis server.,1
This feature does not appear to be requested by enough people to be included in the core API.,1
"Additionally, at this time, it appears that none of the weight files produce accurate results -- all results appear to be random.",1
"If it can be fixed within a reasonable timeframe, I'll remove this application.",1
"This change does not appear to be necessary, it's just UI style preference.",1
"Fractal art with more white or black and white appear to produce very good final images, while colored fractal art generally overpowers the content image.",1
"This doesn't appear to be a common use case, so I would recommend that you subclass the ModelCheckpoint callback for your use to save only after certain epochs, instead of merging this into the standard ModelCheckpoint callback.",1
Checks appear to be failing: no Python 3 compatibility.,1
"To maintain a new class for each and every schedule won't scale well, I think.",1
"Yes, that sounds reasonable.",1
It doesn't appear to have seen any significant adoption.,1
You still appear to have big issues with your Git workflow...,1
So it does not appear to be an issue in any real scenario.,1
"As you say in the original posting, the {c_i}'s in the embedding are weighted by the {p_i}'s from the softmax output, but the code above doesn't appear to do any weighting; it just sums the {p_i} with the {c_i}, but we want \sum_i p_i c_i, so the output sizes seem to be incorrect?",1
"Besides, your word indices don't even appear to be deterministic, which is another big issue.",1
@bstriner you appear to a user who will be affected by this change: https://github.com/bstriner/keras-seq2seq/blob/master/seq2seq/s2s_loss.py,1
- MachineLab does not appear to be able to properly render the Keras progbar.,1
The added code/comments does not appear to serve our goal of simply and clearly demonstrating common patterns via short and readable example.,1
"I was not able to find the weights of the resnet34 in caffe, and the resnet18 weights appear to be only available [here](https://github.com/HolmesShuan/ResNet-18-Caffemodel-on-ImageNet).",1
"on my own tests with the IMDB dataset, setting inner_init to identity does appear to be better than orthogonal, using ReLU units.",1
This has been fixed in the past hour. Checks for this PR appear to be failing.,1
- this script does not appear to link to its training data.,1
"Somehow the tests appear to be failing, though.",1
Currently the test calls compile before saving which does not appear to be the intended behavior of the test.,1
<s>A note: my tests appear to take somewhat longer on my GPU machine than on my normal CPU-only machine.,1
What was previously referenced as loss and accuracy now appear to be called tot_loss and tot_accuracy.,1
Maybe it's related to this PR?,1
Maybe it's random?,1
These arguments (like `units` or `implementation`) don't belong on the base class because there may be subclasses that don't need these arguments.,1
I understand that sometimes loss functions and error messages may not be merged into the core of a project.,1
"But I will fix it and learn from my mistakes and in the future, submit a better PR in the future.",1
"The change in accuracy in `test_temporal_classification_functional` can be explained by the fact that previously orthogonal initializer was using random state after it has been modified by `get_test_data` (and maybe something else), but now it uses fresh random state.",1
Maybe a `Graph` container.,1
Maybe a docstring would help here?,1
"Maybe a little documentation was needed, but not really a major roadblock.",1
"- adding `deconv2d`, `atrous_conv2d` in the Theano backend. `separable_conv2d` may be TF-only for the time being.",1
Common parts may be abstracted in helper functions like for the TF implementation.,1
"For easier implementation of all these layers, we may need to abstract common parts in an ancestor class.",1
Maybe I missed a layer or something,1
"Would be a good thing another example with LeNet5, maybe in contrib.",1
"You are right that the order of weights is affected, so if this has bad consequences (please, confirm me so) I'll try to find another solution, maybe modifying the existing code in a less drastic way...",1
One minor detail is to maybe add some safeguard for the rare case where beta1=0.,1
You may want to change the threshold of the assert allclose.,1
Maybe check out what `layers.convolutional.UpSampling1D/2D` does.,1
"This will be up before the release, maybe even today.",1
"If so, we have to think of a way to make `expand_dim` to accept a list of inputs otherwise it may be too repetitive.",1
That shape value may be symbolic.,1
"maybe hp_lambda should be parameter of __init__(), not call()",1
"Maybe one of the following ways will suit the problem. If you find another way, please let me know =).",1
"however because of the consume_less='gpu' mode, maybe it's better to do the calculations with gamma&beta in a batched style, instead of separately, and that's exactly what my concern is.",1
I'll continue thinking about this.,1
"re: reshaping. hmm. maybe. seems hacky, but then again, updating tensors at all mid-computation is fairly hacky :\.",1
"though, maybe it doesn't matter and I'm [bikeshedding](https://en.wikipedia.org/wiki/Law_of_triviality).",1
I think reshape is super fast because it only changes the stride of the indexing but I may be wrong because even the shape is a theano variable and who knows what is going on there also theano may copy after all if memory is fragmented...,1
"And maybe I'll refactor the Merge layer as a container, too.",1
"There were changes to be made in the Sequential container (needed its own connect method), so that may have been your problem.",1
I will look at tests and documentation now...,1
"the tests seem to be no longer working, I'm not sure why.",1
A rebase may be needed to pass CI tests?,1
"I can confirm it can work well in this way, may be there are some other bad cases.",1
"* In your example, if you change ```trace_steps``` and ```dump_steps```, there would be meaningful output.",1
"This means indeed there is bug, but it doesn't mean we don't handle ```run_metadata``` correctly(maybe, but need further check).",1
"Because actually we can get running metadata(see my example, timeline is depend on ```run_metadata```), this bug maybe caused by some logistic in ```tf.contrib.tfprof.ProfileContext```.",1
"And bug for the difference between _call and _legacy_call should exist, better to be fixed.",1
"However, as you said that tf.contrib.tfprof.ProfileContext is planned to deprecate, the priority could be lower maybe?",1
"I have not tested this fully - there may be situations where a BRNN retains enough information more than an RNN to see improvement over a known, or testable, baseline.",1
Maybe some other similar options out there.,1
It looks like you can configure Sonar to post comments back onto PRs but I haven't tried that out myself.,1
"@kevin-keraudren 
You may be able to submit this to keras-contrib:
farizrahman4u/keras-contrib",1
"@fchollet You may also want to look at this paper: https://jivp-eurasipjournals.springeropen.com/articles/10.1186/s13640-017-0188-z which uses various noises, including uniform noise, to train a robust face recognition CNN.",1
Maybe @taehoonlee ?,1
"Maybe, like you stated, we need to change it to align with the latest caffe version.",1
"(in this case the metric would just be displayed as ""lambda"", to display its name just wrap it into a named function -- okay maybe it's not the most practical thing).",1
"Maybe an example would be helpful, too.",1
The performance gain may be lost ?,1
# maybe this line breaks the metric of loss function.,1
"This may break if, for example we have a training set of 14 samples, the last batch would only be of size 2.",1
Thus the reshape would break.,1
"The Reshape layer seems a little buggy to me - I can't really think of a model it which it would be useful, especially with the first dimension fixed, and no way to revert back and forth from, say, 2D -> 3D -> 2D (which has to happen for RNNs to be effective, or even possible).",1
"In the code we have the comment ""Match the behavior of numpy and Theano by returning an empty seqence."", but I'm not sure that's still relevant (maybe the TF behavior has changed since).",1
"The typo was real, but was causing problems only in Python2 (maybe due to  unpacking changes in Python3).",1
"Maybe a better solution would be to enforce the downcasting at the gpu instead of in numpy, but not really something worth working on right now.",1
May get included in core Keras in the future.,1
Closing since expecting it to go to `keras-contrib`.,1
It may be that we have to fix it there first before we can proceed with this PR.,1
"But maybe let's think higher level for a second: this is only happening for subclassed models, and only for untrained models (as per [this PR](https://github.com/keras-team/keras/blob/d63e67d9f4bd0279a518c7b14a3551a82ed7743a/keras/engine/training.py#L341), if `Model.built is False` copying/pickling is delegated to `object` because SavedModel doesn't support unbuilt models; please correct me if this is wrong).",1
I would suggest simply raising a clear error message when people try to pickle an unbuilt model. That would solve the issue.,1
"2. Revert this PR back to https://github.com/keras-team/keras/pull/14748/commits/28c11877a990783e914764afc1198c17a9143624 (when we were supporting unbuilt models) and exclude the `subclassed` parametrization in the new test, maybe manually testing a simple subclassed model like the one in `keras/keras/tests/model_subclassing_test.py -> test_deepcopy`.",1
"For the Metric issue, maybe using `keras.metrics.serialize` would work.",1
Maybe try it on CIFAR10 instead?,1
"If there are any tips on why these two PEP8 linters did not catch the operator space issues, please let me know, because there may be more lurking about in the code (although I tried my best to find them myself).",1
I may need not have time to carefully reproduce it.,1
I think if we can't reproduce the 87% baseline we shouldn't include the example script as it may be misleading.,1
"Sure, I will remove it.",1
The only downside I see with this is that it breaks any custom regularisers that people may have written earlier.,1
"Maybe this will answer my question why we synchronize this way (instead of, say ""fixing"" Theano/CNTK Conv2D and friends).",1
"If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?",1
Maybe floating point operations errors being not deterministic?,1
That would explain why your tests passed and these do not.,1
Maybe you can add it to the docs instead.,1
"Of course, that may require abstracting away common parts between different conv layers.",1
Maybe it was just raised and you have an higher number?,1
"Additionally, you may want to support the ""sparse_categorical"" case, which is like categorical, but `y_true` is encoded as integers (e.g. `y_true = [2]` in our example).",1
"Or we can keep `None` so that sometimes we do indeed default to `order=0` when, say, we have integer shifts only (something like `random_crop()`, for which I am still designing of a good API, and, maybe, it would work just fine with `order=1`.",1
"BTW, for binary labels, and binary crossentropy, it may make things better.",1
This contribution (fbeta_score & co) is getting removed in Keras 2 (maybe even earlier).,1
"1) search for it, and maybe find about the `copy` argument, and write:

```
preds = model.predict(preprocess_input(imgs, copy=True))
```",1
@fchollet Alright maybe this makes sense.,1
At the time it was maybe 30 lines.,1
"There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.",1
You may also want to check [work],1
"So while it may appear that loss value improvement is flattening, the result is still appreciable.",1
Maybe if I turned off all the image augmentation I'd see a more noticeable gain. Or maybe my CNN's are not the right kind.,1
So other architectures may not see that great a performance improvement.,1
"also, we may need a test like run one step, save, load, run another step vs run two steps.",1
This may work for Theano but it definitely wouldn't for TF.,1
Numbers compiled from proto may change and they are not as readable as the enums.,1
What happens in a case with `steps` where that may be ambiguous?,1
"While the `embedding` of shape (n_samples, n_hidden) may still fit in memory, intermediate representations of higher dimensionality may not.",1
"Maybe I don't understand this well enough but my hunch is that for models with multimodal inputs, say images and their labels, you need to actually *construct* a joint embedding space rather than simply send data through the network and take the output of arbitrary layers as the ""embedding"" (see [1](https://arxiv.org/pdf/1604.04573.pdf), [2](https://arxiv.org/pdf/1511.06078.pdf) for examples).",1
"Thanks for the references @dschwertfeger and I also would like to close this issue, but in the current state, the callback may fail if used together with a model with multiple inputs.",1
"Maybe `_array_generator` can be put into `preprocessing` directory as a new function, will that be OK?",1
"Sorry, maybe I'm confused about your description - I thought what you
describe re the parameter passing problem is future work.",1
Maybe I will find time to contribute and show a graph of word embeddings that are dimensionally reduced by an autoencoder and graphed.,1
"AE itself may be outdated but there are some work based on AE, such as the ladder network in NIPS this year.",1
So this example will be a good starting point for beginners.,1
I would suggest to merge this example.,1
(maybe just the embedding layer?),1
@rilut Maybe it could be added to https://github.com/farizrahman4u/keras-contrib,1
We may indeed want to provide documentation for the other utils.,1
That should be no problem.,1
wrapper_test.py should test TimeDistirbuted(Sequential(Sequential(Dropout())) or something like that to ensure if can chain the parameters regardless of the number of submodels.,1
"I do not want to convert to fix features because that last may lead to accuracy gains, so I want an end-to-end model training.",1
Maybe a great addition to docs.,1
The actual matthew metric may need to be rewritten to handle it a bit more - I'd think it should be rewritten anyways after taking a quick glance at the code.,1
If you better separate the concepts and clarify the conditions under which different data is fixed vs changing the reasons this improves performance may be more obvious.,1
"@datumbox The easiest option may be creating a new branch and a new PR, with a link pointing back to this.",1
"Considering the variability in approaches, an easy way to ""code your mode"" may have value but I think that can be left as future work.",1
1. The difference between 97% and 98% may not be statistically significant.,1
What is in your opinion the best and quickest fix right now and how would I apply it (maybe with example)?,1
So maybe give that a try.,1
Maybe one day someone will provide a more elegant solution and it will be part of Keras. :),1
My concern maybe also the fact that the entire sequence is being send to every processes on end of epoch.,1
"I think Deconv2D may be an altogether different beast, SeparableConv2D and AtrousConv2D won't be difficult.",1
Maybe I'm being optimistic though.,1
"Not yet, but @EderSantana was working on it, so maybe check with him!",1
Maybe I should create an issue rather than a pull request.,1
"While checking custom layers (can throw any error while checking), it uses nested try-except blocks which may not be the best practice.",1
"Maybe travis uses a different version, I'll figure out when later.",1
"There is a place in the code with a similar issue, where readability doesn't matter, but speed may:
https://github.com/fchollet/keras/blob/master/keras/preprocessing/image.py#L762
```
$ python -m timeit -s 'import numpy as np' 'int(np.ceil(10 / float(3)))'
1000000 loops, best of 3: 1.17 usec per loop
$ python -m timeit -s 'import numpy as np' '(10 + 3 - 1) // 3'
10000000 loops, best of 3: 0.0185 usec per loop
```",1
Maybe there is a need for library function for that?,1
Maybe the longer form ValueError was not such a bad idea?,1
- Maybe others I haven't thought of ?,1
Maybe `validation_class_weight` should be introduced.,1
"I think by default `validation_class_weight` should be equal to `class_weight`, unless explicitly provided, maybe with a special value, which means 'unweighted'.",1
"Maybe a tuple `(x_val, y_val, val_sample_weights, val_class_weight)` should be accepted, with `(x_val, y_val, val_sample_weights, None)` overriding?",1
Then it could become serializable (maybe).,1
Maybe we can add one?,1
Maybe we should revert to that.,1
It seems unrelated tests are failing.,1
It seems we have a recurring timeout issue on Travis (cc @taehoonlee).,1
It seems there is a flaky test.,1
"It seems like there are some network issues with travis, re-triggering.",1
It seems unrelated to this PR.,1
"np, I checked the cntk python doc, it seems from cntk Function we only can access the input of the graph, but not the input to the node. a tricky way is to encode dependency rules in the name and use find_name to find its previous node.",1
But that seems too hack.,1
Let's wait and see what @fchollet wants to do with this PR since it seems we can't implement the function right now for CNTK and that the Theano implementation is only working when `targets` is not None.,1
"So, I have been doing a bit of digging and it seems like the problem I had gotten in https://github.com/keras-team/keras/issues/11067 was misdiagnosed.",1
It seems that everytbing came back to normal on master.,1
Looking at this line: https://github.com/tensorflow/tensorflow/blob/2f7e56a65104aeca0a7fcc98a7b10fb2cff9b1a3/tensorflow/python/keras/backend.py#L5139 it seems that the log is there in tensorflow too.,1
"@gabrieldemarmiesse It seems all Tensorflow flows are passing, only CNTK times out.",1
@gabrieldemarmiesse It seems that cntk backend already times out on master since the tf.keras API sync merged by @fchollet,1
Seems pretty fixable.,1
It seems there are non-trivial issues with strings encodings and python 2/3.,1
Overall it seems like the benefits of this refactor are unclear.,1
This would at best be a low-priority project.,1
There also  seems to be a problem with the values in the table.,1
Each contributor seems to have used different methods for coming up with the depth values.,1
it seems that it's not that.,1
"It seems that there were some flaky tests, not due to your pull request.",1
There doesn't seem to be any weird stuff going on.,1
"Okay so after a lot of work, multiprocessing seems to be the cause.",1
The multiprocessing tests seems to be the main reason for insufficient memory errors.,1
"For example, TF 1.3 often seems to require more memory than TF 1.9.",1
I did some experiments and it seems that using 'spawn' instead of 'fork' is solving our issue.,1
Seems like this timeout issue is there.,1
Seems some unrelated test is failing.,1
"The only test, that failed (`test_truncated_normal`) seems to be a bit odd, as it compares the std of a randomly generated array with a constant.",1
"Seems clear enough with more complex layer inputs/outputs too...
(I chopped out some columns and layers just to make it easier to see in the post -- nothing that affects the vertical divisions though):
```
_________________________________________________________________________________________                 
Layer (type)                    Output Shape       Param #  Connected to                                  
=========================================================================================                 
noise_input (InputLayer)        (None, 100)        0                                                      
auxilary_input (InputLayer)     (None, 47)         0                                                      
concatenate_1 (Concatenate)     (None, 147)        0        noise_input[0][0]                             
                                                            auxilary_input[0][0]                          
dense_1 (Dense)                 (None, 1000)       148000   concatenate_1[0][0]                           
batch_normalization_1 (BatchNor (None, 1000)       4000     dense_1[0][0]                                 
leaky_re_lu_1 (LeakyReLU)       (None, 1000)       0        batch_normalization_1[0][0]                   
...                                                                                                       
batch_normalization_4 (BatchNor (None, 400, 1)     4        conv1d_3[0][0]                                
activation_1 (Activation)       (None, 400, 1)     0        batch_normalization_4[0][0]                   
=========================================================================================
```",1
1. Multiple inputs seem okay to me; tell me what you think below.,1
"It seems to produce a nice markdown table, and the text isn't ugly, but it does have the '|''s prepended.",1
There seem to be a problem with travis being stuck.,1
"Well Travis CI failed, but obviously it seems to be caused by another existing issue, and not by this PR?!",1
"I though we could save some LOCs by using the numpy rnn, but it seems that the API is not the same, so it can be postponed.",1
This seems to have a meaningful amount of overlap with your other PR.,1
"It seems the failure case is non-relevant, let me re-trigger it.",1
It seems from the result of the build that you have an issue with a mix of tabs and spaces.,1
Tests seem to be failing: https://travis-ci.org/keras-team/keras/builds/553193401?utm_source=github_status&utm_medium=notification,1
It seems we were careless in merging https://github.com/keras-team/keras/pull/11160/files without looking at the generated documentation.,1
@Dref360 @fchollet  it seems the build fails on a line which was written in the PR #6891,1
And it seems like BatchNorm layer was the reason the code can't loop over the model multiple times.,1
It still triggers the bug and it seems to have nothing to do with siamese networks.,1
I am using keras 2.2.4 and the  restore_model=True command in the earlystop callback seems to work.,1
"Seems pretty hacky to me, but works fine so far... ???♂",1
"it seems to be non-trainable variable problem, like batchnorm",1
"1) Add this example to the examples directory, that is, merging this PR since there seems to be a consensus about the quality of this example.",1
All tests now seem to be passing ??,1
It would seem it is applied _before_ any multiplication with the parameters is done.,1
"It seems you are all enjoying your holidays, right? Or is it something else?",1
It seems there are some major breakage between theano and numpy.,1
But is doesn't seem to be the case looking at the tensorflow code: https://github.com/tensorflow/tensorflow/blob/a3d38e4805ab9b3d7c0d4e8ceef8f90dbaca5e78/tensorflow/python/keras/callbacks.py#L1171,1
t still seems to running in an infinite loop.,1
Seems like this problem has already been fixed in `tf.keras`. https://github.com/tensorflow/tensorflow/commit/24088d19bbbd5a7f331d4dd5d69a17a30c62a465#diff-2afc7c6acfd68474e1e8c56718431276L149,1
It seems dtype can be obtained from self.outputs[i] .,1
Idea seems to be very clear to me so I can do it today,1
I have added a default of `k=5` given that top-5 rates seem to be most common after top-1.,1
Looks like there is only one line change in this PR which doesn't seem to intend to be final.,1
There doesn't seem anything actionable for Keras team at the moment.,1
@fchollet unrelated test seems to be failing?,1
Seemingly some issues on CI: https://travis-ci.org/keras-team/keras/builds/421708916?utm_source=github_status&utm_medium=notification,1
"It doesn't seem
too hard to do.",1
"That in itself seems like a reasonable change, but I don't get the other changes.",1
The issue with the multiple outputs seems to be fixed (tested on python 3.5).,1
it seems like my error belongs to issue .8477,1
"It was a bit of a pain to write, and
>   seems a bit inefficient, and I had to do some things in a relatively
>   round-about way (e.g. the indexing operations are strange and messy).",1
it seems to run.,1
I decided to do the two-layer version because it seemed easier for the GPU-friendly libraries like Theano to work with that.,1
"I had a look at the Theano code underlying the hierarchical softmax method: it seems the main speedups are due to having optimized sparse block dot implementations in Theano (see http://deeplearning.net/software/theano/library/tensor/nnet/blocksparse.html), and also from decomposing a single softmax into two smaller multiplications.",1
"Unless there's another transparent place that records whether you're in train/test mode in Keras somewhere, the current solution seems to be the best.",1
It seems that processes are not properly terminated when multiple instances of training procedure are running. @Dref360 @fchollet,1
"Also, there seems to be merge conflicts now.",1
I mostly suggested the TF-only implementation since this PR doesn't seem to be getting much love.,1
There seems to be a Python 3 compatibility issue.,1
Seems like some merge conflicts have cropped up.,1
Please rebase and I'll merge this PR.,1
It seems like it would warrant a unit test.,1
"The OP on the h5py issue was unclear on exactly why they want this, but demanding that the model be saved at the top-level of the file seems like a rather arbitrary restriction to me.",1
Added what seems like the obvious test.,1
It seems to me like it shouldn't be an issue to convert the checkpoint to work with `image_dim_ordering = 'tf'`.,1
It would just require transposing every conv2d kernel.,1
"""K.set_value(self.model.optimizer.lr, lr)"" line seems to me removed entirely as part of this PR, so ""lr"" is calculated, but not used?",1
"Beyond batch norm specifically, you seem confused by the different between trainability and stateful behavior.",1
"Tbh, it always just seemed more natural on an intuitive basis.",1
"Right now, the best advice seems to be to go through the discriminator model, immediately after `discriminator.trainable = False` is set, looking for BatchNormalization layers and set their `per_input_updates={}`.",1
doesn't seem to work for me,1
You seem to be working from an outdated version of the docs.,1
"Just that unfortunately it didn't fix this particular problem, which seems very related :)",1
"It seems, to me at least, to be a larger issue though.",1
"It seems like something has changed with the SGD implementation to where every example that uses SGD as an optimizer no longer learns, or doesn't learn as well as the docstring states.",1
@pavithrasv It seems there is a bug in the `test_mean_iou` which is unrelated to this pull request.,1
It will hopefully fix the CI problem that this PR seems to have.,1
"Unfortunately this is not a very constructive PR; a few of the ""fixes"" seem flat-out wrong, the rest are debatable.",1
"@taehoonlee I've resolved the conflicts, but there seems to be an issue with Travis builds.",1
Seems doable to support the same in other backends as well (the default injection can be done in `K.function`).,1
Seems like a problem within CNTK,1
In this PR you don't seem to have enabled this test for the CNTK backend.,1
I seems that update_sub was just added by someone else.,1
"There seems to be a way to do it (see link), I don't know how to translate into our use case though. https://github.com/Microsoft/CNTK/issues/3582",1
"I tried running both models, the average vector version seems to be slightly worse ??.",1
For some reason it doesn't seem to be a problem in the signature.,1
I'll take a look at it again.~,1
The way it's written for `Tokenizer` seems enough.,1
@fchollet It seems like the changes have not been reflected in the [docs](https://keras.io/preprocessing/text/) yet,1
"Btw, although conv3d, max_pool3d are in the TF docs, they don't seem to be part of the latest version from pip.",1
The `if dot_axes < 0:` check seems unnecessary to me.,1
"Just

``` python
if type(dot_axes) == int:
    dot_axes = [dot_axes] * 2
```

would do.",1
"Seems that we can not directly remove the `if dot_axes < 0:`, since removing it will cause ""IndexError: tuple index out of range"" Exception due to line 1230.",1
"Yes, seems you're right.",1
"Just an FYI: I have merged the PR, but it turned out to break a Google test for unknown reasons (seems related to the fact that some users created their own `Identity` layer in the past) and the change had to be rolled back.",1
It seems that https://github.com/keras-team/keras-cv/issues/425 is already closed with other fixes.,1
"@fchollet or @farizrahman4u, do you have any insights as to why unrelated test seem to be failing?",1
"To avoid having to keep track of, reshape and permute dimensions given this flexibility, broadcasting seemed like the right solution.",1
"It seemed cleanest to make the Keras broadcasting API behave like Theano, and it seemed useful to have broadcasting in the backend as well.",1
Everything else seemed even more ugly.,1
Sharded seems more correct to me since the alpha is being duplicated across a dimension.,1
This doesn't seem to warrant a new API argument.,1
"Digging into it a bit more, it seems that this is an issue with Lambda that has since been fixed in https://github.com/fchollet/keras/commit/229f13a8648596b1a2cbf96c92e087f821a8d6df",1
It seems that the file is already fixed on head.,1
A Python-side pixel-by-pixel iteration loop seems like a tremendously costly way to implement this.,1
For both optimizers it seems to me that the training loss converges to approx. 0.75 (even after 100 epochs) but adam reaches this threshold faster.,1
"If not, I'll open a new pull request since I seem to have accidentally broken this one with all of my force pushing.",1
"It seem that in the SGD implementation, momentums are always [created](https://github.com/keras-team/keras/blob/5ce6017623a61e7f34daa11569e462ef8fc3f660/keras/optimizers/sgd.py#L144) and [updated](https://github.com/keras-team/keras/blob/5ce6017623a61e7f34daa11569e462ef8fc3f660/keras/optimizers/sgd.py#L167).",1
It seems that it was changed a few minutes ago :D Let me rebase,1
"@fchollet I added some tests, I've also been experimenting with this branch a lot and it seems to be working well.",1
"- This seems more like a primer on neural networks, which isn't the purpose of this guide.",1
It seems like the issues are more about the example than layer/backend implementations.,1
For the rest of the file at first look what seems to have happened is that the tf.keras version basically folded in the common.py and tensorflow_backend.py in the backend.py module which are not really related to the config file persistence.,1
"It seems cleaner to keep the Activation layer shape-agnostic, and it spares us a if branching when shape info is not relevant (which is most of the time).",1
"Anyway, this module seems like a great addition, I'm looking forward to see what you do with it : )",1
That seems reasonable.,1
"Ok, seems reasonable.",1
Closing seemingly abandoned PR,1
"I made a new module because it didn't seem to fit into any other module (Core?), but it can be moved.",1
Tests seems to be failing randomly on MNIST download.,1
For me it seems like you do a small mistake here:,1
Overall it doesn't seem like additive uniform noise is being used as a regularization layer (as a replacement for Dropout).,1
I'll close the PR.,1
Seems that the current implementation of `deconv_length` with `same` padding uses an equivalent output padding of 1 while `valid` and `full` use output padding 0:,1
It seems like this could be implemented with current functionality if you had two separate RNNs for encoding and generating with step functions that share variables.,1
They could actually use the same step function with permuted inputs.,1
"If you have different lengths within a batch, so the generator takes over at different points, I would just put a switch in the step function and use a single RNN.",1
"Either way, this should be straightforward to do with symbolic loops.",1
"* Specifically for sampling and looping back output, I think we need more RNG functions in the backend.",1
Using dummy data as the `targets` you pass to train seem to be the best idea.,1
"Since this computation seems quite heavy (like printing the graph), could you add a flag to enable it? (also don't forget to change the doc if you do!)",1
The API doesn't seem to allow a function passed in instead of a string like "mse" since it goes through metrics_module.get.,1
CNTK tests failed because there seems to be a bug in `cntk_backend.bias_add()` that breaks the dynamic axes.,1
"As for the question, if else statements seem reasonable to me.",1
"@fchollet Seems tests fail because their is a deserialization test in the `layer_test` which cannot deserialize the layer from config, if it has custom objects.",1
"I thought looking for the non-broadcastable was a good solution, but seems the parameters happen to be broadcastable on all dimensions sometimes...",1
We could avoid using cuDNN in that case.,1
Seems you made a PR earlier in the morning :),1
Try / excepting the entire main loop seems a bit heavy-handed.,1
Seems like a good initiative indeed.,1
It also seems possible in the multi-output scenario that someone would want to compute a weighted metric for one output and an unweighted metric for another.,1
"This API would handle that use case very easily, whereas the other would not.",1
"If it's just those, that seems reasonable.",1
"Yes, I think it would be straightforward.",1
"We'd have to do it for `ObjectIdentityDictionary`, `_ObjectIdentityWrapper`, `ObjectIdentitySet`.",1
"In other words, the existing test (`keras/keras/tests/model_subclassing_test.py -> test_deepcopy`) is testing  with _a_ class of model that seems to work fine with `object.__reduce__`, but the na?ve behavior of `object.__reduce__` can't support all Keras models, since we already know that some of the ones generated by parametrization can't be copied via `object.__reduce__`.",1
At least that is my understanding of the situation.,1
This is a valuable layer but its usefulness seems to be limited to a small niche of use cases.,1
The cost of permanently adding it to the core Keras API (with all guarantees it entails) would outweigh the benefits.,1
"Seems auto-merge is not happening but the changes are merged into master now, so we can close this.",1
It seems like a good fit for `keras-contrib` (read CONTRIBUTING.md for more information).,1
This seems to have automatically closed somehow...,1
"This seems quite niche (not included in sklearn, for instance), so we won't include it in core Keras.",1
Seems need to make changes to CNTK backend too.,1
"The CNTK issue seems straightforward: `def tile(x, n):` needs to be fixed to support integer `n`.",1
Seems there is another bug in cntk's tile.,1
It seems to be indicative of a lack of understanding of the purpose of a validation set.,1
"Anyway, tile seems to work, and should be faster.",1
It seems fairly straightforward to modify the code for BinaryTruePositives() but I am not sure how to deal with adding K.epsilon()to the denominator to avoid division by zero.,1
I can't seem to recreate it.,1
"I checked on GitHub Travis, and it the slowdown doesn't seem to be happening anymore.",1
The Embedding idea definitely seems relevant.,1
It seemed more natural to make the BaseLogger print more.,1
Yes I could see this being a bit weird.,1
"Otherwise, this change seems reasonable, so I'll merge it.",1
"I need to study your INetwok.py script, I augmenting my script, basically the origional Keras style-transfer script to use the conv 5_2 but the results never seem to converge, or extremely slowly after 500 epochs.",1
It seems adding MRF loss drastically undermines the results obtained from the INetwork script.,1
It seems to work well and produces good images in the same color as the content image without destroying the content.,1
IMO it seems fine to keep `power` as a static constructor argument.,1
Seems like these two methods were removed in [this commit](https://github.com/keras-team/keras/commit/650c2c8cf9d711d35ab0ca7d1653ef53cbedaab3).,1
@fchollet I just checked and the weights seem to be loading correctly.,1
I don't seem to have that power,1
@ianstenbit Seems I cannot approve that either.... let me ping Francois,1
"I am affraid, we are overcomplicating simple things, and moreover it seems to me, that incorporating parallelization is going straight against one of the ideal behind this:",1
Each module should be kept short and simple.,1
Change how OSS Keras import python deps.,0
But the relationship is: scale = standard deviation * sqrt(3).,0
* keep existing behavior for tensorflow,0
get wrong result when using sparse_categorical_crossentropy in custom loss function,0
"For example, using a Theano backend the following fails with a
complaint about dimension mismatch:

UpSampling1D(2)(MaxPooling1D(2)(Reshape((2,1))(Input(shape=(2,)))))",0
- I'd like the API to be `preprocess_input(audio_path)` rather than `preprocess_input(x)` (`x`:1-d numpy array for raw-audio) as reading audio is much easier with librosa and anyway librosa is required to compute spectrograms.,0
Error when checking model target with sparse_categorical_crossentropy in 1.0.4,0
PiperOrigin-RevId: 459791640,0
Rename broadcast propagation pass to MergeAssumingOps,0
optionally load model by name,0
PiperOrigin-RevId: 364873257,0
denses -> dense,0
* Fix docstrings,0
Fix half of the tests that are failing in v1.,0
* improve the semantics around nesting Keras layers/models & modules *inside* of a VariableScopeLayer.,0
* Simplified code,0
PiperOrigin-RevId: 400836018,0
* Reformat constructor parameters,0
"commit 08c873669f39b37743014db99fcd2d308f8ea5ea
Author: vkk800 <vkk800@users.noreply.github.com>
Date:   Tue May 22 23:03:51 2018 +0200",0
"""from sklearn.grid_search import GridSearchCV""   is out of date and has changed in the new version (0.18-).",0
In my case is working correctly but a don't adapt it this solution for batch_save because a don't use this possibility.,0
Bug fix: Support multiple outputs in Lambda layer (#7222),0
Add documentation for initializations and datasets,0
"Modify to use proper multinomial sampling, with temperature to control diversity.",0
[RELNOTES] Added the mode "bilinear" in the upscaling2D layer. (#10994),0
Fix typos.,0
* Create get_random_transform and refactor,0
* Embed layer-outputs rather than layer-weights in TensorBoard callback,0
I want to decrease crashes as much as possible.,0
"commit 738de4c371503626b4c9dbae6428fb279b368a76
Author: Arel Cordero <arel@ditto.us.com>
Date:   Wed Aug 17 19:56:51 2016 +0000",0
This reverts commit 8593309c371ce716fd039e33ed5ae4079096ee0f.,0
- reset gate after matrix multiplication,0
* Make validation_split strictly between 0 and 1,0
* Fixed ndim behavior for sparse tensor,0
* Fix Python3.5 error,0
Use new saving logic for pickling.,0
Shrinks images in a convolution layer.,0
* Fix failing test.,0
PiperOrigin-RevId: 448113291,0
* Renaming,0
* incorporate suggestions,0
* Changed the name of the numpy backend.,0
* added basic example of functional cell,0
while (assumed != old);,0
add `auto_vectorize` argument to BaseImageAugmentation layer.,0
[MLIR] Fix merge of assuming ops,0
"Currently, polynomial interpolation of 3rd order is done when shifting.",0
Previously lr log had dtype numpy.float32 which throws JSON serializable error if used along with Remote monitor callback.,0
PiperOrigin-RevId: 483705728,0
Fix nested sequential deferred build (#10655),0
"Thus I suggest returning `generator_threads` from function `generator_queue()` and manually terminate these threads in `fit_generator`, `evaluate_generator`, `predict_generator`.",0
PiperOrigin-RevId: 439676157,0
This tool is used to make random number generation semantics match between TF1.x graphs/sessions and eager execution.,0
* Add DenseNet models,0
It is revealed by global presubmit that `variable()` method is heavily called.,0
Allow inputs of model training/testing methods to be a list of int/float values.,0
corrected batch norm implementation in cntk (#10427),0
* readability++,0
Refactor implementation of __call__.,0
* style fixes for documentation on in_top_k function,0
* add scikit-image to dependency,0
@pvieito any chance you could finish this up?,0
* Fix custom_objects for regularizers and other issues,0
- [y] This PR requires new unit tests [y/n] (make sure tests are included),0
@gabrieldemarmiesse I mean that please feel free to see the changes :),0
TimeDistributed doesn't mask correctly in some cases.,0
PiperOrigin-RevId: 379797179,0
"Fix optimizer loading when the Keras has not been imported.

(The `add_slot` error re-emerged in the past few days. Hopefully this should fix it once and for all)",0
* modified api upgrade warning message to be more detailed,0
PiperOrigin-RevId: 493118420,0
* Added fit_generator case to test_TerminateOnNaN,0
Assigned @fchollet as channel admin on Gitter,0
* Another inline if split (found by @gabrieldemarmiesse).,0
Thanks!,0
"--
63f9742c6a9d5a6d15c723dc1f36d7cafbba9ab3 by Ashutosh Hathidara <ashutosh.hathidara@legatohealth.com>:

Modifying docstring for layer_range",0
Add skipTest for a couple of methods in OSS.,0
Fix typos (#7213),0
Bug fix: model save when file already exists (#11289),0
"Added a comment to explain the check for sequentiality in a model:
A model is not sequential if it has multiple nodes or if a layer has multiple inbound_layers",0
* Update imdb_bidirectional_lstm.py,0
- BTW: tests from cudnn_recurrent_test.py are not ran on Travis CI (without GPU),0
* Refactor training part of the Keras engine.,0
* Applications / preprocessing fixes.,0
"Is the only option really to go back and train a larger VGG16 or 19 cov-net on Imagenet with more parameters?, and perhaps more dropout?",0
"Note: For FastUpConvolution, I haven't considered what would happen with border_mode same on feature maps with odd-sized Height and Width dimensions, but that's besides the point of this PR.",0
* Enabled test for matthews metric,0
PiperOrigin-RevId: 443199287,0
"From the documentation:

> `pad_sequences`
> Transform a list of `nb_samples` sequences (lists of scalars) into a 2D numpy array of shape `(nb_samples, nb_timesteps)`.",0
"The changes were designed to preserve backwards compatibility while adding support
for .tar.gz, .tgz, .tar.bz, and .zip files.",0
Imported from GitHub PR https://github.com/tensorflow/tensorflow/pull/43417,0
Support hlo to lhlo buffer placement through shape.assuming ops.,0
I was not aware of that github integration you mentioned.,0
"Test result:
    test env: with Tensorflow(commit a543d9471047ca3f6881c87105fcbe2cdff9207d Date:   Thu May 10 17:43:30 2018, local build), python3.4, centos7.4
    test cases:
      ""pytest  ./tests/keras/layers/normalization_test.py""  <all passed>
      ""pytest  ./tests""      <keep same result as without this commit's modification on BN>",0
* mnist_tfrecord.py and training.py clean up based on review (#7113),0
Bug fix : squeeze (#3433),0
Add documentation for time distributed sample weighting,0
"* Add depth as third dimension in docstring of
      Conv3DTranspose in convolutional.py in keras.layers",0
* link pointing to FAQ,0
What would that look like?,0
[MLIR][MHLO] Make broadcast propagation optional in `merge-assuming-ops` pass,0
It was removed in PR #8829.,0
* training.py test _slice_arrays(),0
"Additionally, we remove the optimizer docstring saying that PSS cannot be used when `jit_compile=True`.",0
KerasClassifier doesn't pass sklearn check_estimator due to shape issue (but still works in some contexts).,0
Add documentation for the MNIST dataset.,0
* Revert unrelated changes,0
This reverts commit 08f6bdeb5652550f36210f64aefda3d0d41e2d79.,0
Added regularization option to BatchNormalization layer (#3671),0
"Are there any ops for which the Numpy version would be too long or hard to read, and thus should be hidden behind a toggle ""show Numpy implementation""?",0
"Where possible use context managers (`with open(...) as f`) that close
the resource even after catching an exception.",0
close the opened hdf5 file in load model in case of error (#6749),0
Add a utility for encoding categorical perprocessing output,0
PiperOrigin-RevId: 481064905,0
fix https://github.com/fchollet/keras/pull/970#issuecomment-154886091,0
"as far as my counting goes, this is actually the 3rd time we get a PR about using custom cost functions (myself included when I started with Keras).",0
Currently OSS keras doesn't generate any __init__.py file for PIP package build.,0
Fixed bug name not defined.,0
* skip sparse tests when TH.sparse import fails,0
Changes:,0
* use .theanorc in Dockerfile,0
"2. Change the default value of `ema_overwrite_frequency` to None, as a magic number is hard to be justified.",0
* unit tests + better error msg,0
Opinions?,0
* Change `batch_size` descriptions to proper ones,0
"commit d0b06c03080131c55ab4777064a196ff339ad7df
Author: Arel Cordero <arel@ditto.us.com>
Date:   Thu Aug 18 15:52:35 2016 +0000",0
* CLN: replace _convert_string_dtype by tf.as_dtype,0
"There is no more use of this class, all adaptable layers are ported to
PreprocessingLayer.",0
* Update convolutional_recurrent.py,0
* Fixup Syntax in Theano Backend,0
* remove del statement,0
* with patch('__builtin__.input') as mock:,0
PiperOrigin-RevId: 439705241,0
Fix typos in FAQ,0
I'd really like if the behaviour from my PR can be preserved.,0
* Cast mask of ones for unmasked input in merge to uint8,0
Fixed duplicate line in keras/engine/training.py. (#5266),0
* Fix eigenvalue regularizer,0
Added learning phase to callbacks (#2297) (#2303),0
remove the example and the dataset for 3d,0
* added test case for when both inital_state and constants are passed to RNN.__call__,0
Added Integer at the `pool_size` of `MaxPooling3D`,0
What am I supposed to do?,0
Rm legacy TF support from TensorBoard callback.,0
fix batch_dot tests on backend,0
"* Added title to plot, got rid of ticks on plot.",0
"Now, instead of disabling it, we temporarily empty it, then restore
the original when we're done.",0
"Create augment_label method:
```
  def augment_label(self, label, transformation=None):
    return label
```
on remaining image augmentation layers",0
Fix for cntk issue 1994 (Keras/CNTK: BatchNormalization layer causes predict() values to be incorrect) (#7258),0
Doesn't address the question of having a better __repr__ since that is a much wider change.,0
"--
32e984392a632e29b660183cac41bf1963eb2b18 by pizzy <horlasehinde@gmail.com>:",0
PiperOrigin-RevId: 458027843,0
"In the loop, we copy only markdown files.",0
manually terminate threads process returned by `generator_queue()` (#4101),0
"Allow steps param in Sequential predict(),predict_proba(),predict_classes() (#8760)",0
This reverts commit 9773e810a527d88b97239e0117be0967a3b4214f.,0
"Otherwise, after `make notebook DATA=~/mywork` I can't use my notebooks residing in `~/mywork` which is actually mounted at `/data` inside the docker.",0
* Comment out added test,0
"bug fix, cast batch_sizes as a list to support indexing (#6057)",0
Add example to compare RELU with SELU (#6990),0
"These types override (or have superclasses which override) `__getattr__` and
redirect it to their stored value.",0
* removed extraneous line,0
"- no PEP8-related changes, please.",0
"The know static batch size is used in the final reshape instead of -1 so that the static shape of the output has the batch dimension defined, which removes the need for `set_shape`.",0
The RNG is only used in attention when there is a dropout.,0
"* mnist_tfrecord.py added (#7061, #7072, #6928, #7046)",0
Fix typo in docstring for `DenseFeatures`,0
Raise a descriptive error if `inputs` are not inputs (#6812),0
Fix to error message in exception (#3213),0
Remove `Conv._convolution_op` assignment in constructor.,0
PiperOrigin-RevId: 431743906,0
Revert "Fix sample_weight and class_weight in validation",0
"ValueError: Error when checking input: gru_4 input to have shape (None, None, 10) but got array with shape (1, 4, 1)",0
So I would rather encourage people to move to the latest Theano version.,0
add: tests for Luong Attention with concat score,0
* Automatically add a `Show the numpy implementation` if the code is more than 10 lines long.,0
* update nvidia-docker plugin,0
* add boolean support,0
Fix issue calling TextVectorization on non-tensor input,0
I read the code and changed the `self.evaluate_generator()` (line 1482) in `fit_generator' to use a multiprocessing approach as training process did.,0
PiperOrigin-RevId: 408709708,0
* Fixed PEP8 issue,0
Enable colocate_gradients_with_ops=True (#3620),0
* Fix style,0
"Numpy was recently upgraded to 1.16, causing the travis build to fail because theano was using a private attribute of a numpy array.",0
[RELNOTES] Introduce `preprocessing.image.save_img` and remove deprecated imsave method in neural style transfer example (#9996),0
Unit tests for GRU and LSTM layers were reorganized so that all generic tests that work for both V1 and V2 are in `gru_test.py` and `lstm_test.py`.,0
PiperOrigin-RevId: 390630992,0
PiperOrigin-RevId: 424727607,0
Add a backup urls for zlib binary.,0
* remove faulty cases,0
@gabrieldemarmiesse do you what the expected output is for a batch with multiple samples when using beam search?,0
Added a note that model.save() is an alias for keras.models.save_model() to clarify that the example above is to demonstrate save_model().,0
Standardize normalization dtypes,0
* Added support for 0 cropping on second axis,0
* Simplify with from six.moves import input,0
"* add comments, fix style issue",0
* Utility function to check if a callable has a given keyword argument,0
* Skip some theano tests,0
Max Over Time in imdb_cnn.py (#2320),0
Recurrent Attention API Additions (#7980),0
[Requests for Contributions] Refactoring _standardize_input_data to make it faster.,0
"The syntax for Eigenvalue Decay is similar to the other Keras weight regularizers, e.g.:

 model.add(Dense(100, W_regularizer=EigenvalueRegularizer(0.0005)))",0
* IndexError fix,0
"However, when some of your operations assume that all the examples in the minibatch have the same shape (e.g. LSTM wrapper for cudnn's LSTM), it is very useful to align the examples to share the same center coordinates.",0
ValueError: The name "sequential_1" is used 2 times in the model.,0
* Bug fix in recurrent layer,0
"commit ffa99d69f7bfa42d060c26032793dc650002419b
Author: Pavithra Vijay <psv@google.com>
Date:   Fri Jun 15 13:52:14 2018 -0700",0
Fix batchnorm momentum in ResNetRS,0
"This same behavior
can be achieved in a single step using dict setdefault method.",0
* Fixed,0
* Ensure correct usage of zca_whitening,0
* Fix mobilenet_v2 filename.,0
The TF utilities module "test_util" is now always imported as "tf_test_utils" to avoid confusion.,0
* Factorized the unit test,0
Merge pull request #15288 from mikael-epigram:master,0
PiperOrigin-RevId: 424658022,0
`channels_last` ->`"channels_last"`,0
PiperOrigin-RevId: 389292301,0
"PR #47726: updated convolutional_recurrent.py to include 1D, 2D, and 3D ConvLSTM instances.",0
Add optional dependencies' links to download pages in README (#9563),0
"@gabrieldemarmiesse @fchollet Would it be possible to extend the loss function interface, to take an optional `weights` parameter?",0
* using single quote for consistency,0
"The keras examples are great, but do not benefit from a good visibility.",0
* Add test for sparse categorical accuracy with timesteps,0
May I ask what is problematic with implementing ` 'same'` border_mode for Locally connected convs?,0
"ImageDataGenerator.flow() for unlabelled test data (only features X, no labels y)",0
PiperOrigin-RevId: 460756589,0
- Add standalone weights file saving/loading functionality.,0
There is some black magic at work with `compile`.,0
Allow variable number of input channels on CNN Application models (#7568),0
* Only test process termination,0
# Exception: All input arrays and the target array must have the same number of samples in 'lstm_text_generation.py',0
* Adjust some more lr.,0
DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved.,0
* added learning phase to callbacks (#2297),0
"This change replaces them with their recommended replacements (bool, int, float, complex, object, str, str, int).",0
* Prevent stateful metrics to leak np.floats to the History object,0
Currently it is calculating precision rather than accuracy.,0
* Progbar: Format stateful metrics values as floats alike other metrics,0
TF warned about deprecated function tf.sparse_to_dense().,0
- [x] Handle multiple inputs,0
* first working proxy,0
PiperOrigin-RevId: 356370747,0
Create a class that delegates LossScaleOptimizer creation to the right subclass depending on the inner optimizer's type.,0
Convert to legacy optimizer if users are requesting new optimizer in TF1 runtime.,0
PiperOrigin-RevId: 381424814,0
- adjust imports to be consistent,0
Is there an alternative API that you think might make this more clear?,0
"It currently only supports scalar inputs on the last dimensions, as we are not sure
how we would like to handle multi element categorical samples yet.",0
Remove mask_value application from _step,0
PiperOrigin-RevId: 533238980,0
InvalidArgumentError with model.fit,0
Change in variational autoencoder example to resolve issue #6373  (#7764),0
utils/generic_utils: fix unicode strings problem,0
PiperOrigin-RevId: 467781811,0
Update tensorflow/python/keras/metrics.py,0
Update sequence.py,0
* Bug fix,0
Merge pull request #16528 from sayakpaul:patch-1,0
PiperOrigin-RevId: 437355007,0
"so, if you assume independence between the two classifications, the linear combination of the two losses is indeed ""minimizing joint negative log likelihood"".",0
- travis is configured to split backend tests into test matrix to make parallel theano vs tensorflow testing as opposed to rerun all the tests twice for python 2.7.,0
Expose Normal/Ragged/Sparse KerasTensor as public API.,0
* Add docs,0
Fix LiL sparse matrix on Tensorflow (#4173),0
Any third-party opinions on this feature?,0
* generic_utils.py don't crash when dealing with batched data,0
Revert "Fix Head params to accept classifier_activation",0
PiperOrigin-RevId: 460315145,0
This changes the exception to a warning.,0
PiperOrigin-RevId: 395109473,0
* Add test for multi-output Lambda layer,0
7) Adadelta adds iterations to its weight list.,0
"- The `join` merge was written with `Graph` in mind, not `Sequential`",0
"I completely agree with your cost-benefit view, however, so if it still doesn't make sense to include, please feel free to close the PR ??",0
Add documentation for 'subset' and interpolation' arguments (ImageDataGenerator) (#9817),0
"loss_scale.py is removed and the sole function from it that was used, `deserialize`, has been inlined.",0
A few things:,0
"Clarified Model constructor's documentation by spelling out that inputs and outputs can be dicts, lists or tuples to combine multiple inputs and outputs.",0
PiperOrigin-RevId: 446308745,0
You passed: <class 'keras.layers.core.TFOpLambda'>,0
Update cntk backend with CNTK 2.1 release (#7493),0
- move from cudnn_recurrent_test.py to test_model_saving.py,0
# /opt/anaconda3/lib/python3.8/site-packages/keras/utils/generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config.,0
* try fixing tf test; again,0
- pickle filenames in tests are renamed to avoid clashes during multiprocessing,0
11) Adamax changes default learning rate from 0.002 to 0.001,0
"This allows you to do nice things like save JSON models so that they're human
readable & editable.",0
"* rename models (MusicTaggerCNN,CRNN), BN mode=0 weights",0
PiperOrigin-RevId: 429388335,0
PiperOrigin-RevId: 480150441,0
Improve SavedModel error message when loading a layer fails,0
* added parallel counting of sample files when initializing DirectoryIterator,0
- [y] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date),0
"If you are going to host protocol file, then you have to update protocol every time official caffe modify it.",0
"commit f361a70da4b40b961f1af9c8f1c3cd26273d0cad
Author: Arel Cordero <arel@ditto.us.com>
Date:   Thu Aug 18 02:29:17 2016 +0000",0
"But hopefully, I'll get back to it asap once everything else is done.",0
PiperOrigin-RevId: 385838285,0
* reorder inputs,0
Thanks for your considerations.,0
* Extract Variables dont' Wrap Lines,0
Replace Doc strings replace suggested usage of `keras.utils.register_keras_serializable` with `keras.saving.register_keras_serializable`.,0
* added example to illustrate effects better,0
This CL also removes the CompositeTensor superclass from Generator.,0
expand_nested bug fix and '_' removal,0
Not widely used,0
* Example with Eigenvalue Decay regularization.,0
* CI failure fix.,0
Let's reframe the situation:,0
Add Integer in `strides` and `pool_size` of 3D layers,0
* Whitespace fix,0
* Added Gitter channel badge,0
Merge pull request #16648 from haifeng-jin:patch-1,0
I don't have any strong opinion about this.,0
* Revert "Explicitly mention dimension order (#7266)",0
PiperOrigin-RevId: 435722952,0
Removes caching of the convolution tf.nn.convolution op.,0
Clearer wording in the Shared Layers Section (#7260),0
"If the PR for `data_utils.py` is rejected, please consider using our modified version of `test_multiprocessing.py`.",0
PiperOrigin-RevId: 380645230,0
* organize codes,0
Add metric API changes (#13256),0
method argument formating.,0
"* expand masks once in KNP.rnn, add test for constants",0
Refactor regularizers and add add_weight method. (#4703),0
Two notes:,0
PiperOrigin-RevId: 406160462,0
Fix typo in test,0
"loss_scale_benchmark.py is removed, since it no longer works and there is not an active effort to improve LossScaleOptimizer performance further.",0
This commit changes the way that masked grouped normalization is computed.,0
"Adding TruePositives, TrueNegatives, FalsePositives, FalseNegatives metric classes. (#13280)",0
"* renamed constants to attended in FunctionRNNCell, avoided duplicating outputs in wrapped model",0
PiperOrigin-RevId: 430974530,0
"Do we currently do any checking there, or is it assumed that is the role of clients?",0
PiperOrigin-RevId: 379565815,0
Merge pull request #15286 from ddrakard:plot_model_show_activations,0
Described in Issue #10561,0
* Commit to trigger the theano cache.,0
* updated kwarg to be shuffle,0
Add tflite-authoring package as a dep for keras API generation.,0
"ValueError: A target array with shape (180568, 80) was passed for an output of shape (None, 180568) while using as loss `categorical_crossentropy`.",0
#9733: Extend RemoteMonitor to send data as application/json (#9734),0
"This is purely a cosmetic issue, since the download logic wasn't impacted.",0
This PR provides fix for `engine.training_generator.fit_generator` when `workers=0`.,0
"@AnikaTabassum 
Can you refer to [this link](https://github.com/tensorflow/tensorflow/issues/34558#issuecomment-565150738) as it answers the issue faced.",0
"However, the speed gains were not high enough for the use-cases I considered to justify sinking more time into this.",0
Add test_loss_weighting,0
* Linked to github issues.,0
PiperOrigin-RevId: 429410341,0
* Better error message for invalid funcational api inputs (#6589),0
- the signature for `reset_states(state_values)` is inconsistent with the signature for  `set_weights(weights)`,0
Error when checking model input,0
"Add **params to BaseWrapper.get_params(self,_) to fix TypeError",0
"It appears to me that if one assumes all zeros for the initial hidden and cell states, which is the default behavior (the user must explicitly pass in an initial state tensor to change this), then the fix to get the correct semantics is rather simple.",0
Add train test split to DirectoryIterator (#6152),0
So always rely on current model metrics.,0
So this load call breaks.,0
PiperOrigin-RevId: 433260497,0
Could you comment on https://github.com/keras-team/keras/pull/8955#issuecomment-355350523,0
(.text._ZN3ruy6detail36CreateTrMulParamsAssumingColMajorDstILNS_4PathE113EhhisEEvRKNS_3MatIT0_EERKNS3_IT1_EERKNS3_IT3_EERKNS_9MulParamsIT2_SC_EENS_16ChannelDimensionEPNS_3CtxEPNS_11TrMulParamsE[_ZN3ruy6detail36CreateTrMulParamsAssumingColMajorDstILNS_4PathE113EhhisEEvRKNS_3MatIT0_EERKNS3_IT1_EERKNS3_IT3_EERKNS_9MulParamsIT2_SC_EENS_16ChannelDimensionEPNS_3CtxEPNS_11TrMulParamsE]+0x1d1): undefined reference to `ruy::Ctx::set_performance_advisory(ruy::PerformanceAdvisory)',0
PiperOrigin-RevId: 439733875,0
Include Keras API design guidelines in the contribution docs.,0
Fix 'MLP for binary classification' example.,0
1. can I assume that input and output arrays given to a CUDA kernel do not overlap?,0
* Minimal SparseTensor support for TensorFlow,0
Make Dot documentation inline with Concatenate (#10271),0
"The max_value argument can not be used in a layer, except
custom layer or Lambda.",0
* TST: also test passing in an h5py.Group,0
Keras Metric - preserve dimension after class_id slicing to align with sample_weight,0
Revert "Add verbose parameter to image_dataset_from_directory",0
Sensible activation for RNNs,0
"I'm not sure if 'cell' should be used as name, or if we should stick to 'simple_rnn_cell', 'lstm_cell', 'gru_cell' instead.",0
* Pep8 again and again.,0
"Replace default value batch_size=32 with None for Sequential.evaluate(), Sequential.predict(), etc (#8479)",0
* Added some details about what was possible with bilinear interpolation.,0
* Squashed commit of the following:,0
* [skip ci] update comment,0
"But, currently it takes different types for input and target.",0
Added a pointer to a Keras FAQ that explains key differences between model.predict(x) and model(x).,0
This reverts commit ced84c4b42d9186842e4cad6c11b0c8f2c18439b.,0
Raising `NotImplementedError` is optional for Model subclass implementers to indicate they would like the framework to use default way of serialization.,0
Split bins into num_bins and bin_boundaries arguments for discretization,0
-   Reshape uses Theano's reshape function.,0
"however this was causing interaction issues if you also used a mask,
because that wasn't using nonzero() properly.",0
"- fix string formatting for ValueError
- inline some function and import
- format docs more consistently",0
* better handling of none axis,0
* Fix docstring of test_trainable_weights_count_consistency,0
* changing 'disable_b' to 'bias',0
* Use single quotes for strings,0
"Also, for the pool_size of 2, we halved the number of features maps and the number of epochs, and it still trains a net that can very nicely reconstruct the input.",0
[MLIR][MHLO] Move elementwise ops into assuming regions to unblock fusion,0
"Changed
    ""# now model.output_shape == (None, 20, 16. 64)""
    to
    ""# now model.output_shape == (None, 20, 16, 64)""

    (There is a dot instead of comma).",0
"There was a bug in the code in the `channels_last` part:

`x += reshape(bias, (1, 1, 1, bias_shape[0]))`",0
Fix typos (#8745),0
PiperOrigin-RevId: 394765626,0
* Remove dead line of code,0
mnist_cnn.py does not give reproducible results,0
Could it potentially be fixed?,0
"Another nice effect: an alternative masking scheme can be introduced
without changing _step at all.",0
.travis.yml fix mkl errors (#8532),0
* Updated fill_mode examples,0
Travis CI: reduce hardcoding of Python 3 versions (#10705),0
#9287 Fix most of the file-handle resource leaks. (#9309),0
* Update test_regularizers.py,0
"--
4ea68093eeaf4c4157368668afd7f809b806a504 by Amogh Joshi <67437306+amogh7joshi@users.noreply.github.com>:",0
* fix bugs in merge,0
Update scikit_learn.py (#3567),0
The multiplication with a float mask then crashes.,0
[Error] mnist_cnn.py,0
Add a predict_generator method to Sequential,0
Cifar-10 example not converging when image_dim_ordering == 'tf',0
Fix learning phase info being left out in multi-input models (#7135),0
* models with shared layers are not sequential,0
Trains fast.,0
Add iteration setter to LossScaleOptimizer.,0
something wrong with U-NET,0
Signed-off-by: CUI Wei <ghostplant@qq.com>,0
"If restoring a model and `standardize` is a custom callable, please ensure the
callable is registered as a custom object.",0
Nonetheless I put this code up for consideration.,0
PiperOrigin-RevId: 503504933,0
Rename random_seed => seed for consistency with the rest of the code.,0
"unsigned long long int old = *address_as_ull, assumed;",0
"--
c350558ce4cdd7b0e32899ba75b13995b43ea532 by pizzy <horlasehinde@gmail.com>:",0
* Switching to thread pool,0
Update BaseImageAugmentationLayer to support "targets" key in the input dict.,0
This commit fixes issue #1275.,0
"* Fixed python style issues, made data files remote, and made code more idiomatic to Keras",0
* Adding #Arguments for some classes.,0
Add documentation to set self.built = True in MyLayer.build() (#4315),0
* Made it python2 compliant,0
5) add momentum and centered to RMSprop.,0
"As such, when performance is the objective, a good rule of thumb is to perform as much of the computation as possible outside of Scan.",0
* Reduces number of ops as much as possible.,0
"[docs] more details for adagrad/delta, clarifying usage of rho (#10410)",0
generator.compile() as has no effect.,0
Updated 'voculary' to 'vocabulary'.,0
Added warmstart_embedding_matrix to tf.keras.utils,0
is:issue is:open I am writing a custom loss function for my research.,0
"- allow passing additional operations, such as StagingArea.put()",0
"set_weights is override
   to maintain backward compatibility.",0
I looked a bit further into what code would be needed for 2.,0
"Slightly expand on the comments about performance in model.predict
e.g. see:
https://github.com/tensorflow/tensorflow/issues/40261",0
"Is this related to this request, or possibly another issue?",0
"`tf.where` needs the x and y tensors to be the same shape but `output` in the demo is `cell_output` concatenated with `attention_h` and `states[0]` (i.e. [?,3000]) and `states[0]` cell_state from from the GRU which is [?,1000].",0
Only pack list and tuple x values inside an extra tuple,0
"This also means that we have less parenthesis and
less nested lists.",0
* add output rank to one hot approach,0
PiperOrigin-RevId: 453355141,0
adding unit tests for loading weights by name,0
* fix cntk static learning phase issue; add a test,0
* Revert docstring changes,0
"* Fix the cntk backend for RNN, and update test case.",0
We were incorrectly normalize the input (with wrong variance).,0
New - tf.keras.utils.pad_sequences,0
- fix typos,0
But in first case I know what the code does.,0
Remove restriction on strides in theano backend conv2d. (#2238),0
* Remove the unnecessary augument in docstring,0
"Add scoring methods, particularly conact for Luong-based attention.",0
The keras 2.12 RC branch is cut at https://github.com/keras-team/keras/tree/r2.12.,0
"Although I do respect your authority on the matter, I kindly ask you to reconsider introducing the fix.",0
Update keras metrics to support DTensor mesh.,0
updated ConvLSTM,0
* improved fit(steps_per_epoch) with separate internal epoch loop in _fit_loop,0
* Updated with suggestions,0
PiperOrigin-RevId: 478299677,0
PiperOrigin-RevId: 476505974,0
* Only call squeeze if mean / var have more than 1 axes.,0
Tensorflow fails to build `GRU` models in some cases.,0
Changing variable name from 'binary_labels' to 'one_hot_encoding_labels'.,0
* fix pep8!,0
* added a sentence to specify that the top-1 and top-5 accuracy refers to the public ImageNet validation set,0
Following PR#3751 this allows mask and images with the same name to be read together.,0
"In respect of your huge contributions to Keras, I do ask that you reconsider this great PR (pending test cases and docs etc)",0
The TimeSeriesGenerator class uses xrange through six which caused an IndexError,0
* Make accuracy metrics work with masked outputs,0
Fix typos (#7495),0
* test_stateful_metrics: Also test validation set evaluation,0
perhaps??,0
Cast image preprocessing inputs to compute dtype,0
"To avoid name confusion and massive code changes, we are creating a BaseLossScaleOptimizer class that delegates object creation to LSO or LSOV3 based on the type of inner optimizer.",0
Imported from GitHub PR https://github.com/tensorflow/tensorflow/pull/48725,0
* Adding arguments list to MeanSquaredError.,0
generalize pad_sequences,0
"* Removed hacky workaround for pyplot Exception, included comment",0
EarlyStopping: Never stop if this epoch was an improvement.,0
"If not, what should be done to address it?",0
Thanks for the suggestion.,0
"* Break long line, and revert interval change.",0
Remove excessive imports.,0
Fix DTensor model checkpoint issue.,0
* rename lambdas,0
1. Fix keras model savedmodel saving to correctly handle the training arg in cases where a bound instance call method was decorated in the class definition *before* binding occurs,0
* Fix issue when working in conjunction with TimeSeriesGenerator,0
Add missing verbose opt for evaluate_generator (#9811),0
* Restore learning rate to previous default.,0
PiperOrigin-RevId: 474574379,0
How would Normalization play with that?,0
* Fixed issue with _keras_shape for sparse Inputs,0
"+ None or empty list for embeddings_layer_names implies monitoring
  of all layers of type Embedding",0
* Added tests.,0
"* Currently broken: TF RNN dropout, go_backwards",0
This change removes the experimental API.,0
"Let me know what you think, and I am happy to write documentation for this.",0
This PR addresses this issue in two ways:,0
* Alpha version,0
"Impetus: Output from RNNs is generally considered of size `(nb_samples, time_steps, values)`.",0
* Some style fixes on doc automatic generation files,0
Add get_initial_state method to Recurrent,0
Use Theano's IfElse instead of Switch for in_train_phase. (#4579),0
Fix VAE example (#3220),0
"Old error message: ""This model has never been called, thus its weights have not yet been created, so no summary can be displayed. Build the model first (e.g. by calling it on some test data).""",0
Fix dropout error in Bidirectional layer (#5985),0
* add broadcasting to cntk backend,0
Proposal: ImageDataGenerator.flow_from_list_of_files,0
- Don't break lines with `\`,0
* Implement GRU that's compatible with CuDNNGRU and allow loading weights.,0
* Whitespace violation,0
PiperOrigin-RevId: 397208043,0
PiperOrigin-RevId: 395026999,0
- no tests to verify that the unrolled version behaves exactly like the scan version,0
- due to silly mistakes in refactoring the LSTM conversion test was not working,0
Fix data_utils.py when name ends with `.tar.gz`,0
Add an optional `validation_freq` argument to `fit` (#12065),0
"Got inputs shapes: [(None, 12, 12, 128), (None, 12, 12, 32), (None, 12, 12, 32), (None, 12, 12, 64)]",0
Avoid DeprecationWarning from inspect.getargspec (#6817),0
"commit a40f33556caef1ab0a3f75758f194728c804dcd3
Author: Max Pumperla <max.pumperla@googlemail.com>
Date:   Wed Jun 13 20:36:50 2018 +0200",0
* Upload examples/imdb_fasttext.py which implement the fasttext model,0
Change the order of function tracing for saved model.,0
Add `batch_get_value` to backends (#2615),0
* Fix conflict resolution merge minor disaster,0
Raise exception if unexpected keys are found in the padding dict.,0
adding unitnorm constraint,0
- [y] This PR changes the current API [y/n] (all API changes need to be approved by @fchollet ),0
Use layer.dtype as the default dtype when adding a new weight (#12740),0
"The kullback_leibler_divergence metric in metrics.py returned an output
with dimensionality N-1 (where N is the dimensionality of the target).",0
DOC update needed.,0
"This also brings the std -0.05 and 0.05 and not to
1 as claimed by the docstring of the BatchNormalization class.",0
"For the test code, had to do more major changes to port from pytest, but
hopefully any errors have been caught by the tests themselves.",0
"Avoid creating the RNG if possible to make the Attention layer to be fully stateless, and can be recreated within the layer.call() body.",0
* PEP8,0
* Made a base class for ZeroPadding.,0
"- **Con**: The Reshape layer currently does not allow a changing of the size of the first dimension
    https://github.com/fchollet/keras/blob/master/keras/layers/core.py#L80 .",0
fixed to use theano.tensor.mean instead.,0
What is the assumed shape of 'weights'?,0
* Delete utils.py,0
In this case it also made it easy to introduce bugs or unexpected behavior.,0
* Added regularization option to BatchNormalization layer,0
* Fixed pep8.,0
Add no_keras_py_deps to enable PIP package test against the installed PIP.,0
PiperOrigin-RevId: 410721138,0
I am having second thoughts on it.,0
* Add generic_utils to mkdocs and add tests for custom_object_scope,0
* - fixing white spaces,0
"This replaces the pattern

```
if isinstance(mask, list):
     mask = mask[0]
```

With 

```
mask = get_first_element_from_list(mask)
```",0
Most of them are failing because of the slight different behavior between v1 and v2.,0
Side effect: disables RNN dropout for Theano.,0
"Allowed values are: `None`, a `Callable`, or one of the following
values: lower_and_strip_punctuation.",0
updated for list check bug in predict/predict_on_batch (#2585),0
* fix formating,0
- changed the meaning of the length parameter: now it's really the length of the output sub-sequences,0
So basically we allow `args` to be passed only up to the point that argument order is the same in both APIs.,0
* Allow dynamic shape for repeat_elements,0
"commit 5a48df22f0d9dd5b365ed5afc9923424d2e8c2c9
Author: Clemens Tolboom <clemens@build2be.com>
Date:   Thu May 24 00:00:42 2018 +0200",0
* shift origin to centre of the image for homographies,0
PiperOrigin-RevId: 427277729,0
### PR Overview,0
* pass pep8 verify,0
"It is more explicit to express as code rather than using words stride value, dilation value.",0
Do you think it is safe to make the switch from `history` to the callback?,0
This function isn't called or mentioned anywhere else in keras.,0
"Add PSS test to the unit test of optimizer, since the variable access issue of XLA has been resolved.",0
* Corrected a comment in function "print_layer_summary_with_connections",0
Doc update (#10376),0
- Raise an error when users are not building the docs with the tensorflow backend to avoid them wondering why this is not working.,0
Also update foldl and foldr to use variables for future proofing.,0
implemented dropout in GRU and SimpleLSTM,0
"commit 2ec486ba338684e066198c88cfbb55af4a34dd4f
Author: Francois Chollet <francois.chollet@gmail.com>
Date:   Fri Jun 15 14:07:28 2018 -0700",0
But we can successfully build and save the models if we switch the backend to Theano or CNTK.,0
* fix: use 'q' instead of 'rate',0
PiperOrigin-RevId: 428046669,0
Merge pull request #164 from phreeza/mnist-docs,0
https://github.com/keras-team/keras/issues/16656,0
Closing; feel free to reopen with proposed fixes.,0
Thanks the coments from fchollet.,0
* remove batch size check,0
* docstring fix,0
"--
960eb402f8c2d4c1f5b14703824c0307ed8bc000 by Matt Lyon <matthewlyon18@gmail.com>:",0
* Change maxproc to nb_worker and update documentation,0
* rewrite tf batch_dot,0
PiperOrigin-RevId: 459547617,0
* Changed the message.,0
_check_array_lengths properly handles corner cases with None (#7063),0
Co-Authored-By: farizrahman4u <farizrahman4u@gmail.com>,0
Shared Embedding Layer with masked input for Bi-directional RNN,0
PiperOrigin-RevId: 432265412,0
Update depthwise_conv2d.py,0
"Changes Keras' RandomGenerator to use tf.nn.experimental.general_dropout instead of stateless_dropout in RNG_STATEFUL mode, to avoid unnecessary seed generation and scrambling (i.e. a roundtrip from (key, counter) to seed and back) incurred by stateless_dropout.",0
"how fix error  A target array with shape (178, 222, 222, 3) was passed for an output of shape (None, 3) while using as loss `mean_squared_error`.",0
* Check GPU support via tf in pytest skipif with short-circuit evaluation.,0
* Added an error message for undefined shape on NASNet.,0
Fix renamed inbound_nodes in CuDNN recurrent test. (#9127),0
* Improve test_sparse_categorical_accuracy_correctness,0
I have added a URL of the TextVectorization API in the StringLookup Layer page so that users can easily look at and experiment with the API.,0
* Fix return states,0
PiperOrigin-RevId: 391415472,0
9) RMSprop adds iterations to its weight list.,0
"I'm not super keen on adding Theano support myself since I don't have any need and I don't know Theano, but I'm not sure how you feel about having things that only support one backend.",0
* enable recurrent layer's dropout on cntk,0
"If you use Kannada-MNIST in a peer reviewed paper, we would appreciate referencing it as:

```
Prabhu, Vinay Uday. ""Kannada-MNIST: A new handwritten digits dataset for the Kannada language."" arXiv preprint arXiv:1908.01242 (2019).
```",0
"Cap the last batch to not index past the end of the array, which can happen if the
total number of items is not a multiple of the batch size.",0
Support only build models; mitigate https://github.com/keras-team/keras/issues/14808,0
This class computes IoU for a binary classification task where there are only classes 0 and 1.,0
PR #49376: Added batch as formatting parameter during ModelCheckpoint callback,0
Is this correct?,0
Added dense_shape property delegation,0
* Added dropout to reference_operations.py,0
I'd appreciate if you could once again paste the logs here.,0
Fixed issues with conv2d in Theano backend (#5528),0
"In the meantime, the tf.Variable from tf.random.Generator is not showing up in the model/layer.weights since keras only auto track the weights from sub-layer or sub tf.Module.",0
This requires merging of assuming regions before broadcast propagation.,0
Changing the name of the boolean & flipping its behavior so that the default is True and when set to False the bias is not used.,0
* Fixed test,0
Fix unit tests for Merge,0
* Format docstrings to follow the project code style.,0
Contents: <SoftThresPerc_TIL.SoftThresPerc object at 0x7f12932d7908>.,0
PiperOrigin-RevId: 486809443,0
[keras/mixed_precision/loss_scale_optimizer.py] Docstring minor improvements,0
Fix TypeError positional argument when used conjointly with tf-addons wrappers,0
* Fixed formating.,0
* Specify explicit epochs=20,0
"ExtensionTypes that want to support these layers can do so by adding dispatch.  (E.g., tf.matmul supports dispatch; but tf.raw_ops.MatMul does not.)",0
1. Add a wrapper named `_update_step_xla()` to wrap `update_step()` in order to use XLA acceleration.,0
* Sync the callback API,0
true/false -> True/False,0
limit progress bar update rate (#2860),0
* Slightly refactor SGD.,0
"* Reduce network size, reduce dropout rate, reduce dense units",0
"* Fixed the bug preventing to have block code in multiple sections in
docstrings.",0
* Refactor keras.engine.saving.preprocess_weights_for_loading().,0
FAQ updates (#5281),0
* - add arbitrary n-gram range,0
Here I set val_samples as 10 and batch_size is set as 100 in generator for consideration of processing speed.,0
* Fix documentation error,0
What does `inputs` look like at that point?,0
Available metrics are: WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_accuracy` which is not available.,0
[RELNOTES] [P] Write to TensorBoard every x samples. (#11152),0
"If you're still interested in pursing this (and responding to my comments), please feel free to reopen!",0
"This refactor allows the inherited method to work properly for
Sequential and Graph (with single input) containers in addition
to normal layers, so there's no need to override the method.",0
"- Add useful tools like jupyter notebook, ipdb, sklearn for experiments",0
It is not clear why displaying it (rather than any other parameter) helps with debugging.,0
"Still to-do: Update all docstrings, expose as compat.v1 apis, finish guide.",0
A user-visible string got mangled by a buggy string autoformatting package.,0
* Speed up tests,0
PiperOrigin-RevId: 382422309,0
Fix typo (#5347),0
PiperOrigin-RevId: 355451756,0
change rounding mode in theano backend to match tensorflow backend (#5089),0
Fix typos (#6879),0
* Fixed typo,0
"* In Tensorflow backend, let batch norm call to FusedBatchNorm only NHWC format, also gamma and beta are not None.",0
Reasons:,0
Update docs for 2.2.0.,0
Fix typo in docstring.,0
* Revert stateful metrics documentation until the API stabilizes,0
"Previously, __call__ did not get the speed benefits from caching
because it disabled it in order to feed the layer new input.",0
PiperOrigin-RevId: 394586210,0
Improve a number of error messages in Keras layers.,0
Remove CategoryCrossing layer,0
Added batch as formatting parameter during ModelCheckpoint callback,0
Hope it might help you integrate with keras.,0
"Not changing keras.backend, because that gives ImportErrors due to
a circular import (conv_utils uses the backend, and is imported
before generic_utils in utils/__init__.py)",0
PiperOrigin-RevId: 487424923,0
* Update metrics.py,0
How do you feel about this?,0
Add model_utils.print_graph_layer_shapes to handle Graph models.,0
update cntk 2.3.1 with py 36 wheel,0
Failing for a bad batch size is better than secretly running and producing bad results when the shader is written with a certain assumption.,0
I did it in this ugly way to allow for non-defined shapes (even though this is an odd case for images) and to minimize memory usage.,0
"Now the mentioned members are set in the `build` method and the
`set_previous` method calls the `build` method every time the
input changes.",0
PiperOrigin-RevId: 379868721,0
follow fchollet review comment. use `if not`.,0
"* fixed flakey test, auto-dense in KTH.eval",0
Add API conversion interface for Dense layer.,0
Use callback to print generated text in lstm_text_generation example (#8938),0
I tried to make it as similar to existing codebase as possible.,0
"Previously the __init__py in optimizers/ folder does not include rmsprop, adamax and adamw, so they are not caught when updating golden.",0
* update ci test with cntk 2.1,0
The error message present in ConvLSTM2D as documented by [this thread](https://github.com/tensorflow/tensorflow/issues/36901) is still persistent.,0
"So, I am waiting to hear your thoughts on the matter.",0
Make custom_object_scope thread-local,0
add stack to numpy backend (#11629),0
* TF convnets perf improvement: fused BN + native bias_add for NCHW.,0
* Fixed line lengths in backend tests file.,0
Hence I don't understand what this metric is supposed to be useful for...?,0
"There is no benefit in allowing any order, and it makes the code less complex
if it can assume the reduction dimensions are sorted.",0
Received: some_function,0
- This PR first depends on #7060 to pass,0
@pranv you can submit a PR to the `caffe` branch in Keras.,0
PiperOrigin-RevId: 474621706,0
Hinton mentions to 'keep citing the slides' for this method.,0
PiperOrigin-RevId: 481720094,0
#NAME?,0
"I'm considering taking the [beam search test values](https://github.com/tensorflow/tensorflow/blob/92985e67564c119203f0aaca94b5a334d87c35e4/tensorflow/python/kernel_tests/ctc_decoder_ops_test.py#L176) from TF, looks good to you?",0
Fix saved model for TextVectorization with a vocab set on init,0
Please consider using the`keras.utils.Sequence class.,0
"* Also clarify that the default activation for recurrent is
  `hard_sigmoid`.",0
Add option (re-)initialize weights in set_previous,0
* Update .travis.yml,0
* updated for list check bug in predict/predict_on_batch,0
Allow predict() to return RaggedTensor,0
* Change progbar interval from 0.05 to 0.1,0
Good thoughts!,0
* Rename file to be more descriptive,0
ValueError: Operation u'init_165' has been marked as not fetchable.,0
"Previously we wrap `update_step()` on the fly to be a tf.function, which created a lot of overheads.",0
PiperOrigin-RevId: 496507496,0
* remove useless padding code,0
This PR always returns a copy to ensure that any change made to `struct` after calling this function does not propagate to the original `struct` which leads t...,0
"Can I follow this issue and assume you'll post updates here, or is there another ticket?",0
"The squeeze implementation tells Theano to make
    the dummy dimension broadcastable, and then calls Theano's ""squeeze"",
    which removes ALL the broadcastable dimensions; not just the dummy
    dimension, but also the length 1 dimension flagged as broadcastable
    by reshape.",0
"Same case as for Bidirectional, except that in TimeDistributed there's only
    one nested layer instead of two.",0
Fix indentation for Keras pull request 15286,0
Fix typos on comments and docstrings (#9220),0
We don't keep the original argument because that's a bad arg name.,0
* Correction to the set_value() function,0
* Whitespace,0
Remove in(out)bound_nodes,0
"Update some of the refactorings to get line lengths under control by
extracting sub-expressions to their own variables ratther than
wrapping long lines.",0
Do you assume that the entire dataset to be shuffled fits in memory?,0
PiperOrigin-RevId: 406399754,0
typo,0
* Use // instead,0
Update lr in LearningRateScheduler. (#8888),0
PiperOrigin-RevId: 478587439,0
* simplify check if cntk for test,0
* Add an explanation about padding in Conv1d,0
* 1. add default value -1 for parameter axis in batch_normalization function in backend.,0
* Add metric API changes part 2,0
* Parametrized the bilinear test.,0
"So I think to save others' future hard work, it's better to make it right at the beginning.",0
Improve TF backend's Switch function (#7958),0
ImageDataGenerator.flow_from_directory() is outputting the wrong shape data,0
"In predict(), the variable ins only have inputs.",0
PiperOrigin-RevId: 410089237,0
https://github.com/tensorflow/tensorflow/issues/60314,0
Add `Model.save_spec` property to get the model's call argument TensorSpecs.,0
"* Added the possibility to choose how frequently tensorboard should log
the metrics and losses.",0
"Class activation maps using resnet50, inception-resnet-v2, and nasnet model (#11820)",0
PiperOrigin-RevId: 359580709,0
Added an error message for undefined shape on NASNet. (#9891),0
- rename inbound_nodes to _inbound_nodes,0
* fix theano batch_dot for 2d inputs,0
full issue: https://github.com/fchollet/keras/pull/7033,0
Embedding Layer Input Dimension Problem,0
"Instead, I have added a check for whether the passed `weights` array
is empty, this avoids tripping the bug.",0
PiperOrigin-RevId: 420197457,0
Fix test failures under NumPy 1.24.,0
debugging,0
Add tests for inputs set dynamically (#10416),0
Currently I am using Keras 1.1.1 and Theano-0.9.0.dev4.,0
"commit 13548e8b212b504c9f506495b01855de6d9f6117
Author: Taehoon Lee <me@taehoonlee.com>
Date:   Thu Jun 7 03:51:37 2018 +0900",0
Fix typo in Layer.add_loss. (#7657),0
"If this seems suitable, the next step is the improvement of the tests themselves.",0
Btw. https://keras.io/layers/writing-your-own-keras-layers/ shows an older version of this page.,0
"Fix OrthogonalRegularizer to implement the (1,1) matrix norm.",0
Use RewriterConfig to control `assume_valid_feeds` for GenericLayoutOptimizer.,0
Feel free to introduce this there.,0
* Fix merge_dot tests,0
"@fchollet If possible, can you remove the extra import I added in engine/training.py ?",0
* Refactored preprocess_weights_for_loading() to allow for loading to TimeDistributed and Bidirectional.,0
* disable theano for dropout,0
Add API conversion interface for MaxPooling1D layer (#5667),0
* change to zoom_range,0
PiperOrigin-RevId: 467247602,0
* deleted custom padding/replaced by a slice,0
* handle case when ndim is None,0
fixed the document string for all newly added layers,0
"Also, the OrderedDict
allows the user to simple .values() and use it as a list if he knows in which
order the inputs were merged.",0
change docstring in Convolution3D,0
"`test_model_methods` became `test_model_methods`, `test_fit_generator` and `test_fit_generator_shape` with two helper functions, `get_model` and `TrackerCallback`.",0
* Revert 9273,0
PiperOrigin-RevId: 485485280,0
- The plural form `initial_states` is used throughout the code and documentation.,0
s/conjonction/conjunction/g,0
Disable flaky `keras/rnn/gru_test_gpu` in OSS Presubmits.,0
simplify backend check bug fix,0
Fix typo in docstrings.,0
PiperOrigin-RevId: 437340074,0
tf.keras.utils.get_file option of 'cached_dir' is not properly set for values that do not expand from user-directory,0
Breaking down the attention API PR: part 2 (#11140),0
* with patch('six.moves.input') as mock:,0
Add a new mode for backend.RandomGenerator.,0
https://github.com/keras-team/keras/pull/8829/commits/b847f4235c4595432397d8c5486c6eaad4a08f00,0
Resolves the issue #11382,0
"For loops replaced with list comprehensions and changed the starting point
of the final for loop depending on the check_batch_axis argument.",0
### Summary,0
"Still, HDF5Matrix, CSVLogger and keras.preprocess.image.load_img()
are difficult to fix without changing their API.",0
Add arg `custom_shape` to method `add_variable_from_reference()` so that users can control the shape of optimizer variables.,0
add audio models: audio_convnet and audio_conv_rnn (#3718),0
* Delete VSWorkspaceState.json,0
"I didn't think to re-read the docs because I am already reasonably conversant in keras, but I did look for an example, and not finding one I searched the github issues for clues.",0
"This change allows saving models to memory-mapped files that do not have a physical presence on disk, and extraction of the serialized model data as a raw binary byte stream.",0
Faster and more accurate sentiment analysis using combination of convolutional and recurrent layers.,0
Keras 2 _*generator displaying warning always about semantic changes from Keras 1 (#7001),0
User just need to feed in any existing keras_tensor as inputs to the model when constructing it.,0
"If y'all decide this is the right fix after all, feel free to submit it yourselves.",0
* Doc update,0
"We can fix that
by using the dynamic shape to calculate padding for output_sequence_length.",0
You want it to be not in separate file (audio_utils.py) but copy&pasted in both audio_convnet.py and audio_conv_rnn.py?,0
#   warnings.warn('Custom mask layers require a config and must override ',0
Added stacked what where autoencoder. (#3616),0
AssertionError:  mnist_cnn.py,0
"4. Remove epsilon_std, since (standard) VAE uses isotropic gaussian prior.",0
Return None when not masking Embedding.,0
Increase the version for keras.,0
Does h5py sound more like an option extra or a test requirement?,0
"Additionally, (not sure about this, or whether it is important) the implementation of the attention operation may be able to avoid materializing an N by M `attention_mask` when only `key_mask` or `query_mask` is provided.",0
Thoughts?,0
* Revert "Replace ceil() with faster a operation",0
based on my similar fix at https://github.com/farizrahman4u/keras-contrib/pull/182,0
[1] http://keras.io/preprocessing/image/,0
* add unit tests,0
test config and weight init in batch normalization,0
- test just by save/load model weights instead of calling preprocess_weights_for_loading() directly,0
* Duck typing (as soon as test passes tuple as a list),0
"Test result:
test env: with Tensorflow(commit a543d9471047ca3f6881c87105fcbe2cdff9207d Date:   Thu May 10 17:43:30 2018, local build), python3.4, centos7.4
test cases:
  ""pytest  ./tests/keras/layers/normalization_test.py""  <all passed>
  ""pytest  ./tests""      <keep same result as without this commit's modification on BN>",0
PiperOrigin-RevId: 538803225,0
I'm still thinking how to handle this situation but I'm open to suggestions.,0
"If this fix is not important in your opinion - I do not argue, you are a maintainer and you know better!",0
"Moving `assuming_all` ops over assuming region unblocks merging assuming
regions.",0
* equip TimeDistributed with mask and unspecified input length,0
Add another backup url from bazel mirror so that we can still build with old version until there is an alternative solution.,0
The log level for the "Using X backend" messages has been set to "debug" since if everything is working as expected there is no need to inform about which backend is being used.,0
"NEVERTHELESS, _they can just paste this as pre-formatted text_ -- the markdown doesn't confer much advantage (are they going to paste it in a spreadsheet?), so...

...what do you think about this for the current version (and default if we offer options in the future, or separate calls, like model.summary_csv()).",0
There appears to a number of issues,0
Please take a look at [gist](https://colab.research.google.com/drive/1ynkoCxW9RPh8s0HgUAo_N0pNDrUXOqKk?usp=sharing) to see that the code changes in this PR actually works. (To see sub-graph plot on passing `layer_range`),0
* Fixed identation,0
"4. Evaluate `Tensor::flat<tstring>()` once for each of the key tensors, instead of re-evaluating it for each key, and similarly for the missing-assumed-empty tensor.",0
* ci: add whitespace around arithmetic operator for PEP8-check,0
TF convnets perf improvement: fused BN + native bias_add for NCHW. (#8785),0
"Before this change, if you leave the default `patience=0`, training always stops after the second epoch.",0
Copy the current optimizer to legacy namespace.,0
"This gives a consistent default across the preprocessing layers, and is the more efficient option.",0
* correct the PEP8's E128 error,0
Instead of norm clipping they do an elementwise clip.,0
I hope it will be helpful for someone =,0
Fix function serialization + deserialization where the function has values captured in its closure. (#8592),0
ImageDataGenerator return dtype vs  ImageDataGenerator.flow_from_dataframe dtype mismatch,0
* fixing a blank line to appease pep8,0
Remove deprecated model.model from engine/saving (#10275),0
`os.listdir` to `sorted(os.listdir)` for alphabetical order instead of arbitrary order.,0
FEATURES="assume-digests binpkg-logs config-protect-if-modified distlocks ebuild-locks fixlafiles merge-sync news nostrip parallel-fetch preserve-libs protect-owned sandbox sfperms splitdebug strict unknown-features-warn unmerge-logs unmerge-orphans userfetch userpriv usersandbox usersync xattr",0
* CI reinit,0
added support for padded_batch and fixed comments,0
fix initialization of BatchNormalization,0
* training.py fix test error,0
"Instead of

	K.std(x)

the user is able to write

	K.sqrt(K.var(x) + self.epsilon)

avoiding a division by zero in the gradient computation of `sqrt`.",0
* Correct `callbacks` description docstrings,0
Fix for #10265,0
"Therefore, a new `'methods'` key is introduced to make this distinction.",0
Rename random_seed => seed (#8235),0
This PR allows the reader to quickly know what differs from one test to another.,0
Move tests for applications (#10341),0
"While the code in LossScaleOptimizer is copied to LossScaleOptimizerV3, there are still many helper functions/classes that the two classes use, so most of the loss scaling-related code is not copied.",0
All the work to do the porting back and forth for prs  between keras and tf.keras.,0
Add documentation for embeddings,0
The only problem (and a big problem at that) are the ops involved in shape constraints: cstr* ops as well as shape.assuming*.,0
I would really appreciate any help.,0
* Add more tests,0
* Allow multiple inputs and validate input data,0
You can use this API to build any kind of new model / container.,0
"This change also enables models with multiple input arguments to be saved, for example:

```
class Subclass(keras.Model):

  def call(self, a, b):
    ...
```",0
* Comment out functional guide test,0
tf.keras.preprocessing.image.smart_resize does not accept a batch of images.,0
"Is this the right move for us to do this, or should we expect TF to do it?",0
Would there be any potential conflicts in the proposed extension to also include images of 2 channels?,0
* support mask in recurrent layer,0
"acgan: Use Generator/Discriminator more closely resembling the ones from the referenced paper, and don't train discriminator to produce class labels for generated images (#8482)",0
See https://numpy.org/neps/nep-0034-infer-dtype-is-object.html .,0
@joelthchao do you have an opinion about this?,0
"## error occured
```
---------------------------------------------------------------------------
IndexError                                Traceback (most recent call last)
<ipython-input-2-c38539c7e5b8> in <module>()
    385 # run the experiments
    386 net2wider_experiment()
--> 387 net2deeper_experiment()

<ipython-input-2-c38539c7e5b8> in net2deeper_experiment()
    375                               x_test, y_test,
    376                               init='net2deeper',
--> 377                               epochs=epochs)
    378 
    379 

<ipython-input-2-c38539c7e5b8> in make_deeper_student_model(teacher_model, x_train, y_train, x_test, y_test, init, epochs)
    301     if init == 'net2deeper':
    302         prev_w, _ = model.get_layer('conv2').get_weights()
--> 303         new_weights = deeper2net_conv2d(prev_w)
    304         model.add(Conv2D(64, 3, padding='same',
    305                          name='conv2-deeper', weights=new_weights))

<ipython-input-2-c38539c7e5b8> in deeper2net_conv2d(teacher_w)
    196     student_w = np.zeros_like(teacher_w)
    197     for i in range(filters):
--> 198         student_w[(kh - 1) / 2, (kw - 1) / 2, i, i] = 1.
    199     student_b = np.zeros(filters)
    200     return student_w, student_b

IndexError: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices
```",0
Also fixed the test_no_grad that was catching ValueErrors that had nothing to do with not having a gradient. (#10647),0
* stastify the PEP style,0
"In particular, it must not be used from within
   `Layer.call()`, even if the model is trained with `Model.fit()`.",0
Could you reconsider it?,0
* Remove mode argument from on_epoch_begin and on_epoch_end,0
* training.py _weighted_masked_objective fix crash when weights is None,0
"Consider the following model:

```
m1  = Sequential()
m1.add(LSTM(....))

m2 = Sequential()
m2.add(Embedding(...))
m2.add(m1)

m2.compile(...)
m2.fit(x,y)
```",0
* fix broadcasting in theano backend,0
This removes a lot of boilerplate and complexity.,0
PiperOrigin-RevId: 360954528,0
"As far as the optimizers, I'm not sure what should go in the parent class.",0
+ reduce function disappeared (requires import from functools),0
* fix list_devices() function is not available issue,0
* api change,0
* Add docstrings,0
"We had a tf.cond which called tf.image.resize on one path (returning float32) and
cropping the input dtype on the other, which lead to a error.",0
add Scaled Exponential Linear Unit activation (#6924),0
The mayor optimisation a part of the Max over time are:,0
Reason: This is because the `tiled_mask_t` is not updated correctly for each `states[i]` but instead is simply copied from that of the `output` (`states[0]`).,0
PiperOrigin-RevId: 404825596,0
* Replace tensorflow deprecated attribute : reduction_indices -> axis (#7126),0
* Fix TypeError message,0
Converts word_index to 0-based indexing.,0
(.text._ZN3ruy6detail36CreateTrMulParamsAssumingColMajorDstILNS_4PathE113EhhisEEvRKNS_3MatIT0_EERKNS3_IT1_EERKNS3_IT3_EERKNS_9MulParamsIT2_SC_EENS_16ChannelDimensionEPNS_3CtxEPNS_11TrMulParamsE[_ZN3ruy6detail36CreateTrMulParamsAssumingColMajorDstILNS_4PathE113EhhisEEvRKNS_3MatIT0_EERKNS3_IT1_EERKNS3_IT3_EERKNS_9MulParamsIT2_SC_EENS_16ChannelDimensionEPNS_3CtxEPNS_11TrMulParamsE]+0x2a6): undefined reference to `ruy::Allocator::AllocateBytes(long)',0
* [skip ci] remove unnecessary check,0
Remove spurious warning.,0
PiperOrigin-RevId: 393553060,0
* Undone changes made:Revert "casted ReduceLRonPlateau lr log to float",0
"--
c80cd7f67b0839d263a48f2dbe29f7113c95ea42 by Albert Villanova del Moral <8515462+albertvillanova@users.noreply.github.com>:",0
* Fix typos in docs/templates/datasets.md,0
Merge pull request #1338 from rpinsler/master,0
* Remove outdated example code for manual division by global_batch_size.,0
Cast constants in optimizer as floatx.,0
[P] Use with to ensure no resource leak in get_word_index() (#11975),0
Update metrics.py,0
I don't know if it is any good.,0
This change resolves two inconsistencies:,0
I've never seen the abbreviation "ce" for crossentropy.,0
Add spaces around subtraction,0
"When TPUStrategy is used, we force jit_compile=False since TPU by default turns on XLA.",0
Revert "Update metrics.py",0
PiperOrigin-RevId: 435468686,0
Broadcast mask to input during normalization.,0
PiperOrigin-RevId: 431196813,0
Do you have any thoughts for making this work for Sequential models?,0
* Update comment,0
PiperOrigin-RevId: 464573876,0
"* Update docs, parameters, and styles",0
Fix missing return line in the print log.,0
* Code review is in progress,0
Change the default random algo for tf.random.Generator to be auto-select.,0
Update image.py (#6618),0
* github PR review:,0
Add example to tf.keras.layers.deserialize function,0
* Allow shift_range to be 1-D array-like or int,0
The log level for these messages has been set to "debug" as if everything works as expected there is no need to inform about which backend is used.,0
"commit 0fe6e02699e2da553f8f1a866aaaa081c26a1cbd
Author: Michael Oliver <michael.d.oliver@gmail.com>
Date:   Mon Apr 4 03:35:29 2016 +0000",0
Test with some travis steps removes,0
PiperOrigin-RevId: 399706416,0
6. Use adam instead of rmsprop,0
Enable Keras functional model building from intermediate tensor.,0
* raise error if is_keras_tensor is called on a non-tensor object,0
"It isn't clear at all what it means to train a model when you don't have a 1:1 mapping between inputs and targets/outputs, in the general case.",0
* Change the GRU parameter "variant" to "reset_after" based on code review.,0
PiperOrigin-RevId: 475911899,0
"For instance, the actual batch size of incoming Tensors can be different if the `batch_size` specified in `predict()` is set differently from `keras.Input`, or if the last batch is incomplete because the data size is not a multiple of the batch size.",0
Resolves the acute symptoms in https://github.com/fchollet/keras/issues/3357,0
fix: Sort subdirs before mapping them to classes. (#3052),0
Merge pull request #1336 from wb14123/loop,0
"When a class inherits from object without defining __init__,
AttributeError is raised instead of TypeError.",0
ACGAN : Remove lines with no effect (#4503),0
Added quick tests.,0
"- put both implementations together, differentiate by argument ""variant""",0
Add initial version of Theano/TensorFlow backends,0
* fixed some more len/shape issues for fit_generator,0
* Added optional path argument,0
PiperOrigin-RevId: 432554966,0
"Bug fix, batch_size set instead of default one (#3590)",0
"* remove skimage dependency, rename the file",0
LeakyReLU returns a tensor with float64 dtype.,0
* spelling mistake trining -> training,0
Output int64 by default from Discretization,0
* fixed shaddowig of log_probs,0
* Set padding value for the missing keys to 0.,0
"Most importantly, the `input_shape` argument.",0
May it be caused by feeding `attended` which is not recieved from `Input`? Or what may be the reason if someone knows?,0
"- the name is ambiguous, since ""shared"" is a reserved keyword in Theano development.",0
"The (input_type='masked', reduction='auto') case fails (doesn't match the ragged case) before this change.",0
PiperOrigin-RevId: 427277621,0
Added hinge loss for categorical classification (#6687),0
It's annoying to have to think about adding `@keras_test` all the time.,0
"- If `Lambda` can not be stacked over a `join` `Merge`, its worthless.",0
* Fix pep8 error,0
This reverts commit 2942328112dc694d47b44b7a0929a9496247cde5.,0
Add support for dynamic RNNs in TensorFlow. (#3474),0
Add dummy data generation code to 'Multilayer Perceptron (MLP) for multi-class softmax classification' example.,0
"Also allow the weights used in the test to have proper gradients, and make the input shape key in config consistent across Sequential and other models.",0
* fix dtype issue,0
* Updated test,0
Make tensorflow backend fully mimic theano.dot,0
* Simplify the unit_test for rnn with additional states,0
These types are converted to float32 or float64 as appropriate.,0
* 1. Add axis parameter in backend's batch_normalization functions.,0
* Support constants in StackedRNNCells,0
"commit 25a8973dfce5251c0bd527ffa16ce17174b94218
Author: Taehoon Lee <me@taehoonlee.com>
Date:   Wed May 23 04:18:46 2018 +0900",0
Add a TODO for removing the extra tf.function in keras.dtensor.,0
[1] https://github.com/keras-team/keras-preprocessing/pull/29,0
* Used update_freq instead of write_step.,0
"Currently,  only 3D input is supported by the rnn function.",0
Feel free to update since 5.1 has better support for the Pascal Architecture of the 1060-1080 GPUs.,0
Splitting the test_model_method which had more than 400 LOC. (#11398),0
* Fix docstring content,0
"We do in fact already have something analogous to example testing / integration testing, in `test_tasks.py`.",0
I took the code from https://gist.github.com/rduplain/1249199,0
Rename "params" to "trainable_weights",0
I have a GAN model that worked fine with keras 1.2. I submitted a training on a machine with keras 2.1.,0
"Only track their weights/losses via the object-oriented style, and no double-counting",0
"--
d29974bccd731c423e5acd1ce297afb0494057b2 by Ashutosh Hathidara <ashutosh.hathidara@legatohealth.com>:

Fixed bazel errors",0
"--
67e723d2c14127f200e2830e94f1999296f60969 by pizzy <horlasehinde@gmail.com>:",0
PiperOrigin-RevId: 411652148,0
* add cos + sin + tests to numpy backend,0
* better tests,0
"I've experienced speed gains in my application by making the following modification: Have the batch slicing operation done on the host side using multiple cpus, and then each GPU can pull its own relevant slice of data.",0
Write TensorBoard Histograms with Tensor names (#3635),0
PiperOrigin-RevId: 357874763,0
* Update sequence.md.,0
PiperOrigin-RevId: 382347472,0
Dot/cos merge : bug fix (#3708),0
Fix typo in writing-your-own-keras-layers.md (#11325),0
"Adding explicit output_size to cell
so that the contract is not inferred by state_size anymore.",0
Fixes for Python 3 (#4121),0
(I have no strong opinion on this because I have not investigated the problem).,0
PiperOrigin-RevId: 430086240,0
"The stackedRNNCells is also updated to by default return natural
order state_size as the cells' state, instead of reverse order.",0
ACGAN: Remove unnecessary dimension in label input (#4501),0
"- CuDNN layers can be instantiated only inside test with required backed,
  not in the pytest decorator",0
"When providing an list of labels, tensorflow.keras.preprocessing.image_dataset_from_directory cannot find images in root of specified directory",0
"--
64afe2d199ec4513223bbf5176835bf681cf056b by Amogh Joshi <67437306+amogh7joshi@users.noreply.github.com>:",0
Fix typo: categorial -> categorical,0
* add resnet50 example,0
#NAME?,0
* update the recommandation.,0
Squashed commit of the following:,0
PiperOrigin-RevId: 420339539,0
"I started by looking at how I might insert nodes, but quickly discovered that although Keras provides easy methods to grow a model ""downstream"", it is difficult to remove nodes from the ""upstream"" of a Model, or to, more ambitiously, ""rebase"" or ""graft"" a portion of a Model onto another one.",0
better error message when ReduceLROnPlateau conditioned on non-existing metric (#7134),0
"This commit delays the check for pydot until it is
actually used, in line with the treatment of a PIL.Image dependency
in keras/preprocessing/image.py",0
So I wish to 're-fit' [update NOT re-train] the model with new data such that model parameters are just updated and not re-initialized.,0
PiperOrigin-RevId: 394625024,0
"If anyone has a solution for that, feel free to update.",0
* update equation,0
---,0
* Update preprocessing/applications integration,0
"""total_loss"" -> ""loss""",0
Fixes to example/stateful_lstm.py (#7928),0
PiperOrigin-RevId: 462446908,0
Fix kullback_leibler_divergence (#4800),0
"Add mean after sum to fix this, such that always a scalar is returned.",0
"conv3d2d uses 2d convs to create a 3d conv, so I wonder if it would be possible to implement strides efficiently inside conv3d2d by using strides in the conv2d calls.",0
"Not sure what conversation this is a part of, there are a few conversations hovering around using TFRecords (e.g. #6928 and #8287)",0
"When I use model.fit_generator as following:
>history = model.fit_generator(train_data_generator, samples_per_epoch=train_data_generator.nb_sample,
                              nb_epoch=nb_epoch, verbose=1, callbacks=[early_stopping, model_checkpoint],
                              validation_data=test_data_generator, nb_val_samples=test_data_generator.nb_sample,
                              max_q_size=10, nb_worker=8, pickle_safe=True)
I found that the validation process consumes much longer time than training despite it contains less data.",0
"[keras/utils/audio_dataset.py,keras/utils/conv_utils.py,keras/utils/data_utils.py,keras/utils/dataset_utils.py,keras/utils/feature_space.py,keras/utils/generic_utils.py,keras/utils/image_dataset.py,keras/utils/image_utils.py,keras/utils/layer_utils.py,keras/utils/losses_utils.py,keras/utils/metrics_utils.py,keras/utils/text_dataset.py] Standardise docstring usage of ""Default to""",0
The same fix was applied to the `tf.keras.backend.sigmoid` function and the `tf.keras.layers.Sigmoid` layer.,0
Input Source operations connected to node sequential_3/embedding_3/embedding_lookup:  sequential_3/embedding_3/embedding_lookup/12643 (defined at /home/jpandeinge/anaconda3/lib/python3.7/contextlib.py:112)  Function call stack: train_function,0
* Added padding test case for AveragePooling1D,0
This was kept as a temporary measure to preserve backwards compatibility.,0
What are your thoughts on this?,0
Update regularizers.py,0
"This is related to b/226547716: in optimizer like compact adagrad, the optimizer variable is by intention set as a different shape from the model variable to reduce memory cost: go/alise-ml/compact_adagrad.",0
Add ParameterServerStrategy combination to ketrics_metrics_test.,0
[MLIR][MHLO] Move `cstr_broadcastable` and `shape_of` out of `assuming` regions,0
"Applying `LossScalerOptimizer` to them raises the following error:

```
File "".../python3.9/site-packages/keras/mixed_precision/loss_scale_optimizer.py"", line 671, in _apply_gradients
    self._optimizer.apply_gradients(

TypeError: apply_gradients() takes 2 positional arguments but 3 were given
```

Which can be easily fixed by transforming `name` into a named argument.",0
Add new target for tensorflow_core which doesn't contain keras.,0
Will we be able to reclaim our build?,0
* Fix a issue when only specify one dot_axes for in the Merge layer,0
Bump the keras version to 2.11 for nightly.,0
* load_weights reshape parameter added,0
Python 2.7 needs __pil__ but _all other_ currently supported versions of Python need __Pillow__ instead.,0
* Update image.py documentation,0
* Update functional-api-guide.md,0
Update local.py docstrings (#13373),0
"Add constraint fusion pass to simplify constraints and to merge all assuming
regions of a function.",0
Can you provide a few screenshots of what the plots look like?,0
"* remove expection(), add one empty line at end, turn K to k for backend tests to avoid confusion.",0
"@ahundt, I'd like to see this merged, too.",0
"If it sounded confusing, I'm sorry.",0
- add code for weights conversion similar to CuDNNLSTM (except for biases),0
"After this change, no upranking is applied.",0
PiperOrigin-RevId: 452831406,0
Fix common LaTeX encoding issue,0
PiperOrigin-RevId: 380934634,0
I would appreciate if I could get some information on the usage of it.,0
Update convolutional.py (#10452),0
Workaround is to create a copy of the dict and `update` it with the other dict.,0
Add a model.check_trainable_weights_consistency (#8234),0
Add output shape equation to docstrings,0
PiperOrigin-RevId: 408777016,0
* Replace uses of getargspec with the new has_arg function,0
"But in the implementation tensorflow implementation as well as the [MobileNet Paper](https://arxiv.org/pdf/1704.04861.pdf) (see page 3 formula 3), a different kernel is applied per channel.",0
* limit progress bar update rate,0
"My original docs were:
```Python
shared_axes: the axes along with to share parameters for
 -                     the activation function. For example if the
 -                     incoming feature maps from a 2D convolution
 -                     has dimensions 16x32x32 and you wish to share
 -                     parameters across space so that each feature
 -                     maps only has one set of parameters, set
 -                     shared_axes = [1, 2]
```",0
Keras was using stateful RNG op in various place when seed is not provided.,0
"Add Preprocessing Layer support in Keras v3 saving (IntegerLookup, StringLoop, TextVectorization).",0
`ZeroDivisionError` when using `class_mode=None` with `ImageDataGenerator.flow_from_directory()`,0
PiperOrigin-RevId: 479397788,0
* Add F measure test,0
For splitting we are adding support for character level splitting of text.,0
PiperOrigin-RevId: 355282407,0
* fix the reversed rnn bug,0
The current way of putting None check inside tf.cond does not work well in graph mode.,0
"If you think it is important, feel free to merge it.",0
Add nesterov acceleration support to SGD optimizer.,0
PiperOrigin-RevId: 437336145,0
"WARNING:tensorflow:Can save best model only with val_loss available, skipping.",0
Allow weights trained with CuDNNGRU to be used without GPU (#9112),0
* change to binary mode in gcs file transfer,0
* update,0
Use six for wrapping in keras_test (#4235),0
* training.py restate set more cleanly,0
"It only accepts one reduce dimension at a
time.",0
* Docstrings; remove dropout_keep_prob in doc,0
We would like normalization to be usable for unbatched multidimensional samples data in a dataset.,0
* Add a unit test for `fetches` passed to K.function().,0
"* Revert ""Theano cudnn code now throws Exception when it is not available, need to catch this""",0
Change keras.backend.RandomGenerator to be a trackable for savemodel.,0
PiperOrigin-RevId: 417662901,0
Batch size support for histograms introduced in #6065.,0
Update keras.sparse_top_k_categorical_accuracy to use dynamic shape info when reshape.,0
* MAI: refine error messages for `pydot` and GraphViz,0
"update Convolution3D, MaxPooling3D and AveragePooling3D, add UpSampling3D and ZeroPadding3D",0
let me know what you guys think.,0
removing pudb line,0
* add Scaled Exponential Linear Unit activation,0
"And if you think my PR has a little work,Hoping you could merge it.",0
* Update pooling.py,0
* Fix error messages.,0
"commit 52e3f9835c1a25a8b895773f64524e27a5ae10c0
Author: Anirudh Swaminathan <aniswami97@gmail.com>
Date:   Sun Jun 3 01:22:09 2018 +0800",0
PiperOrigin-RevId: 474040485,0
That's a reasonable addition.,0
* Fix Conv2DTranspose test,0
(.text._ZN3ruy6detail36CreateTrMulParamsAssumingColMajorDstILNS_4PathE113EhhisEEvRKNS_3MatIT0_EERKNS3_IT1_EERKNS3_IT3_EERKNS_9MulParamsIT2_SC_EENS_16ChannelDimensionEPNS_3CtxEPNS_11TrMulParamsE[_ZN3ruy6detail36CreateTrMulParamsAssumingColMajorDstILNS_4PathE113EhhisEEvRKNS_3MatIT0_EERKNS3_IT1_EERKNS3_IT3_EERKNS_9MulParamsIT2_SC_EENS_16ChannelDimensionEPNS_3CtxEPNS_11TrMulParamsE]+0x22a): undefined reference to `ruy::Allocator::AllocateBytes(long)',0
PiperOrigin-RevId: 387644492,0
Move serialization-related logic in utils/generic_utils.py to saving/legacy/serialization.py.,0
* Update FAQ,0
* examples/lstm_stateful.py: add more documentation as per PR review,0
* bilinear upsampling initial implementation,0
* typo in var autoencodeur example,0
"* parantheses, not backslash",0
Initial Sparse Matrix Support (#3695),0
One behavior change is that `tf.keras.backend.softmax` and `tf.keras.layers.Softmax` no longer accept inputs of rank 1.,0
"Thus, we place the LearningRateSchedule in apply_gradients so that each update round only calls LearningRateSchedule once.",0
* make gcs filenames unique to allow for parallel execution of tests,0
- [x] This PR is backwards compatible [y/n],0
With this change we add a space between "the" and "tensors",0
Please consider this update to the text generation example.,0
* docstring fix for fit / fit_generator,0
I'd love to see this PR completed!,0
Bump the keras version to 2.7.,0
PiperOrigin-RevId: 437333889,0
This PR resolves two issues:,0
* Make ensure_value_to_cell function private (used inside func_load function),0
"* Support of sparse arrays as input in fit, predict and evaluate.",0
* models.py adds reshape,0
* Next step: Unit tests,0
I didn't catch when my original documentation was changed by @fchollet (overall for the better) but introducing this bug: https://github.com/fchollet/keras/issues/4851,0
* replicate example with paper's params,0
#NAME?,0
PiperOrigin-RevId: 385910950,0
"This matches the argument name in other
preprocessing layers (e.g. Hashing).",0
* Reduce zero threshold,0
#12076,0
Better error messages for Sequential,0
The interface for building functional model from tensor that is not tf.keras.Input is same as the existing tf.keras.Model().,0
* Include multi-output layer case during layer output type checking,0
I see three issues.,0
How to create a dynamic embedding layer in keras ?,0
Fix typo in FAQ,0
* fix docstring comments from review (#7113),0
Introduce a new public `convolution_op` method that subclasses can depend upon.,0
* Remove blank spaces.,0
* Update normalization.py,0
* Fix Mixup with `add` and `append`,0
* Add multi-input model test to TB callback,0
bug fix: can't use code blocks in multiple sections in docstrings. (#11508),0
* try again,0
Bug fix in convolutional recurrent state setting,0
"--
1223335a8d34a8ce656dbd10b2a236ef6204ff47 by Amogh Joshi <67437306+amogh7joshi@users.noreply.github.com>:",0
Added examples for fill_mode (#8859),0
- If `initial_states` is passed to `__call__` it is always treated as a tensor / list of tensors.,0
* Add a symbol to avoid indent,0
* Add custom_object_scope,0
* remove white spaces at the end of lines,0
* data_utils.py get_file() cache_dir docs (#5861),0
* Fix docstring to state that bilinear is the default,0
"This modification gives the user the ability to define, if the zoom transformation should be the same on the xy axes or seperate for each axis.",0
"* Add support of callbacks to internal loops as well as fit, predict and evaluate methods",0
"When set_previous was called, the mentioned members were not updated.",0
(.text._ZN3ruy6detail36CreateTrMulParamsAssumingColMajorDstILNS_4PathE113EaaiaEEvRKNS_3MatIT0_EERKNS3_IT1_EERKNS3_IT3_EERKNS_9MulParamsIT2_SC_EENS_16ChannelDimensionEPNS_3CtxEPNS_11TrMulParamsE[_ZN3ruy6detail36CreateTrMulParamsAssumingColMajorDstILNS_4PathE113EaaiaEEvRKNS_3MatIT0_EERKNS3_IT1_EERKNS3_IT3_EERKNS_9MulParamsIT2_SC_EENS_16ChannelDimensionEPNS_3CtxEPNS_11TrMulParamsE]+0x1e1): undefined reference to `ruy::Ctx::GetMainAllocator()',0
Removed unused function in autogen.py (#11872),0
* test_training.py _check_array_lengths() unit test,0
Fix DenseFeature layer missing from the API __init__ file.,0
I've just pushed a commit that refines the abstract interface.,0
Fixes following @fchollet revision,0
Add weighted_metrics arg to compile (#7536),0
"to show this, let's consider two examples:",0
correction on the description of y_true,0
A pending change to the histogram summary (https://github.com/tensorflow/tensorboard/pull/5093) breaks the Keras automatic outside compilation test when run without the MLIR bridge.,0
"# WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built.",0
* Add tests for generator-based methods,0
PiperOrigin-RevId: 472567932,0
Is this still something you want to include? Or might want to include in the future but not now?,0
Fixes https://github.com/keras-team/keras/issues/16146,0
# This is the 4th commit message:,0
Fix NotImplementedError in data_utils.py,0
Feel free to argue for/against either approach.,0
"* np.split --> np.array_split, making _save_attributes_to_hdf5_group() robust to unrealistically long layer names",0
* Rename visualize_util.py to vis_utils.py and and model plot direction,0
* Add API conversion interface for 'Global pooling',0
Docker image for test and experiment Keras (#3035),0
"@zachmayer, did you create a new PR?",0
* Added batch_size in tests/keras/test_callbacks.py::test_TensorBoard_convnet,0
Merge pull request #18076 from sampathweb:update-dev-container-py39,0
"@fchollet @bbartoldson Is monitoring the validation loss to reduce the learning rate ,when it reaches a plateau, not considered tweaking the parameters ?",0
@farizrahman4u any thoughts on getting S2S to look good in Keras?,0
#11383 Making backend_tests pass PEP8 test (#11411),0
* Changed behavior of weights sorting,0
"commit 56b255cc043f57e712a95a90819e5c005a2fee8a
Author: Francois Chollet <francois.chollet@gmail.com>
Date:   Wed Jun 6 10:51:06 2018 -0700",0
"The `EagerTensor` special case no longer uses the
passed-in context and instead checks `context.executing_eagerly()`
directly.",0
This reverts commit f6688c950a1d82cd499c65152bc2a191fd8c0128.,0
loading sparse_categorical_crossentropy as custom loss function gives different results to loading normally,0
* Update warning message for keywords.,0
I've wanted it before for making the output of Deconvolution2D layers the right size.,0
* fix pep8 and tensorflow backend failure,0
* model.fit(steps_per_epoch) added,0
"1. From [this](https://github.com/fchollet/keras/issues/68) link: when we do `datagen.fit(X_sample)`, do we assume that `X_sample` is a big enough chunk of data to calculate mean, perform feature centering/normalization and whitening on?",0
"Sadly the select() doesn't work for macro, but only for rule (see https://docs.bazel.build/versions/master/configurable-attributes.html#why-doesnt-select-work-in-macros).",0
* Docstring fixes.,0
Fix typo in README,0
Make PEP8 compliant and use int_shape,0
"Add dot_axes argument, used by the recently added dot merge mode.",0
PiperOrigin-RevId: 397792405,0
LossScaleOptimizerV3 subclasses from the experimental optimizer and wraps instances of the experimental optimizer.,0
[API DESIGN REVIEW] sample weight in ImageDataGenerator.flow,0
Recently I custum a video sequence DataGenerator (based on ImageDataGenerator) for experiment.,0
PiperOrigin-RevId: 379542858,0
Why can't I reproduce mnist_cnn.py in the Keras example?,0
* Fix indent,0
* TST: more test cases,0
* cifar10 resnet v1 and v2,0
Replace np.ceil() with a faster operation (#10184),0
* betterer,0
"It is stupid, but this line actually produces a float64 array:

```
    0.5*np.array(0.2, dtype=np.float32)
```",0
"* removed FunctionalRNNCell and AttentionRNN, added back support for constants in RNN",0
"In graph mode, tensors are specific to the graph they were created in, and using a tensor from a different graph is not allowed.",0
added documentation + a hint if hdf5/shuffle conflict suspected,0
"This is the easiest solution I can figure out, but after run this script, switch backend to theano and load 'th_resnet50.h5' we just generated, the test result is still not correct. ('n02443485 black-footed ferret, ferret, musterla nigrips' for both test images)",0
"See: https://github.com/Microsoft/CNTK/issues/2938
  (Slicing of arrays is strange and not numpy compatible)",0
"* Split a RNN weight loading test, so that non-CuDNN stuff can run on Travis CI.",0
* fix test code - PEP8,0
* update reshape to support free dimension,0
* fix(AlphaDropout): add get_config method,0
RELNOTES: This breaks weight loading and model loading/saving for models from Keras 0.* that used Merge layers.,0
* avoid expand_dims diff,0
PiperOrigin-RevId: 362614634,0
"Thank you, can we assume that every InternalError is the 'GPU sync failed' error?",0
* Update docstring,0
"- convert weights on model, not layer (not test nesting in models)",0
"@farizrahman4u Sorry about the unit tests, wasn't feeling well enough to code much.",0
* ignore tes_api,0
Testing,0
* better error message,0
add proper shape inference,0
Better error message when there is no gradient defined (#9170),0
Add more numpy-style attributes to HDF5Matrix (#6982),0
* Remove unnecessary cast garbage,0
* Minor renaming,0
assert ndim>=3,0
"* Fix function serialization + deserialization where the function
has values captured in its closure.",0
* fix for tf backends,0
fix typo for load array (#5315),0
Speed up random shifts in data augmentation,0
"* mnist_tfrecord.py and training.py fixed review comments, docs, and error messages (#7113)",0
"If we assume that you installed tensorflow after installing CUDA 11.1, the error messages indicate that CUDA 10.1 libs are still visible but not CUDNN 7.",0
Fix typos (#11340),0
"The theano nnet.relu function does something similar like this with the
LeakyReLU alpha parameter, which lead to a float64 tensor.",0
- [n] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date),0
Revert "Sync Keras optimizer with tf.keras optimizer (#12841)" (#12888),0
Can you provide a few examples of what the return strings look like for each version of TF?,0
PiperOrigin-RevId: 384725251,0
As discussed in [tensorflow issue 49933](https://github.com/tensorflow/tensorflow/issues/49933).,0
Is there any data on the potential benefits?,0
PiperOrigin-RevId: 387844394,0
"To clarify, here is my thought process:",0
"The only tests in `gru_v1_test.py` and `lstm_v1_test.py` are the ones that compare V1 and V2 for accuracy or performance, and V1 specific tests.",0
@zachmayer do you mind checking that you have run `git fetch mcarbajo` first?,0
- fail fast when converting incompatible weights,0
"1. Previously we grouped args together for readability, but it violates our style guide.",0
"I filed a new PR at #13892, let's see if it will be accepted. :)",0
"- A cropping of `(n, 0)` is now valid on any axis",0
Better error message for invalid functional api inputs (#6589) (#6593),0
ARM CI build passed but it's not testing with TF_ONEDNN_ASSUME_FROZEN_WEIGHTS=1,0
fix docstrings,0
"Fix unit test: test_finite_dataset_unknown_cardinality_no_step_with_train_and_val

self.assertEqual(batch_counter.batch_begin_count, 21)
AssertionError: 22 != 21",0
1.0.1 release,0
"However, this operation search for a key twice in the dict.",0
Added predict() for Sequential models,0
* fixed whitespace PEP8 issue,0
PiperOrigin-RevId: 380045050,0
* CONTRIBUTING.md keras-2 release update,0
PiperOrigin-RevId: 382778202,0
Fix https://github.com/tensorflow/tensorflow/issues/49930,0
"Please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`",0
"When ""fused"" mode is enabled, a constant 1 and 0 tensor of an appropriate shape is cached as a member variable in BatchNormalization.",0
PiperOrigin-RevId: 409065377,0
Remove upranking behavior from normalization,0
Temporarily don't try to expand tf.Variable.,0
Add documentation for optimizers,0
"--
7e718e6538e72d125bc5edc857c15fc2053877a2 by Zirui Zhuang <zr.zz.alp@gmail.com>:",0
#9642 Add kwarg and documentation for dilation_rate to SeparableConvs (#9844),0
fix typo in unit test,0
* Add exampe to compare RELU with SELU fchollet/keras#6924,0
* Enable reverse along multiple axes,0
PiperOrigin-RevId: 383923268,0
"## my environment
```
# python -V
Python 3.6.2
# pip freeze | grep Keras
Keras==2.0.9
# pip freeze | grep numpy
numpy==1.13.3
```",0
"commit a3664246de4bb8ef3232dd84ff47fc2694c69e58
Author: Zhengping Che <Peterche1990@Hotmail.com>
Date:   Sat Jun 2 07:13:24 2018 +0800",0
"Added error message to ensure user-overridden methods train_step, test_step, and predict_step in models are not decorated with @tf.function",0
* Reorg inputs of Bidirectional.call,0
"Fix the issue that backend.learning_phase() update the global
learning phase state.",0
Have noticed how default GRUs works usually worse than LSTMs?,0
Add keras/layers/preprocessing/benchmarks:feature_column_benchmark as a PIP deps.,0
* Update the RNN cell API to be explicit about output_size.,0
"As far as code quality goes - yeah, it needs improvement and it was largely involuntary.",0
Used K.backend() instead of K._BACKEND. (#12084),0
"--
3f7943f2c2ee7a9ab8943234a6366087dd508c49 by Ashutosh Hathidara <ashutosh.hathidara@legatohealth.com>:

Added regex match logic and refactoredred as per comments",0
"--
57dbe0fd01d3d4548f3453013177e49073edb463 by Zirui Zhuang <zr.zz.alp@gmail.com>:",0
"* Bug fix of Bidirectional(LSTM(..., stateful=True)) https://github.com/fchollet/keras/issues/4421",0
"#22 0x0000ffffbb3bfe98 in tensorflow::grappler::GraphProperties::InferStatically (this=0x100de6d8, this@entry=0xffffffffba08, assume_valid_feeds=<optimized out>, aggressive_shape_inference=aggressive_shape_inference@entry=false, 
    include_input_tensor_values=255, include_input_tensor_values@entry=false, include_output_tensor_values=12, include_output_tensor_values@entry=true) at tensorflow/core/grappler/costs/graph_properties.cc:2610",0
"This is inspired by a bug report to
h5py (https://github.com/h5py/h5py/issues/1076) to allow the user to
pass a Group or a File (which is a sub-class of Group) into save_model
and load_model",0
* Initial unit test code,0
* Fix pep8 complaint,0
"I haven't tested it yet, but does it look like something reasonable?",0
* undo add (delete) K.floor on backends,0
Add keras API target to common_pip_deps,0
Calling sequences_to_matrix results in an IndexError when nb_words = None.,0
Fixed python 2.x bug with input() in save_weights(),0
* Check if stride is greater than output padding,0
"#7617 does some scalar batch updates, don't know if it is what you're looking for.",0
"I changed the name -- if you have any thoughts on how we could generically implement this, I'm all ears.",0
PiperOrigin-RevId: 347068926,0
Fix predict_generator output shape for multi-output models when batch size is larger than the dataset. (#8795),0
* add(initializers): selu_normal,0
"- I removed 'auto' since it sounds redundant considering the context, I used auto-tagging in the title of my paper though.",0
* Add missing test wrappers,0
I included a new regularizer named Eigenvalue Decay to the deep learning practitioner that aims at maximum-margin learning.,0
* Added LambdaCallback callback,0
"fix 5D tensor in theano, add examples",0
"As such, they are already testing the architectures of several scripts from `examples/` (including the MLP), though not all (e.g. not IRNN or MemNN, etc).",0
Revert "Avoid DeprecationWarning from inspect.getargspec (#6817)" (#7018),0
PiperOrigin-RevId: 461980689,0
It also adds support for any value of num_oov_indices when invert=True.,0
A few questions:,0
"In my use case, I started from a binary problem and extended it to a multi label problem by manually labeling ~ 20% of the images.",0
Merge pull request #125 from jramapuram/hotfix/print_inner_activation,0
* Add test case.,0
Fix the Efficientnet input normalization issue.,0
"fix get_config according to mdering, and other small fix",0
"* Simplify multiprocessing test, clarify doc replace maxproc by nb_worker",0
* Add refs and comments of training generator lock,0
Fix missing callback refactoring.,0
Add a test for preprocessing function for flow_from_directory (#9639),0
@zachmayer fyi,0
It was misusing the merge layer and had an incorrect parameter in of the GRU layers.,0
PiperOrigin-RevId: 399942051,0
Fixed the windows line endings in the CSVCallback. (#11124),0
* Resolve naming conflict,0
Any other way you could test this?,0
* Add test for reverse op,0
Fix np.load call for np v1.16.3 (#12714),0
PiperOrigin-RevId: 380531746,0
"Without this change, setting model.stop_training = True in on_batch_end of a callback has no effect when using the fit_generator.",0
"I realized that it makes more sense to have _step *apply* a mask, but
then to set the masked entries to mask_value outside of step.",0
* Add a unit test for CuDNNGRU conversion with TimeDistributed.,0
* Use tensorflow leaky_relu op for efficiency,0
* Update convolutional_recurrent_test.py,0
Bug fixes : Theano shape inference (#5827),0
* getfile() extract parameter fix (#5861),0
* Blank spaces this time.,0
Adds Keras v3 saving testing coverage to Keras layers tests.,0
* Fixup Broken For Loop,0
PiperOrigin-RevId: 364378098,0
Otherwise we can define the marker only once at all.,0
Rename mnist_siamese_graph.py to mnist_siamese.py (#8089),0
Migrate Keras to DTensorCheckpointV2 (tf.train.Checkpoint integration to DTensor),0
"For example, consider the unit norm constraint.",0
- works with a `Graph` or a `Sequential` model,0
Thank you for your consideration.,0
* Refactoring: Added a data_generator to the test_utils.py.,0
"To use the same terminology than in the documentation:
pad_sequences transforms a list of nb_samples sequences (list of scalars/ list of numpy arrays) into a 2D/3D numpy array of shape  (nb_samples, nb_timesteps)/(nb_samples, nb_timesteps, nb_dimension_embeddings)",0
* topology.py corrections based on comments in #9167,0
"ga_uint old, assumed, sum, new;",0
Are there any assumptions made by this method regarding the data?,0
* Fixed PEP8 Issue : Extra whitespace,0
This reverts commit bf12d744075791538392b0f60833da7d533994ab.,0
* [skip ci] s/selu_normal/lecun_normal,0
"Before I go ahead and add those, I just wanted to make sure that this approach seems fine with you, since it, if only very slightly, messes with the core `Layer` class.",0
* Added a decorator for flaky tests to resume our work.,0
its removal breaks tests and stuff.,0
Allow `var_list` to be a callable for backward compatibility.,0
@fchollet any thoughts on the best way to implement this behavior?,0
* docstrings,0
"In terms of calling things _trainable_ or _non-trainable_, I don't see what difference does it make conceptually whether the parameter updates happen during forward prop or backprop.",0
"--
fe40432f36ff199747af25acf16cc5adf07d4c46 by Albert Villanova del Moral <8515462+albertvillanova@users.noreply.github.com>:",0
* Added CTC to Theano and Tensorflow backend along with image OCR example,0
PiperOrigin-RevId: 536456175,0
Add test case for asymmetric padding.,0
Add documentation to tf.keras.layers.serialize function.,0
* Fix syntax error,0
[ RELNOTES] Add `output_padding` in `Conv2DTranspose`,0
"When lookup layers are in tf_idf output mode, a set of inverse document frequency
weights can be learned via adapt, or set via set_vocabulary as an idf_weights
argument.",0
* Add test for documentation,0
@gabrieldemarmiesse Any idea on what should be the appropriate behaviour?,0
* Actually process embeddings in batches,0
"- make clear that wrapping a layer with Sequential model is done
  to initialize the weights",0
PiperOrigin-RevId: 474642967,0
I wonder if the current support has too many hidden assumptions that restrict the use cases.,0
* Adding MeanAbsolutePercentageError loss.,0
- separate biases for input kernel and recurrent kernel,0
* Working on improving tensor flow callbacks,0
"* Basic unit test for sparse dot; TF works, TH fails",0
"* When constructing a new KerasTensor: fail immediately if the wrapped TypeSpec has no shape, or if the shape is not a TensorShape.  (Exception: NoneTensorSpec is allowed, even though it has no shape.)",0
Convolutional layer supports float64 dtype after tensorflow 1.8.0 (#10977),0
Inputs received:,0
load_weights() now properly closes file (#13048),0
Add UpSampling*D API conversion interface.  (#5719),0
Added extra points in the error message to provide a better error message.,0
Note: `patience=0` and `patience=1` give the same behavior.,0
training.py _weighted_masked_objective fix crash when weights is None (#7068),0
* Allow converting LSTM weights to CuDNNLSTM.,0
* autogen classes and functions,0
Skip both of them to unblock the API generation.,0
Bug fix to remove parentheses around serialization library context manager for compatibility with Python 3.8 grammar.,0
* Documentation: remove the need of a custom theme,0
https://github.com/Theano/Theano/pull/6671,0
"If there is not a general agreement with these changes, by all means we can ignore this request, but I at least wanted to put it in front of people to get their thoughts.",0
[RELNOTES] Sync Sequential.fit() with Model.fit() (#8192),0
Correction to fan_out initializaiton (#2252),0
* six.moves.input() in the script,0
Moreover it requires less memory (300k parameters vs 3M+) since the number of parameters do not depend  by the length of the input sequence anymore.,0
* Add metric API changes part 1,0
Merge pull request #404 from tleeuwenburg/test_norm,0
(.text._ZN3ruy6detail36CreateTrMulParamsAssumingColMajorDstILNS_4PathE113EhhisEEvRKNS_3MatIT0_EERKNS3_IT1_EERKNS3_IT3_EERKNS_9MulParamsIT2_SC_EENS_16ChannelDimensionEPNS_3CtxEPNS_11TrMulParamsE[_ZN3ruy6detail36CreateTrMulParamsAssumingColMajorDstILNS_4PathE113EhhisEEvRKNS_3MatIT0_EERKNS3_IT1_EERKNS3_IT3_EERKNS_9MulParamsIT2_SC_EENS_16ChannelDimensionEPNS_3CtxEPNS_11TrMulParamsE]+0x4b3): undefined reference to `ruy::Allocator::AllocateBytes(long)',0
PiperOrigin-RevId: 430826954,0
"A variety of different changes to ensure linelength falls within 85 charicter
linelength",0
* Repushing for timeout,0
Make the TF1 variable scope shim layer expose its forward_pass call signature to the Keras machinery that decides if `training` should get passed in or not.,0
* add SpatialAlphaDropout1D layer,0
"/home/yeverino/.conan/data/tensorFlowLite/0.1/demo/testing/package/d351525cc53ebe68279edf1978846402420066e7/lib/libtensorflow-lite.a(conv.cc.o): In function `void ruy::detail::CreateTrMulParamsAssumingColMajorDst<(ruy::Path)113, unsigned char, unsigned char, int, unsigned char>(ruy::Mat<unsigned char> const&, ruy::Mat<unsigned char> const&, ruy::Mat<unsigned char> const&, ruy::MulParams<int, unsigned char> const&, ruy::ChannelDimension, ruy::Ctx*, ruy::TrMulParams*)':",0
babi_rnn bugfix: QA19 requires vocab from the answer,0
How would you feel about incorporating a class like [this](https://gist.github.com/lukedeo/4b872c7a2d5bd1c5d951) into `utils/generic_utils.py`?,0
PiperOrigin-RevId: 455222167,0
"Can I assume that the parameter `y_pred` in `custom_objective(y_true, y_pred)` is just the list generated by my `generate_batch_data function` and I can treat it as a normal list?",0
"Especially since there are some unique issues to consider when using multiple losses (loss scaling, for one).",0
2. Can we design the stateful metrics API UX to look like a streaming statistical API such as [boltons.statsutils](http://boltons.readthedocs.io/en/latest/statsutils.html)?,0
- I'm not sure that name `DenseAnnotationAttention` will be clear for users.,0
* Fixed weights.sort for Python 3,0
Edit errors and docstrings for `@keras.utils.register_keras_serializable()` to reduce user confusion on decorator.,0
[Use feature detection instead of version detection](https://docs.python.org/3/howto/pyporting.html#use-feature-detection-instead-of-version-detection),0
Close _SESSION.session in clear_session,0
* updated FAQ to reflect dependency change,0
"Previously, only the activation function had this behavior.",0
"This new feature is only enabled in tf v2 eager mode, and not available in v1 graph mode.",0
"On Wed, May 1, 2019 at 2:49 AM JunHyungYu <notifications@github.com> wrote:",0
But all the files in `templates` are markdown files so it's fine.,0
"For normalization we are adding support for lowering text (without stripping
punctuation), and stripping (without lowering case).",0
Fix typos and even more informative docs.,0
* clean up documentation strings,0
Merge pull request #13981 from tedhtchang/better-gpu-driver-assumption,0
Added code delimiters and `cval=k` to `fill_mode` examples.,0
change variable name in test code,0
* add backward compatible check,0
"Previously, the scheduling parameter was not passed to the OrderedEnqueuer, which was needed in training.",0
"In autogen.py, we copy template into sources and then work on it.",0
"commit 6aace3052716e24fad3ff7f168c9de49e61e1982
Author: ebatuhankaynak <ebatuhankaynak@users.noreply.github.com>
Date:   Fri Jun 15 22:00:24 2018 +0300",0
* ENH: allow save_model/load_model to accept h5py.Group,0
Should this be noted in the documentation somewhere?,0
"Is there a better way than replacing

```assert K.dtype(y) == expected_output_dtype```

with the following?

```
if isinstance(y, list):
    for tensor in y:
        assert K.dtype(tensor) == expected_output_dtype
```",0
PiperOrigin-RevId: 538097599,0
"With that plus random tests failing and timing out that touch nothing to do with the meager Java related toe nail clippings of files that i touched, can we assume that there is a larger problem here?",0
* rem print,0
Initial commit for tensorflow/python/keras to Github project keras-team/keras.,0
* Added notes to manually install h5py if needed,0
"Briefly all of these benchmarks share the same binary, and we use borg config to change the env setup.",0
Part of issue #11383,0
Fix typo.,0
keras.preprocessing.image_dataset_from_directory resizes image even if its source size is already the target size.,0
* handle the case noise_shape=None,0
Prevents an invalid `x[:-0]` slice,0
"--
2b7f4d924251a67a65953b1f83a0499986ee1475 by Zirui Zhuang <zr.zz.alp@gmail.com>:",0
* Fewer layer names; remove dropout; update FAQ doc,0
"Therefore, the function has been rewritten using placeholders and feed_dict to avoid allocating additional memory.",0
output dimension mistmatch when using sparse_categorical_crossentropy,0
keras.model.load_weights does not consider custom model(layer),0
* Update models.py,0
"Several accuracy metrics end in a call to `K.equal()`, which gives a tensor with dtype `bool`.",0
"Port keras lookup layers to new adapt, use a StaticHashTable during call",0
https://joeshaw.org/python-daemon-threads-considered-harmful/,0
* CLN: join lines,0
"There's a separate test, since we needed different data
and to make the whole test as obvious as possible.",0
Add control dependency consideration in topo sort in `executor_tpuv1_island_coarsening` pass,0
* tf batch dot minor fix,0
This PR cleans up preprocessing of `depthwise_kernel` for Theano.,0
Adds extract_archive() and hash_file() functions.,0
"If rx is pure Python, then couldn't we isolate the subset of its functionality that we are going to use, and introduce that bit of code as a Keras util?",0
Raise UnavailableError to be caught at a higer level to let TPU worker be able to recover from preemptions.,0
* add resnet 50,0
Some thoughts:,0
Thanks for the PR.,0
[MHLO] Move side effect-free ops into assuming regions over side effecting ops,0
Avoid slicing,0
"When dealing with sequences of different lenghts, this OPTIONALLY
fixes cost function bias to the largest sequences.",0
[BatchNormalization] set updates in get_output,0
"I'm not sure that this is the right way, feel free to comment.",0
Add new LossScaleOptimizerV3 subclassing from the new experimental optimizer.,0
* line length,0
PiperOrigin-RevId: 421380718,0
Export BaseImageAugmentationLayer as a keras internal API.,0
"This PR considers the following two main items:

- Adding `resize_volumes` and its test for CNTK
- Adding tests that existed for all backends except CNTK",0
The documentation says "direction as radians".,0
Imported from GitHub PR https://github.com/keras-team/keras/pull/15867...,0
* Revert "Fix for cntk issue 1994 (Keras/CNTK: BatchNormalization layer causes predict() values to be incorrect) (#7258)",0
"Since the scheduling paramater is currently a binary decision, I've also altered the value to a boolean.",0
Is it possible to rerun the CI job or do I need to make some rebase/force push to trigger it?,0
Guiding users to use the same steps followed for Tensorflow repo.,0
Delete all the py srcs and test files.,0
reference_operations.py,0
This reverts commit fb7c367a1560f89d9940e32962d2b3807a54ce08.,0
Also update the docstring to make it clear about the math part for how contrast is calculated.,0
Merge https://github.com/fchollet/keras into BRNN_latest,0
"Currently, when `y_pred` is three dimensional we incorrectly state that `y_true` must have two dimensions.",0
* REL: bump to `pydot >= 1.2.4` in `extras_require`,0
PEP8 (#8228),0
Hi @andhus - thanks so much for your work on this.,0
Remove experimental Keras mixed precision API.,0
"* Fix the issue that when n can be mod by batch_size, the shuffle never happened",0
Merge pull request #2013 from carlthome/master,0
"Hence, we are adding this `variable()` method for backward compatability.",0
* Update core.py,0
* Change according to review,0
## Another thing to consider,0
Please let me know your thoughts regarding this quick fix and slight quality-of-life for custom_objects.,0
* Delete slnx.sqlite,0
"- Switch to in-memory, single write / single read archive saving for better performance.",0
- also convert biases from H5 Dataset to np.array for reshape() (#9662),0
PiperOrigin-RevId: 443446864,0
"2. Can I assume that input arrays are not modified, or would I have to check this per-kernel bases?",0
"Example output:
`4/4 - 0s - loss: 0.6805 - accuracy: 0.5500 - 13ms/epoch - 3ms/step`",0
"* Added class for allowing functional composition of RNN Cells, supporting constants",0
"Of course, weight initialization can be more of an art than a science so if there was a reason to just use the output shape I'd be interested to hear and feel free to close this PR.",0
"@xiejw do you assume that if the session_config has been provided, and devide_filters are empty, then the user explicitly did not set them?",0
* Removed unnecessary import,0
* Improved tests.,0
* Add pooling test,0
* update weights links and remove load_weights,0
* std -> stddev for random_normal,0
"As it is recommended in the issue, the strings are now encoded as utf8.",0
Add dot_axes argument to Graph,0
2. Make _compute_gradients() and _aggregate_gradients() public api.,0
Update the contribution guide to include a applications section,0
Does it omit them maybe?,0
"commit 1365ed5d9a872631b0d451f8508cc61d79228dc0
Author: Taehoon Lee <me@taehoonlee.com>
Date:   Tue Jun 5 02:07:23 2018 +0900",0
* add test for case lambda multi out no mask,0
I have tried to keep the output format for the new function as close to the existing `categorical_accuracy()` function as possible.,0
So is it possible that i know the predicted image came from which class so the loss function can handle it accordingly.,0
I'd be very happy if you could either update the code to cover this case or just drop me a short comment on how this is not a problem.,0
Merge pull request #238 from jfsantos/patch-1,0
* Fix style issue,0
Dataset generation utils docstring fixes.,0
* Fix a typo,0
"image_ocr: revert ""Fix input shape of OCR model (#7908)"", and change text_to_labels to make it easier to extend the alphabet  (#8085)",0
Add inner_activation to get_config,0
See https://github.com/fchollet/keras/issues/7804 for details.,0
Change the validation error to warning for functional models that has different static batch for all the inputs.,0
The PR fixes #42872 (code snipped to reproduce the bug also present there),0
* Nit,0
+ Frequencies now takes 0-th epoch as first.,0
Thanks for consideration.,0
"This assignment is not present in pool3d function which is a similar one, thus I considered removing it.",0
* Simplified pydot installation checking,0
added clarifying statement to save_model,0
Changed exception to warning for NumpyIterator (#7623),0
1. Include `custom_objects` in `from_config` for deserializing custom learning rate.,0
Update keras RNG logic to use tf.random.Generator if possible.,0
* Support return_state parameter in ConvRecurrent2D,0
Adds warnings for Keras module serialize APIs when an object of unrecognized type is passed.,0
Now it is fixed.,0
PiperOrigin-RevId: 445528142,0
* fixed pep8,0
Initialization with one was missing from the docs.,0
"commit 844cfc2e8c9c6f267799a22ed54ac4d75807c5ab
Author: Arel Cordero <arel@ditto.us.com>
Date:   Thu Aug 18 02:42:10 2016 +0000",0
"This allows
'multi_hot' and 'count' encoding unbatched multi-dimensional samples in a
tf.data.Dataset.",0
"This makes the metrics behavior consistent with `keras/engine/base_layer.py`
usage of `tf_utils.maybe_init_scope`.",0
Embedding layer input_shape incorrect?,0
* Fix bug where progress indicator doesn't complete,0
* bug fix : gather,0
"If we assume that you use a data type which needs 32bit for each value, your complete tensor needs 131072*2048*32bit/1024/1024/1024=8GB of memory on your GPU.",0
PiperOrigin-RevId: 429669589,0
Add 'one_hot' output mode to StringLookup and IntegerLookup,0
"When an op is moved out of an assuming region we already know statically that it
is independent of the assuming region.",0
"It helps greatly
when working with large but simple data sets with small batches, which
leads to millions of relatively useless screen updates per second.",0
"In order to propagate state through _predictions_, I created a new
property of the model, `state_updates` that returns any model step
updates that are needed when doing a stateful prediction.",0
Copy image utils from keras_preprocessing directly into core keras,0
Merge pull request #16893 from matangover:fix-compile-metrics-doc,0
Keras training: Give up on inferring steps if the dataset is not a `tf.data.Dataset` such as a per-worker dataset (thus doesn't have a variant tensor).,0
Correct example indentation,0
RNN initial state: bug fix + suppress false warning (#13138),0
PiperOrigin-RevId: 417856176,0
@kracwarlock Actually I'm not sure if the mask is supposed to be applied during that operation.,0
PiperOrigin-RevId: 438150625,0
PiperOrigin-RevId: 380652823,0
Merge pull request #15222 from harupy:log-best-epoch-2,0
* Simplified weight sorting and backend check,0
Section for Training history visualization (#11076),0
"I don't know if it will help, but feel free to merge if this is interesting!",0
Bug fix in recurrent layer (#6393),0
Add negative parameter validation to Core Keras layers.,0
"commit 513f7b1bff6b79382b679b728c1435b91631aa7e
Author: Taehoon Lee <me@taehoonlee.com>
Date:   Thu Jun 7 00:47:37 2018 +0900",0
Fix documentation of flow_from_directory() (#9910),0
* Use same latent vector for all classes in a row,0
Remove shape argument when creating sparse placeholder.,0
* fix pep8...,0
This fixes that crash.,0
"old = atomicCAS(base, assumed, new);",0
(.text._ZN3ruy6detail36CreateTrMulParamsAssumingColMajorDstILNS_4PathE113EaaiaEEvRKNS_3MatIT0_EERKNS3_IT1_EERKNS3_IT3_EERKNS_9MulParamsIT2_SC_EENS_16ChannelDimensionEPNS_3CtxEPNS_11TrMulParamsE[_ZN3ruy6detail36CreateTrMulParamsAssumingColMajorDstILNS_4PathE113EaaiaEEvRKNS_3MatIT0_EERKNS3_IT1_EERKNS3_IT3_EERKNS_9MulParamsIT2_SC_EENS_16ChannelDimensionEPNS_3CtxEPNS_11TrMulParamsE]+0x232): undefined reference to `ruy::Allocator::AllocateBytes(long)',0
* fix bugs in theano.,0
Fix custom_objects for regularizers and other issues (#5012),0
* Changed return NotImplementedError to raise NotImplementedError.,0
Please move the Dropout layer creation to layer.__init__() if needed.,0
"* fix doc, refine code",0
This PR does a few things:,0
* Remove unnecessary comment,0
Fix OSS Keras API export issue for v1 endpoints.,0
New Callback: EarlyBaselineStopping (#10061),0
* fix test failures,0
New error message: "This model has not yet been built. Build the model first by calling build() or calling fit() with some data. Or specify input_shape or batch_input_shape in the first layer for automatic build",0
It only accepts a single image.,0
layers.LocallyConnected2D takes a lot of time to get initialized,0
"+ embeddings_metadata now can contain just a string with metadata
  filename if it's common for all the embedding layers.",0
"It was deprecated in TF 1.15, which was 3 years ago.",0
"* add one_hot to numpy back end , change test to compare to new ref function rather than hard coded anser",0
Available metrics are:,0
- add nested models (#10080),0
* Added documentation for using an external backend,0
Add documentation for save and load functions.,0
* removed new trailing whitespaces,0
* Removed name improvement in TensorBoard callback,0
"--
1b807a6d304800e993fd4bfe6bd263272c3c6307 by Ashutosh Hathidara <ashutoshhathidara98@gmail.com>:

Update tensorflow/python/keras/utils/vis_utils_test.py",0
Recent update broke HDF5Matrix,0
addition_rnn example formatting changes (#8523),0
Support additional standardization and splitting mode for TextVectorization,0
PiperOrigin-RevId: 489512158,0
Fix signature of functions and methods in generated docs (#10743),0
LSTM keras - Value error how to resolve input dimension,0
* Removed whitespace from white line,0
"* Reduce network size, add recommendations to reduce overfitting",0
* Add @tboquet's suggestion to export to png #6990,0
"- cells with different implementation: GRUCell, GRUResetAfterCell",0
Furthermore I tighten the `test_utils.layer_test`.,0
I've changed it to have both W_regularizer and b_regularizer (also for constraints) to make it easier and clearer.,0
PiperOrigin-RevId: 472594216,0
I hope this fix would change related auto-generated documents as well.,0
Fix typo in training (#3014),0
Fix for Issue #4851 (#4855),0
import LRN2D,0
Implement class `OneHotIoU` that inherits class `IoU`.,0
* bug fix: batch_flatten,0
"Since there're no gradients updated during `evaulate` and `predict` processes, changed their `batch_size` docstrings from `""Number of samples per gradient update""` to `""Number of samples per evaluation step""` and `""Number of samples to be predicted at once""`. (The sentence in fit remains unchanged.)",0
[MLIR][MHLO] Add pattern to move ops into the assuming region,0
PiperOrigin-RevId: 388251397,0
also set intra_op_parallelism_threads (#12254),0
Previous topological sorting algorithm in the pass does not consider control dependencies between `Island` ops.,0
"Therefore, we can take the below two measures:",0
Corrected a comment in function "print_layer_summary_with_connections" && Fixed issue #6286 (#6284),0
PiperOrigin-RevId: 367061588,0
* Minor tensorboard callback fixes,0
Fix various LossScaleOptimizer issues.,0
"However, the code was adding classes in the order `os.listdir` returned them.",0
Currently layers with a Bidirectional or TimeDistributed wrapper are not considered by preprocess_weights_for_loading() as only the layer.__class__.__name__ property is examined.,0
It was never a stable API in the first place (it was an `experimental` API) and had no backwards compatibility guarantee.,0
Does TF inference assumes certain `CUcontext` to be available?,0
1. Remove redundant args from `update_step` of Adagrad and RMSprop optimizer.,0
Custom layer TypeError: Failed to convert object of type <class 'SoftThresPerc.SoftThresPerc'> to Tensor.,0
* Updated to actually run in parallel.,0
fixed RemoteMonitor: Json to handle np.float32 and np.int32 types (#9261),0
"So, _consume less memory time_?",0
Remove "at least 2D" rank expansion in fit/predict/evaluate.,0
But it has a temporary disk space impact.,0
added class weights to the Model class and one of the objective functions as an optional parameter,0
It wasn't 100% clear to me what "reflect" and "wrap" modes do exactly so I looked in scipy source for examples.,0
"Also add tests for triply-nested `Sequential`
models.",0
"- various model types: add Model, Sequential (not only Sequential)",0
Remove the conditional import for tensorflow/dtensor.,0
Added Gitter channel badge (#3744),0
Add a GPU-efficient Augment2D example (TF-only) (#9056),0
"""here"" links are difficult for individuals that need a screen reader for accessibility. (#6976)",0
* Add support for stateful metrics.,0
PiperOrigin-RevId: 389204681,0
This reverts commit 00d48891ef440eaf6f5bc599e052f2b221a03a08.,0
"For example anything that walks the graph may or may not want to modify placeholders, such as an automated labeling model to segmentation model converter.",0
Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset.,0
PiperOrigin-RevId: 446227407,0
* Add visualization to Dockerfile,0
- [x] This PR changes the current API [y/n] (all API changes need to be approved by fchollet),0
Add documentation for sequence preprocessing.,0
"* remove sci-image, implement ndimage based methods, refactor random_transform",0
Can I assume that you installed using a binary via pip?,0
* Update the map test to include the dtype parameter,0
Merge pull request #494 from wxs/document-sampleweight,0
"When calculating 'sigma' denominator is # of instances (axis=0), not dimensionality (axis=1)",0
I changed keras bzl file to remove the deps from tf_py_test within the tf repo and mimic most of the content to keras.bzl.,0
PiperOrigin-RevId: 386960334,0
This PR always returns a copy to ensure that any change made to `struct` after calling this function does not propagate to the original `struct` which leads to undesired behavior.,0
Model.load_weights(): add new reshape option (#9167),0
"Containers have a layer_to_yaml method | plus fixed a minor typo, inputs were mistakenly added to output_config, not input_config",0
Merge branch 'keras-2' of https://github.com/fchollet/keras into pool2d-api-conversion-interface,0
* Test LambdaCallback examples,0
"* rename gcs decorators, update docs, fix mock imports to be python3 compatible",0
Add a link to the metrics document (#13334),0
* Added initial_epoch argument to fit functions in trainer,0
Update CONTRIBUTING with info wrt commit squashing,0
Added averaging support in merge and a TimeDistributedMerge layer,0
"```py
model = Sequential()
model.add(Convolution2D(30, 3, 3, input_shape=(1, 28, 28)))
model.add(LRN2D())

model_def = model.to_yaml()

# this line raises Exception: Invalid layer: LRN2D
model_from_yaml(model_def)
```",0
* topology.py changes from review in #9398,0
cleaning up code based on comments,0
Fix SimpleRNN dropout typo,0
fix bug: change seed range for RandomStreams in Theano (#2865),0
"We also link the preprocessing layer guide, which is the only convinient way
to find the full set of these layers on tensorflow.org.",0
* Corrected some bad formatting.,0
"* inspect function supports python2, 3",0
Add variable() method for the new optimizer.,0
"""_If you currently specify __sudo:__ in your __.travis.yml__, we recommend removing that configuration_""",0
* fix all tests,0
- variable names to lower case,0
* acgan: don't train discriminator to produce class labels for generated images,0
* white space fix,0
50 ms is too fast for a human anyway.,0
"It can handle other types, like anything that implements the `__array__` protocol (`pd.DataFrame` and `pd.Series`) for example.",0
* Adding support for swapped axes when ndim==2,0
Move pad_sequences to /utils,0
PiperOrigin-RevId: 379750075,0
Documentation added to "Switching from one backend to another" section of documentation,0
Also update keras build script to remove keras-nightly package if it is there.,0
I have begun to review the changes made in da21c15.,0
"For example:

>>> with open('output.json', 'w') as f:
...     f.write(model.to_json(indent=4, sort_keys=True))
...",0
"* move static shape inference to theano_backend, add docstring, etc.",0
Correction at https://github.com/fchollet/keras/pull/6800/files/8a93935d99fae4b8dc2ce0ea1a169906da0a165d#r120219133 also applies to all other contributers.,0
General stateful metrics fixes (#9446),0
* add test for K.deconv2d which verifies behavior,0
Please reopen if you feel that doesn't fix the original issue.,0
Implement `BinaryIoU`.,0
one line fix for TensorBoard callback issue (#2574),0
Syntax fixes for incorrect line breaks.,0
Improve TensorBoard callback tests.,0
* allowed user specified input lengths,0
Anyone up for adding this?,0
"This feature only makes sense if `verbose=2` is used, but if this PR is going to be accepted, I suggest considering changing the parameter name `step` to `verbose_step`.",0
PiperOrigin-RevId: 442594178,0
"When loading, the custom mask layer must be passed to the custom_objects argument.",0
* Fixed the issue of the validation data not being displayed.,0
Ingore `xla_gpu` which is specially reserved by TF (#12928),0
Update metrics.md with references to losses.md (#11569),0
* Support for return_state parameter for ConvLSTM2D,0
"commit d7141937317634af23b602de63363d06e96804a8
Author: David Silva <davidtvs10@gmail.com>
Date:   Tue Jun 19 05:26:57 2018 +0100",0
PR #44105: Make fname optional in get_file,0
- new functionality does change metric values when considering removing samples through 0 weighting,0
also updated the neural style transfer example to use the new save_img method,0
For detailed discussion consider checking issue #11217 on keras repo.,0
"The bottleneck, like in DenseNet, is used to prevent escalation in the number of parameters in deep networks.",0
This makes sure the metric is reset before evaluating valset.,0
5th pass,0
Added missing space in multi-line warning strings  (#8654),0
longuest -> longest,0
* added _check_num_samples for cases when batch_size does not apply,0
Add two passes `XlaClusterFormation` and `XlaInlineDeviceOps` into non Tpu bridge pipeline.,0
Create check_graphviz function to be called in tf.keras.utils.plot_model and change check_pydot to only check for installation of pydot.,0
I agree.,0
"# The first commit's message is:
get_file() with tar, tgz, tar.bz, zip and sha256, resolves #5861.",0
Add input_shape property to Graph container,0
* readme: fix reference to renamed file,0
Please let me know what you think :),0
* Added stacked what where autoencoder.,0
This reverts commit 2d107a6a9aca469d545d6ee31624c4b530c7ea0a.,0
PiperOrigin-RevId: 411179350,0
* Made the lines shorted in the resize implementation of tensorflow.,0
* Refactor theno_backend to shorten linelength,0
* fix naming: gcs everywhere,0
Would there be a better way?,0
* deindentation and doc-string formatting.,0
Do share your model definition file as soon as possible.,0
generalize pad_sequences #1718,0
Merge pull request #859 from r9y9/patch-1,0
"**You can assume**：
when you have  a big '.tfrecord' file that dont know it length , how to know its length and length//batch_szie easily ?",0
- What is your motivation for this scheme; why do you think it was necessary over all over possible options?,0
Various fixes,0
* Add back configs for RNN layers,0
"Some user has to specify the static shape in their model, eg if they would like to use TPU.",0
Fix value added for padding and add explanation on truncation.,0
Created new model update list for state updates,0
"Instructions for updating:
dim is deprecated, use axis instead",0
* Fix PEP-8 failures.,0
* Made changes more readable.,0
Make tensorflow backend fully mimic theano dot,0
Update Sequential model to accept multiple inputs/outputs.,0
"We need to handle this case and clear the setting to avoid an
error on saved configs when output_mode=""int"".",0
PiperOrigin-RevId: 474437220,0
Merge pull request #642 from wuaalb/lr-scheduler,0
Feel free to start fresh or reuse some of our code.,0
* Explanation of changed condition,0
"This is
in preparation for constraint fusion, which will replace the slow merge
assuming regions pass.",0
"On Fri, Aug 23, 2019 at 9:55 AM Philip May <notifications@github.com> wrote:",0
The scan in get_output TimeDistributedDense leaked memory like crazy.,0
fix deconv2d None error (#5093),0
* theano_backend.py pep8 & padding fix,0
assumed->height = height;,0
"This is because variables not having gradients are filtered out, but moving_average_variable is updated based on the full variable list.",0
PiperOrigin-RevId: 399307314,0
Are you assuming they get combined in some way?,0
Refactor RNN classes such that V2 cells and layers no longer depend on V1 counterparts.,0
Bug fix: ocr example; python 3 (#6060),0
PiperOrigin-RevId: 431736705,0
"- Sometimes we can't have both, because the order of the arguments has changed.",0
* Using TF backend during shape test,0
PiperOrigin-RevId: 467813901,0
* Remove leading dots,0
Fix serialization recursion problem,0
Add collection of models to be used for integration tests.,0
* Fix imports,0
* address code review comments,0
* DEV: ignore `.pytest_cache`,0
PiperOrigin-RevId: 388347064,0
Address the issue of "partition_offset" being ignored by keras initializers.,0
"LocallyConnected2D fails on [N, 1, x,y] type tensor",0
- [?] This PR is backwards compatible [y/n],0
* shortened lines.,0
* import statments cleaning,0
- please update the docstrings as well,0
Faster and better Sentiment Analysis example.,0
Both conferences are happening in May this year.,0
PiperOrigin-RevId: 480374191,0
* reverted changes to the example scripts,0
* Add test coverage for dilation rate in DepthWiseConv2D,0
"If the solution is to assume TF 2.5.0 is not 10.2 compatible (or tested), it is a valid solution to my issue.",0
"In those places resource
ownership is not properly defined.",0
Fixed https://github.com/fchollet/keras/issues/4048 : in TensorBoard callback which fails when it is not the only callback (specifically when another cbk is ReduceLROnPlateau). (#4159),0
Merge branch 'keras-1' of https://github.com/fchollet/keras into keras-1,0
* fix PEP8 problem....again...,0
* Add better error message for model.summary(),0
Rename internal set_policy function to set_global_policy.,0
The solution is to not cast the alpha to float32.,0
WARNING:tensorflow:11 out of the last 11 via using Keras library,0
The test is updated for mocking RNG in tf.image ops.,0
Using shutil rather than copying the tree manually in autogen.py (#12146),0
Added support for the return_state=True parameter in the ConvRecurrent2D abstract class.,0
* Initial Commit,0
* TF fix,0
code contributed by @bnaul,0
what rmse does is to do the RMSE over the internal dimension of y which in may case is one and then do a mean over the all samples (first over the batch and then over all batches.),0
* replicate deconv example with with paper's params,0
"Was trying to add a new test, but found this file has quite some broken format.",0
This is to avoid issue when tf is build with tf_api_version=1.,0
* Fix for Issue #4851,0
* Fix backend test,0
* Move tests of CuDNN RNN weight conversion to a more proper place.,0
* removed unnecessary functions,0
"There is no benifit to following a higher percision variable_dtype for mean
and variance, as they are non-trainable and have no gradient updates.",0
Using the sparse_coo data fixes it.,0
"Feel free to submit an API design proposal in the future, in case you are still interested in developing this feature.",0
* Add output shape argument to transposed conv. to resolve ambiguity,0
* Delete ProjectSettings.json,0
PiperOrigin-RevId: 491437848,0
- in order to make it consistent with GRU,0
#10219,0
PiperOrigin-RevId: 379989338,0
"* update test_convolutonal.py for PEP8, test code to us K.image_dim_ordering()",0
"commit db849f8e9cd2e7639afb843022db621eb761258b
Author: jlopezpena <jlopezpena@users.noreply.github.com>
Date:   Thu Jun 7 19:54:51 2018 +0100",0
* Pushing again for travis.,0
Remove TimeDistributedHighway tests,0
PiperOrigin-RevId: 478563891,0
Validate file integrity on `get_file` on download.,0
"* turn stack into a def func in numpy backend, add test",0
"This allows to specify a
theano.compile.mode.Mode instance to use, for example to use a MonitorMode
with a post_func to detect nans.",0
Can we assume that eval_once() is successfully executed and use this result?,0
Fix serialization of hashing layer,0
* fix PEP8 problem,0
added example to illustrate effects of `to_categorical`  (#11327),0
Change formatting as requested by review in PR 15286,0
"If you think it's possible to implement it with current functionality, can you please provide a code example (seq2seq)? :)",0
PiperOrigin-RevId: 416140492,0
Bugfix: Fix the expression of pictures (#5153),0
PiperOrigin-RevId: 395815316,0
Make layer and shape caches more robust,0
* Add test for logsumexp,0
* add missing import,0
Updated documentation for `axis`,0
Added a section to address the security practices and to report security vulnerability found in keras.,0
* Add test_image_data_generator_with_split_value_error,0
- There is an inconsistency between using the singular and plural of `initial_state` and `initial_states`.,0
Fix a version number (#10361),0
I needed another reading in Keras backend...,0
"Replacing np.ceil() with faster operations, as suggested in #8488",0
small fix (caused by autopep8),0
Another but related question: it is even possible to use any of Merge layer in a Sequential model?,0
Fix typo in recurrent.,0
PiperOrigin-RevId: 400835355,0
Signed-off-by: Amit Beka <amit.beka@gmail.com>,0
Bugfix: Pass show_layer_activations to expand_nested calls,0
"Add benchmark testing for TpuStrategy, OneDevice and MultiworkerMirrored.",0
* Update docstrings.,0
* Interim commit -- added notes.,0
assumed->width = width;,0
Fix crash in mixed precision stateful RNNs.,0
`shutil` has a function for this purpose.,0
* training.py improve docstrings and error case,0
per channel samplewise normalization,0
"1) epsilon has been removed from argument list, using default instead
   for future support of mixed precision.",0
* Code review fixes,0
* update doc,0
Merge pull request #1052 from EderSantana/patch-4,0
data_utils.py and data_utils_test.py updated based on review (#5861),0
* Fix PEP8,0
* Some blank lines are restored.,0
* Propagate uses_learning_phase via RNN states,0
"First of all, this is about the same quantity of code.",0
PiperOrigin-RevId: 504885528,0
Fix OSS keras API generation issue.,0
* reverted callbacks.py,0
"The documentation for `DepthwiseConv2D` describes the operation as: split input into individual channels, convolve each with the layer's kernel and finally stack the results.",0
* deconv_length handles output_padding=None,0
* Test built-in RNN cells,0
Fix https://github.com/keras-team/keras/issues/15791.,0
PiperOrigin-RevId: 506084493,0
* Add missing doc,0
Align vocab indices for keras preprocessing lookup layers when invert=True,0
"--
d6ee4a941b79a464a9b229f6a22be50baab62d4d by Zirui Zhuang <zr.zz.alp@gmail.com>:",0
* Fix PEP8 issue for Travis,0
But could someone explain how is this working ?,0
* Integrate the preprocessing into `imagenet_utils`,0
But isn't that supposed to work or give an proper error message?,0
* Masked and non-masked merge bug fix,0
PiperOrigin-RevId: 397401505,0
4) add initial_accumulator_value to Adagrad.,0
"Any ideas on how to implement RNN callbacks @fchollet, @farizrahman4u ?",0
Not sure if you'd think this details though.,0
PiperOrigin-RevId: 384321649,0
my bad.,0
Clarify documentation of DepthwiseConv2D,0
Update citation information. (#9650),0
Merge branch 'BRNN_latest' of https://github.com/yaringal/keras into yaringal-BRNN_latest,0
* Use third-person and close docstrings on a new line.,0
"So ensure that `fname` always has `.tar.gz`, and `untar_fpath` never does.",0
* Make batch_dot unique,0
"However, when the author wants to save images with a batch size of one, the probability of a conflict increases since {index} is always 1.",0
"This is in preparation of replacing the slow merge
assuming regions pass.",0
* topology.py load_weights adds reshape docstrings,0
* Enable tensorboard with other backends.,0
* Bug fix & pep8,0
@fchollet any thoughts or request for this PR?,0
Fix typo in the test case name.,0
Fix serialization error due to EagerTensor constant,0
* finally,0
"commit f55245199a11a202857efb1413ffa3b97c1dcfaf
    Author: Yarin <yaringal@gmail.com>
    Date:   Sat Feb 20 01:57:50 2016 +0000",0
* int->tuple,0
* Fixed API-conversion for Dropout,0
Chenta/cntk bn (#9952),0
* Checks if model.stop_training is true after on_batch_end in fit_generator,0
PiperOrigin-RevId: 420932194,0
"* Add docstring for plot_model method, format code according to PEP8",0
* Minor change,0
Fix typo LearningRateScheduler,0
"Metrics top_k_categorical_accuracy and sparse_top_k_categorical_accuracy
produce wrong result when weighted by sample.",0
Merge pull request #205 from tdhd/save_weights_input,0
fix issue: http://github.com/keras-team/keras/issues/10058,0
PiperOrigin-RevId: 431994960,0
* Update Graphviz link in README as they just changed it,0
MaxoutDense no activation; incorrect docs (#2895),0
The output shape can be inferred from the output of the wrapped layer combined with the known batch size and number of time steps.,0
`keras.utils.get_file` does not support gzip as advertised,0
- Added some assertions,0
Ref: https://github.com/fchollet/keras/issues/2570,0
updates to coding style,0
"I think to get two `StagingArea` instances to work on the CPU to GPU transfer as you describe https://github.com/fchollet/keras/pull/6974 might be required, or something similar.",0
Updated `voculary` with `vocabulary`,0
fix typo in keras/layers/merge-> concatenate description (#8453),0
* Add argument merge_repeated to K.ctc_decode() (#12238).,0
* Make sure to close the opened hdf5 file in load model even when an error is raised,0
Was incorrectly reporting the `loss` argument instead of the `loss_weights` argument when an exception related to loss_weights was thrown.,0
"""channels_last""->`""channels_last""`",0
"Previously, the file integrity was checked only if the target path existed, as a mean to prevent redowloading the same file.",0
* Fix typo,0
- Add `get_config` to `Lambda`,0
* Improve documentation for `axis` argument,0
* update cntk to 2.3.1,0
load_weights does not consider custom model(layer),0
* support tf dim_ordering,0
* Update io_utils_test.py,0
"Due to security issue, zlib 1.2.12 is yanked, just like 1.2.11 was before.",0
Fix typo in docstring,0
"```
    m = tf.keras.metrics.SparseCategoricalAccuracy()

    m.update_state([[2], [1]], [[0.1, 0.6, 0.3], [0.05, 0.95, 0]])  # Correct usage,  `y_true` as integer labels and `y_pred` as probabilities.
    print(m.result().numpy())
    # >>> 0.5

    m.update_state([[2], [1]], [[1], [1]])  # Wrong usage, both as integer labels.
    print(m.result().numpy())
    # >>> 0.25

    m.update_state([[0, 1, 0], [0, 1, 0]], [[0.1, 0.6, 0.3], [0.05, 0.95, 0]])  # Wrong usage, both as probabilities.
    print(m.result().numpy())
    # >>> Error
```",0
"Documentation for `array_to_img`, `img_to_array` and `save_img` under `preprocessing.image` #12711 (#13252)",0
* renamed objectives to metrics for xent_loss,0
"commit 4f90f95fa5fb087445acb40c110770ebb3817b28
Author: ebatuhankaynak <ebatuhankaynak@users.noreply.github.com>
Date:   Wed Jun 13 21:39:47 2018 +0300",0
* Add 'initial_epoch' argument to Sequential.fit() and Sequential.fit_generator() wrappers.,0
Update training_utils.py (#8597),0
Bug fix when target is a SparseTensor. (#4200),0
* Refactor and simplify tests.,0
"--
ce61651713881185a04d04459950ae794301bb51 by Ashutosh Hathidara <ashutoshhathidara98@gmail.com>:

Update tensorflow/python/keras/utils/vis_utils_test.py",0
docstring fix for fit / fit_generator (#7806),0
PiperOrigin-RevId: 364339229,0
Fix typos and minor inconsistencies.,0
Fix typos (#4591),0
sparse_categorical_crossentropy with tensorflow backend,0
"commit fe066966b5afa96f2f6b9f71ec0c71158b44068d
Author: fuzzythecat <fuzzy0427@gmail.com>
Date:   Wed May 30 13:49:44 2018 +0900",0
* Set learning phase,0
* revert to previous indexing,0
- add the data flow graph to the log,0
Model test callback,0
passing decay is still supported.,0
Updated args of train_on_batch method,0
"@AnikaTabassum 
Can you please let us know the gcc version, and as per error faced can you refer to [this link](https://github.com/tensorflow/tensorflow/issues/31760#issuecomment-523114446).
[link](https://github.com/tensorflow/tensorflow/issues/32677#issuecomment-534278822).",0
Refactoring: Added a data_generator to the test_utils.py. (#11153),0
"- Check for the `__tf_tensor__` magic method and invoke
it, if present.",0
Adds to and alphabetizes documentation of Layer base class. (#10282),0
* document transformation dictionary,0
PiperOrigin-RevId: 414769654,0
* Write better docs for keras.engine.topology._convert_rnn_weights().,0
* Expose and document utils.layer_utils.print_summary as utils.print_summary,0
Allow controlling output dtype of categorical preprocessing layers,0
@danFromTelAviv feel free to read this PR and comment if you see things which need changes.,0
* Sync Sequential.fit() with Model.fit(),0
Add merge_mode join,0
Optimizer backward compatibility change.,0
PiperOrigin-RevId: 401140248,0
- added stateful option to help parameters tuning in stateful mode,0
Minor tensorboard callback fixes (#7566),0
Update keras API generate script.,0
fix model_from_json issue by passing a 3d border_mode,0
"This is a preparation to disable broadcast propagation in the
`merge-assuming-ops` pass.",0
Added a warning in `model.fit_generator()` if the batch generator produces more samples than expected by `samples_per_epoch`.,0
Remove Sequential.model deprecation warning (#10256),0
* Only support lanczos resampling if available,0
This also disables the legacy copy of this test within the TensorFlow repo entirely (rather than backporting the fix and other changes it depends on).,0
* Added support for the new pydot API to fix find_graphviz error,0
* Bugfix & simplification,0
This commit also adds a clear_previous method.,0
"/home/yeverino/.conan/data/tensorFlowLite/0.1/demo/testing/package/d351525cc53ebe68279edf1978846402420066e7/lib/libtensorflow-lite.a(batch_matmul.cc.o): In function `void ruy::detail::CreateTrMulParamsAssumingColMajorDst<(ruy::Path)113, signed char, signed char, int, signed char>(ruy::Mat<signed char> const&, ruy::Mat<signed char> const&, ruy::Mat<signed char> const&, ruy::MulParams<int, signed char> const&, ruy::ChannelDimension, ruy::Ctx*, ruy::TrMulParams*)':",0
Avoid deprecated getargspec (#11463),0
* Update docstrings,0
* Add weighted_metrics arg to compile,0
Add missing license file to the keras pip package.,0
Merge pull request #1442 from jfsantos/patch-8,0
add tests for batch normalization,0
PiperOrigin-RevId: 433516308,0
* fix docs,0
Functional API guide: fix variable names "loss"->"output" (#3856),0
"1. The issue described in https://github.com/fchollet/keras/issues/7397
I.e. the embedding layer has gradients represented by an IndexedSlice as
opposed to a tensor.",0
* Code formatting to address CI errors,0
* Progbar: Explain stateful metrics handling,0
"commit 67e242d926b577f440217d9d10b890f54bb875c3
Author: Max Pumperla <max.pumperla@googlemail.com>
Date:   Thu Jun 7 20:54:23 2018 +0200",0
* Update variational_autoencoder_deconv.py,0
"- if asked, add the accuracy to the log",0
* Fix PEP8 errors,0
* Remove lines with no effect,0
* change plot_model to fully support plotting submodel and fix bugs,0
* update ds,0
3rd pass,0
"or instance, data are not looped infinitely anymore.",0
Added objective: Kullback Leibler Divergence (#2872),0
Signed-off-by: Micka?l Schoentgen <contact@tiger-222.fr>,0
"@fchollet , I made the requested change.",0
- Cleanup TODO related to removing testing infra as a dependency of the Keras target.,0
PiperOrigin-RevId: 410381238,0
Refactor disparate metrics-related files into a single metrics folder.,0
batch updating weights,0
extract_archive() redundant open (#5861),0
"I added cudnn availability check, but I am not sure how to check "" if the code is supposed to run on GPU"".",0
PiperOrigin-RevId: 474587165,0
bug fix on pandas DataFrame support (#8494),0
IndexError fix (#7865),0
"I just used made up values, feel free to change to whatever makes more sense!",0
"This commit fixes the DisconnectedInputError described in issue
the `get_output` method.",0
* Switch use of TF cond function to use public function.,0
* Add reference to slides for RMSprop,0
so can i assume both of the two commands are building the TF C libs for `M1 darwin_arm64`?,0
Let me know what you think.,0
* #10356 Convert weights of CuDNN/plain RNN nested in TimeDistributed.,0
The code in tensorflow/tensorflow repository IS the source of truth for the moment.,0
"passing lr is still
   supported.",0
PiperOrigin-RevId: 493652632,0
"commit 7365a99f6e832847808c7aa28718d32fbc744b21
Author: fuzzythecat <fuzzy0427@gmail.com>
Date:   Fri Jun 1 04:45:26 2018 +0900",0
"The old behavior (before the previous change) was to always add `.tar.gz`, giving `.tar.gz.tar.gz` files.",0
Also pin the numpy version to 1.19 which is same as the one TF is using.,0
"Documentation/Example for:
* tf.keras.optimizers.schedules.serialize
* tf.keras.optimizers.schedules.deserialize
* tf.keras.layers.serialize
* tf.keras.layers.deserialize",0
Add output_mode to Discretization layer,0
* remove usage of tf.assign() in the tensorflow backend (#3316),0
Hope CNTK team could find a more standard solution.,0
* Make padding argument polymorphic.,0
"IIRC the accuracy metric when paired with binary-crossentropy loss assumed two classes or a different kind of encoding in the labels, so the network was trained well but the reported accuracy was wrong.",0
cannot run keras test autoencoders code:  Error when checking model target,0
PiperOrigin-RevId: 426181926,0
"To address this issue, we introduce a new tag `oss_excluded` for platform exclusion design.",0
Use all top MAX_NUM_WORDS words for the embedding matrix. (#11202),0
* Made Sequence iterable,0
Merge pull request #1081 from farizrahman4u/patch-17,0
Are we ready to merge?,0
Some clarifications about the mxnet backend in the docs. (#11729),0
Do not you think it's a bit strange?,0
"@AnikaTabassum
Can you please confirm if your cpu supports AVX,  as informed earlierplease refer to the instructions [here](https://www.tensorflow.org/install/pip?lang=python3#hardware-requirements)",0
PiperOrigin-RevId: 458959592,0
@georgepaw feel free to open this PR again when the comment from Reed is addressed.,0
so either this Eigen package is assuming cuda initialization order without a guarantee or nvidia is changing their protocol.,0
* Fixing pep8.,0
Would you perhaps like me to close this and change it into an issue instead of a PR?,0
* Issue to get shape of a tensor.,0
This reverts commit f4df2240c1ce8944ffa88bcaf7ab527e600c4378.,0
Remove `keras.experimental.export_saved_model` API.,0
- The extraneous check of `input_spec` is removed.,0
The slowest test is usually cifar dataset test and tensorflow convolutions.,0
Detailed description：,0
* Remove deconv2d  legacy preprocessor,0
- add the loss to the log,0
PiperOrigin-RevId: 501583135,0
make pydot optional (#5567),0
* Fix docs autogen when running on python 3.6.2,0
* Checking that ndim is >= 3 for TF batch_dot,0
* Corrected stylistic issues -- brought to compliance w/ PEP8,0
"Network without the Softmax activation in the Input Memory Representation at epoch=100
======================================================================================
```
Iteration 10
Train on 10000 samples, validate on 1000 samples
Epoch 1/10
10000/10000 [==============================] - 8s - loss: 0.0549 - acc: 0.9819 - val_loss: 1.8088 - val_acc: 0.6470
Epoch 2/10
10000/10000 [==============================] - 6s - loss: 0.0612 - acc: 0.9802 - val_loss: 1.7839 - val_acc: 0.6650
Epoch 3/10
10000/10000 [==============================] - 6s - loss: 0.0542 - acc: 0.9812 - val_loss: 1.7595 - val_acc: 0.6750
Epoch 4/10
10000/10000 [==============================] - 6s - loss: 0.0538 - acc: 0.9826 - val_loss: 1.8198 - val_acc: 0.6670
Epoch 5/10
10000/10000 [==============================] - 6s - loss: 0.0590 - acc: 0.9790 - val_loss: 1.7891 - val_acc: 0.6650
Epoch 6/10
10000/10000 [==============================] - 6s - loss: 0.0548 - acc: 0.9803 - val_loss: 1.7682 - val_acc: 0.6790
Epoch 7/10
10000/10000 [==============================] - 6s - loss: 0.0455 - acc: 0.9841 - val_loss: 1.8394 - val_acc: 0.6730
Epoch 8/10
10000/10000 [==============================] - 6s - loss: 0.0559 - acc: 0.9797 - val_loss: 1.7764 - val_acc: 0.6650
Epoch 9/10
10000/10000 [==============================] - 6s - loss: 0.0488 - acc: 0.9835 - val_loss: 1.7711 - val_acc: 0.6620
Epoch 10/10
10000/10000 [==============================] - 6s - loss: 0.0502 - acc: 0.9834 - val_loss: 1.8225 - val_acc: 0.6700
```",0
Fix typo (#3070),0
PiperOrigin-RevId: 458318117,0
Fix typo in why use keras docs (#8696),0
"The OP of the linked SO question didn't bother to give a sample input, 
so I've no idea what it could possibly be.",0
* Add `separable_conv1d` for Theano,0
* added tests for clipnorm and clipvalues,0
* Fix things based on code review.,0
PiperOrigin-RevId: 479367785,0
Add dummy data generation code.,0
Model generators: Make sure all threads finish when stop is requested (#5049),0
Simplify the conditional logic check for KPL.,0
Minor typo is fixed.,0
PiperOrigin-RevId: 443528565,0
"So we need to catch
both exceptions to be compatible.",0
Improvement for tf.keras.utils.get_file,0
fix https://github.com/keras-team/keras/pull/8274 (#8854),0
* Fix control_flow_ops import,0
The discriminator also uses Batch normalization and drop out.,0
Allow saving weights of a very deep model into a HDF5 file.  (#9398),0
"Saving time for NASNetLarge:

- Legacy h5: 2.8s
- New h5 + zip: 2.6s
- New h5 + no zip: 2.5s
- New npz + zip: 3.2s
- New npz + no zip: 3.0s
- Legacy savedmodel: 142.2s (!)",0
* add check for filepath is string before parsing,0
- The signature for `reset_states(state_values)` is changed to `reset_states(states)`.,0
* Added 'causal' convolutions padding option to Conv1D.,0
* cleanup,0
Reduce tests for applications (#10346),0
"commit 25283eacbf21f963205ccadcfb821e6cae7e0023
Author: Francois Chollet <francois.chollet@gmail.com>
Date:   Tue May 29 09:31:14 2018 -0700",0
"* fix and add test for overwrite option, add docs",0
2) Makes JSON encoding/decoding symmetric if the user provides the modules and custom objects to the decoder.,0
"* Fix get_file download progress bar, including no Content-Length header.",0
autogen helper for classes and functions (remove code duplication) (#10462),0
(.text._ZN3ruy6detail36CreateTrMulParamsAssumingColMajorDstILNS_4PathE113EaaiaEEvRKNS_3MatIT0_EERKNS3_IT1_EERKNS3_IT3_EERKNS_9MulParamsIT2_SC_EENS_16ChannelDimensionEPNS_3CtxEPNS_11TrMulParamsE[_ZN3ruy6detail36CreateTrMulParamsAssumingColMajorDstILNS_4PathE113EaaiaEEvRKNS_3MatIT0_EERKNS3_IT1_EERKNS3_IT3_EERKNS_9MulParamsIT2_SC_EENS_16ChannelDimensionEPNS_3CtxEPNS_11TrMulParamsE]+0x1d9): undefined reference to `ruy::Ctx::set_performance_advisory(ruy::PerformanceAdvisory)',0
Changed the image captioning example so it works with current keras.,0
* Merge GRUCell and GRUResetAfterCell.,0
Added a test to ensure that the module name is always valid. (#12288),0
Skip histograms in Keras automatic outside compilation test if not using MLIR bridge,0
PiperOrigin-RevId: 427512047,0
Error when checking VGG16 input shape with include_top=False,0
add regularizer and constraint to embedding,0
Optimize MultiHeadAttention layer by removing a transpose,0
DOC: don't reuse names in introductory example (#12721),0
We need to check with the Theano devs to what extent it's possible to do shape inference outside of the graph in Theano.,0
PiperOrigin-RevId: 417732427,0
* Trigger,0
What you would expect after one epoch is to see both accuracies around 0.7 or so.,0
Fixes automatic doc generation problem with nested lists.,0
This example yields a gain in the accuracy by the use of Eigenvalue Decay of 2.71% (averaged over 10 runs).,0
"commit 39a59192e96fe4098f1d663384b79b10e3bcc979
Author: Yarin <yaringal@gmail.com>
Date:   Sat Feb 20 02:15:29 2016 +0000",0
"Also, the `output_shape` needs to be passed by hand, do you think we can infer that but just forcing the user to use `batch_input_shape` when a deconv layer is part of the model?",0
* Cleanup legacy Keras [1/N],0
* data_utils.py and data_utils_test.py updated based on review (#5861),0
...instead of relying on implicit default value.,0
"From what I can remember, these are the open issues raised on this PR.",0
Fix typos in functional API guide,0
Merge branch 'master' of github.com:keras-team/keras,0
* Corrected 3 small typos in training.py error messages.,0
PiperOrigin-RevId: 526604980,0
"Can you give us more information about your problem domain, data and model? Or perhaps a code snippet that illustrates the performance degradation.",0
Add F-score metric to metrics.py (#3895),0
* add arguments arg to merge,0
* update Docker image to cuDNN v5,0
"Remove CategoryCrossing benchmark, update hashed crossing benchmark",0
"Considering clipvalue is positive and the definition of clip (http://deeplearning.net/software/theano/library/tensor/basic.html#theano.tensor.clip), shouldn't it be T.clip(g, -self.clipvalue, self.clipvalue) instead of T.clip(g, self.clipvalue, -self.clipvalue)?",0
Reading though `test_callbacks.py` isn't easy because one have to check all the arguments of `get_test_data` every time to check that something out of the ordinary isn't there.,0
Added a decorator for flaky tests which rerun the test on specific errors. (#11660),0
* Adding MeanSquaredLogarithmicError loss.,0
I followed @fchollet's suggestion and tried to keep the test as minimal as possible.,0
PiperOrigin-RevId: 463620470,0
Update requirements.txt for OSS keras.,0
"Otherwise the order of magnitude of your objective changes
purely based on the number of masked entries in your training data.",0
* removed space at the end of a line in save_img method.,0
This is somewhat cleaner since it restores the exact same model (no usage of traces).,0
PiperOrigin-RevId: 426773173,0
"The existing conversion functions are also still
registered to maintain backwards compatibility.",0
Added travis_retry for commands which often fail. (#10980),0
Improve the docstring of Conv3DTranspose (#10342),0
Remove TimeDistributedHighway,0
"In Keras syntax it implies that we are applying the dense layer to an `activation` tensor, but that isn't the case.",0
A Keras callback to save a checkpoint before worker preemption or maintenance.,0
* imsave method in scipy.misc package is deprecated - now using imageio,0
Bug fix + test - Sequential.pop() (#3252),0
"In contrast, tf.keras allows this:

```python
from tensorflow import keras
clf = keras.wrappers.scikit_learn.KerasClassifier(...)
```",0
I would really appreciate your thoughts on this.,0
* bug fix on pandas dataframe support,0
* Fix backend batch_dot tests,0
why use np.random.seed(1337) in mnist_cnn.py example,0
"* Under a distribution strategy, `Loss(reduction=SUM_OVER_BATCH_SIZE)`
   is disallowed everywhere except when passed to `compile()` for
   use by `fit()`.",0
"Do you
> plan to add automatic inference for the type attributes or should I assume
> I need to set them?",0
fix list_devices() function is not available issue (#8567),0
@titu1994 might the keras-contrib version be easy to update accordingly as well?,0
Error in Lambda layer when wrapped function expects non-float argument,0
Fix common backend styles (#7476),0
This class can be used to compute the IoU metric for a multi-class classification task where both the labels and predictions are in the one-hot encoding format.,0
PiperOrigin-RevId: 417513682,0
* main() removed,0
"@captainst your approach doesn't work, when you want to fine-tune top-k layers part of your base-model that may have BN layers.",0
* manually terminate threads process returned by `generator_queue()`,0
Decrease the number of epochs to 3 to prevent keras_premade_models_test from timing out with lengthy MultiWorkerMirroredStrategy tests.,0
PiperOrigin-RevId: 493003876,0
"update conv3d, pool3d, add resize_volumes and spatial_3d_padding",0
* mnist_tfrecord.py pep8,0
"commit bbf4283457e38859d6dff5a2f0990f8347799e6c
Author: Bohumír Záme?ník <bohumir.zamecnik@gmail.com>
Date:   Wed Jun 6 20:52:26 2018 +0200",0
"--
660d02ebccbd1327d2674ff35bc0af2303c612d5 by Matt Lyon <matthewlyon18@gmail.com>:",0
- extract the code to a separate function,0
Update pooling.py (#13467),0
Update audio_conv_utils.py (#5111),0
"https://github.com/bnaul/keras/commit/e04ce5e37ec234debaea8c6482ef90be1f
88286d",0
PiperOrigin-RevId: 401625742,0
"Beam search is not trivial to follow, I tried to make it as instructive as possible (please give feedback!).",0
* Stacking Arguments in split Function Signatures.,0
TBD.,0
Minor update to optimizer.aggregate_gradients under DTensor.,0
PiperOrigin-RevId: 365252577,0
"Travis pep8 (but not autopep8 -d on my box) complains that
/home/travis/build/fchollet/keras/keras/utils/generic_utils.py:296:21: W503 line break before binary operator
                    and current < self.target):
                    ^",0
* Forgot to change the constructor call.,0
docs: fix typo inputs_shape -> input_shape (#4901),0
Replace keras.engine.topology.Layer with keras.layers.Layer in the API (#11972),0
* Add missing ')',0
"`K.switch` is exactly `K.where`, except it also works for higher-dimensional cond arguments.",0
* * more doc in deconv layer,0
"Merge changes to add unitnorm constraint, support for constraints and regularizers in Embedding",0
"* fix init/get_config of crop1d/3d, add test codes for cropping1d/2d/3d",0
"This PR just puts a warning in the docs, but I encourage someone to think of a better solution.",0
This pass cannot replace yet the EarlyBroadcastInDimOp pattern because it does not allow to move elementwise ops into blocks (which is needed to be able to merge assuming ops).,0
I ran into this issue myself and this fixed it for me.,0
Pulls keras/ directory out of graph/ directory to resolve namespace resolution issue,0
"Currently, `no_oss` is used to exclude a test from running in the official TF OSS test infrastructure.",0
cc @mihaimaruseac @bhack,0
Add a HashedCrossing preprocessing layer,0
Expose a test related internal API for keras.,0
"There is no reference to this method, so we just delete the method.",0
"It was still very convenient to store the images in separate folders, since it allowed:
- to infer the single class for 80% of the images
- to easily check some exemplary pictures of a class in the file system",0
Add the numpy implementation in the keras backend documentation (#11507),0
What are the possible types of output_mask?,0
* Added error messages,0
Fix typo in index.md,0
"- Test is now modular with @pytest.mark.parametrize making it easy
  to add more tests in this category.",0
* Remove the check about first state,0
Or do certain parts of the system assume int32 ops will always be placed on CPU?,0
* Add test for Sequential.pop(),0
"That indicates a problem with the model, or a unreasonable assumption by TOCO.",0
PiperOrigin-RevId: 402346094,0
* batch_matmul removed,0
* Add option to specify resampling method in load_img,0
this obviously works if you can assume 0.0 is not real value in your data.,0
update documentation for "load_weights",0
* Clean up generic_utils.py docstrings,0
Print EarlyStopping verbose message on_train_end. (#4332),0
Add a few explanatory comments in recurrent.py,0
PiperOrigin-RevId: 392092094,0
* Added Cropping layer tests with no cropping,0
"* get_file() with tar, tgz, tar.bz, zip and sha256, resolves #5861.",0
* I converted the list to a numpy array directly to avoid multiple conversions `list` -> `ndarray`.,0
add cropping1d/2d/3d layers (#3509),0
* Fix naming convention,0
* bypass shape inference in deconv2d,0
"- Take filepath as argument, not dir",0
Please consider updating [CONTRIBUTING.md](https://github.com/keras-team/keras/blob/master/CONTRIBUTING.md) to be more explicit about what kinds of contributions are welcome.,0
* mnist_tfrecord.py indentation fix,0
"Open resources (ordinary file, HDF5, tar, urlopen response, etc.) were often not
closed properly.",0
* training.py pep8,0
I had not noticed this.,0
Sorry for not doing all the work at once.,0
PiperOrigin-RevId: 380115199,0
Implement a Sharpness-Aware Minimization (SAM) API in Keras.,0
* extract_archive() py3 fix (#5861),0
[MLIR][MHLO] Merge assuming ops with compatible witnesses,0
PiperOrigin-RevId: 484125705,0
- [x] This PR requires new unit tests [y/n] (make sure tests are included),0
Bump the keras version from 2.8 to 2.9 on head.,0
* Fix parameterization,0
* Making variable names more explicit.,0
Add pyux test (#12137),0
* typo,0
"Alas, I don't know whether the problem is that the session state pointer isn't valid,
or that the GetSessionHandleOp code is assuming that the value is valid without
first testing it.",0
We can control which files get displayed with `mkdocs.yml`.,0
"If self.layers is empty, an IndexError appears when accessing it.",0
Apply clang-tidy fixes for performance-for-range-copy in merge_assuming_ops.cc (NFC),0
* Add 'one' initialization,0
Improvements to style transfer as discussed in https://github.com/fchollet/keras/pull/6872 (#6877),0
Bug fix,0
* Fix bug in sparse_categorical_accuracy,0
"--
e4cca710258601ca23b15ad3c85c4f7b9fe04d6c by Ashutosh Hathidara <ashutosh.hathidara@legatohealth.com>:

Refactored as per comments",0
FIx typos,0
"* Adding Loss, LossFunctionWrapper, MeanSquaredError classes.",0
ImageDataGenerator save_to_dir changes generated data,0
"commit 3f4ccbb1966f3b14b3c98f4df45e018ac24ede13
Author: Francois Chollet <francois.chollet@gmail.com>
Date:   Tue Jun 5 17:30:48 2018 -0700",0
"Is this a random error during launch, or is it maybe due to a memory leak when running different tests sequentially on the same GPU?",0
PiperOrigin-RevId: 476463106,0
* remove inaccurate warning,0
* PEP8 Fixes,0
PiperOrigin-RevId: 481043423,0
2. Might it be able to extract some data directly from the internal model by default?,0
Touch ups in new saving logic:,0
* fix batch_dot in ref ops,0
PiperOrigin-RevId: 415624914,0
* Add documentation to several activation functions,0
"Instead save the wrapped function in an attribute and call
getargspec on this attribute during documentation generation.",0
TensorFlow K.Function() additional ops via fetches (#8286),0
Add missing comment for `assume_valid_feeds` in GenericLayoutOptimizer.,0
* image_ocr: change transcription technique to make it easier to extend the alphabet.,0
* set_of_lengths if/else + whitespace,0
"When using `tf.keras.Model.fit` and `ParameterServerStrategy`, `on_batch_end` is not called when the batch finishes, but rather when it has been enqueued.",0
# This is a combination of 6 commits.,0
Fix serialization,0
"Luong-style attention attention use three types of scoring methods, namely dot, general and concat.",0
Increase file save hash size (#8277),0
This change makes fit and fit_generator respond alike to a training stop at the end of a batch in a callback.,0
PiperOrigin-RevId: 417846024,0
"* add zoom_range test, exception for invalid zoom_range",0
This PR fixes the redundant function module names in auto-gen docs.,0
PiperOrigin-RevId: 393891991,0
Creates very good reconstructions.,0
- fix GRU class name in topology.py (weights conversion),0
- added stateless model that converges or not depending on the parameters in the script head,0
PiperOrigin-RevId: 449079528,0
Sync Keras optimizer with tf.keras optimizer (#12841),0
"Yeah, I know, didn't think about tests too much tbh.",0
- [ ] This PR changes the current API [y/n] (all API changes need to be approved by fchollet),0
"commit 5eecd55a6f1d6d149b42f9b76aa53d4c5ab8d3eb
Author: Amir Alavi <s.amir.alavi@gmail.com>
Date:   Thu May 24 16:54:20 2018 -0400",0
PiperOrigin-RevId: 515713758,0
"I had the exact same line of thoughts, and below are what I came up with:",0
* Fixed newly introduced PEP8 errors,0
"Set error message with single quotes, as requested",0
"The version information is current populated with dummy data, and not being consumed by the Keras code.",0
Allow Lambda layer to pass arguments to Layer constructor.,0
revert back to register_keras + print value,0
Add an advanced activation layer for ReLU (#10322),0
"For example, input can be a numpy array and target can be a tensor.",0
"To fix this, this change stores the param shape as a member variable and creates a ones or zeros tensor of that shape on the fly.",0
Doesn't seem like anything is out of date?,0
PiperOrigin-RevId: 433874639,0
Change the size of //third_party/py/keras/layers/preprocessing:normalization_distribution_test_gpu to large due to timing out occasionally in TAP,0
Add `tf.keras.__internal__.apply_name_scope_on_model_declaration(...)` flag for Keras base layer to respect `tf.name_scope` in layer declaration context.,0
* training.py pep8 whitespace,0
Feel free to maintain your own `.gitignore`.,0
13) Adagrad changes default learning rate from 0.01 to 0.001,0
Any chance this might also help with tensorflow + input tensors?,0
Exception: Output tensors to a Model must be Keras tensors.,0
Even more informative docs.,0
Bug fixes:,0
Enabling limited TensorBoard callback use with Theano and CNTK. (#8996),0
* Add TF shape correctness test,0
update comment,0
I would appreciate it if you could check this issue.,0
Fix small doc error (#10453),0
* Checking error is thrown if ndim < 3 in batch_dot for TF,0
"import `pydot`, improve error messages about `pydot` and GraphViz, bump to `pydot >= 1.2.4` (#9904)",0
Update error messages in keras/utils/generic_utils.py,0
PiperOrigin-RevId: 502721473,0
Added tf.keras.layers.TextVectorization instead of the explicit URL.,0
* Add multiprocessing as an option with the pickle_safe argument,0
- I put music_ as a comnon prefix as this is the most different aspect of then from other models.,0
* remove spatialalphadropout test,0
"* Added in the documentation an example of custom layer with multiple
inputs and outputs.",0
* Add API conversion interface for Dropout layer,0
This can trigger cross-graph bugs when using a BatchNormalization instances from different graph functions.,0
@xingdi-eric-yuan?,0
Revert "Add verbose parameter to audio_dataset_from_directory",0
* fit(steps_per_epoch) initial validation support,0
Masked and non-masked merge bug fix (#3218),0
Final tweaking,0
"vst1_lane_f32(__builtin_assume_aligned(c, 1), vreinterpret_f16_f32(vout01), 0);",0
Thus it fails on theano and cntk backends.,0
* Added the missing argument in the test suite.,0
Sync OSS keras to head.,0
* PEP*,0
* README for docker,0
(.text._ZN3ruy6detail36CreateTrMulParamsAssumingColMajorDstILNS_4PathE113EaaiaEEvRKNS_3MatIT0_EERKNS3_IT1_EERKNS3_IT3_EERKNS_9MulParamsIT2_SC_EENS_16ChannelDimensionEPNS_3CtxEPNS_11TrMulParamsE[_ZN3ruy6detail36CreateTrMulParamsAssumingColMajorDstILNS_4PathE113EaaiaEEvRKNS_3MatIT0_EERKNS3_IT1_EERKNS3_IT3_EERKNS_9MulParamsIT2_SC_EENS_16ChannelDimensionEPNS_3CtxEPNS_11TrMulParamsE]+0x2ae): undefined reference to `ruy::Allocator::AllocateBytes(long)',0
PiperOrigin-RevId: 421625771,0
"The issue arises due to the conflict of two behaviors specific
to the Theano backend:",0
* Add test for preprocessing_fucntion,0
PiperOrigin-RevId: 389234454,0
PiperOrigin-RevId: 364897754,0
"* Minor cleanup & improvments in docs, fixed PEP breaking formatting in attention test",0
This includes calling layers with positional arguments with the old interface.,0
"The non-experimental mixed precision API was added in TensorFlow 2.4, and since then the experimental API has been deprecated.",0
* improve reabability of numpy rnn,0
Bug fix: K.batch_dot(); tf backend (#6219),0
Update keras to import tensorflow.compat.v2 as tf.,0
I haven't thought about Merge layers much,0
Add requested test for error message when None origin,0
"For e.g, the 2nd model in my first comment.. what would it look like ?",0
Enable automatic shape inference when using Lambda layers and CNTK.,0
* added file_format and **kwargs parameter to save_img and updated docstring,0
Add missing closing parens.,0
Non training Batch Norm operator has bad performance for it running into tensorflow's non fused batch norm API (#10207),0
"add test functions for Convolution3D, MaxPooling3D, AveragePooling3D, ZeroPadding3D and UpSampling3D",0
* Moved to_data_format to generic_utils.py.,0
* fix minor formatting,0
Is there anything you could afford to leave out? (@fchollet),0
Update the OSS keras to test with _PREFER_OSS_KERAS = true.,0
* TST: add unit test,0
This reverts commit d064d6e41d2f3fad390e82eea6b4edc6b9c46558.,0
"Previously `class_weights` was ignored with a logging warning if
`sample_weights` was also provided.",0
"In other words, the backend functions, implemented in only a single backend, are not included in the ""backend_test.py"".",0
Received: keras.engine.input_layer.InputLayer object,0
Remove CombinerPreprocessingLayer,0
Add instructions to docstring about using metrics with from_logits=True losses.,0
Raise error if a non-optimizer is passed to LossScaleOptimizer.,0
"commit 0de2adf04b37aa972c955e69caf6917372b70a5b
Author: fuzzythecat <fuzzy0427@gmail.com>
Date:   Tue May 29 13:58:18 2018 +0900",0
adding option to specify classes in all models in applications (#4947),0
PiperOrigin-RevId: 407952415,0
* update VAE examples (MLP and ConvNet) to the new API,0
Experiment new layout map API for keras models.,0
fix according to jruales' review,0
...as an experiment to see if makes a difference in test running times.,0
"This patch allows to
reduce terminal I/O throughput while keeping reasonable high visual
update rate (defaults to 100 refreshes per second).",0
PiperOrigin-RevId: 388839492,0
PiperOrigin-RevId: 419977356,0
Fix doc (#10327),0
* Fix comments and cosmetics on count_params,0
* add support for case static axis is in front of batch axis,0
clean code,0
"commit 1ab4e19dfe9d49defd5575a5c2b0b880b5c46eb5
        Author: Yarin <yg279@cam.ac.uk>
        Date:   Fri Feb 19 16:41:48 2016 +0000",0
"So if a layer has multiple input layers (""inbound_layers""), the whole model is no longer sequential...",0
use autopep8 to fix the code to match pep8 coding style,0
Reverse the type checks before `convert_to_tensor`.,0
- Export optimizers to `keras.optimizers.__init__` to resolve discrepancy between tf.keras and keras packages.,0
Merge branch 'backend' of https://github.com/fchollet/keras into backend,0
* add test_tfoptimizer_pass_correct_named_params_to_compute_gradient,0
It requires very little work since all the code and docstrings have already been written.,0
- These changes do not tamper with the existing get/set_weights code,0
"If your problem still occurs, feel free to raise an issue in the tensorflow repo.",0
Add a 'period' variable to ModelCheckpoint to save every period epochs (#4687),0
Use tensorflow leaky_relu op for efficiency (#9044),0
- make them parametric,0
"Currently, the module name of functions (those which are not methods of a class) is repeated two times in documentation.",0
* Add support for go_backwards in dynamic TF RNNs,0
PiperOrigin-RevId: 453967472,0
Merge pull request #17231 from haifeng-jin:mha,0
Add `-oss_excluded` to TF build/test tag filters,0
PiperOrigin-RevId: 381352128,0
Update wording in "LearningRateScheduler" (#10617),0
PiperOrigin-RevId: 428542266,0
* Update cifar10_cnn_capsule.py,0
PiperOrigin-RevId: 360702882,0
Also cleanup some small parts in BaseImageAugmentationLayer for docstring.,0
change notations and docstrings for 3D layers,0
* test_model_saving.py tests reshape when loading weights,0
* Reverted wrappers.py,0
"Do you think we may have problems changing the learning rate of adam, rmsprop and such?",0
cannot use tf.keras.preprocessing.image.random_channel_shift or apply_channel_shift with tf.data.Dataset functions like image_dataset_from_directory or tensor_slices.,0
"- Have you considered adding the name-based connection scheme as a new class of model, or a new class of container?",0
Fix stop_gradient inconsistent API (#7416),0
Fix summary about models (#8245),0
Add API conversion interface for both Pooling3D and Global Pooling  (#5707),0
This allows us to avoid one of the hard deps back to TF.,0
- Specify return types as many as possible.,0
Fork and update the API compatibility test for OSS keras.,0
Hope it could help to finalize this.,0
* fix pep8 issue,0
"Consider:

```python
text_encoder = LSTM(...)

x = Input(...)
y = text_encoder(x)
y = Dense(...)(y)

text_clf_model = Model(x, y)

x2 = Input(...)
y2 = text_encoder(x2)

feature_extraction_model = Model(x, y)
feature_extraction_model.set_trainable(False)

# And now I can't train `text_encoder`? Really?
text_clf_model.fit(...)  # does not work
```",0
"Plus, if you suspect a bot (e.g. based on browser signature), ask to solve a Captcha.",0
The most common use case is to one-hot 1D integer tensors (typically labels) into a 2D float tensor.,0
TypeError: __init__() got multiple values for keyword argument 'input_dim',0
Nope.,0
* raise ValueError if `inputs` is not a Keras tensor,0
Add negative parameter validation to convolution layers.,0
"* refactor rnn generate dropout mask method, to enable cntk and theano",0
Modify the check on if model variables should be overwritten.,0
* Much better image data augmentor,0
* Adding FalsePositive metric class.,0
Fix typos (#5753),0
* TST: only test on tensorflow,0
Fix Sckit-learn API get_parameters bug (#5121),0
"- on the TH front, it isn't the case, because the (niche) 3D use case is hard-coded.",0
* fix signature,0
Added CropImage layer.,0
"At ```backend_test.py```, we would like to check the equality between static keras shape and dynamic shape.",0
* Fix applications imports,0
image_dim_ordering causes very different convergence results (between using 'th' and 'tf' in keras config),0
This reverts commit 6d3c3ddbe6f9c7548b8502b4432ad9690ccb386f.,0
"You can do it the same way it is done for vision models: the code is in a separate file, but each model module imports util functions from there so they are available as module attrs: https://github.com/fchollet/keras/blob/master/keras/applications/resnet50.py#L23",0
### Changes:,0
* Add kwarg and documentation for dilation_rate to SeparableConvs,0
The 2.13 release branch has been cut.,0
That's a very good point.,0
PiperOrigin-RevId: 395780095,0
Support the new `Deprecated:` and `Preview:` notices.,0
* add test with arguments for lambda layer too,0
"Keras premade models: Change the API endpoints of LinearModel and WideDeepModel to `tf.compat.v1.keras.models.XModel`, and deprecate the existing experimental endpoints.",0
Many subclasses currently depend on `self._convolution_op`  when subclassing the `Conv` class.,0
ping @EderSantana I'd love to hear Your opinion.,0
This reverts commit 459a4abd6b1898eb14b6d129578c6dca0d290543.,0
Merge pull request #1082 from PFischbeck/patch-1,0
Hey @DavidAriel.,0
* allow len1,0
This is breaking on head and blocking other cl submission.,0
"I haven't fixed them, as I am waiting your thoughts on the matter.",0
Also added unit tests for the various types of regularizers and when used as bias regularizers.,0
* Replace HTML markup by markdown,0
* Workaround for pydot generic Exception raising,0
Merge pull request #986 from tzachar/patch,0
"--
51d489a348e837031e65e7f425b95ada4b00d56e by Ashutosh Hathidara <ashutosh.hathidara@legatohealth.com>:

Adding layer name support for layer_range",0
PiperOrigin-RevId: 402437044,0
* Stop running np.median if no callbacks are run,0
* Finalize dynamic RNNs in TF,0
PiperOrigin-RevId: 428139848,0
support strides in conv3d by slicing the output,0
* fix a bug when calculate cntk version,0
* ValueError added,0
small fix by changing pad_z to pad_t,0
* Continued changes,0
* Add doc,0
@fchollet The tests are fixed now.,0
PiperOrigin-RevId: 480110921,0
* Remove loss_weights in Sequential.compile(),0
I'd appreciate more guidance to contributing if I didn't follow any guideline correctly.,0
Add one_hot code path for keras embedding layer.,0
"Because i want the enqueuer to be GeneratorEnqueuer and not OrderedEnqueuer.
(as keeping warning for the not safe in the fit_generator)",0
8) Adagrad adds iterations to its weight list.,0
* add example code on Cropping2D,0
* skip theano,0
* KLD: Clip at 1,0
Checking before using the attribute.,0
Add documentation for summary() feature,0
* Section for Training history visualization,0
* Bug fix - Sequential.pop(),0
Remove comments disabling pylint g-direct-tensorflow-import.,0
Update `Conv2D` call to the Keras 2 API,0
What is your issue with the architecture?,0
"test_random_uniform:
5.92s -> 0.18s",0
But we copy the tree manually.,0
Changed implementation for numpy reference operations (there is no need to iterate),0
Giving interesting speedups.,0
Revert the change for license section that cause OSS build failure.,0
List files in alphabetical order (#3871),0
* updated faq.py,0
Also we are removing `optimizers_legacy` namespace.,0
"Currently, it build the input_shape as a single `None` value if there is any of the inputs don't have `.shape`.",0
Updated the link.,0
Bypass the warning `warnings.warn('Custom mask layers require a config and must override '` when saving a model containing marge layers like `Add` / `Multiply`.,0
* #9112 Add (failing) tests of compatibility weights of GRU variants.,0
I haven't thought of that.,0
"This class consolidate most the common logic for augmentation layers, eg train/inference behavior.",0
reuse update_state docstring by using inheritance,0
- Use float divisions for Python 2.7 compatibility,0
BackupAndRestore callback: Graduate from experimental endpoint.,0
Update TensorBoard callback,0
[P] Update tensorflow_backend.py (#11294),0
Fix typo in the PIP package creation script.,0
"* When accessing KerasTensor.dtype, fail with a useful error message if the wrapped TypeSpec has no dtype field, or if the dtype field is not a DType.",0
* InceptionResNetV2 is not supported on CNTK (backend issues),0
* mnist_tfrecord.py extended description,0
"This is not always the case, for example when the mask is a single channel image and the input is a three channel image.",0
* Added keyword argument for *_generator methods,0
correct metrics.py and test_metrics.py appropriately,0
Add support for class methods documentation (#9751),0
* Removed the error check.,0
* changed rounding mode in theano to match tensorflow and updated docs,0
- add reset_after to GRUCell config,0
Remove lock in fit_generator (#3528),0
* clarifying documentation,0
It is something that makes sense.,0
* clean up tests,0
* Fix line length,0
Limit progress bar update rate in verbose=1 mode.,0
10) Nadam changes default learning rate from 0.002 to 0.001,0
Address requested changes in docstring,0
Add multiprocessing for fit generator (#3049),0
Fix issue probably-meant-fstring found at https://codereview.doctor,0
* Merge tests of converting weights from CuDNN RNN layer.,0
* fix spacing.,0
"passing epsilon is still
   supported.",0
* Duplicated tests to check sparse placeholder.,0
* Travis CI: reduce hardcoding of Python 3 versions,0
"Allow (n, 0) croppings on Cropping2d and 3d (#4941)",0
"* add audio_conv_utils.py, update applications.md",0
@hermansje would you like to open a new PR for your changes? (unless you are going to push your changes to this PR).,0
PiperOrigin-RevId: 431500786,0
ValueError: Unkown value for `standardize` argument of layer TextVectorization.,0
FIx `Exception: Invalid layer: LRN2D`,0
PiperOrigin-RevId: 448601665,0
* casted ReduceLRonPlateau lr log to float,0
Merge : Serialize output mask; Enable user arguments for callable mode (#4445),0
* Added the footer and header automatically.,0
* Fix typos,0
Fixes tensorflow_docs/site/en/tutorials/load_data/text.ipynb,0
7. Increase hidden unit size to improve model,0
Add generate dummy data.,0
8. Increase batch size to speed up training,0
Sync the callback API with new tf.keras API (#11808),0
Merge pull request #15423 from FabianGroeger96:bug-multi-head-attention,0
Add better error message for model.summary() (#11222),0
* fix too many values to unpack error,0
Thanks for the suggestions @lucasdavid!,0
"* Force overrides, print warning",0
Is there something wrong in OrthogonalRegularizer?,0
"Some argument descriptions referred to ""two"" values, which for 3D functions must be ""three"".",0
"# Conflicts:
#	keras/backend/tensorflow_backend.py",0
Also change some references to the experimental "set_policy" function to the nonexperimental "set_global_policy" function.,0
I would really appreciate if this would be looked into again.,0
Is that supposed to work without screwing up the already compiled discriminator?,0
Numpy backend implementation of rnn + cleanup of rnn tests (#11622),0
But framework-native data tensors are already supported by `_fit_loop` and `_test_loop`.,0
* Update test_metrics.py,0
Allow saving models directly to binary stream (#9789),0
PiperOrigin-RevId: 364604880,0
- Refactor learning rate schedule code to live in `keras/optimizers/schedules` (to match the API namespace).,0
"commit 88faa440d02df8ff356011258e3e89ce44a13e1d
    Author: Yarin <yaringal@gmail.com>
    Date:   Sat Feb 20 02:13:24 2016 +0000",0
First draft of the documentation for callbacks,0
Standardize on `use_causal_mask` in `call()` and mark `causal` argument in constructor as deprecated.,0
PiperOrigin-RevId: 471919942,0
Minor update for the dtensor tests to use keras code directly.,0
"set_weights
   is override to maintain backward compatibility.",0
I am using flow_from_directory and Data_generators when calling my loss function i want to know that image from which class or folder was taken in the input which is like unknown to me as data generators do not have that information .,0
PiperOrigin-RevId: 460537204,0
Argument documentation minor fix.,0
We also moved the check of variable key existence to base optimizer so that subclassed optimizers no longer need to copy the check around.,0
PiperOrigin-RevId: 422950111,0
Feel free to reopen a PR with at least a matching implementation in numpy/scipy and cntk or theano.,0
Add spatial dropout and 3D global pooling to docs (#10373),0
"* unit test, pass args and set uses_learning_phase for Bidirectional layer",0
keras/utils/vis_utils.py,0
PiperOrigin-RevId: 393836711,0
- How exactly does the name-based connection scheme work?,0
fix typo (#9391),0
* Support float64 dtype after tensorflow 1.8.0,0
"- Standardize import naming: there is now only ""test_combinations"" for test combinations, and ""test_utils"" for utilities.",0
PiperOrigin-RevId: 452594281,0
Is this going to be an issue?,0
* changes for @gabrieldemarmiesse,0
Merge branch 'tf-2' of github.com:keras-team/keras into tf-2,0
"The numbers here were obtained on my laptop, using tensorflow.",0
Fix SparseCategoricalAccuracy.update_state() doc string,0
* Fix Theano type issue,0
Fix typo in documentation,0
"ommit 574c4549da69f8c0831f02dce1ad05331d8b38ed
        Merge: 19ef51c bdb149d
        Author: Yarin <yaringal@gmail.com>
        Date:   Sat Feb 20 01:23:54 2016 +0000",0
Dimension error with sparse_categorical_crossentropy,0
Bug fix : Model.from_config (#5730),0
Please send any PR to that.,0
Merge pull request #941 from stephenroller/master,0
PiperOrigin-RevId: 432566225,0
data_utils: add error handling on url fetches,0
Crossentropy backend API consistency cleanup (#7199),0
PiperOrigin-RevId: 382130441,0
Adding `dict_items` [does not work](https://stackoverflow.com/questions/13361510/typeerror-unsupported-operand-types-for-dict-items-and-dict-items) in Python 3.,0
Change the ctc cost function to try and make the `test_ctc` pass again.,0
Add idf_weights as an init argument for lookup layers,0
Just a thought!,0
ValueError: A `Concatenate` layer requires inputs with matching shapes except for the concat axis.,0
"Theano's reshape
    automatically makes dimensions with length 1 ""broadcastable""",0
PiperOrigin-RevId: 528485014,0
* Update validation docs,0
It's just a DirectoryIterator.,0
"Could you provide the any verification for this PR? (eg the model is achieving the expected performance with this PR), and also does it need to generate a new set of weights?",0
* PEP8 linter fixes again...,0
"Previously, __call__ did not work correctly for Graph containers.",0
"There was some confusion around whether you could mask individual
timesteps.",0
"Dropout for LSTM, GRU, SimpleRNN, and Embedding layers.",0
The argument bias_initializer was not used in _SeparableConv. (#10687),0
* fix problem caused by interrupted git push,0
Allow oov tokens in vocabulary when invert=False,0
Add option to specify resampling method in load_img (#7975),0
PiperOrigin-RevId: 508776143,0
PiperOrigin-RevId: 425983026,0
"Based on a request from [this issue](https://github.com/keras-team/keras/issues/15185), added a link to the guide on masking.",0
* Removed trailing spaces,0
Fix typos (#11997),0
"The `tf.keras.activations.softmax` function, the `tf.keras.backend.softmax` function and the `tf.keras.layers.Softmax` layer now behave consistently and save the logits in `_keras_logits`.",0
"However, it is difficult to distinguish between temporary and permanent exclusions.",0
Update recurrent Keras layers with less cryptic messages,0
PiperOrigin-RevId: 437066591,0
Handle `mask` in `TimeDistributed` wrapper. (#10242),0
* Fix test,0
Add documentation for tf.keras.optimizers.schedules serialize and deserialize functions,0
SWWAE uses residual blocks.,0
* Docker image for test and experiment Keras,0
"""Epoch %d out of %d""",0
PiperOrigin-RevId: 355510565,0
* handle SummaryWriter based on tensorflow version,0
* Pull request revision (v2),0
Let me know how you think of this style and if this 'syntax' works well for the generated document.,0
"Saving best metrics based on Custom metrics failing (WARNING:tensorflow:Can save best model only with CUSTOM METRICS available, skipping)",0
Fix typos in CONTRIBUTING.md,0
* use ndi insteadskimage in random_transform,0
* Pass embedding data explicitly,0
"commit 3eab6103e0069d261c3e3586c12d5aaf0a331429
Author: Francois Chollet <francois.chollet@gmail.com>
Date:   Thu Jun 7 16:09:58 2018 -0700",0
* fix a free dimension bug,0
"However, it is useless to make this computation as there is nothing that can be determined about the output shape.",0
Any thoughts on your side?,0
Small fix in EarlyStopping,0
Don't rely on the per-batch times to compute the per-epoch `steps_per_second`.,0
"Further, this PR also removes from the docs the (wrong) module name of methods of classes like `ImageDataGenerator`.",0
@gabrieldmarmiesse thoughts?,0
"""ouput"" -> ""output""",0
* Fix tests.,0
"Deserializing the now-removed PolicyV1 and LossScaleOptimizerV1 classes is still supported, if they were serialized with get_config() prior to this change.",0
acgan: Fix generator producing pure black images (#8383),0
The tf.keras symbols are visible under tensorflow.python.keras and tensorflow.keras.,0
Information from the docstrings of the file constraints.py was not grabbed by autogen.py because the autogenerated code block was absent in templates/constraints.md and the corresponsing part of the PAGES list in autogen.py was not there too.,0
"commit f25b56f3a7547da94ffecee8701da5b34e757104
Author: Michael Oliver <michael.d.oliver@gmail.com>
Date:   Mon Apr 4 19:01:49 2016 +0000",0
This `test_model_method` is very big and makes it hard to find out how to work with it or add new test.,0
* Fix merge mixup.,0
"- GRU: add parameter variant: 'reset_before' (default), 'reset_after'",0
- py.test is configured to run with pytest-xdist with 2 processes in parallel because travis does provide multicore support (1.5 cores) and because the slowest cifar test spends time on download which can run in parallel with other tests.,0
PiperOrigin-RevId: 383705736,0
Bug fix + test : Initializing states for ConvLSTM2D (#6564),0
Added optional path argument (#3118),0
"Full shape received: (None, None, None, None)",0
* Minor changes,0
"Updating ConvLSTM to include 1D & 3D cases, as suggested by [this thread](https://github.com/tensorflow/tensorflow/issues/42399).",0
PiperOrigin-RevId: 352876083,0
(.text._ZN3ruy6detail36CreateTrMulParamsAssumingColMajorDstILNS_4PathE113EhhihEEvRKNS_3MatIT0_EERKNS3_IT1_EERKNS3_IT3_EERKNS_9MulParamsIT2_SC_EENS_16ChannelDimensionEPNS_3CtxEPNS_11TrMulParamsE[_ZN3ruy6detail36CreateTrMulParamsAssumingColMajorDstILNS_4PathE113EhhihEEvRKNS_3MatIT0_EERKNS3_IT1_EERKNS3_IT3_EERKNS_9MulParamsIT2_SC_EENS_16ChannelDimensionEPNS_3CtxEPNS_11TrMulParamsE]+0x2a6): undefined reference to `ruy::Allocator::AllocateBytes(long)',0
* move statement outside of if,0
* Cleanup legacy Keras [2/N],0
"To work around this, we disable the histogram-specific parts of the test in that case.",0
* Added the mode "bilinear" in the upscaling2D layer.,0
The same applies to the mask.,0
Add documentation for Merge layer,0
Fix interaction issues with mask and weights in weighted_objective,0
Replace literal constant 10 with variable num_classes in example/ (#8041),0
* Delete CIFAR10_with_Eigenvalue_Decay.py,0
Not sure how to solve this bug: "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint.",0
"Update metrics.md with a better reference to the losses.md page, in terms of losses",0
fix iteration shadowed in loop,0
* Added examples for fill_mode,0
Can Keras-1 help with that?,0
"We can work around this by calling into a deliberately
XLA compiled op for grouped convolutions only.",0
PiperOrigin-RevId: 448866495,0
"Currently if optimizer's learning rate is configured as LearningRateSchedule, then during each update step we call LearningRateSchedule for multiple times, which is harmful for performance.",0
* Fix slicing biases on CNTK backend.,0
Correct tokenization with multi-character `split` (#9585),0
"ParseSingleSequenceExample/ParseSingleSequenceExample/feature_list_dense_missing_assumed_empty,",0
"And by the way [TF is not afraid of converting biases](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py#L636) between both conventions there and back a hacky way - sum, divide to halves. :)",0
Fix typo (#7849),0
Now we can't import from `tests/` and `keras.utils.test_utils` don't se pytest.,0
Graph model was removed and the example was (incompletely) switched to functional model API in https://github.com/fchollet/keras/pull/2152,0
* links named "here" are difficult for individuals that need a screen reader for accessibility.,0
* Update imdb.py,0
fix typo (#9792),0
"Previously, strides were required to be smaller than the convolution
kernel.",0
* Update naming convention,0
Cheers!,0
Input() docstring fixes (#8573),0
"Luckily, urlretrieve is just a thin wrapper around
FancyURLopener, so we can make our own thin wrapper
that throws an exception instead of caching the
wrong file.",0
"This allows keras embedding layer to work better with DTensor use case, since the one_hot matmul is better supported in the SPMD expansion.",0
"This change was necessary because there exist objects which are instances of
`Tensor` and `EagerTensor` whose type does not subclass `Tensor` or
`EagerTensor`.",0
Move the util methods for checking dtensor strategy to a common place.,0
Updated Docs string with new apis .,0
PiperOrigin-RevId: 528838260,0
* Make PEP8 compliant,0
* add test for load/save weights (these methods are wrapped separately),0
- tweaked stateful model to converge,0
Added support for both Sequential and Graph,0
Deflake TensorBoard callback tests.,0
"--
3eee56fc4b62f40756277adf231a665ac89d2ab6 by Amogh Joshi <67437306+amogh7joshi@users.noreply.github.com>:",0
[P] Make keras.wrappers.scikit_learn accessible without extra import (#11966),0
PiperOrigin-RevId: 401282166,0
Revert "[Performance] Add a manager to share the sequence" (#7274),0
"Then, we rename `allow_sharing` to something like `advanced_sharing`, which means that the only users that understand the behavior can use it.",0
bug fix - run_internal_graph() (#9599),0
PiperOrigin-RevId: 382784449,0
I'm excited to be able use this.,0
"- Implementation involves creating Base N-dimensional `ConvRNN`, `ConvLSTMCell`, and `ConvLSTM` classes which are inherited from by the concrete implementations in `ConvLSTM1D`, `ConvLSTM2D`, and `ConvLSTM3D`.",0
* Update topology.py,0
* fixed minor review comments,0
"Add a paragraph to the 'Getting started with the Keras Sequential model' section
explaining how a Dense layer looks like and how it relates to activation
functions.",0
* Update target_tensors error message,0
PiperOrigin-RevId: 427329018,0
* Made the change on only one file.,0
Modify embedding to accept arbitrary input dim (#6392),0
* Allow variable number of input channels,0
* rest travis ci,0
This commit alphanumerically sorts the sub-directories before mapping them to label indices.,0
"commit 9f3d213c91906b3be5c876d539819a8577bc438c
        Author: Yarin <yaringal@gmail.com>
        Date:   Sat Feb 20 00:42:58 2016 +0000",0
* Move  to respective backends,0
* Pull request revision,0
* spelling/grammar,0
"- Refactor regularizers into callable objects, taking a tensor/variable and returning a loss contribution.",0
- The `LambdaMerge` layer is exclusive for `Sequential`.,0
ValueError: Please initialize `Prune` with a supported layer.,0
* fix,0
Issue to get shape of a tensor in the class EigenvalueRegularizer: the type returned for shape is different for Theano backend (Theano tensor type) and TF backend (TF TensorShape).,0
PiperOrigin-RevId: 406448465,0
Fix various failing tests in v1.,0
"Updating `stride` argument in `DepthwiseConv2D` class as it currently supports equal
length strides in the row and column dimensions.",0
0.3.2 PyPI release,0
* a capsule cnn on cifar-10,0
30:20WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available.,0
"If they are independent, or you make the assumption that they are, then you can do `-log(P(output1=1|data) * P(output2=c|data))` which can further decompose into `-log(P(output1=1|data))-log(P(output2=c|data))`.",0
Merge pull request #17965 from SamuelMarks:keras.layers.normalization-defaults-to,0
PiperOrigin-RevId: 480657508,0
Fix too many values to unpack error (#13511),0
* Added missing "depth" comment in 3D function,0
"First, it introduces a test which checks the composition of ""reshape""
and ""squeeze"" to make sure we get the same result using both Theano
and TensorFlow backends.",0
I don't understand why the tests didn't fail until now.,0
Should I close the PR ?,0
Support return_state parameter in ConvRecurrent2D (#7407),0
"This allows us to use set_previous in places where we previously
manually adjusted the previous layer, which means that layers
that have non-standard set_previous implementations (like Graph)
work properly when they are, for example, the first layer in a
Sequential model.",0
Update theano_backend.py,0
"With this modification the user does not have to know about the offset of 3, which is very tricky considering alsoe that even the [official tensorflow documentation](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/imdb/get_word_index) does not take into consideration this aspect.",0
* Correction to previous commit,0
I'd be happy to implement/PR but...,0
* multiple updates according to @fchollet's review,0
Imported from GitHub PR https://github.com/tensorflow/tensorflow/pull/49292,0
* space after period,0
When saving the weights a TypeError is raised by h5py.,0
Simplify - remove K.cast() (#8258),0
Remove batch_size when doing stepwise fit (#10144),0
"* The training loop (not the code in `Layer.call()`) takes care
   of averaging the input to `add_loss()` between replicas.",0
Add error message when calling `summary` on unbuilt subclassed models.,0
Issue: https://github.com/keras-team/keras/issues/16518,0
"However, this turned out to be very complicated since the two base optimizers (OptimizerV2 and the experimental Optimizer) have different method names and argument names, so I didn't go with this approach.",0
fix small inconsistencies in the documentation (#5817),0
* Skipping tests when py2 on other backends than tf.,0
Add an automatic PEP8 check on the pull request submission:\n - ignore most of the errors to avoid disrupting others\n - add a separate job to avoid confusion that all jobs fail because of a single pep error\n - fix few small pep errors,0
Allow unrolled RNNs with input_length=1 (#13078),0
Avoid double key lookup on callback.py (#3018),0
Found: None,0
* fixed pep8 blank line bug,0
GaussianDropout Bugfix (#5665),0
"Add 3D Convolutional layers(Convolution3D, MaxPooling3D, AveragePooling3D, UpSampling3D and ZeroPadding3D, working with theano backend)",0
PiperOrigin-RevId: 350851648,0
"For details, see:
Oswaldo Ludwig. ""Deep learning with Eigenvalue Decay regularizer."" ArXiv eprint arXiv:1604.06985 [cs.LG], (2016). https://www.researchgate.net/publication/301648136_Deep_Learning_with_Eigenvalue_Decay_Regularizer",0
py3.6 is about to reach end of support timeline.,0
* Improved backend handling for weight calculation,0
Error when checking model target,0
I am not sure exactly what are the expected inputs/ outputs.,0
* cam added,0
Also fix its docstring,0
Acc bug when using sparse label and custom sparse_categorical_crossentropy like loss?,0
* Add optional dependencies' links to download pages in README,0
Some refactoring.,0
Does that sounds reasonable?,0
* Fix warning message.,0
* Forgot semicolon.,0
Consider sending a PR to `keras-contrib` instead (see `CONTRIBUTING.md` for details).,0
"This has been fixed in recent PRs (albeit we still need to apply the same fix for `bias_add`, which isn't covered yet -- feel free to open a new PR for it :))",0
Added dtype parameter to zeros_like and ones_like (#5062),0
PiperOrigin-RevId: 383686466,0
Changed the tag for detecting where to put the numpy implementation.,0
Add Inception-ResNet v2 to application (#7753),0
Fix typo (#3505),0
added support of pydotplus (#6869),0
"Tennessee Leeuwenburg
http://myownhat.blogspot.com/
""Don't believe everything you think""",0
PiperOrigin-RevId: 439347906,0
Update sequence.md. (#4905),0
Changes in this CL are necessary to not break existing code.,0
* bug fix: flatten,0
Hard to test though.,0
Bypass shape inference in deconv2d and use the output shape provided by the user (#3838),0
Add K.resize_images backend op.,0
Updated 'voculary' with 'vocabulary'.,0
Bug fix for empty evaluations.,0
"However, `input_spec` is never `None`, because it is defined in `__init__` to be `InputSpec(ndim=3)`.",0
Fixes IndexError when converting sequence to matrix,0
- add parametric ids,0
* restored RNN layer,0
"Thus, we need a way to let users control the shape of added variable, but meanwhile we also want optimizer variables to be placed at the same device as model variable.",0
* Changed the to_data_format signature.,0
"If you believe that the pooling layers should offer this functionality, too, I can create another pull request with the necessary changes.",0
1.1.0 version costs triple training time than 1.0.1 in mnist_cnn.py,0
"2 - Makes custom RNNs with extra args in `call()` serializable when an initial state is also provided (super niche, I know)",0
Forgot dropout.,0
Found: [[[[3.30749512e-01 6.00091577e-01 4.06596988e-01]    [3.30761194e-01 6.00126684e-01 4.06620413e-01]    [3.30772936e-01 6.00161910e-01 4.06643867e-01]    ...,0
@yarri-oss does the change sound good?,0
PiperOrigin-RevId: 430801796,0
Add missing named arguments in ImageDataGenerator in examples (#10389),0
* training.py fix unit test error for steps_per_epoch,0
PiperOrigin-RevId: 381148805,0
* PEP8 for test_convolutional.py - indentation,0
Fix the ordering issue of newly added `mask` param in the BN layer.,0
* Fix indentation to comply with PEP8,0
* Fix bug in tile when n is int,0
Added 1 as a valid length.,0
"The response vector from the memory o is then a
sum over the transformed inputs c<sub>i</sub> , weighted by the probability vector from the input.",0
* Changed exception to warning for NumpyIterator,0
Typo in docstring for softplus (#10277),0
Fix top_k_categorical_accuracy weighted metric. (#12632),0
Now that theano has released 0.8.1 does it make sense to change the readme to use that or perhaps remove the need to install from git?,0
* Tiny refactor,0
"ValueError: A `Concatenate` layer requires inputs with matching shapes except for the concat axis: input_shape=[(None, 512, 2, 2), (None, 256, 1, 1)",0
"Previously operations were only moved into assuming regions if they were
direct successors.",0
PiperOrigin-RevId: 528862990,0
"Masked losses with the default ""auto"" reduction were giving outputs that are
inconsistent with what you would get from a ragged input.",0
- It's not clear that it would be sufficiently useful to a sufficient number of users.,0
Add Matthews correlation coefficient to metrics (#3689),0
"@AnikaTabassum 
Please update as per above comment.",0
* Fix dependencies.,0
2. Rename z_log_std to z_log_var in order for the objective function to make sense,0
* Added support for dynamic noise_shape in Dropout,0
PiperOrigin-RevId: 528478841,0
"For consistency, and to make code a bit easier to port from one Keras implementation to another, I suggest adding `from . import scikit_learn` in  `keras/wrappers/__init__.py`",0
Could you list a few use cases where this approach is better?,0
* use one hot workaround,0
"commit d476ecc7eb23509350b60c8cd917808ee4c61d29
Author: jnphilipp <mail@jnphilipp.org>
Date:   Thu May 24 19:52:11 2018 +0200",0
"I don't know if it will be relevant or useful to you, but I just created a PR with a segmentation data generator in keras-contrib which has a number of these augmentation options. https://github.com/farizrahman4u/keras-contrib/pull/195",0
...to address comments in PR.,0
"#PRIVATE_TF_API_USAGE_CLEANUP Remove the test cases on object_meta(), as there is no real reference to this tf private api.",0
* Add "input" class_mode to the docs.,0
* Resolve #2960,0
"Prior to newer TFs, cond was unavailable and thus was being
imported via private module namespaces.",0
* Try testing on Python 3.7,0
* deleted redundant remark about h5py,0
add one_hot to numpy backend (#11497),0
"Hi, may I know what is the correct way of finetuning pre-trained models with BN layers on a new dataset?",0
Increase test coverages by factorizing CNTK pads (#10259),0
"The `params`, `regularizers`, `constraints` and `updates` member of the
AutoEncoder were set in the `__init__` method.",0
"@colinskow While you're exploring could you consider creating an mnist example (or any other kind) with keras models, an estimator & experiment and submit a PR here or directly in TF?",0
Fix a issue when only specify one dot_axes for in the Merge layer in the dot mode (#3470),0
* Increase size of MLP #6990,0
Add 'one' initialization to docs (#4893),0
Use `tf.nn.separable_conv2d` instead of `tf.compat.v1.nn.separable_conv2d` in Keras layer.,0
doc: Preserve the right order for model.compile,0
Switch use of TF cond function to use public function. (#4064),0
* Fixing formatting issues.,0
"* In decoder, the index of the features and pool size and wheres are all equal to nlayers-1-i, so set ind variable to this value and passed it to them.",0
Add element-wise weighting of the loss function.,0
Fix typo in comment,0
PiperOrigin-RevId: 474146108,0
And I'm not even sure if it's possible to have an optimal solution with reasonable compile time even if we assume all nodes cost the same amount of time.,0
"Feel free to reject or refactor, I know it's a feature and not a bugfix.",0
Not published yet,0
* fixed comment format to pass failing test,0
* Rename bias variables in GRU to make them consistent with kernels.,0
This change is ported from https://github.com/keras-team/keras-cv/pull/122.,0
* Fix unit test.,0
Temporary bug fix.,0
"If you approve this PR, may I suggest adding a small note to [Docs ? Models ? Model (functional API)](https://keras.io/models/model/#methods) for the three generator methods (fit_generator, evaluate_generator, predict_generator)?",0
But I'm thinking about building a proper layer to handle shape inference etc.,0
"Another thing, why do we want to go as far as 15 stds?",0
* allow int n for cntk tile,0
Add back the tutorial link for batch-level summary writing for TensorBoard callback.,0
`channels_first` ->`"channels_first"`,0
"* more tests, sparse KTH.eval, pep8",0
"Having those functionality, multi worker resource access in TF/XLA bridge can be solved",0
AttributeError: module 'keras.backend' has no attribute 'image_dim_ordering',0
PiperOrigin-RevId: 528505929,0
For detailed discussion consider referring to the issue #11217,0
Compatibility of TimeDistributed layer and embedding layer with mask_zero=True,0
Added dtype to map_fn (#5658) (#6009),0
RNN : Support for nD data,0
Update convolutional.py,0
Fixes:,0
Fix issue avoid-misusing-assert-true found at https://codereview.doctor,0
"Modifies the logic in `convert_to_tensor` to check for the
`__tf_tensor__` magic method on the object and not the type of the object.",0
"@fchollet, kindly check the full discussion at #1753 (especially [here](https://github.com/keras-team/keras/issues/1753#issuecomment-223784234)) and please reconsider this pull request.",0
PiperOrigin-RevId: 383873991,0
* Add DenseNet to the performance table,0
Think of `K.repeat` as the backend op for the `RepeatVector` layer.,0
* Fixed on_epoch_begin assignment,0
"In this PR, I adapted the change in the commit e40ffd2 to other tests.",0
"commit 19ef51c633544f847cddebeb7a3add0936051f19
        Author: Yarin <yaringal@gmail.com>
        Date:   Sat Feb 20 01:12:23 2016 +0000",0
* thano_backend.py fix bilinear interpolation ratio,0
* Refactored to be part of EarlyStopping and modified unit tests,0
"In other words, can I assume that vulnerability would be present in all the lower versions of tensorflow that aren't specifically mentioned as being patched, like the [NVD entry](https://nvd.nist.gov/vuln/detail/CVE-2022-23572) asserts?",0
* Update regularizers.py,0
"Changing check_pydot since the tf.keras.utils.model_to_dot method does not perform rendering and does not need graphviz, but the plot_model method which calls it does.",0
Update the RandomContrast layer to output value in the range of RGB.,0
keras: fix typo in keras optimizers migration recommendation,0
Note that it's difficult to test if an op is going to run on CPU or GPU -- it cannot be done 100% reliably.,0
"We now consistently enforce that a vocabulary must be set when calling the
layer on anything besides a keras.Input.",0
binary crossentropy adapted with weights.,0
PiperOrigin-RevId: 434006616,0
* Fixed PEP8 violations,0
What do you think of this?,0
"This behavior
    is distinct from the behavior of the TensorFlow backend, which
    removes only the requested dimension.",0
Fixes #48641,0
* * typo doc,0
Fix error message for `sparse` setting in IndexLookup layer when `output_mode = "int"`.,0
"Since I'm really bad at naming thing, don't feel bad to suggest to change them all.",0
fix: thresholded_relu,0
"Added get_value, count_params, int_shape and get_variable_shape to (#11388)",0
Add documentation for image & text preprocessing.,0
(.text._ZN3ruy6detail36CreateTrMulParamsAssumingColMajorDstILNS_4PathE113EhhihEEvRKNS_3MatIT0_EERKNS3_IT1_EERKNS3_IT3_EERKNS_9MulParamsIT2_SC_EENS_16ChannelDimensionEPNS_3CtxEPNS_11TrMulParamsE[_ZN3ruy6detail36CreateTrMulParamsAssumingColMajorDstILNS_4PathE113EhhihEEvRKNS_3MatIT0_EERKNS3_IT1_EERKNS3_IT3_EERKNS_9MulParamsIT2_SC_EENS_16ChannelDimensionEPNS_3CtxEPNS_11TrMulParamsE]+0x1d9): undefined reference to `ruy::Ctx::GetMainAllocator()',0
* Allow model saving/loading code to accept h5py.File objects.,0
* Bug fix: convolutional recurrent (again),0
"all_outs -> outs_per_batch to avoid confusion, all_outs has swapped dimensions in predict_generator().",0
* Revert "Pull request revision",0
layers.core: add Masking layer,0
"I thought of a really quick fix for this, that requires to explicitly mark the end of the line in the progress bar.",0
* Sparse Input for Both + Sparse Concat for TF,0
"So
it’s necessary to check if it’s non-empty first",0
Created a function to_data_format to abstract the shape and data_format handling. (#10781),0
Update BaseRandomLayer to eagerly init the random generator.,0
Update keras initializer to be fully stateless.,0
- `test_specify_states` explicitly checks if `initial_states` is added to the computational graph.,0
"@AnikaTabassum 
Is there any particular reason to install older version of tensor flow when later versions are available.",0
PR #49292: Update metrics.py: Fix SparseCategoricalAccuracy.update_state() doc string,0
* fix PEP8 problems,0
"Since the offset is only provided at call(), we need to add
extra param to all the methods in keras RNG.",0
PiperOrigin-RevId: 425248502,0
* FAQ updates,0
PiperOrigin-RevId: 355213864,0
---------------------------------------,0
Change the default value for verbose in Model.predict() to auto to be consistent with Model.fit() and Model.evaluate().,0
PEP8 Fixes.,0
* Added batch histogram computation,0
Update global_clipnorm,0
PiperOrigin-RevId: 527921888,0
* Remove MAX_NUM_IMAGES_PER_CLASS,0
* use mode arg,0
* make compat.v1.template work inside the shim w/ consistent tracking of weights & losses,0
PiperOrigin-RevId: 385208121,0
* Single tensor as target_tensors: Handle error for multi-output model.,0
"ImageDataGenerator.flow() with tf tensor of images/labels, ex: TFRecord",0
Is it possible to add support for this parameter for TF users?,0
* I kept the number of samples generated identical.,0
"Instead of replicating the docstring, we let child class point to the parent class' docstring.",0
"After this change, unkown callable arg:",0
PiperOrigin-RevId: 518424850,0
* theano fix,0
Remove LRN2D layer.,0
Moved epoch_logs = {} before batch loop to avoid UnboundLocalError.,0
2. If `fpath` and `untar_fpath` are set to the same value the `untar` doesn't run.,0
* Improve converting GRU/CuDNNGRU weights.,0
* Alphabetizes and adds to layers doc.,0
"* Use layer.dtype as the default dtype when adding a new weight, and add dtype to network initialization.",0
Fixed KerasRegressor.predict() squeezing length-1 output arrays. (#11658),0
PiperOrigin-RevId: 383675578,0
Add negative parameter validation for recurrent layers.,0
"old = atomicCAS(address_as_ull, assumed,\n0059\t _double_as_longlong(val +\n0060\t longlong_as_double(assumed)));",0
Allow broadcasting in Merge layer (#5812),0
"module attributes {tf.versions = {bad_consumers = [], min_consumer = 0 : i32, producer = 0 : i32}} {
  func @main(%arg0: tensor<1xf32>, %arg1: tensor<1xf32>) -> tensor<1xf32> {
    %0 = mhlo.constant dense<9.99999997E-7> : tensor<f32>
    %1 = mhlo.constant dense<0.000000e+00> : tensor<1xf32>
    %2 = shape.shape_of %1 : tensor<1xf32> -> tensor<1xindex>
    %3 = shape.shape_of %0 : tensor<f32> -> tensor<0xindex>
    %4 = shape.cstr_broadcastable %2, %3 : tensor<1xindex>, tensor<0xindex>
    %5 = shape.assuming %4 -> (tensor<1xi1>) {
      %8 = shape.const_shape [1] : tensor<1xindex>
      %9 = ""mhlo.dynamic_broadcast_in_dim""(%1, %8) {broadcast_dimensions = dense<0> : tensor<1xi64>} : (tensor<1xf32>, tensor<1xindex>) -> tensor<1xf32>
      %10 = ""mhlo.dynamic_broadcast_in_dim""(%0, %8) {broadcast_dimensions = dense<> : tensor<0xi64>} : (tensor<f32>, tensor<1xindex>) -> tensor<1xf32>
      %11 = ""mhlo.compare""(%9, %10) {comparison_direction = ""LT""} : (tensor<1xf32>, tensor<1xf32>) -> tensor<1xi1>
      shape.assuming_yield %11 : tensor<1xi1>
    }
    %6 = shape.const_witness true
    %7 = shape.assuming %6 -> (tensor<1xf32>) {
      %8 = ""mhlo.select""(%5, %arg0, %arg1) : (tensor<1xi1>, tensor<1xf32>, tensor<1xf32>) -> tensor<1xf32>
      shape.assuming_yield %8 : tensor<1xf32>
    }
    return %7 : tensor<1xf32>
  }
}",0
"* With ind variable in decoder, don't need two lines for the upsampling layer.",0
"--
0d081c2ba84657ab61a04f73fd740cefd6365308 by Ashutosh Hathidara <ashutosh.hathidara@legatohealth.com>:

[Feature] Adding layer_range for plot_model and model_to_dot",0
This class can be used to compute the mean IoU metric for a multi-class classification task where both the labels are one-hot encoded.,0
08WARNING:tensorflow:Early stopping conditioned on metric `val_binary_accuracy` which is not available.,0
- generalized for any lahead/tsteps combination,0
12) Adadelta changes default learning rate from 1.0 to 0.001,0
"In the second case I don't, unless I go to the utils file where the method is defined.",0
* [skip ci] edit docstring,0
"The documentation for Session notes that this is important:  
https://www.tensorflow.org/api_docs/python/tf/compat/v1/Session",0
* + mult by ndim,0
* Added better exceptions when theano.sparse fails to import,0
Add an option to create dot model in different directions (#5472),0
* Update test,0
A number of changes:,0
Fix serialization/loading for wrapped custom objects (#5865),0
PiperOrigin-RevId: 461919349,0
"Change the `LICENSE` file to be a verbatim copy of the complete Apache 2.0 license:
https://www.apache.org/licenses/LICENSE-2.0.txt .",0
* Upgrade deprecated tf.sparse_to_dense() in CTC beam search (#12240).,0
Bug fix - Cos,0
Enable Model subclassing API (#10046),0
Can I assume this is a feature request of OpenCL support for normal Linux machines?,0
Add more meaningful message when cnkt can't handle variable length input (#7094),0
"commit f89b3397bbb6377186fe050b421cd2e0fa75ebee
Author: Taehoon Lee <me@taehoonlee.com>
Date:   Sun Jun 3 02:21:06 2018 +0900",0
Update the reference of Batch Normalization (#2700),0
"And also remove the BUILD deps of dtensor, which is already included in the TF by default.",0
Fix bug in sparse_categorical_accuracy  (#11373),0
"#13239 Improved documentation for EarlyStopping/ReduceLROnPlateau, take validation_freq into account. (#13240)",0
* remove print statements,0
* fix max_value clipping,0
PiperOrigin-RevId: 407906966,0
* Add support for dynamic RNNs in TensorFlow.,0
* fixed links in model.py,0
"This was creating one tf.function per initializer, and causing function retracing.",0
The current implementation for leaky_relu is extremely inefficient.,0
* #6670 Remove Progbar implementation details from docstring,0
* Fix invalid PIL Image name,0
* merge_test.py axis order fix + pep8 fix,0
CuDNN RNN layers nested in TimeDistributed are not converted when loading (#10357),0
"Yes, that's a very good point, I've thought about the same thing.",0
Fix the broken format for the losses_test.py,0
Update metrics.py: Fix SparseCategoricalAccuracy.update_state() doc string,0
"* Adding TruePositives, TrueNegatives, FalseNegatives metric classes.",0
"Corrected `callbacks` description docstrings in `evaluate_generator` and `predict_generator`: ""List of callbacks to apply during training"" -> ""- during evaluation"", ""- during prediction"".",0
Documentation updates for keras preprocessing layers,0
Some of the variable names in this guide were misleadingly named.,0
Currently limited to 3D as maximum Convolution dimensionality as that is the highest rank implemented in `keras.backend`.,0
"If you think I made a mistake, please re-open this issue.",0
Improve readability of pull request 15286,0
"commit 315a80ae3cb65da2aa6308abd483f2f8643f1c8b
Author: Taehoon Lee <me@taehoonlee.com>
Date:   Wed May 30 01:43:37 2018 +0900",0
PiperOrigin-RevId: 471137058,0
* few fixes,0
Add new API for keras.Model to show weight path mapping.,0
* some more meat for ada docs,0
Added more info about categorical_crossentropy (#12282),0
Merge pull request #1668 from jstypka/master,0
PiperOrigin-RevId: 388305496,0
so that only the value for the last time step is considered.,0
simplify backend check,0
Is there an expected difference between GPU and CPU training?,0
Implement class `OneHotMeanIoU` that inherits class `MeanIoU`.,0
* Changing metric call for output loss metric to update_state and result calls.,0
"* add random_channel_shift, support fill_mode and cval",0
"**Problem** If a session is stopped and rerun or kernel dies, then the best value of metric is taken as np.inf or -np.inf and the model is saved after the first epoch without taking into consideration the initial performance of model.",0
"The cons outweigh the pros heavily in leaving it up to the user, and the Theano convention made me think that if a tensor3 is involved it follows that shape.",0
PR #49860: [Feature] Adding layer_range for plot_model and model_to_dot,0
"These updates
are identified as *any updates defined by a stateful layer*.",0
Old - tf.keras.preprocessing.sequence.pad_sequences,0
"1. > E       assert 71 == (12 * 5)
E        +  where 71 = len([0, 1, 2, 3, 4, 5, ...])
E        +    where [0, 1, 2, 3, 4, 5, ...] = <test_training.RandomSequence object at 0x7fcfc5f16390>.logs [build.log#L3042-L3046](https://travis-ci.org/keras-team/keras/jobs/452492102#L3042-L3046)",0
"--
9410d39d0a9f850c4fb615a1d8b607f1b75d80c3 by Zirui Zhuang <zr.zz.alp@gmail.com>:",0
@taehoonlee what is your opinion on this?,0
"Here is the result:

![1](https://user-images.githubusercontent.com/12891691/49258375-88c73200-f435-11e8-8dc9-95c4201bfcbe.png)
![2](https://user-images.githubusercontent.com/12891691/49258377-8a90f580-f435-11e8-81f0-d6fa42df09a9.png)
![3](https://user-images.githubusercontent.com/12891691/49258378-8bc22280-f435-11e8-98d4-df9e6b677aa0.png)",0
"Thus, when we finally silently fade away the old optimizer, users' existing code can still work correctly if they have calls to `lr()`.",0
Currently the model evaluate returns the last scheduled worker metrics.,0
- Unit tests are failing,0
Added dropout to reference_operations.py (#11390),0
* Fixed a couple more style issues brought up in the original PR,0
"commit ce56322aadc6a861db21e598720c2dce03747ec3
Author: David Schwertfeger <david.schwertfeger@googlemail.com>
Date:   Tue Jun 5 00:15:25 2018 +0200",0
add Convolution3D and MaxPooling3D layers,0
* get_input() —> input(),0
Keras Metric.,0
tensorflow 0.12 fixes (#4815),0
[MLIR][MHLO] Do not yield results of ops that were moved out of assuming regions,0
"Use metrics_names, rather than metrics + index juggling to skip loss.",0
- Allow shared layers to be first layers in models,0
Do not initialize tables automatically for lookup layers,0
* _check_array_lengths properly handles corner cases with None,0
The only build/bzl level TF deps now is the tf_proto_lib in keras/proto.,0
Add API conversion interface for Dropout layer (#5629),0
PiperOrigin-RevId: 355263967,0
"* make cntk test similar to concat, add {{np_implementation}} to docs",0
* don't reuse names in introductory example,0
Solution: Tile the `mask_t` with the correct shape of each `states[i]`.,0
Updated Docs string with new apis,0
Adding extra target that are needed by PIP package dependency.,0
"@fchollet:
If this shouldn't be a clean way of doing that, please suggest a different solution.",0
* Fix PEP8 (whitespace).,0
1. Exclude optimizer weights when getting model weights.,0
* Added documentation to set self.built = True in MyLayer.build(),0
* Added missing space in multi-line warning strings,0
"As mentioned in (#2260), metrics don't skip output values that ought to be masked out.",0
* Remove Sequential.model deprecation warning,0
* Bug fix when target is a SparseTensor.,0
Fixes #38668 . It is to complete the work done in two of my previous stale PRs #38669 and [#1702](https://github.com/tensorflow/addons/pull/1702).,0
* Keep the tests for single input/output TB callback and rename new test as multi_input_output,0
NumPy 1.24 release notes: https://numpy.org/devdocs/release/1.24.0-notes.html,0
* Replace output_shape with output_padding,0
removed dependence on theano,0
Bug fix: Don't change original dict in from_config (#7903),0
"For safety reasons, this is disallowed.",0
"Add 'one_hot' output mode to CategoryEncoding, remove upranking in multi_hot",0
* Added a more meaningful error message for bilinear and CNTK.,0
"@fchollet In order to override the default value of parameter `scale` in `uniform` for example, I have to define a lambda function with unnecessary parameter `name`, and deal with the problem of serialization, and everyone who wants to override has to do the same thing.",0
Move object registration logic to keras/saving/.,0
* Change to match existing batch_set_value,0
* Adding MeanAbsoluteError loss,0
* Fix the CuDNN RNN tests.,0
* Add pr template,0
PiperOrigin-RevId: 516295859,0
Merge pull request #1817 from AIshb/patch-1,0
* put back accidentally commented out recurrent tests,0
"Does it mean, that if assume that the point Xi depends on the previous ten points, my i-th training example should be of shape (10,30) and include concatenateed X_i-10...X_i-1?",0
Rewriting image augmenter   (#2446),0
Preparing for the Keras 2.5 RC cut.,0
* Add reverse op,0
* Added unit test,0
Add ragged support for keras.layers.Resizing,0
"commit 0d74f0e997960886b1044c26001de6cd6ad90bb9
Author: Arel Cordero <arel@ditto.us.com>
Date:   Tue Aug 16 04:15:43 2016 +0000",0
PiperOrigin-RevId: 463715988,0
* Fixes a bad space in convolutional_recurrent.py,0
- added several regression tests,0
* Don't pip install tensorflow,0
This reverts commit 74fe60b445377b4f1be1d0a36b4777d7ed4f1c1b.,0
"- Static tables can be distributed to end workers in a multi-worker setting
   allowing more efficient distributed training.",0
Fix some typos. (#7144),0
* Added documentation for loading external backends,0
I fixed both issues in a new commit.,0
Also remove testing of causal masks from `layer_correctness` since not needed and changing arguments in call doesn't fit easily into this test fixture.,0
* change to conv2dtranspose and tuple strides,0
Added optional trainable column to model.summary,0
Changed line 82 from "# node is node part of the current network" to "# node is not part of the current network",0
- Make sure temporary directories get deleted,0
This is already the behavior of tge RandomCrop layer at inference time.,0
"Hence, similarly to LeakyReLU or
for example Softmax, this PR adds a layer for ReLU,
enabling also a capped ReLU to be used.",0
"Sure, I meant to create a file called something like `keras/examples/cifar10_embeddings.py` which demonstrates how to use the API.",0
Small fix to Theano softmax for numerical stability (#9606),0
This indicates that some work must be done to simplify this file and making it more accessible.,0
- [ ] This PR requires new unit tests [y/n] (make sure tests are included),0
"Keras API Design Review google doc with comments enabled here
https://docs.google.com/document/d/19BDXgNmeTgpgb9xYKzNboXyM7XX2PeM3mlvCFCdIQj0/edit?usp=sharing",0
"In Python3, 50000 / 10 = 5000.0.",0
Then `XLAInlineDeviceOps` Pass can inline the `StatefulPartitionedCall` op based in the parent region so that it can be executed as part of the function library runtime.,0
* Fixed _flattened_layers under Python 3,0
Feature Wanted?,0
PiperOrigin-RevId: 421180573,0
PiperOrigin-RevId: 420957876,0
PR #48725: Added negative parameter validation to Core/Recurrent/Convolutional Keras layers.,0
"Before this change, all value errors:",0
"imdb_lstm.py

Train...
Train on 20000 samples, validate on 5000 samples
Epoch 1/4
20000/20000 [==============================] - 784s - loss: 0.4773 - acc: 0.7769 - val_loss: 0.3613 - val_acc: 0.8396
Epoch 2/4
20000/20000 [==============================] - 788s - loss: 0.2691 - acc: 0.8946 - val_loss: 0.3644 - val_acc: 0.8376
Epoch 3/4
20000/20000 [==============================] - 791s - loss: 0.1770 - acc: 0.9351 - val_loss: 0.3913 - val_acc: 0.8370
Epoch 4/4
20000/20000 [==============================] - 800s - loss: 0.1137 - acc: 0.9612 - val_loss: 0.4621 - val_acc: 0.8308
5000/5000 [==============================] - 48s
Test score: 0.46212145137
Test accuracy: 0.8308",0
- allow converting weights from GRU(reset_after=True) to CuDNNGRU,0
adding a disable_b boolean to Dense (#2512),0
Move TensorBoard callback to v2 -- still need to fix some tests.,0
* Add tests to directory_iterator_with_validation_split,0
* Add `separable_conv1d` for CNTK,0
This can be found in the 3rd page of...,0
PiperOrigin-RevId: 384618968,0
Standardize and fix RandomCrop and CenterCrop when inputs too small,0
"Do you think we may have problems changing the learning rate of `adam`, `rmsprop` and such?",0
* argument option added,0
Add documentation for models,0
Use count_params function for non_trainable_count. (#10280),0
I hope it makes us more productive.,0
May we assume that TF is going to use semantic versioning for [releases](/tensorflow/tensorflow/releases) (ie. major.minor.patch)?,0
Fix typo in doc,0
I tried the standalone example in Keras 2.2.4 using Tensorflow 1.14.0.,0
Should I go with the highest value in the categories and then assume the network thinks it is most likely that class?,0
* add test with arguments,0
"commit 20644772372738708660cd3f9404f1760fb7e9fe
Author: askskro <ak@aiascience.com>
Date:   Wed May 23 23:59:58 2018 +0200",0
"If we assume that, `keras` gives stable release and for that, we don't need to tweak the internal code - **IMHO**, that's a bad argument.",0
PiperOrigin-RevId: 380625966,0
"* image doc, update test_image, PEP8",0
Control ImageDataGenerator.flow_from_directory image modification seed and shuffle seed independently,0
Refactor RNN dropout to be self-contained in RNN cells (#8660),0
fix typo (#10078),0
Update BaseImageAugmentationLayer for transformation that are input dependent.,0
Make custom_object_scope() thread-safe,0
"- If steps_per_epoch (or steps in predict and evaluate) is set, I noticed that the variable ""ins"" isn't sliced and never changes but the model is trained with it multiple times (it felt strange).",0
* Simplify split logic,0
* proper exception,0
* Refactor to using split,0
This prevents the computation of the gradient of the crossentropy from underflowing.,0
This commit fixes it by initializing gamma to 1.,0
It considers training strip of length `k`.,0
* Finish enabling Model subclassing.,0
* Simplify.,0
"Bug fix of Bidirectional(LSTM(..., stateful=True)) (#4424)",0
Any thoughts about extending Graphs to multi output type solutions?,0
* Remaining PEP8 issues fixed,0
Persist attribute "sparse" of IndexLookup layer,0
The 2.7 release has been cut at https://github.com/keras-team/keras/tree/r2.7.,0
"The error:

```
""keras/engine/training.py"", [line 3279], in potentially_ragged_concat
    non_batch_shapes == non_batch_shapes[:1], axis=0)
...
Invalid reduction dimension (0 for input with 0 dimension(s)
```",0
"Also, avoid unnecessary abbreviations that make code harder to read, such as ""lr_mult"".",0
"Also consolidate some of augmentation logic into self-contained method, so that we can easily refactor them later if needed.",0
* Fix warnings module mistake,0
fix unit test about 'legacy_pooling2d_support',0
I can't think of an instance where an tesnor3 would stand for something else..?,0
This results in a two dimensional array.,0
Best to set self.built=True at the end of build() (#10191),0
* Adding Binary Crossentropy loss.,0
"- After:
  ```py
  inputs = keras.layers.Input(shape=(32, 32, 3))
  keras.models.Model(inputs, keras.layers.Add()([inputs, inputs])).save('aa.h5')",0
* pop before call,0
Avoid recalculation of output in join merge.,0
Do you think this patch addresses the problem?,0
"Noteably
this includes dictionary types.",0
For me it is like putting 'Machine Learning' in the title in 2016 :),0
* Fix image.py errors,0
Merge pull request #528 from stephenroller/ndim_tensor,0
This is much simpler and more general than the previous setup.,0
* also check free dimension,0
"test_random_binomial:
5.95s -> 0.23s",0
V2 GRU and LSTM cells no longer extend their V1 counterpart; instead the inheritance is the other way around.,0
Fix tensorflow_backend  deprecation warning (#9488),0
* fix tf test,0
"The following occurs twice in different places, so far harmlessly but
still redundantly:

self.optimizer = optimizers.get(optimizer)",0
crash in standardize_input_data (with sparse_categorical_crossentropy) [regression],0
Author: Thomas McColgan <thomas.mccolgan@gmail.com>,0
# This is a combination of 4 commits.,0
"For the library code, just fixed linting errors.",0
[image_ocr.py] Unwanted characters predicted instead of blank/no label in CNN-RNN-CTC network,0
I would like to appreciate the feedback.,0
Merge pull request #489 from dribnet/url_check,0
* Update cuDNN link in README,0
* aligned code snippet to keras.utils.generic_utils,0
Fix typos (#7916),0
This makes merge_mode='join' complaint with keras API.,0
The original zlib download url was invalidated on zlib side.,0
"@fchollet, thoughts?",0
"Previously, the mask had to have the same shape as the input.",0
PiperOrigin-RevId: 389006751,0
* Allow for RandomSequence instances with custom lengths during testing.,0
PiperOrigin-RevId: 358956952,0
Exclude iterations and learning_rate from getting variables of experimental optimizer.,0
"The existing LossScaleOptimizer does not support the new experimental optimizer in the file keras/optimizer_experimental/optimizer.py, so a new LossScaleOptimizerV3 class is created to support it.",0
PiperOrigin-RevId: 394564902,0
* Update CIFAR10_with_Eigenvalue_Decay.py,0
Fix Hashing layer compatibility when dtype=float and output_mode=int,0
I would like your input on that.,0
How does it look like in horizontal orientation? (`rankdir="LR"`),0
* Cleanup legacy Keras code [3/N],0
Fixes https://github.com/fchollet/keras/issues/6612,0
This is useful if you want to extend your training for extra steps.,0
* Sync keras optimizers with tf.keras optimizers.,0
* fix code sytle.,0
A couple of variables are "used" in two examples without being defined.,0
sha256 hash is now supported in addition to md5.,0
- DropConnect: random drop on weights,0
Minor mixed precision cleanup.,0
Quoting the paper.,0
* also set intra_op_parallelism_threads,0
"commit a07d9f3f3665ed79401f37f0c5759f271268a34f
Author: Stefano Cappellini <contact@stefanocappellini.com>
Date:   Thu May 24 19:50:21 2018 +0200",0
* add audio models: audio_convnet and audio_conv_rnn,0
_extract_archive() now private,0
Please let me know your opinions on an aliasing approach.,0
"Currently it is necessary to `import keras.wrapper.scikit_learn` before using it:

```python
import keras
import keras.wrappers.scikit_learn
clf = keras.wrappers.scikit_learn.KerasClassifier(...)
```",0
"Previously we did not have full API support, and treated h5 as a deprecated format.",0
Are any assumptions made on the contents of a mask?,0
- [ ] This PR is backwards compatible [y/n],0
ValueError: Error when checking model input,0
"NEVERTHELESS, they can just paste this as pre-formatted text -- the markdown doesn't confer much advantage (are they going to paste it in a spreadsheet?), so...",0
"As far as GRU vs LSTM, I wrote it the code to be easy and generic to swap RNNs out, then didn't really think about it too much more.",0
PiperOrigin-RevId: 506937640,0
"There are a number of things to keep in mind when contributint
Keras applications.",0
"* get_file() comment link, path, & typo fix",0
* Fix case of boolean values in comments.,0
This causes the problem observed above.,0
"Bug fixes:
“TypeError: Cannot cast ufunc subtract output from dtype('float64') to
dtype('uint8') with casting rule 'same_kind'” in
keras/preprocessing/image.py, line 239, when using data augmentation.",0
"--
f0c1103bf5cbed0978ff586d2660aab3436cc9f0 by Albert Villanova del Moral <8515462+albertvillanova@users.noreply.github.com>:",0
Any ideas?,0
* add line removed by accident (that what happen when you commit your changes too fast),0
* Add callback support to internal generator-based methods,0
Mention URL path in docstring,0
Typo fix for TextVectorization documentation,0
Allow regularizers to return scalar values in all contexts.,0
"If you suspect there is a bug, please refer to these guidelines for the proper way to report it.",0
If you don't feel like looking around just copy + modify the lines that save mnist images so they save the labels and set the dimensions.,0
"@fchollet, reconsidered?",0
* ensure that epoch_logs is never unassigned,0
"If the assumption was batch size 1, would it be a better idea to change the `IsBatchMatchesForAllValues` check to something like `IsBatchOne` to make things more consistent?",0
Parallel directory iterator initialization (#6890),0
* Update reuters.py,0
"Before, `tf.keras.mixed_precision.LossScaleOptimizer(1)` was None.",0
* Adjust for epoch being zero-based,0
* Fix docstring,0
Updated documentation.,0
Fix use_bias in some convolutional layers (#10444),0
"--
41bc44a4f371b9209fe742ac9dfe23d91e6fc76d by Ashutosh Hathidara <ashutoshhathidara98@gmail.com>:

Update tensorflow/python/keras/utils/vis_utils_test.py",0
Before making further changes here I wanted to ask about what I think is the root issues and what I feel is a reasonable solution.,0
Sorry for the delay.,0
"In fact, tf.keras does not have `tensorflow.keras.engine`.",0
"So, can I assume the implementation in TF-2.0 is fundamentally different?",0
Allowed to return the image as a Jupyter Image only if the extension is not pdf (#13383). (#13384),0
Please let me know your thoughts on the same.,0
- [y] This PR is backwards compatible [y/n],0
"--
b446d75e24a08212f3cdc4f9784c72016cd165bc by Ashutosh Hathidara <ashutosh.hathidara@legatohealth.com>:

Ignore when layre_range is None",0
The longer term fix for this is https://github.com/tensorflow/tensorboard/issues/2885.,0
"const float16x4_t va01 = vreinterpret_f32_f16(vld1_dup_f32(__builtin_assume_aligned(a, 1)));",0
* align naming and remove TODOs,0
* skip if not tensorflow,0
related to #15715.,0
Please see the layout_map docstring for how the new API works.,0
"As far as examples are concerned, I usually encourage upstream to include them, since they can enhance the documentation.",0
"Adding Loss, LossFunctionWrapper, MeanSquaredError classes. (#12859)",0
"Make the currently-internal variable scope shim for TF2 ignore `reuse=False`, because it needs to work with code that was written to include some reuse=False but is now needed to be run multiple times.",0
The `fill_mode` is implemented using `NI_ExtendLine()` from [ni_support.c](https://github.com/scipy/scipy/blob/master/scipy/ndimage/src/ni_support.c).,0
* Format the code in the PEP8 style guide,0
Allow dynamic shape for repeat_elements (#7422),0
"2. Fail loudly if validation_data is None and histogram_freq is non
zero.",0
Fix memory leak,0
Can you elaborate?,0
"Add a method `lr()` to new optimizer, which is an alias of `learning_rate()`.",0
"It doesnt pass test (only in cropping2d and basic_test), but my laptop setting is not correct (it doesnt pass some other existing layes as well), so committing to test it in a correct way.",0
PiperOrigin-RevId: 395747883,0
Fix issue where TimeDistributed didn't pass uses_learning_phase,0
* Reduce tests for applications,0
Fix typo in Merge layer docstring.,0
PiperOrigin-RevId: 431736718,0
* Added FAQ entry on h5py,0
Fix typo in Lambda layer,0
PiperOrigin-RevId: 394779149,0
* Fix a warning on python3,0
Style fixes and small bug fixes,0
"#11382
#11375
#11306
#11673
#11623",0
* line breaks,0
PiperOrigin-RevId: 527732364,0
* rename example file + fix input average + aesthetic progress fix,0
* Remove num_subdir_files,0
* selu: hardcode alpha and scale variable,0
Fix doc  (#10308),0
# This is the 2nd commit message:,0
How does keras handle the mask padding  if go_backward == 1?,0
use correct cpu-only build,0
PiperOrigin-RevId: 393195894,0
Corrected 2D relicts in 3D function comments (#12406),0
"Error InvalidArgumentError: Incompatible shapes when using accuracy metric, sparse_categorical_crossentropy, and batch size > 1",0
Does this have the potential to get merged soon? :-),0
tensoflow.keras.preprocessing.image_dataset_from_directory doesn't recognize there are files in a directory when labels are supplied as a list/tupple comp:keras stat:awaiting,0
PiperOrigin-RevId: 359320366,0
PiperOrigin-RevId: 515704007,0
* upgrade K.deconv to handle None dim in batch_size,0
Merge all the dtensor related initializer into core keras.,0
Add API generator for Keras API from third_party/py/keras.,0
"Also, any chance the bug detected by https://github.com/fchollet/keras/pull/7033 might be breaking things here?",0
* undo add (delete): selu in check_single_tensor_operation,0
The constants here are stored as float32 by default and break graph compilation for float16.,0
Currently the code is still under development/migration and it is NOT the source of truth.,0
This refactor has the following advantages:,0
When slicing `class_id` it drops the dimension causing error reported in https://github.com/keras-team/keras/issues/16271 since there's a dimension mismatch with `sample_weight`.,0
"""xent"" is more common.",0
Hope this might be useful to some folks out there.,0
add test on timedistributed + masking,0
"Structure had 2 elements, but flat_sequence had 1 elements.",0
* Add properties; reverse -> backward,0
- Some style enrichments in order to make the doc clearer:,0
* Update metric __call__ calls to update state and result calls,0
PiperOrigin-RevId: 489554870,0
Please share your thoughts on this.,0
* loss defaults to None in compile(),0
I am not a fan of the idea of modifying every example to make them testable.,0
This includes calling layers with positional arguments with the new interface.,0
Conv3D is supported in gpu and cpu with all possible border modes.,0
This is to fix the issue https://github.com/tensorflow/tensorflow/issues/49852.,0
:memo: Add typing to some callback classes,0
- merge tests of converting between plain RNN and CuDNN RNN,0
* improve documentation according review comments,0
PiperOrigin-RevId: 463869630,0
* Update mnist_acgan.py,0
PiperOrigin-RevId: 493346024,0
* data_utils.py address docs comments (#5861),0
The type of list keys was float (#9324),0
Clean up,0
+ name of th loaded models,0
- please add a simple test to ensure that serialization and argument passing won't get broken in the future.,0
PiperOrigin-RevId: 388309942,0
Fix the shape mismatch in `rnn()` with `not unroll` and `mask is not None` of the Tensorflow backend.,0
Fix typos in layer writing guide,0
Could you please open a new PR?,0
* update set_value() of the tensorflow backend,0
@fchollet what do you think should be our approach towards flaky tests?,0
Any second opinion from other Keras contributors?,0
* workaround free dimension in squeeze,0
Solved: UnknownError: Failed to get convolution algorithm.,0
Should we maybe create a separate test function for multi-input/multi-output layers?,0
* Add unit test for broadcasting,0
* Add test to recurent layer,0
The 2.8 release branch is cut at https://github.com/keras-team/keras/tree/r2.8,0
Thanks for letting me know your opinions though.,0
* Add header description,0
"- so far there are two classes for easier testing, ideally we'd like a single class
  with configuration option",0
PiperOrigin-RevId: 380211940,0
* Manage test,0
Fix compute_accuracy() in mnist_siamese_graph.py (#7942),0
* add comments,0
"commit 52f608cbe7cf685bd9f92fcedc3ef02ba4292dc6
Author: Taehoon Lee <me@taehoonlee.com>
Date:   Thu Jun 14 05:44:22 2018 +0900",0
TimeDistributed doesn't handle mask-reductions,0
* Fix abstract method,0
Add documentation for core layers,0
- similar problem to nesting in Bidirectional (#8860),0
"To avoid the type spec mismatch, we replace resource variables with tf.nest atoms just for the purpose of tf.nest.assert_same_structure.",0
Recurrent Additive Networks.,0
PiperOrigin-RevId: 408466384,0
* Fix incorrect predict_generator output shape when using multi-output model and steps_done=1.,0
"Added tf_py_test, docstrings and other minor corrections",0
3) all lr has been changed to learning_rate.,0
"Merge layer and associated functionality, which was scheduled for 08/2017.",0
Argument target_tensors from Model.compile: accept single tensor (#10616),0
* Update docs.,0
Merge pull request #1756 from gw0/fix-for-refactor-callbacks,0
Added h5py to the conda install,0
- [x] This PR requires to update the documentation [y/n] (make sure the docs are up-to-date),0
Zip has no speed impact (the long saving/loading time was due to the breakdown into many files/dirs previously).,0
* Fix indentation problem causing build error in python 2.7,0
* Fixup Linter Warnings,0
added missing hashes (#7988),0
This reverts commit 1dc67f374cde47a721e5fe5d9237bc2573bda2f0.,0
* Remove validation_split is None statements,0
Fix error in ImageDataGenerator documentation (#9798),0
* Add merge mode 'max' where it was missing (fixes #3486) (#5729),0
Add initial public version of Keras,0
"Calling `context.executing_eagerly()` is functionally identical,
as it checks `_context` (if it has been initialized) or checks that
the default execution method is set to `EAGER`.",0
Corrected some grammar issues in the docstring.,0
* initial tensorflow 0.12 fixes,0
"--
8d386fa167443d4edca8d3137c24ecabbd981818 by Ashutosh Hathidara <ashutosh.hathidara@legatohealth.com>:

Ignore when layre_range is None",0
* Added another test case,0
Layers have their own API that is independent from connection models.,0
"2. Refine the batch_normalization function in tensorflow backend, Let's it call to fused batch norm as much as possible.",0
The fix is to simply "cast_to_floatx()" on the constants.,0
Warn in LossScaleOptimizer if the loss or gradients are not scaled.,0
"commit c9cb6087394656247b13dbcb447135dfcb91685c
Author: Fran?ois Chollet <francois.chollet@gmail.com>
Date:   Fri Jun 1 23:53:49 2018 -0700",0
Unable to import :- from keras.preprocessing.image import ImageDataGenerator,0
* Document stateful metrics,0
"np.__version__ = 1.16.3
keras.version = 2.2.4
keras.datasets.imdb.load_data()",0
* Added newline at end for PEP8,0
"# The first commit's message is:
test image preprocessing",0
@pranv do you think you could try running my code and see what you get?,0
Rewriting of the batch_set_value() to avoid multiple calls to session.run() to improve speed.,0
* Style fixes,0
- [x] Fix data processing in batches,0
Feel free to submit a new PR once you get the tests to pass locally.,0
Add about using loss with from_logits=True to metrics docstrings.,0
* Docstring style,0
Let me know what you think -- really simple Maxout implementation using a tensor dot.,0
[#10855](https://github.com/keras-team/keras/issues/10855),0
Give me your opinion.,0
The version of CuDNN is 4.0.7 and we are using CUDA 7.5.,0
PiperOrigin-RevId: 427274651,0
"* Fixed the issue about the callback not remembering when was the last
time it wrote to the logs.",0
Let me know what you think and if you think I should change something.,0
"commit 8e5b8533ea819d0252d08f45648782ecd543ac70
Author: Taehoon Lee <me@taehoonlee.com>
Date:   Thu Jun 14 03:39:13 2018 +0900",0
"The pass currently does two things: merge
assuming ops and propagate broadcasts.",0
"commit 25d0193eaeed91ac899bf8b572d98ce0e0c76d3a
Author: tiferet <tgazit@gmail.com>
Date:   Tue Jun 5 21:23:27 2018 +0300",0
Fix typo in docs.,0
Based on discussion in https://github.com/fchollet/keras/issues/4944 and https://github.com/farizrahman4u/keras-contrib/issues/9.,0
Fixes #8105,0
Create a `keras.saving` endpoint and add the ExportArchive class to the public API.,0
"Removal of the *1. dummy multiplication, replacement with a split() to avoid creating a new operation in the graph.",0
get_file() progbar fix (#6670),0
* remove stray line from merge,0
* Fix some error.,0
@fchollet what do you think about the above?,0
Fixes set_learning_phase in CNTK (#7826),0
PiperOrigin-RevId: 407124393,0
* Fix KTH is_sparse,0
* make changes work with TF 0.11,0
* extend existing test,0
This reverts commit f1df2a58ff635bbf698444e3d7403785a92dfed1.,0
added clarifying comment to sparse_cat_acc in metrics,0
This change is a hack to fix that issue.,0
* add apply_affine_transform,0
Being able to push those back to PR's is an awesome feature.,0
Fix initialization of index_array (#2590),0
"@zachmayer, here the command line procedure I used (I beg your pardon if I misunderstood your question)
```
$ git remote add mcarbajo https://github.com/mcarbajo/keras.git
$ git fetch mcarbajo
$ git checkout -b mcarbajopatch -t mcarbajo/patch-1 
```",0
@douglaseck (lead on TensorFlow Magenta) used that terminology in a paper of his for example.,0
Add pr template (#10590),0
"This change make sure we use this new approach when seed is provided in v2, and also leave a flag to enforce the new approach, which has not been turn on yet.",0
Fix typo (#9158),0
"The manner
    in which this dummy method is removed it to call ""squeeze(x, axis)""
    from the backend.",0
* added missing hashes,0
Keras Layers: Make the recommendation to create a nested layer inside the outer layer's `__init__()` explicit in the docstring.,0
* Update docstring and allow multiple inputs,0
* updated travis to tf 0.12.1,0
"--
53276475c786462d5c8ea0a315fc4b3ba885ab44 by Ashutosh Hathidara <ashutosh.hathidara@legatohealth.com>:

Changes as per feedback",0
BackupAndRestore callback: Allow the train_counter to be fault tolerant across training interruptions.,0
RuntimeError: Unable to restore a layer of class TextVectorization.,0
- less duplication,0
The Merge layer has been deprecated for 2 years.,0
* Fixed small out of range bug.,0
* Encapsulate hyperparameters and create generic network builder,0
* Removed trailing whitespace and refixed identation,0
There's a precedence for "autotagging".,0
"This may mitigate the OOM issue, (maybe not), but there is no reason to use big numpy arrays in the tests.",0
Move pad_sequences to tf.keras.utils,0
"Example:

``` python

def linear(x, a, b):
    return x * a + b

model = Sequential()
model.add(Dense(input_dim=10, output_dim=10))
model.add(Lambda(linear, arguments={'a':5, 'b':10}))
#OR:
model.add(Lambda(linear, arguments=[5, 10]))
```",0
"--
8d83bffd4776bbfad12a4e2669e8e30f7a26d3a7 by Zirui Zhuang <zr.zz.alp@gmail.com>:",0
Support 'tf' axis ordering in keras.preprocessing.image,0
* Test weighted_metrics with multiple outputs,0
* Make Model.check_trainable_weights_consistency private,0
* Add zero threshold and set F measure to zero if no true samples exist,0
"- **Pro**: In this regard, putting it in the Softmax makes sense.",0
* NumPy 1.24 is pickier about the dtype= option passed to comparison ufuncs.,0
PiperOrigin-RevId: 396441290,0
"What do you think about modifying this PR to check if the code is supposed to run on GPU + if cuDNN is available, and only then does a manual call to cuDNN?",0
PiperOrigin-RevId: 404633146,0
* Add a manager to share the sequence,0
This change also update the RNG behavior for initializer.,0
"Hi @AnikaTabassum 
I'm trying to build tensorflow from source on centOS 7.",0
* Update backend.md,0
Merge branch 'keras-2' of https://github.com/fchollet/keras into keras-2,0
Refactor the RandomCrop logic for the boolean "training" flag handling.,0
__sudo: required__ no longer is...  [Travis are now recommending removing the __sudo__ tag](https://blog.travis-ci.com/2018-11-19-required-linux-infrastructure-migration).,0
* Added a comment to clarify the purpose of the "enclosed" dictionary,0
Can I use a binary index to the embedding layer instead of using integer index,0
All other combinations work with GCS.,0
"I am wondering if we instead use the EWA weights in the correct places, will it perhaps fix the reduced prediction confidence that we are observing in our models.",0
* fixed indents for pep8,0
Consider casting elements to a supported type.,0
Update mnist_siamese_graph example (#6223),0
Added support for new pydot versions to fix find_graphviz error (#6398),0
Ensure correct usage of zca_whitening in ImageDataGenerator (#8699),0
Fix for Keras `Softmax` layer gradient underflow.,0
Add more unit test for stateless dropout + tf.random.Generator ckpt loading,0
tf.keras.preprocessing.image_dataset_from_directory does not work in Keras 2.4.2,0
- note that provided feed_dict substitutions are merged with substitutions from inputs,0
rename symbolic tensors to output,0
The comparison made between v1 and v2 focused on deeper networks only.,0
Fix typos in image preprocessing docs (#2906),0
Correntions in the cost functions masking,0
implemented dropout in GRU and SimpleRNN,0
* feat(AlphaDropout): add 'noise_shape' param back,0
* get_file() improve large file performance #5861.,0
See this issue https://github.com/h5py/h5py/issues/289 for details.,0
Fixes #42872: map_to_outputs_names always returns a copy,0
Pardon me if it sounds stupid.,0
Subclass of keras.utils.Sequence does not get the value I want when I use predict_generator,0
* Replace maxproc by nb_worker in test,0
"It died in the K.rnn call at line 2974 of tensorflow_backend.py where it does:
`                 output = tf.where(tiled_mask_t, output, states[0])
`",0
Causal Dilated Convolutions  (#5489),0
fix a little mistake in pad_sequences,0
Fixing RNN compute_dtype in v1.,0
"LossScaleOptimizerV3 is essentially a copied version of the old LossScaleOptimizer class, with some minor changes to support the interface of the new optimizer.",0
"Would it be possible to add sklearn as a dependency for testing instead in `setup.py` like Theano, and implement parameterized tests instead?",0
* Style fixes.,0
Passed the scheduling argument through the `*_generator` function. (#7236),0
Pin the tf-nightly to an old version to mitigate the OSS build error,0
This reverts commit 12f7f374c38760a265c468f8cb65f8c030a0cddb.,0
Fixing the travis build by downgrading numpy. (#12037),0
"commit 5f06a7879bd5679eb290e379b73ff68d5cfceda1
Author: David Silva <davidtvs10@gmail.com>
Date:   Sat Jun 16 17:26:20 2018 +0100",0
* Fix invalid syntax under python 2,0
- consolidated the init method by adding a host of assertions,0
"colocate_gradients_with_ops puts these matricies next to the operations, allowing you to split your model across multiple GPUs.",0
* pep8 - one line too long,0
Automatically close stale issues (#6701),0
"--
aa6eeebdb8dbe1b6d796c57cca19009f52c0e52d by Albert Villanova del Moral <8515462+albertvillanova@users.noreply.github.com>:",0
"Well, I'm not sure you are going to find anything useful from this blog post.",0
* fix small inconsistencies in the documentation,0
idomatic -> idiomatic,0
* Add tests for new callbacks methods,0
Update lstm_text_generation.py,0
Fix typo error of tf.compat.v1.keras.experimental for export_saved_model and load_from_saved_model,0
Add documentation for activations and objectives.,0
* Revert "[Performance] Add a manager to share the sequence (#7256)",0
Propagate uses_learning_phase via RNN initial states (#8911),0
Make loss-only output handling consistent with other Model methods.,0
"For example, it returns `keras.preprocessing.sequence.keras.preprocessing.sequence.pad_sequences` instead of `keras.preprocessing.sequence.pad_sequences`.",0
"Test result:
 test env: with Tensorflow(commit a543d9471047ca3f6881c87105fcbe2cdff9207d Date:   Thu May 10 17:43:30 2018, local build), python3.4, centos7.4
 test cases:
      ""pytest  ./tests/keras/layers/normalization_test.py""  <all passed>
      ""pytest  ./tests""      <keep same result as without this PR's modification>",0
An example from Keras including regularization with Eigenvalue Decay.,0
* Flip thresholded non-zero count,0
* add blankspace around operator,0
PiperOrigin-RevId: 468290082,0
@DaniyarM  Consider extending your `.gitignore` to handle unrelated files.,0
"So we are not sure if it is always same file for everyone with different system configuration. (different OS, protobuf, caffe, C++ compiler version, etc)",0
Change to the set_value() function that had a bug when the variable "value" was a float.,0
* Multiple axes are now supported for std and var.,0
Corrected a typo in line 65.,0
"commit 4e829712a2c6153d4cb0c34507fa3f5a7814a2a9
Author: Francois Chollet <francois.chollet@gmail.com>
Date:   Wed Jun 6 16:17:29 2018 -0700",0
* Fixes automatic doc generation problem with indented lists.,0
I hope the following codes may help you to check functionality when `depth_multiplier > 1`.,0
Are you suspecting that there needs to be a fix on tf.distribute side?,0
(.text._ZN3ruy6detail36CreateTrMulParamsAssumingColMajorDstILNS_4PathE113EaaiaEEvRKNS_3MatIT0_EERKNS3_IT1_EERKNS3_IT3_EERKNS_9MulParamsIT2_SC_EENS_16ChannelDimensionEPNS_3CtxEPNS_11TrMulParamsE[_ZN3ruy6detail36CreateTrMulParamsAssumingColMajorDstILNS_4PathE113EaaiaEEvRKNS_3MatIT0_EERKNS3_IT1_EERKNS3_IT3_EERKNS_9MulParamsIT2_SC_EENS_16ChannelDimensionEPNS_3CtxEPNS_11TrMulParamsE]+0x110): undefined reference to `ruy::Ctx::SelectPath(ruy::Path)',0
I don't guarantee that this small test will run.,0
"As for avoiding assumptions on the structure, or to write it by hand, we can craft a version of map_structure that can work with None shapes:

```
  def empty_or_zeros(shape, dtype):
    empty_shape = [0 if s is None else s for s in shape]
    return tf.zeros(empty_shape, dtype=dtype)
  return tf.nest.map_structure(empty_or_zeros, it.output_shapes, it.output_types)
```",0
* theano_backend.py remove border_mode as per review,0
Improve summary event assertions in Keras automatic outside compilation test,0
Do you know how this could be an optional output?,0
fix TensorBoard callback with unit test (#10173),0
* Formatting and comment changes,0
* Under NumPy 1.24 no longer automatically infers dtype=object when ragged sequences are passed to np.array().,0
* Fix some typos.,0
Integration with redesigned preprocessing & applications modules. (#10952),0
Change the keras saved_model metadata to use the copied version data from keras.,0
* Simplified the test.,0
- `init_weights` was not renamed everywhere,0
`categorical_crossentropy`  is another term for multiclass log loss.,0
Would this be possible or is it crazy?,0
Updated global_clipnorm in the doc string which is allowed **kwargs of optimizer.,0
"There are small typos in:
- keras/layers/preprocessing/discretization.py
- keras/layers/preprocessing/image_preprocessing.py
- keras/saving/pickle_utils_test.py",0
- Separating the parsing and the declaration of the structure of the docs.,0
adding K.name_scope to deserialize methods in losses.py and metrics.py to improve TensorBoard Graphs usage experience,0
Fix typo (#7191),0
* fixed validation y size for weighting,0
Setting image_dim_ordering or image_data_format explicitly as per Theano requirements while using Theano Backend gives error,0
- Consolidate disparate test-related files into a single testing_infra folder.,0
#5738,0
* Make uppercase to be consistent,0
Relocate `EagerTensor` and `Tensor` special-case conversions.,0
* Used ' instead of " for consistency.,0
Merge remote-tracking branch 'upstream/master' into trans_out_pad_dev,0
Update OSS keras to use python 3.9 for test.,0
"Pep8 was complaining about a missing whitespace after comma, now it's fixed.",0
FIX: Tensorboard callback only supports logging Embeddings layer weights (#7766),0
Add test for documentation (#6324),0
* PEP8 fixes again,0
"* random_zoom, array_to_img consider dim_ordering",0
PR #15867: add scoring methods in Luong-style attention,0
adds support for list/tuples of arrays with tests,0
* Removed getargspec from legacy wrapping function,0
Added tests for saving layers that write/load custom assets via _save_assets() / _load_assets() and write/load custom variables via _save_own_variables() / _load_own_variables().,0
"It works fine when the defaults are probably fine, as with the initializations.",0
* fix wrappers,0
"Would it be a good idea to assume that nobody will ever need to load plugins for more than one type of exotic hardware, and just have a single 'kThirdPartyPluginPlatformId' for third party hardware?",0
@asampat3090 @pranv Any thoughts on how this could be addressed?,0
"Yeah, for `flatten` too, if possible.",0
* update interface name,0
Reapply patches to legacy Merge layer (#5791),0
- Please add a unit test.,0
Does top_k_categorical_accuracy has any assumptions I am not aware of?,0
# This is the 3rd commit message:,0
resolves #15715.,0
Is there an undocumented assumption about the input?,0
* remove top_k_categorical_accuracy from being tested together with other all_metrics,0
Hopefully whatever build changes are made to TF won't be making assumptions that things are located in the "standard" places the latest flavor of the Nvidia installer decides to use.,0
Use the most_specific_compatible_type method to calculate the common specs.,0
Small fix to array_to_img function (#5070),0
I'm also not sure where the `DeviceSlice` class should be put.,0
PiperOrigin-RevId: 413806840,0
* use native batch reshape,0
* add cropping1d/2d/3d layers,0
Keras saving/loading: Fix `tf.keras.utils.custom_object_scope` where the custom model class is not respected by using an empty dict as the default for `Model.get_config`.,0
* Change hash size to 1e7,0
Add reference to slides for RMSprop (#5120),0
update residual connection example (#3278),0
PiperOrigin-RevId: 503514528,0
PiperOrigin-RevId: 404848570,0
"Also adds `__tf_tensor__` magic methods to `DistributedVariable`
and keras's `AutoCastVariable` to avoid breaking their conversion behavior.",0
"You are right, my mistake.",0
"* When use tensorflow as backend, let batch norm run into fused batch norm as much as possible, which has better performance.",0
@fchollet should the mask be applied to the inputs during concat merge [here](https://github.com/fchollet/keras/pull/2413/files#diff-fe3ca734e8421a17729d0b0ea4c800baR1216)?,0
* topology.py raise value error on reshape size mismatch,0
* Progbar accepts target None in addition to -1.,0
Is it possible that MWMS is doing reduction ReductionOp.MEAN? ([distribute/distribute_lib.py#L1449](https://github.com/tensorflow/tensorflow/blob/v2.10.0/tensorflow/python/distribute/distribute_lib.py#L1449)),0
For where this keeps coming up,0
* added _load_attributes_from_hdf5_group() and _save_attributes_to_hdf5_group() methods that can deal with the problem of saving models with a lot of layers (or with nested deep models) into HDF5 files,0
Also modified generate_legacy_interface to allow value conversions in positional args.,0
"1GB is too few, which was almost used up, and with the new optimizer taking slightly more memory (due to XLA), it does not have enough room.",0
Another thought: should this be serializable?,0
Is the new version check correct; i.e. in this supposed to work in TF 1.10?,0
"--
3002ea588650ac59233220f87cef7b7eb56d52a2 by C. Wick <wick.chr@gmail.com>:",0
.travis.yml: The 'sudo' tag is now deprecated in Travis CI (#12842),0
* Wait on process to terminate,0
* Link fix,0
This PR fixes the Typo error for tf.compat.v1.keras.experimental.export_saved_model and tf.compat.v1.keras.experimental.load_from_saved_model,0
- py.test is configured to display test profiling information that shows 10 slowest tests.,0
Imported from GitHub PR https://github.com/tensorflow/tensorflow/pull/49141,0
Please stop opening new PRs when making commits.,0
Link to the metrics document(/metrics) was missing in 'Compilation' section.,0
* Doc style fix,0
* Style fix,0
Make the shim_test compatible with tf1,0
* removed trailing whitespace,0
"* NumPy 1.24 removes a number of deprecated NumPy type aliases references (np.bool, np.int, np.float, np.complex, np.object, np.str, np.unicode, np.long).",0
PiperOrigin-RevId: 408666683,0
* Bug fix : Model.from_config (#5730),0
* Update callbacks.py,0
Update cntk backend with CNTK 2.2 release (#7907),0
Bidirectional Wrapper (#3495),0
"@fchollet Merge this pull request plus follow https://github.com/integration/probot-stale to automatically mark the many 3 month old issues as stale, then close them after an additional 30 days.",0
"These classes are deserialized into the non-experimental Policy and LossScaleOptimizer classes, which has been the case since TensorFlow 2.4.",0
* Update writing-your-own-keras-layers.md,0
"commit 0237542f48566c9115b3dde4cce920b00e25507a
Author: EyeBool <diataha.personal@gmail.com>
Date:   Mon Jun 11 09:44:02 2018 -0700",0
* Add a test for K.ctc_decode() with merge_repeated=False.,0
* Fix TF functionality,0
PiperOrigin-RevId: 399276053,0
"Is TensorFlow assuming that the Computation Graph is acyclic, especially in the XLA module?",0
* Refactoring _standardize_input_data to make it faster.,0
Export current optimizer to legacy namespace.,0
can both input layer and output layer are the same embedding layer in Keras?,0
"Assuming ops can only be merged if their witnesses will dominate the merged
assuming op.",0
"In particular, when unexpected data types are passed in, the error is much clearer than the current behavior (crash) if an unsupported type is passed in.",0
all zero arrays no longer get divided by zero in the process of being turned into images (#3401),0
"Change variant='reset_after'/'reset_before' to reset_after=True/False
in GRU and GRUCell.",0
"Was getting an error when calling

```
K.set_learning_phase(0)
```",0
How do you think?,0
Thank you for the review.,0
sparse_categorical_crossentropy: better documentation and general dimension handling,0
* Fix RNN cell serialization,0
Comparison with other sentiment analysis examples (run on a slow machine so that the time differences are visible):,0
* Update tensorflow_backend.py,0
Internal change,0
PiperOrigin-RevId: 362193657,0
@fchollet I took your feedback into consideration.,0
cifar10 resnet v1 and v2 (#8231),0
Enable the tf.random.Generator for all the keras RNG related code.,0
PiperOrigin-RevId: 463361589,0
* Use Generator/Discriminator more closely resembling the ones from the referenced paper,0
* return_state unit test,0
your thoughts?,0
This reverts commit 2d1086447a25d281f9428832d046c473d80ad761.,0
Add traceback filtering to primary Keras API endpoints.,0
Also change mixed_precision/model_test.py to use the new optimizer instead of the legacy optimizer when TF2 is used.,0
Why might this be useful?,0
[RELNOTES] Simplify implementation of Sequential and remove legacy Merge support (#10077),0
PiperOrigin-RevId: 435395712,0
* fix code style issue,0
Embedding visualization is added to TensorBoard callback. (#5247),0
* Fix pep8 errors (add spaces around arithmetic operations),0
Only the source directory is synced.,0
PiperOrigin-RevId: 481705383,0
* Add KA,0
"It's consistently two characters too long (see screenshot above), with the default page size, giving ourselves as much room as possible and going full screen.",0
* clean up the test a bit,0
* Fix style issues.,0
* fixed some more len/shape issues for prediction,0
* Add Recurrent.from_config() test,0
* minor clean-up of docs,0
Add clip value as in Neural Turing Machines,0
Make `sample_weights` and `class_weights` multiplicative. (#11914),0
Added the numpy implementation of switch to the docs. (#11575),0
Export legacy tf.layers code to keras.__internal__.legacy.layers.,0
* add stricter condition,0
* integrating bias flag fully,0
* Add Inception-ResNet v2 to application,0
"tensorflow breaks if the shape of the state changes
https://github.com/fchollet/keras/issues/4008",0
* Now we check for the whole feed instead of just inputs for the conversion.,0
* Fix some pep8 errors.,0
* Added Shuffling to Sequence Class,0
- Remove ability to pick between zipping or not zipping a Keras saved artifact: it's always a zip archive now.,0
PiperOrigin-RevId: 358446889,0
Switching learning/brain dependency to OSS compatible test_util,0
The docstrings are only present in `tensorflow_backend.py`.,0
Please wait for #11521 to be merged into master.,0
sparse_categorical_crossentropy only works on single output,0
"Revert ""Make merge layer work with a single model, turning it into a container layer.""",0
* Fixed the unicode issue by opening in binary mode.,0
Increase test coverages by adding invalid CNTK usecases (#10236),0
"imdb_cnn.py

Train on 20000 samples, validate on 5000 samples
Epoch 1/3
20000/20000 [==============================] - 1414s - loss: 0.6401 - acc: 0.5930 - val_loss: 0.5144 - val_acc: 0.7442
Epoch 2/3
20000/20000 [==============================] - 1411s - loss: 0.3908 - acc: 0.8255 - val_loss: 0.3615 - val_acc: 0.8344
Epoch 3/3
20000/20000 [==============================] - 1416s - loss: 0.3173 - acc: 0.8636 - val_loss: 0.3788 - val_acc: 0.8256",0
Fixed load_weights to not create empty/corrupt .h5 files,0
* runtime error,0
Add `separable_conv1d` (#10125),0
* identical class_mode code.,0
* Unit tests added,0
Create 2 more internal APIs which are used by youtube.,0
From the documentation I gather that this is logical considering how batch_dot() is typically used.,0
"""from sklearn.grid_search import GridSearchCV""   is out of date (#11240)",0
It takes the predictions from logits and applies a `threshold` to convert them to either class 0 if the predicted value is below `threshold` or class 1 if the predicted value is above `threshold`.,0
Imported from GitHub PR https://github.com/tensorflow/tensorflow/pull/49376,0
### Summary (#11456),0
Update Keras API after internal TF codebase file moves.,0
Merge pull request #1417 from farizrahman4u/patch-21,0
"imdb_cnn_lstm.py

Train...
Train on 20000 samples, validate on 5000 samples
Epoch 1/2
20000/20000 [==============================] - 575s - loss: 0.4312 - acc: 0.7900 - val_loss: 0.3457 - val_acc: 0.8456
Epoch 2/2
20000/20000 [==============================] - 580s - loss: 0.2302 - acc: 0.9094 - val_loss: 0.3546 - val_acc: 0.8498
5000/5000 [==============================] - 26s
Test score: 0.354624111649
Test accuracy: 0.8498",0
(I saw that in the keras.doc there's a dense layer added before the MAxOutDense; but I don't understand how that might help. Nor does it..),0
* add cntk reset_uids,0
OK.,0
PiperOrigin-RevId: 413723566,0
* Extract duplicated function convert_model() to _convert_model_weights().,0
@souptc would you have any thoughts on what might be the issue here?,0
* add one black line at the end for pep 8 compliance,0
"Serious implementation gap of `ConvLSTM2D` across 3 backends causes obvious performance differences, no matter what the `padding` scheme is.",0
PiperOrigin-RevId: 452584167,0
"Add unitnorm constraint, support for constraint and regularizers to Embedding",0
"Layers of class
TextVectorization require that the class be provided to the model loading code,
either by registering the class using `@keras.utils.register_keras_serializable`
on the class def and including that file in your program, or by passing the class
in a `keras.utils.CustomObjectScope` that wraps this load call.",0
* indentation fix,0
PiperOrigin-RevId: 362167274,0
Thank you for considering.,0
- LSTM default arguments dropped,0
* Match default signatures,0
* Raise a descriptive error if `Model` constructor `inputs` are not inputs.,0
Also handle Merge layers,0
Keep shape of the initial (dummy) state (#4146),0
"Currently, `fit/evaluate_generator` don't support this case without this fix.",0
"- ideally, the usage of the layer to be obvious from its name.",0
Clarify docstrings of Losses and `Layer.add_loss()` for distribution:,0
"* Batch size reduced in tests, targets and sample_weights sliced",0
Add prefetching to datasets generated via Keras utility functions.,0
Update the RNN cell API to be explicit about output_size. (#11021),0
Often related to `autogen.py`.,0
Than you for your consideration and please correct me if I mis-understood things here,0
Allows creating tf.random.Generator under distribution-strategy scopes.,0
"The issue was self.states is created as a float32 variable, which causes TypeErrors, so I cast self.states.",0
PiperOrigin-RevId: 445261970,0
"https://github.com/numpy/numpy/blob/v1.16.2/numpy/lib/npyio.py#L288
https://github.com/numpy/numpy/blob/v1.16.3/numpy/lib/npyio.py#L292",0
* rest travis ci - also add Execption() around ctc decode.,0
PiperOrigin-RevId: 387654476,0
"But all things considered, this one is the more widely used one since it replicates the Numpy API.",0
* Responding to @cais comments,0
So I made a function for both and moved the statement `expected_output_shape = layer.compute_output_shape(input_shape)` up since it was not part of the sequential API tests nor the functional API tests.,0
Bump the keras nightly version from 2.12 to 2.13.,0
Merge Exception: Error when checking model target,0
Thanks the comments from fchollet.,0
15% more efficient RNNs with TensorFlow,0
* Create copy of inputs if list,0
But I don't know if it would work or not and the user can decide it.,0
[P] all save_model/load_model to accept h5py.Group (#10912),0
PiperOrigin-RevId: 407862342,0
PiperOrigin-RevId: 399077719,0
Keras -Considering only certain values in Custom Loss Function,0
Merge branch 'BRNN_latest' of https://github.com/yaringal/keras into BRNN_latest,0
Grouped common function calls together in the test_callbacks.py. (#11167),0
"commit 72ade3f493dd725fb414cbc65a847259360be138
        Author: Yarin <yaringal@gmail.com>
        Date:   Sat Feb 20 00:52:01 2016 +0000",0
add error messge for tensorflow backend,0
PiperOrigin-RevId: 397563904,0
More updates to the model bookkeeping shim.,0
I sincerely wish my PR will help you.,0
Add saving tests (#10523),0
Do you plan to add automatic inference for the type attributes or should I assume I need to set them?,0
"--
55dc323db43e69ae574847f48fb59a0f9cf87882 by Ashutosh Hathidara <ashutoshhathidara98@gmail.com>:

Update tensorflow/python/keras/utils/vis_utils_test.py",0
* Assert that layer attached to input tensors is an InputLayer,0
"Added unit tests for the case of 0 and 1 inputs; existing tests cover
the case of > 1 inputs.",0
* test fixes,0
small bugs in local.py on LocallyConnected2D?,0
updated instances of imsave in example scripts with save_img method.,0
Move `get_source_inputs` (#10415),0
PiperOrigin-RevId: 385002802,0
Bump zlib to 1.2.13.,0
Add "input" class_mode to the docs. (#8730),0
"* removed buggy code in random_rotations, shears etc  and replaced it with todos.",0
Could there be an endianness assumption in the [singlejar tool](https://github.com/bazelbuild/bazel/tree/master/src/java_tools/singlejar) that is being violated on the s390x?,0
"More surprisingly,  the models built by Theano can be successfully loaded and predicted on Tensorflow then.",0
"- on the TF front, it's already the case, but the docstring is incorrect.",0
how is it possible?,0
* Add API conversion interface for both AvgPooling3D and MaxPooling3D,0
API style changes in ModelCheckpoint callback,0
* Replace literal constant 10 with variable num_classes,0
2. update track_tf1_style_variables shim usage tests to directly use the decorator. (This raised issue 1 which was by chance being missed in the prior setup due to reflection & signature inspection subtleties),0
Remove caching of constants as member variables in BatchNormalization.,0
Merge pull request #1191 from jfsantos/patch-7,0
Added support for dynamic noise_shape in Dropout (#7999),0
* Add a 'period' variable to ModelCheckpoint to save every period epochs,0
* ws fix,0
PiperOrigin-RevId: 416335971,0
"It involves rewiring the TF graph, or possibly reconstructing a new graph on top of the provided inputs:

```python
x = Input(shape=(3,))
y = Dense(1)(x)
model = Model(x, y)
model.compile(optimizer=tf.train.AdamOptimizer(), loss=tf.nn.sigmoid_crossentropy_with_logits)
model.fit(tf_record_tensor_input, tf_record_tensor_target, steps_per_epoch=10000, epochs=10)
```",0
At least multiple occurrences within a test module.,0
Issue when try to run the model (Error when checking model),0
* Fix elif statement in optimizers.py,0
Imported from GitHub PR https://github.com/tensorflow/tensorflow/pull/44105,0
explicitly return,0
removed additional whitespace lines,0
* one line fix for TensorBoard callback issue,0
"This commit changes the behavior by slicing everything in val_data, excluding the learning_phase.",0
Add an option to BackupAndRestoreCallback to keep the checkpoint after training is done.,0
Fixes https://github.com/keras-team/keras/issues/17275,0
"In TF backend we just pass it to ctc_beam_search_decoder(),
other backends have just a new dummy argument.",0
Remove stray comma causing a tuple to be created instead of a string.,0
In my specific usecase it took as much time as the convolution itself and led to tensorslow being much slower than theano.,0
* Fix GRU with "reset_after" after code review.,0
* Removed the seed.,0
I see...??,0
* addition_rnn example formatting changes,0
"The dependency path is Dropout._random_generator._generator._state_var, all the component on this path are Trackable object.",0
* Try fixing TF test,0
* Fix annotation,0
This is causing related metrics to calculate wrong result when metric is created in the MirroredStrategy scope.,0
Fix a warning on Python3 (#5042),0
* PEP8 fix,0
* removed dublicated code,0
* Fix BN add_update syntax,0
* Warn always about semantic changes if having keras1 args in *_generator calls.,0
"This PR is just a small refactor on the `keras.utils` module, using python generators over list comprehensions whenever possible in order to use less memory and avoid computing things beforehand.",0
Simplify with from six.moves import input (#9216),0
"distinguish between absence of `pydot` and failure to find
the executables of GraphViz in the $PATH.",0
Update recurrent.py. (#4970),0
* get_input() in the script,0
PiperOrigin-RevId: 383912483,0
* mnist_tfrecord.py,0
Thus this is changing to let base class provide an empty dict.,0
Add API conversion interface for both AvgPooling2D and MaxPooling2D,0
PiperOrigin-RevId: 494070652,0
* Parametrized tests.,0
Add API golden file for keras API endpoints.,0
support for multiple files in ModelCheckpoint,0
* Remove do_validatoin_split from _list_valid_filenames_in_directory,0
Two things come to mind:,0
"commit 5544f66148676d86cb53309701eee6a4e99a3aeb
Author: Michael Oliver <michael.d.oliver@gmail.com>
Date:   Mon Apr 4 18:03:05 2016 +0000",0
"Help added in the code, but as noted in the API Design Review doc, I also need a bit of guidance with that.",0
"Could you update Convolution3D to expect an input array of form

```
(n_samples, n_channels, axis_size, axis_size, axis_size)
```

to match the other cnn example?",0
* changes discussed in pull request,0
* fix PEP8 E127,0
add trig funcs for numpy backend (#11254),0
"Also made cell wrappers API more consistent, all wrappers now expose a `wrapped_cell` property, not just `DropoutWrapper`.",0
"But when it comes to the models built by CNTK, Tensorflow fails in loading.",0
sparse_categorical_crossentropy loss function output shape didn't match,0
PiperOrigin-RevId: 475724528,0
Added **kwargs to to_json and to_yaml.,0
Bug fix.,0
Merge pull request #1811 from fchollet/faster-rnn,0
"The Theano implementation crashes if the argument is a list of
variables and the CNTK implementation crashes if it is not.",0
Fix Syntax error for combined_model.compile of WideDeepModel,0
PiperOrigin-RevId: 421105088,0
* Update initializations.md,0
* add reverse support,0
Add issue template that redirect to KP and KA (#12115),0
* Code formatting for CI errors,0
PiperOrigin-RevId: 413214401,0
Fix some optimizer issues.,0
"* clarify comment, remove np.float32",0
Update security section.,0
The current method doesn't provide any information to user.,0
Please revert.,0
UX tweaking might or might not be needed.,0
* Refactor (deduplicate) skipif decorators for TensorFlow and GPU.,0
Fixed a type: repeated 'in common'. (#10394),0
Any chance you might be able to do a review?,0
* Fix up bad closing brackets,0
This CL fixes this issue.,0
"We still allow users to provide no sample weight with no weighted metrics, but required them to pass an empty list to weight_metrics.",0
- implement GRUResetAfter based on 1406.1078v1,0
Hopefully I'll have a chance to take another look soon ...,0
4th pass,0
Fix typos. (#7374),0
Following this issue https://github.com/fchollet/keras/issues/2296 i propose this PR.,0
"On a side note, this PR has been lying stagnant since August since I still need to know if it's possible to create the same effect as this custom layer using a Lambda layer with the object-oriented interface, and how to do so.",0
Added average duration per epoch and per step to logging when verbose = 2,0
Logs a warning when users attempt to call evaluate() with a sample_weight when no weighted metrics are provided.,0
Re-add safe_mode for Keras v3 model loading.,0
Hence I thought to replace the word `half` with `part`.,0
PiperOrigin-RevId: 393180735,0
Keras Saving: Make sure the optimizer weights are also built and restored upon loading.,0
"Import statements now try to add the various backends one by one, so … (#7620)",0
This fixes the cases where the dataset is trained with a per-worker dataset.,0
* update the style,0
PiperOrigin-RevId: 442435248,0
* Updated to reflect @Dref360 's comments,0
"* Added a table in Applications docs that compares model size (file download), accuracy on ImagetNet (top 1 and top 5), number of parameters, depth",0
PiperOrigin-RevId: 429127641,0
* fix PEP8 problem..again!,0
* Fix shape mismatch in `rnn()` of tensorflow_backend,0
"Binary cross-entropy and categorical cross-entropy give differently
shaped results, which used to not matter since mean() ignored the shape",0
This reverts commit 42339994bfeb72d128f5fa08ad20b61dd51a2825.,0
PiperOrigin-RevId: 444879832,0
"Consider this example:
```
y_true = [[0, 1, 0], [1, 0, 0], [0, 0, 1]]
y_pred = [[0, 0.9, 0.1], [0, 0.9, 0.1], [0, 0.9, 0.1]]
sample_weights=[1.0, 0.0, 1.0]

fn = partial(top_k_categorical_accuracy, k=2)

# before fix:
fn(y_true, y_pred) # returns 0.66
weighted_masked_objective(fn)(y_true, y_pred, sample_weights) # returns 0.66

# after fix:
fn(y_true, y_pred) # returns [1.0, 0.0, 1.0]
weighted_masked_objective(fn)(y_true, y_pred, sample_weights) # returns 1.0
```",0
docs: Fix a few typos,0
"Please review your loss function or consider using a standard 
differentiable loss function.",0
PiperOrigin-RevId: 385218971,0
"I'm not the best at thinking in Theano ways, so I apologize if its not the best use of the code.",0
* Refactor topological part of Keras engine.,0
"Document each adapt, and cross link StringLookup, TextVectorization and
Embedding layers.",0
"But feel free to submit new examples if the future; we are looking for short, very nice and readable scripts demonstrating Keras best practices around common deep learning use cases.",0
2. fix some code style.,0
Add an explanation about padding in Conv1d (#6796),0
Borrow the main body of the tf api compat test for diffing and api generation.,0
* fix fit and retain old functions for unit test,0
* Update imdb_cnn.py,0
Fix docs (#3609),0
- Remove indent of `__test_split__` to show correctly,0
* Add issue template that redirect to KP,0
Fix `fit_generator` for `workers=0` (#11285),0
@fchollet let me know what you think.,0
All of this were caused by the fact that `clean_module_name()` was not called on the `function.__module__` in `render_function` (therefore this mostly affects the docs for `keras.preprocessing` and `keras.applications`).,0
The reason for this is that `tensorflow_backend` uses the version of tensorflow to decide if it will execute eagerly or if it will use a `tf.Session` to evaluate a variable.,0
- management of training/testing modes,0
* Simplify - remove K.cast(),0
* formatting fixes,0
Bug fix: Batch dot (#11458),0
replace string with appropriate NotImplementedError (#11922),0
@fchollet let me know if you can think of a cleaner approach to this!,0
"2) decay has been removed from argument list, for future support of
   learning rate decay objects.",0
* modifed embedding to accept arbitrary input dim,0
"Thanks to nostalgebraist for pointing out this bug:
https://nostalgebraist.tumblr.com/post/641628845811908608",0
I made a change.,0
PiperOrigin-RevId: 488663939,0
"With
this change the introduced test passes and the above example works.",0
* add unit_test for rnn() with states whose shape is different from that of the output.,0
"Also the `original_backend` is not found automatically in the old models and so is set to `None`, which makes it difficult or impossible to always convert correctly.",0
Allows user to specify how often to run validation.,0
"ResourceVariable is now a CompositeTensor, but can't be packed and unpacked like other CompositeTensor.",0
"I submit it for reconsideration, hoping we can align the two behaviors.",0
* responding to comments,0
"Now we have
a parametrized test.",0
"Is it possible to do the shape-handling ops with tf shape tensors rather than Python ints, so as to allow the tensor shapes to not be predefined?",0
"Previously we made it a CompositeTensor by returning Variable.handle, but that breaks down when the variable is a DistributedVariable (in cross-replica context).",0
PiperOrigin-RevId: 430336909,0
* Disable explicit nearest neighbor test which is platform dependent,0
* MAI: import pydot (as required in `extras_require`),0
Any opinions on which behavior we should choose?,0
PiperOrigin-RevId: 510514963,0
* Keras 2 and keras-contrib pull request process,0
PiperOrigin-RevId: 528845572,0
"Consider the inception module used in iconic GoogLeNet:

![inception](https://cloud.githubusercontent.com/assets/8753078/8402663/f690e31c-1e5a-11e5-97c1-6a9b9b9c6085.png)",0
* added case where uses_learning_phase is False,0
"Regarding the SharedDense layer, I see a few issues:",0
Update BaseImageAugmentationLayer to preserve the input format in the output format.,0
* Add corresponding test,0
Added MarkDown formatting to examples/conv_filter_visualization.py (#12252),0
Update PIP package script to include OSS keras as a PIP dependency.,0
Speeding up the tests by reducing the number of K.eval(). (#11036),0
* Add Bidirectional Wrapper,0
Merge pull request #1216 from farizrahman4u/patch-20,0
Model is not sequential if there is a "merge" layer somewhere in the graph.,0
PiperOrigin-RevId: 395027075,0
Fix typo in data_adapter.py,0
Merge pull request #819 from xingdi-eric-yuan/master,0
2nd pass.,0
Available metrics are: lr,0
Support multiple axes for some operations (tests and docs) (#11114),0
3. Use strategy.extended.update() to update the moving average variable so that it is done on each device.,0
PiperOrigin-RevId: 416612230,0
- forgotten in commit 958239c (Make private topological properties Python-private),0
[P] [RELNOTES] Support seamless load/save of models and weights (incl. checkpoints) to Google Storage (#11636),0
Merge pull request #752 from jfsantos/patch-4,0
Add tests for inputs set dynamically (#10367),0
"`refs` is a class attribute, not an instance attribute.",0
* ignore scalar input,0
We can achieve this by having a whitelist of allowed positional arguments.,0
Any thoughts on how Keras could accommodate such metrics correctly?,0
The error is similer to [this thread](https://stackoverflow.com/questions/34952651/only-integers-slices-ellipsis-numpy-newaxis-none-and-intege) and I fixed it.,0
Increase the memory limit.,0
* use dnn_available to check if cudnn is available,0
Added a if-else which was forgotten in the tests. (#10986),0
Keras predict/predict_on_batch says "too many values to unpack",0
[Performance] Add a manager to share the sequence (#7256),0
"For Adadelta, Adamax, Adagrad",0
* Adding channels_first,0
* Add Matthews correlation coefficient to metrics,0
"commit bdb149d1bbff64cc6b4d694090b905153d28e33a
        Author: Yarin <yaringal@gmail.com>
        Date:   Sat Feb 20 01:12:23 2016 +0000",0
- [n] This PR requires new unit tests [y/n] (make sure tests are included),0
PiperOrigin-RevId: 528613302,0
* Fixed PEP8 issues,0
Remove lstm_benchmark from examples/README.md (#8024),0
What do you think about my approach to test objectives?,0
* Added unit tests for the has_arg function,0
Allow convolutions to operate on fully dynamic shapes.,0
Is this an important issue or should we safely assume that it's due to labeling error (annotations are not exact)?,0
PiperOrigin-RevId: 358706703,0
Bug fix to set correct uses_learning_phase flag,0
"The max_value argument can not be used in a layer, except
    custom layer or Lambda.",0
"Theano only supports
(2, 2) though.",0
* Added hinge loss for categorical classification,0
* more deconv layers in var autoencoder example,0
Resolves https://github.com/fchollet/keras/issues/7854,0
Can you clarify?,0
(.text._ZN3ruy6detail36CreateTrMulParamsAssumingColMajorDstILNS_4PathE113EhhihEEvRKNS_3MatIT0_EERKNS3_IT1_EERKNS3_IT3_EERKNS_9MulParamsIT2_SC_EENS_16ChannelDimensionEPNS_3CtxEPNS_11TrMulParamsE[_ZN3ruy6detail36CreateTrMulParamsAssumingColMajorDstILNS_4PathE113EhhihEEvRKNS_3MatIT0_EERKNS3_IT1_EERKNS3_IT3_EERKNS_9MulParamsIT2_SC_EENS_16ChannelDimensionEPNS_3CtxEPNS_11TrMulParamsE]+0x22a): undefined reference to `ruy::Allocator::AllocateBytes(long)',0
"Tested to be working as before when running cached and
uncached datasets, and also verified to fail loudly
when asked to fetch http://httpstat.us/500",0
Use Model metrics as logs in `fit` and `evaluate` instead of last worker train or test step result,0
- added dtype parameter to force output dtype,0
"New usage:

merge_mode = 'dot', dot_axes=[axis1, axis2]",0
"model.fit(steps_per_epoch), 	mnist_tfrecord.py, progbar np.mean (#7113)",0
* Fix variables broken by removing name fixups,0
"--
e4c37031b007b4cd61b3a4135ceeee7762312b79 by pizzy <horlasehinde@gmail.com>:",0
We inject the kwargs `mesh` to all th...,0
"When mode='ave', and the dtype of the input is float32, dividing the sum
by shape[1], which is of dtype int64, results in an output of dtype
float64, which is wrong.",0
Keras Metric: Override default behavior of `Metric.__deepcopy__()` so `update_state` is invoked on the right instance.,0
- Not happy with serialization and naming at all.,0
Are there any consideration to make `embeddings_data` work with Keras sequences or generators?,0
* Added scikit-image to extras_require in setup.py,0
Add "input" label mode to tf.keras.preprocessing.image_dataset_from_directory,0
"- Added tests for the case of `(0, 0)` crops",0
even though the tests don’t fail on travis…,0
* add stack to backend,0
* Put Sequential.loss_weights attribute back.,0
Fix typos (#6949),0
Add a conditional import for dtensor related API.,0
Documentation fix for imdb.load_data (#8646),0
Revert "Add an Autoencoder model and a test to go with it.",0
apply_transform not in keras.preprocessing.image anymore.,0
- Export schedules to `keras.optimizers.schedules.__init__` to resolve discrepancy between tf.keras and keras packages.,0
"If sample_weights is to be used as a mask as well as for re-weighting
then it's important that, at least when used as a mask, the output be
rescaled.",0
* Split `applications` and `preprocessing` modules.,0
"It was also strange that it only raised error when 'image_data_format' was set to 'channels_first', not 'channels_last'.",0
Merge pull request #118 from dansbecker/master,0
"For example...

tf.keras.layers.RandomRotation(0.2, dtype='uint8')  # Always output uint8",0
"commit fd47e763855c34ed78d26ee441d83e0e63f08119
Author: Arel Cordero <arel@ditto.us.com>
Date:   Thu Aug 18 16:02:14 2016 +0000",0
Tell me what you ( @fchollet  ) and @EderSantana (the original creator of the join mode) think and in particular if any further modification is needed.,0
* cleanup variable name,0
* cntk doesnt support symbolic tile,0
* Add function to get multiple values at once,0
"There is no difference in inference or training, but harms training from scratch and in finetuning mode.",0
"* Style cleanup, in particular crossentropy backend API",0
mnist_cnn.py not working out of the box,0
* Removed two unused imports and added assertions to make it easier to understand that methods arguments are lists.,0
* remove backend-specific details,0
* Input() docstring fixes,0
[[node model/conv2d/Conv2D (defined at :6) ]] [Op:__inference_distributed_function_7653],0
"In reference to the above example, if I have a folder containing all the images and making an assumption that each image has atmost 3 components.",0
"- In `reset_states`, there is a check if `input_spec` is not `None`.",0
* Update optimizers and Lambda to respect global_custom_objects,0
Better error message on `model.fit` failure for empty dataset,0
Added documentation for loading an external backend,0
* return meaningful message when variable input length detected.,0
Imported from GitHub PR https://github.com/tensorflow/tensorflow/pull/49860,0
"* Validate merge_mode arg, Add None mode",0
.gitignore visual studio code IDE excluded (#7070),0
Keras IoU Metrics.,0
"* Change optimizer to sgd, increase epochs",0
Squashed from the following commits,0
Fix Issue #11384 - Explaining how to load external backends in the documentation (#11405),0
fix pep8 error,0
"2. Experimental optimizer automatically restores the iteration value, so skip the specific handling in sidecar evalutor.",0
"Can I assume that it means it flattens the Q matrix and A matrix as before such that when applying cosine similarity to the output vectors of the embedding layers taking Q and A, word order also matters?",0
Thank you for the PR @abrad1212.,0
* Small fix to Theano softmax for numerical stability,0
- should we expect the user to know that they need to take care of the types of their layers when doing a subclassing API model?,0
* Bug fix: Support multiple outputs in Lambda layer,0
"@bjacob Gentle ping: I see some commit to `third_party/ruy` that moves to 1b313682ef8b8fc8ed08719c610d1c3503b016bf, should I assume this is not yet uptodate with the fix?",0
@fchollet,0
* Update variational_autoencoder.py,0
* forgot to commit changes - updated save_img,0
Fix masked losses.,0
Also changed the documentation of return value to be clear that it always returns a batch of images.,0
"V2 cell wrappers and legacy cell wrappers no longer have a complex hierarchy with multiple inheritance to share code; instead, the common code was duplicated.",0
* Fix get_file download progress bar,0
Update core Keras layers with less cryptic input validation,0
Will we take back what is ours?,0
Do you assume that users create a base model on a GPU unlike the example?,0
5. Re-balance the weighting of KL and reconstruction terms,0
+ multiprocessing in legacy - unused imports (#4139),0
PiperOrigin-RevId: 484611354,0
How should I enter a list of tensors into cntk_func_tensors()?,0
"commit b4530ae775ec67b79db801b1e2a514a83ba980cc
Merge: 6b99d23 5fcd832
Author: David Silva <davidtvs10@gmail.com>
Date:   Sat Jun 16 16:17:41 2018 +0100",0
Expands Keras internal testing coverage for the new v3 saving format for common tests.,0
* Docstring clean-up,0
using private string UPDATE_STATE_DOCSTRING,0
"do we assume y_pred of keras.losses.categorical_crossentropy(y_true, y_pred) comes from softmax layer?",0
Adds a new test,0
Also a lot of `on_epoch_end` happen not when they are expected.,0
* Corrected 2D relicts in 3D function comments,0
Use var_list argument in TFOptimizer wrapper (#12106),0
"3. Adjust reparameterization trick to reflect use of z_log_var, not z_log_std",0
small fix for pep8,0
* pep8 applied,0
* Fix pep8 W293 error,0
- `name` is a string that internally maps to a layer number.,0
Pass `strides` as a keyword argument instead.,0
Fix all the learning rate scheduler for non-default constant dtypes.,0
* evaluate_generator(): Do not leak np.float to History here either,0
"Introduce `K.var` so that the standard deviation computation can
be made numerically stable.",0
* Test both implementations of the GRU/LSTM for CuDNN weight conversion.,0
This inconsistency can be very confusing or even bring unexpected errors if users assume automatic conversion in all cases.,0
Fix merge_dot tests,0
Could you possibly add something about how to use LRN in the code?,0
- shuffle is now a real shuffle (i.e. without replacement),0
All things considered: let's not do it.,0
This was due to checking rank of input during build.,0
* improved docstring format,0
Add missing Softmax activation memnn. (#3706),0
"There's a separate test, since we needed different data and to make the whole test as obvious as possible.",0
Add kwarg and documentation for dilation_rate to DepthWiseConv2D (#12526),0
"When not all inputs have `.shape`, still build the `input_shape` as a list using `.shape` for the ones with the `shape` attribute` and using `None` for those who don't.",0
Convert all the benchmark code to use tensorflow.compat.v2 as tf.,0
Delegate `finalize_variable_values` in `LossScaleOptimizerV3`,0
Fix mistakes in uniform initializations equations,0
* Show the supported interpolation methods if invalid method is specified,0
Support Loss classes that have names indicating protected access,0
PR #49141: Docs: Added documentation to some serialize and deserialize functions in keras,0
Add compilation support in new saving logic.,0
fix h5py string encoding,0
imported TimeDistributedMerge,0
* removed old reference to kernel_size,0
* Fix existing docstring for ones_like and zeros_like,0
Made a base class for ZeroPadding. (#10984),0
Tensorboard visualisation of Embedding layer in model within a TimeDistribution layer,0
(docs) Update `Conv2D` call to the Keras 2 API (#10692),0
- Still not sure what exactly the embedding is supposed to visualize if multiple inputs are given.,0
PiperOrigin-RevId: 378021595,0
"For example all below existing ops/fusions are covered under the new op `_QuantizedConv2D`:
_MklQuantizedConv2D
_MklQuantizedConv2DAndRequantize
_MklQuantizedConv2DWithBias
_MklQuantizedConv2DWithBiasAndRequantize
_MklQuantizedConv2DAndRelu
_MklQuantizedConv2DAndReluAndRequantize
_MklQuantizedConv2DWithBiasAndRelu
_MklQuantizedConv2DWithBiasAndReluAndRequantize
_MklQuantizedConv2DWithBiasSumAndRelu
_MklQuantizedConv2DWithBiasSumAndReluAndRequantize
_MklQuantizedConv2DWithBiasSignedSumAndReluAndRequantize
_MklQuantizedConv2DPerChannel",0
* rem unusedvar,0
Fix TimeDistributedMerge,0
"See
https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object
for details.",0
* fix pep8 style issue,0
"While this provided some performance benefits, it also produced some surprising behavior for users in eager mode.",0
Signed-off-by: Karel Ha <mathemage@gmail.com>,0
PiperOrigin-RevId: 392728394,0
add resnet50 example (#3266),0
fix typo in some layers' `get_config()` (#5810),0
Support constants in StackedRNNCells (#9089),0
Fixed warning showing up when channel axis is 1 (#7392),0
Added error message + PEP8 Fix (#5525),0
CNTK fails in building  the model with the layer`ConvLSTM2D`in some cases when `kernel_size` is greater than input dimension,0
* fixed typo (filterss -> filters),0
* Fix explanation message.,0
* - add comment,0
Added in_train_phase and in_test_phase in the numpy backend. (#11061),0
Added DetermisticRandomTestTool (from www.tensorflow.org/guide/migrate/validate_correctness) to variable_scope_shim.py.,0
Add 'initial_epoch' argument to Sequential fit() and fit_generator(). (#4779),0
"But, considering the fact that this PR is a superset of #12232  I can close mine to get things done.",0
Fix typo (#8953),0
Fix issue wrt redundant weights being saved in new saving logic.,0
"cc @mihaimaruseac , please review.",0
* Adjusted to comply with coding style,0
Do you know if the expected output returns -1 for the null?,0
PiperOrigin-RevId: 480761542,0
* TensorBoard callback improvements,0
- Cleaner separation of `NA` (impossible) vs `--` (no data).,0
"Add more tests on the new optimizer, and some fixes on the original code.",0
training.py _slice_arrays() fix crash when arrays are None (#7069),0
"Rather, by introducing indirection, it makes it harder to read the code.",0
BackupAndRestore callback: Update the `tf.keras.callbacks.experimental.BackupAndRestore` doc with the deprecation message.,0
* Simplify Sequential implementation.,0
Fixed doc,0
* adding bi-gram embeddings for better test accuracy,0
Bump the keras version to 2.8.,0
3) Perhaps weighting would be useful as part of a boosted architecture? (I'm less sure of this case),0
* cntk is only accurate to two decimal places,0
PiperOrigin-RevId: 391675068,0
- Assert the file is a .keras,0
Bug fix : RNNs (#3550),0
* Forgot $,0
* argparser removed,0
"Add metrics CosineSimilarity, MeanAbsoluteError, MeanAbsolutePercentageError, MeanSquaredError, MeanSquaredLogarithmicError, RootMeanSquaredError.",0
"Changed to only cast floats when the dtypes are not float, to avoid numerical precision loss for float64.",0
Supporting channels_first data format with crossentropy losses (#9715),0
Change the order of param "mesh" for DTensor based strategy.,0
* Update optimizers.py,0
"however, how do they manage to calculate the gradient for the back propagation phase if the F is assumed to be a black box function?",0
PiperOrigin-RevId: 491682409,0
PiperOrigin-RevId: 463727820,0
PiperOrigin-RevId: 423165160,0
* make sparse boolean in K.placeholder,0
The base Layer was not returning an output shape.,0
PiperOrigin-RevId: 402676476,0
* Remove trailing whitespace,0
Fix "VGG-like convnet" example.,0
Update faq.md (#10422),0
Add theano_mode argument to models.compile.,0
Merge pull request #16001 from spatil6:Keras_resnetrs,0
delete docstring about TensorFlow,0
*shrugs* mostly the typo "of top" -> "on top" was bugging me a bit.,0
Can you try to use a network as small as possible?,0
"pycodestyle and pydocstyle raises no info, warning, or error with this pr.",0
Make TextVectorization work with list input.,0
"""It is diffcult or impossible to do obsure(very unique) things in Keras"".",0
Fix typos in docs/templates/datasets.md (#5706),0
* Used a dummy name for the module containing the backend.,0
Tweaking,0
- added target_seq option for seq2seq models,0
PiperOrigin-RevId: 438345895,0
PiperOrigin-RevId: 444911837,0
2. Handle the error of seeing unrecognized variable with a better error message.,0
Fix 1D convolution layers under Theano backend (#2938),0
Preserve input shape data when serializing deferred-build Sequential models.,0
+ tarfiles and encodings - decoding bytes to ASCII at line level,0
"* remove unused, regex strings, simpler ###",0
* Use callback to print generated text in lstm_text_generation example.,0
PiperOrigin-RevId: 433030165,0
"let us know what do you think, specially regarding the `output_shape` inferecen",0
I'm willing to make a PR for this in `tensorflow/tensorflow` if this is a feature that makes sense.,0
- Make layers use a `add_weight` methods to create weights.,0
Revert "Corrected preprocess_input docstring in regnet.py and convnext.py",0
Update augment_*() to have transformation as a required parameter,0
"Adds `__tf_tensor__` magic methods to `Tensor`
and `EagerTensor` to handle the special-case conversions
formerly located in `convert_to_tensor`.",0
Remove. (#8363),0
PiperOrigin-RevId: 424734850,0
* bug fix cntk tile,0
Estimator was using third_party/py/tensorflow_estimator:tensorflow_estimator that generate API files.,0
This commit adds an optional argument to functions plot() and model_to_dot() specifying the direction of the dot object,0
* Add comment clarifying the design choice,0
Fix a little bug in pad_sequences,0
PiperOrigin-RevId: 484118253,0
* init commit,0
PiperOrigin-RevId: 484399643,0
Fix MaxPooling1D.,0
* Add a dtype paramater to the map_fn backend function,0
"This adds idf_weights as an init arg to the lookup layers, which allows
specifying a vocabulary in tf_idf output mode on layer construction.",0
* Created a function to_data_format to abstract the shape and data_format handling.,0
* Add a model.check_trainable_weights_consistency,0
support stride in pool3d,0
PiperOrigin-RevId: 503518032,0
* remove useless line in example in application.md,0
PiperOrigin-RevId: 474118860,0
* mooore fix,0
* better error messag,0
"commit cb0971b3cfe62452ab445e4034098cab2be3031b
Author: Arel Cordero <arel@ditto.us.com>
Date:   Tue Aug 16 23:45:32 2016 +0000",0
* Added documentation to correct section,0
See https://www.zlib.net,0
For better performance (#13144),0
PiperOrigin-RevId: 423184717,0
I also replaced BACKENDS by WITH_NP where it was possible.,0
PiperOrigin-RevId: 410602610,0
* Fixed issue #6286,0
It is important to release these resources when they are no longer required.,0
PiperOrigin-RevId: 459305398,0
* Revert uncorrectly resolved merge-conflict,0
I hope I was clear enough.,0
Since all the deps are controlled in local venv within the build script.,0
"* add AlphaDropout (from SELU), K.floor backend function, and tests",0
* Added dtype parameter to zeros_like and ones_like,0
(.text._ZN3ruy6detail36CreateTrMulParamsAssumingColMajorDstILNS_4PathE113EaaiaEEvRKNS_3MatIT0_EERKNS3_IT1_EERKNS3_IT3_EERKNS_9MulParamsIT2_SC_EENS_16ChannelDimensionEPNS_3CtxEPNS_11TrMulParamsE[_ZN3ruy6detail36CreateTrMulParamsAssumingColMajorDstILNS_4PathE113EaaiaEEvRKNS_3MatIT0_EERKNS3_IT1_EERKNS3_IT3_EERKNS_9MulParamsIT2_SC_EENS_16ChannelDimensionEPNS_3CtxEPNS_11TrMulParamsE]+0x4c3): undefined reference to `ruy::Allocator::AllocateBytes(long)',0
* Update test_sequential_model.py,0
This reverts commit 4392d120d845adf25d96d353df1513aa8e1df0ad.,0
Fix bug where progress indicator doesn't always complete (#8066),0
"Ported dropout for LSTM, GRU, SimpleRNN, and Embedding layer to latest Keras (turned off by default).",0
Summary of changes:,0
Merge pull request #17441 from mohantym:pad_sequences_update,0
Add documentation to several activation functions (#10066),0
Make ZeroPadding2D optionally asymmetric (#3595),0
I havent checked out graphs yet.,0
* What should in your opinion be done to make it Keras 'worthy'?,0
Update to Keras Applications 1.0.2 (fixes NASNet issue).,0
"Modified `TimeDistributed` to not require `compute_output_shape` to be implemented by the wrapped layer, and to not use `set_shape` on the output.",0
* Fixed tensorboard tests,0
Move the _distributed_container attribute from ResourceVariable to handle.,0
Python lists `append` not `add` :-/,0
Update CONTRIBUTING.md,0
That is pretty good!!!,0
Added one just as other explained arguments.,0
fixes https://github.com/tensorflow/tensorflow/issues/48137,0
* Update theano_backend.py,0
* Changes the test_doc_auto_generation in order to include a doc string taken from the codebase.,0
A broader question: maybe I should replace all those `len(x[0])` in the file with `x[0].shape[0]`?,0
"I just wanted you to approve the proof of concept before I spent more time on it, since it changes a few things :-)",0
I work on that and submit a new PR,0
PiperOrigin-RevId: 412925311,0
* Added regularization to BN test,0
Updated VAE examples (MLP and ConvNet) to the new API (#5552),0
What do you think?,0
* Add validation_split to generator flow,0
PiperOrigin-RevId: 480926164,0
* Fix a bug to write no-need blank line each line on windows,0
Any thoughts on merging this?,0
"In the embedding space, we compute
the match between u and each memory m<sub>i</sub> by taking the inner product followed by a softmax.",0
Fix TextVectorization with output_sequence_length on unknown input shapes,0
The add_input before Embedding layer in Graph,0
PiperOrigin-RevId: 467797050,0
We need to think about all the work that will need to be done to adapt ourselves and fix the bugs of TF eager.,0
PiperOrigin-RevId: 505214178,0
* Delete .suo,0
Import error " from keras.preprocessing.image import ImageDataGenerator ",0
* updated save_img method to use array_to_img method.,0
#PRIVATE_TF_API_USAGE_CLEANUP Remove the usage of gather_non_trainable_weights.,0
* #10080 Convert CuDNN weights in nested Model.,0
Fix RandomCrop layer called on integer input,0
tf.keras.utils.get_file() produces duplicate file with dot underscore "._",0
Better and faster results when compared to using either convnet or rnn alone.,0
* CLN: remove type check,0
PiperOrigin-RevId: 390475709,0
V2 GRU and LSTM layers no longer extend their V1 counterpart; instead the common code was duplicated.,0
* add newline,0
* pep fix,0
I forgot to check the style before committing.,0
PiperOrigin-RevId: 388606987,0
PiperOrigin-RevId: 387883278,0
* update to follow pep8,0
"* Change save_format from jpg top png, because jpg is a loss format.",0
"Consider any target with 3 elements [0,0,1] and the output [0,0,0].",0
Or did you assume caffe style image format which is CxHxW,0
PiperOrigin-RevId: 438437215,0
Lambda layer: Bug Fix,0
Fix typo in siamese example (#12339),0
* adding a disable_b boolean to Dense,0
"Not sure what the reason for the failure might be, would appreciate your kind enlightening!",0
Add 3 experimental backend API in preparing for RNG behavior change.,0
* Fix for _t_enter_batch attribute,0
PiperOrigin-RevId: 353274439,0
Style fix,0
"The validation acc after this fix with imagenet is:

b0 0.7699
b1 0.7875
b2 0.7979
b3 0.8141
b4 0.8294",0
I propose to implement an asymmetric padding as an option in the ZeroPadding2D.,0
PiperOrigin-RevId: 408761441,0
Add import/fit/evalulte codes.,0
PiperOrigin-RevId: 431984106,0
Merge pull request #17068 from shanejohnpaul:master,0
* suppress serde warning,0
Fix `Sequential.set_weights`,0
"SidecarEvaluator: Remind user with logs if no checkpoints have been found for every 30 sec, to hint what users can check into.",0
Add merge mode 'max' where it was missing (fixes #3486) (#5729),0
Warning about custom user code:,0
Thanks for the PR anyway.,0
* Removed the conversion loop if training from symbolic tensors.,0
Refactor theno_backend to shorten linelength (#11391),0
PiperOrigin-RevId: 528624142,0
"In any case, it is interesting to notice that samplewise batch normalization has been performing better than featurewise batch normalization on the 3 tasks I tried it on so far.",0
* unit test _weighted_masked_objective function,0
"Previously, the strategy relied on whether or not it is enclosed by a
`shape.assuming` op, which can easily be canonicalized away.",0
Add API conversion interface for Embedding layer. (#5702),0
"If I were to write an anonymous function for `tf.nest.map_structure` in this case, how would I obtain the structure without making a hard assumption ?",0
This is incongrous and not minimal.,0
Fix format issue caused by https://github.com/keras-team/keras/pull/16799,0
* added kwargs to docstring.,0
changed style and numpy randint range,0
is there any chance https://github.com/fchollet/keras/pull/7033 might be fixed by this or could be updated to do so?,0
Keras saving: supplement more information including an example for `register_keras_serializable` decorator API.,0
* make dict behaviour similar,0
* Fixes temporal_padding bug and test_utils input_data param.,0
Corrected a small annotation in Input(),0
There were two similar tests for LSTM and GRU.,0
Flip the default value of jit_compile=True for optimizer.,0
"commit 29a22a8d59b5e2c4282f1e7f664d82595049eb9d
Author: fuzzythecat <fuzzy0427@gmail.com>
Date:   Wed Jun 13 02:57:38 2018 +0900",0
Author:    Wei OUYANG <oeway007@gmail.com>,0
"--
8ecf23338753fc77da0b40f4609b480d4e70476a by Ashutosh Hathidara <ashutosh.hathidara@legatohealth.com>:",0
* Add support for stateful metrics in fit_generator() and evaluate_generator(),0
This is a update for https://github.com/tensorflow/tensorflow/pull/50287.,0
"You can fast-track the merge of LRN, Pooling with strides, and ZeroPadding by submitting them in a different PR, if you want.",0
corrected version (#5027),0
PiperOrigin-RevId: 395783105,0
* Fixed checking input masks in Layer.compute_mask,0
Fix HDF5Matrix issue when working in conjunction with TimeSeriesGenerator (#10334),0
PiperOrigin-RevId: 466528723,0
Make fname optional in get_file,0
This behavior resulted in a DisconnectedInputError.,0
* Add test,0
"--
7a31d214126456fef9bb992fd4ca88d6d96959fd by Albert Villanova del Moral <8515462+albertvillanova@users.noreply.github.com>:",0
"To do this, either invoke the tf.Session.close method on the session, or use the session as a context manager.",0
* Replacing getargspec with has_arg in the backend modules,0
PiperOrigin-RevId: 407396897,0
Added 'jit_compile` option in `Model.compile()` on an opt-in basis,0
* Update wrappers.py,0
PiperOrigin-RevId: 370814983,0
This way is also more consistent with how `keras.optimizer_v2.optimizer_v2.OptimizerV2#minimize` invokes `apply_gradients`.,0
The 2.10 release branch is cut at https://github.com/keras-team/keras/tree/r2.10,0
Added model comparision table (#7837),0
Try fixing issue #49252,0
I'm not sure what this test should look like.,0
- Dropout: random drop on activations,0
see #4805,0
Added dtype to map_fn (#5658),0
* detail explain of zoom range,0
adding unitnorm unittest,0
* Changed the status of the mxnet backend.,0
* Fix docstring.,0
Please let me know if it seems I am making an incorrect assumption on anything here.,0
fix pep8 check failure,0
* Fixed the windows line endings in the CSVCallback.,0
"I'm facing the issue too, can I assume my model will still works correctly ?",0
"Before:

merge_mode = 'dot', dot_axes=[[axis1], [axis2]]",0
Integrate with cntk 2.3.1 (#8713),0
Another fix for tf_doctest,0
Sync Sequential.compile() with Model.compile() (#8182),0
"Conflicts:
	keras/models.py",0
* [RELNOTES] Remove support for Keras 0.*,0
This allows us to keep the backward compatibility for weights saving/loading for any existing application models.,0
TypeError: __init__() got multiple values for keyword argument 'data_format',0
Refactor training part of `engine` module. (#10029),0
* Fixed issues with pool2d,0
PiperOrigin-RevId: 479075288,0
PiperOrigin-RevId: 485393113,0
PiperOrigin-RevId: 528615714,0
"* Add a ′# Returns′ section to shape, dtype, ndim, size.",0
New saving: add npz support and make zipping optional.,0
Use `serialize_keras_object` in the JSON encoder and `deserialize_keras_object` in the decoder.,0
PiperOrigin-RevId: 516372702,0
We need to flatten.,0
Merge pull request #16772 from chunduriv:patch-3,0
work in progress on BayesianLSTM,0
Disregard objective output dimensions when weighting,0
* python2,0
* Fix process_XXX_docstring functions to work with models function,0
Fix learning_phase int check (#5749),0
Fixed typo in training_utils.py (#11566),0
* rename to mathews_correlation,0
* Record file opening only after successfully opening the file.,0
"Moves all files currently in saving/ to saving/legacy/ (except for pickle_utils, object_registation, and their tests).",0
"Hence, similarly to LeakyReLU or
    for example Softmax, this PR adds a layer for ReLU,
    enabling also a capped ReLU to be used.",0
Moved the structure of the keras documentation into a separate file. (#11722),0
Model input validation fix.,0
"Move caches to properties so that containers can override the
implementation to ensure that the cache gets propagated correctly
to child layers when it is changed.",0
* ENH: use tf.as_dtype to convert dtype,0
* Use public fields to access TypeSpec's shape.,0
removed extra spaces,0
* Remove Dropout and unnecessary imports,0
* Fix nested sequential deferred build,0
"commit 2d183db0372e5ac2a686608cb9da0a9bd4319764
Author: Sachin Abeywardana <sachinruk@users.noreply.github.com>
Date:   Fri Jun 15 04:19:45 2018 +1000",0
* Move cast to metrics,0
Fix typos (#9138),0
Update LICENSE dates for all other contributors (#6867),0
* Pass interpolation method as parameter,0
* Update sequential-model-guide.md,0
PiperOrigin-RevId: 356397987,0
"- GRU in Keras follows 1406.1078v3, while CuDNNGRU is based on 1406.1078v1",0
"2. Add kwargs to `apply_gradients` to accomodate `experimental_aggregate_gradients`, which is widely used.",0
"I've experienced some weird issue with testing `keras` -- despite couple of `.mark.skipif` marks over tests, running
```bash
pip install .[tests] && pytest tests/
```
ends up with
 - 42 errors with `ModuleNotFoundError: No module named 'tensorflow'`
 - 16 errors with `ImportError: `save_weights` requires h5py`
 - 1 error with `ModuleNotFoundError: No module named 'PIL'`",0
Using `assume_valid_feeds=true` also enables preserving _Arg node _output_shapes attributes in GenericLayoutOptimizer.,0
Improve discoverability of preprocessing layers among keras layers,0
"When I think about event based programming, like the callbacks and GUI is, I think about streams of messages and how to handle them.",0
* Revert "Fix test style",0
* Update backend docs.,0
* add wrappers of load and save methods for automatic support of google storage,0
"commit 794f814343b655e01de73578d71e8b8a53523687
Author: Botty Dimanov <bottydim@users.noreply.github.com>
Date:   Fri May 25 22:21:41 2018 +0100",0
PiperOrigin-RevId: 396758022,0
PiperOrigin-RevId: 442291981,0
Copybara import of the project:,0
Softplus docstring missing a parenthesis.,0
"--
b4e4562eaa071d750216bf87a2343a1c92af69aa by Ashutosh Hathidara <ashutosh.hathidara@legatohealth.com>:",0
* Update local.py,0
* changed random file names to use tempfile module,0
PiperOrigin-RevId: 417686461,0
Checking that ndim is >= 3 for batch_dot in TensorFlow backend (#5132),0
"@taehoonlee should we merge this PR, or is there a risk that not testing `test_multiprocessing` with TensorFlow on CI would lead to coverage problems and potentially lead to introducing TF bugs down the road?",0
"Then I wish to call this pre-fed training  file into any other X,Y,Z fresh files where testing is done.",0
* Imports,0
* rewrite batch dot for cntk,0
This version approximates the dominant eigenvalue by a soft function given by the power method.,0
Also updated existing test cases to cover the new feature.,0
* Fix tests,0
PiperOrigin-RevId: 424897875,0
Print "Epoch %d out of %d" instead of just "Epoch %d",0
* Remove whitespace in blank lines,0
* Masked merge concat logic with an expanded loop,0
Add predict() for Sequential models,0
* skip tests on cntk with multiple unspecified time lengths.,0
* bilinear interpolation docstrings added,0
* update travis with cntk 2.2,0
* None shape test for batch_flatten and flatten,0
Added average duration per epoch and per step to logging when verbose = 2 and fixed test cases that relied on the previous interface,0
Fix tf too,0
"- now fails for GRU(reset_after=True) since the code cannot distinguish
    its weights from CuDNNGRU",0
- quick fix: just copy/paste.,0
- Leaving it up to the user,0
Handle capitalised extensions in list_pictures (#10220),0
- `test_specify_initial_states` does not check if `initial_states` is part of the computational graph.,0
Fixes https://github.com/keras-team/keras/issues/15140.,0
Theano fix for saving models (#5497),0
docs: update "pad_sequences()" parameters in the docs,0
This behaviour is different when using fit.,0
Added examples for fill_mode (#8398),0
Hi keras team.,0
Hope you could take my advice and look forward to your reply! ??,0
Merge pull request #15227 from MohamedAliRashad:master,0
Loading times are similar across the board (nozip is a bit faster).,0
* Renamed to matthews_corrcoef to be consistent with sklearn,0
"Simplifies the implementation of `convert_to_tensor`
to two operations:",0
* Recursive implementation of preprocess_weights_for_loading to accomodate Bidirectional and TimeDistributed wrappers.,0
"--
8a292489805a2f7dd78bd374181a80a7bd6f7d59 by Amogh Joshi <67437306+amogh7joshi@users.noreply.github.com>:",0
The problem occurs because PyYAML can't recognize numpy's data types.,0
* Fix example,0
Remove the @tf.function for the dtensor run_with_layout().,0
* [skip ci] fix docstring to LeCun normal init,0
Test fixing OSS build for Keras.,0
"commit 632560d91286bf278228de72e7ce64f6c5aa530c
Author: Francois Chollet <francois.chollet@gmail.com>
Date:   Wed Jun 6 11:53:18 2018 -0700",0
* lower batch size and epochs,0
* Avoid DeprecationWarning from inspect.getargspec by general_utils.getargspec,0
Add documentation for recurrent layers.,0
Port https://github.com/keras-team/keras/pull/14834 with copybara config change.,0
"Please consider making this optional as there are actually cases in which this leads to significant slow-downs (Theano, GPU).",0
- fix default value for reset_after parameter in GRU,0
* improve k.switch,0
FIxed Tensorboard callback for Python 3,0
* Use expand dims if ndim for inputs are available,0
Some code refactoring using `transpose_shape` in tensorflow_backend.py. Part 2 (#10859),0
Sync OSS keras to head. (#14300),0
- Rewrote tests to include 1D & 3D cases.,0
* Make selection over all models random,0
- remove GRUResetAfter class,0
* Specify interpolation as string rather than PIL constants,0
* acgan: Fix generator producing pure black images,0
Update RandomFlip layer to use BaseImageAugmentationLayer as parent layer.,0
* Added documentation and removed commented-out code,0
"Pls, give me your thoughts. @rmothukuru",0
PiperOrigin-RevId: 474615037,0
I just saw some of the other PRs have been merged during past week and therefore wondered maybe there is a problem with my PR or maybe the plan for the sync has changed or something like that.,0
"@willnorris for corporate CLAs, do we expect googlebot to say this has been signed? or do we just assume that if the user has @dropbox.com in their email that it is fine?",0
"from probabilities to logits in ""sparse_categorical_crossentropy(target, output, from_logits=False)""",0
PiperOrigin-RevId: 393010573,0
[1]: https://arxiv.org/abs/1708.07120,0
added unit testing for new metrics_utils 'matches' methods,0
Can you please submit separate PRs for each change?,0
* Unit tests,0
change docstring in Convolution3D and theano_backend,0
Not sure if it is good idea to run fit multiple times as if it might have some randomized algorithm in future(like randomized PCA etc).,0
1. Add several public apis that gets called at different phases of apply_gradients.,0
Masked and Ragged are two different representations of the same thing (when it can be represented as ragged).,0
"Keras Optimizer: (part 2) Move the logic of distributed_apply and whether a strategy support merge call to tf.distribute, and reference from Keras via a tf.__internal__ endpoint.",0
"* Tested on Python 2.7 with Unicode and non-Unicode strings, and on Python 3.5",0
recurrent Layers: Fix doc strings on default activations (#9181),0
* Addresses code review comments,0
I want LSTM to learn with newer data.,0
#NAME?,0
why no visualization modle？,0
* Fix style for 'flow' and 'flow_from_directory' ImageDataGenerator methods doc,0
"With the new symbol location of preprocessing layers directly in the keras layers
namespace, we need to be more explicit in the doc strings that these layers
are preprocessing layers.",0
Fixes https://github.com/keras-team/keras/issues/15681,0
* get_input() in the test,0
"1. use backend.get_value() to get learning_rate, which is more robust than numpy() call.",0
* used self.__dict__ instead of eval and exec.,0
fix typo (#2881),0
"v1/v2 paper says
>the usage of bottleneck designs is mainly due to practical considerations.",0
Why don't we pass the causal mask as the attention mask to keep the same flexibility and reduce assumptions?,0
* Update scikit-learn-api.md,0
"Change save_format from jpg top png, because jpg is a loss format. (#6638)",0
Tensorflow automatically does this so I'm not sure why keras has this issue.,0
"Added the tests test_shape_with_key_concat, test_shape_concat, test_calculate_scores_one_dim_with_scale_concat and test_calculate_scores_multi_dim_concat",0
* Fix under-indent error,0
"--
1408e1f6e391f4f848848a2fc8c475206587844e by Ashutosh Hathidara <ashutosh.hathidara@legatohealth.com>:

Resolved bazel test errors",0
PiperOrigin-RevId: 380647901,0
"commit 84aa7b5f4167afaa8e4b24f2449ac76c11d5e8df
Author: Wang, Zhiming <zhiming.wang@intel.com>
Date:   Sat May 26 05:20:57 2018 +0800",0
"This change adds `_epoch_start_time`, which is set to the current time in `on_epoch_begin`, and used to compute the total epoch time in `on_epoch_end`.",0
* using native padding api,0
Changed "Notes that the methods...." to "Note that the methods",0
Update the numpy version for keras to align with TF.,0
"However, even if we assume that the model overfit on the training dataset, isn't it weird that model.predict() gives a very low accuracy even on the training set?",0
Add sparse and ragged options to TextVectorization output,0
"That's how decisions are made: if enough people seem to need a feature, we add that feature, otherwise we don't.",0
Hierarchical softmax is an approximate version of softmax that is much faster to compute when the number of potential classes is high.,0
No module named keras.preprocessing.image,0
@linxihui any chance you might be able to take the last steps on this?,0
This is essential to prevent malicious downloads / corrupted ones / MitM type of attacks.,0
* updated docstring to be consistent,0
PiperOrigin-RevId: 432692921,0
Makes sense.,0
* tf tensor can't be used as bool,0
Change the way of turning on XLA for `optimizer.update_step()`.,0
Merge join returns OrderedDict instead of list,0
* update padding interface,0
* Refactor common code in LSTM/GRU CuDNN weight conversion.,0
"If this pull request is merged and a new verison of tf released, can I assume that tf 2.5+ GPU will work with CUDA 11.3/cuDNN 8.2?",0
"Do we assume that when using TimeDistributedDense, labels (y) are sequences of the same size as corresponding input sequences (x)?",0
add reset_uids to cntk backend (#12300),0
fix warmstart_embedding_matrix to handle edge case when there is nothing common between base vocab and new vocab.,0
Consider the case where Lambda is input layer,0
This reverts commit cee460a3720ee2a277c290332d1ffbdcef77da92.,0
fixed TensorBoard callback (#2363),0
"Moreover,
   the story is more complex for Losses used within `Layer.call()`.",0
* fixed RemoteMonitor json to handle np.float32 and np.int32 types,0
Add top-k classification accuracy metrics (#3987),0
Do you have samples that are supposed to maximize instead of minimize the loss function?,0
About how much of a performance difference would you guess this translates into?,0
* remove empty_dict return on reset_uids cntk,0
* integrate with cntk native batch axis convert api,0
Merge pull request #17065 from myaaaaaaaaa:ghost-norm,0
Merge pull request #105 from floydsoft/floydsoft-patch-1,0
Signed-off-by: Yong Tang <yong.tang.github@outlook.com>,0
Implement Graph.__call__ for multiple inputs,0
Use a jit compiled convolution op for grouped convolutions,0
This PR is an attempt to help others avoid the pain that we experienced due to this bug.,0
"[keras/testing_infra/test_combinations.py,keras/testing_infra/test_utils.py] Standardise docstring usage of ""Default to""",0
* Improve docstrings,0
remove usage of tf.assign() in part of tensorflow backend (#3316) (#3320),0
"In this change, we preserve the dimension when slicing on `class_id`",0
Note that I temporary resolved the first issue by a merged PR (#10664); however that PR did not address the underlying problem.,0
what do you think ?,0
* fix typo. add assert to check cropping lengths,0
* add tests,0
How would you write docs about it?,0
* class to func,0
"The custom training guide does it correctly using
   `tf.nn.compute_average_loss()` for prediction losses.",0
"Borrow the implementation of `Graph.set_weights` to
get it working.",0
#10080 Convert CuDNN weights in nested Model. (#10081),0
* Add multiprocessing for fit generator,0
"The average mode in `Merge` and the new layer `TimeDistributedMerge` can be considered together, but the example should definitely be submitted as a separate PR.",0
So far the issue is only noticed for mirrored strategy and works fine for TPUStrategy.,0
* Make ZeroPadding2D and ZeroPadding1D optionally asymmetric,0
PiperOrigin-RevId: 372395334,0
* typo doc,0
Allows text lines following nested lists,0
Merge pull request #1307 from gw0/fix-shape-tuples,0
Add RandomBrightness layer as one of the image KPL.,0
PiperOrigin-RevId: 401346175,0
Was it just because most neural network assume to have a vector as output?,0
Add initial epoch argument to fit functions (#4429),0
Imported from GitHub PR https://github.com/keras-team/keras/pull/15867,0
"/home/yeverino/.conan/data/tensorFlowLite/0.1/demo/testing/package/d351525cc53ebe68279edf1978846402420066e7/lib/libtensorflow-lite.a(fully_connected.cc.o): In function `void ruy::detail::CreateTrMulParamsAssumingColMajorDst<(ruy::Path)113, unsigned char, unsigned char, int, short>(ruy::Mat<unsigned char> const&, ruy::Mat<unsigned char> const&, ruy::Mat<short> const&, ruy::MulParams<int, short> const&, ruy::ChannelDimension, ruy::Ctx*, ruy::TrMulParams*)':",0
2023-03-15 12:26:30.064332: W tensorflow/c/logging.cc:37] Token file must be specified to use STS AssumeRole web identity creds provider.,0
Update sequential-model-guide.md (#5913),0
"""UnboundLocalError: local variable 'epoch_logs' referenced before assignment"" is really annoying error.",0
[P] change plot_model to fully support plotting submodel and fix bugs (#12675),0
Thanks.,0
Rename the pass to merge assuming ops.,0
Looking at this now.,0
keras.preprocessing.image is using float32 instead of uint8,0
* Fix style and add tests,0
renames tests with common convention,0
"* For TypeSpecs other than DenseSpec/RaggedTensorSpec/SparseTensorSpec, the `set_shape` method requires and uses a `TensorSpec.with_shape()` method that returns a copy of a spec with a new shape.  (Raise a useful error message if it's not there.)",0
Is it?,0
"#10658 
#10662",0
batch_dot is not tensordot!,0
"/usr/lib/python3.5/site-packages/h5py/_hl/attrs.py:87: in __setitem__
    self.create(name, data=value, dtype=base.guess_dtype(value))",0
(.text._ZN3ruy6detail36CreateTrMulParamsAssumingColMajorDstILNS_4PathE113EhhihEEvRKNS_3MatIT0_EERKNS3_IT1_EERKNS3_IT3_EERKNS_9MulParamsIT2_SC_EENS_16ChannelDimensionEPNS_3CtxEPNS_11TrMulParamsE[_ZN3ruy6detail36CreateTrMulParamsAssumingColMajorDstILNS_4PathE113EhhihEEvRKNS_3MatIT0_EERKNS3_IT1_EERKNS3_IT3_EERKNS_9MulParamsIT2_SC_EENS_16ChannelDimensionEPNS_3CtxEPNS_11TrMulParamsE]+0x107): undefined reference to `ruy::Ctx::SelectPath(ruy::Path)',0
* Replace ceil() with faster a operation,0
"Can you list the user-facing changes? Provide some examples of the user experience? (e.g. what code would the user be writing, what problems would the user potentially be facing).",0
Update a CNTK version on Travis (#10419),0
* Add API conversion interface for Embedding layer.,0
"ga_uint old, assumed, new;",0
Add CNTK to the list of backends and `code` indicators.,0
* Require stateful metrics layers to be actually stateful,0
there is something wrong with the custom layer,0
Configurable interpolation in flow_from_directory (#8533),0
* add rnn numpy implementation docstring refrence,0
* yml fix,0
* Fix CNTK test.,0
* Removed raise,0
"commit 0f3f56327b661ade7824b18811163138755122dd
        Author: gw0 [http://gw.tnode.com/] <gw.2016@tnode.com>
        Date:   Thu Feb 18 17:01:45 2016 +0100",0
Add a unit test to cover https://github.com/keras-team/keras/issues/15012.,0
bug in sparse_categorical_crossentropy in theano backend,0
* add support for pandas DataFrame,0
Fixing SyntaxError: positional argument follows keyword argument,0
* Cleanup + Theano concat (untested),0
What does `fetches` achieve in `fit`: how are users supposed to understand its usage?,0
clear_session sets _SESSION.session to None.,0
Does that make sense?,0
Replace two spaces by br tag to force new line,0
Add set_learning_phase in TF backend.,0
"Use tf.eye(), instead of np.eye() (#8246)",0
Add DenseNet models (#8800),0
* merge_test.py reproduces bug (#5972),0
"Image preprocessing layers are intended as a TF2 API, and image augmentation
layers do not support training/inference call time branching in a TF1
friendly way.",0
* Add pooling option,0
"Of course, if `batch_` and `epoch_` metrics are assumed to be interpreted in conjunction for one run, there is a need to know how to interleave the two, in which case I understand the current behavior somewhat.",0
File was removed in https://github.com/fchollet/keras/pull/7943,0
* enable tests with non-specified shape,0
"If you would like to
send a PR to fix this by using the tf.shape() on the input Tensor instead
of assuming beam_width, and adding a unit test, I can review when I return.",0
"These `__tf_tensor__` methods simply redirect to the existing conversion
functions for these types.",0
"commit 9a58f7b29026270afbec58c9255750b527ceff27
Author: Francois Chollet <francois.chollet@gmail.com>
Date:   Tue Jun 5 17:40:44 2018 -0700",0
Fix shape mismatch in `rnn()` of tensorflow_backend (#10038),0
"This was written for one-hot encoding 2D integer tensors into 3D float tensors, which isn't even the most common use case of one-hot encoding (by far).",0
* Fixed weight sorting for Theano backend,0
PiperOrigin-RevId: 433021990,0
Also updated test.,0
Resolves https://github.com/fchollet/keras/issues/8232,0
PiperOrigin-RevId: 379624593,0
"Theano cudnn code now throws Exception when it is not available, need… (#4832)",0
Move all the visibility setting into separate build file.,0
Bug fix - Siamese layer,0
[keras/mixed_precision/loss_scale_optimizer.py] Standardise docstring usage of "Default to",0
* fix RemoteMonitor json to handle np.float32 and np.int32 types,0
they fail locally…,0
* Adding batch level TensorBoard logging (implementing the `on_batch_end` method to the TensorBoard class,0
Numpy 1.16.3 changed the default value for the allow_pickle flag.,0
Standard deviation values were being passed as scale values for uniform distributions.,0
* 3d global pooling in docs,0
(.text._ZN3ruy6detail36CreateTrMulParamsAssumingColMajorDstILNS_4PathE113EhhihEEvRKNS_3MatIT0_EERKNS3_IT1_EERKNS3_IT3_EERKNS_9MulParamsIT2_SC_EENS_16ChannelDimensionEPNS_3CtxEPNS_11TrMulParamsE[_ZN3ruy6detail36CreateTrMulParamsAssumingColMajorDstILNS_4PathE113EhhihEEvRKNS_3MatIT0_EERKNS3_IT1_EERKNS3_IT3_EERKNS_9MulParamsIT2_SC_EENS_16ChannelDimensionEPNS_3CtxEPNS_11TrMulParamsE]+0x1d1): undefined reference to `ruy::Ctx::set_performance_advisory(ruy::PerformanceAdvisory)',0
fix test error caused by wrong strides in conv3d,0
Added type check in axis to allow only integers.,0
"commit 1e80c1a2dbaceba9a8280c37e4e896599eb927f6
Author: KuzMenachem <35711942+KuzMenachem@users.noreply.github.com>
Date:   Tue Jun 5 20:10:43 2018 +0200",0
* Fix for python3,0
Update check for sequential models (#6305),0
Thoughts on this?,0
Add explanation on shuffle=False.,0
Typo fix (#10293),0
PiperOrigin-RevId: 400835665,0
added an encoding parameter to TextVectorization layer,0
My refactoring fixes this.,0
"If you need this feature, use functional Model API.",0
* Fix compute_accuracy().,0
At some degree it's covered in #531.,0
"```
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-2-154d5969a0d5> in <module>
----> 1 k.datasets.imdb.load_data()

~/venv3/lib/python3.6/site-packages/keras/datasets/imdb.py in load_data(path, num_words, skip_top, maxlen, seed, start_char, oov_char, index_from, **kwargs)
     57                     file_hash='599dadb1135973df5b59232a0e9a887c')
     58     with np.load(path) as f:
---> 59         x_train, labels_train = f['x_train'], f['y_train']
     60         x_test, labels_test = f['x_test'], f['y_test']
     61 

~/venv3/lib/python3.6/site-packages/numpy/lib/npyio.py in __getitem__(self, key)
    260                 return format.read_array(bytes,
    261                                          allow_pickle=self.allow_pickle,
--> 262                                          pickle_kwargs=self.pickle_kwargs)
    263             else:
    264                 return self.zip.read(key)

~/venv3/lib/python3.6/site-packages/numpy/lib/format.py in read_array(fp, allow_pickle, pickle_kwargs)
    690         # The array contained Python objects. We need to unpickle the data.
    691         if not allow_pickle:
--> 692             raise ValueError(""Object arrays cannot be loaded when ""
    693                              ""allow_pickle=False"")
    694         if pickle_kwargs is None:

ValueError: Object arrays cannot be loaded when allow_pickle=False
```",0
- add a test,0
"* Change default format to png, because jpeg is a loss format.",0
"It was changed to new tf.sparse.to_dense() and we pass
tf.sparse.SparseTensor instead of its components.",0
* ENH: keep compatible,0
(.text._ZN3ruy6detail36CreateTrMulParamsAssumingColMajorDstILNS_4PathE113EhhisEEvRKNS_3MatIT0_EERKNS3_IT1_EERKNS3_IT3_EERKNS_9MulParamsIT2_SC_EENS_16ChannelDimensionEPNS_3CtxEPNS_11TrMulParamsE[_ZN3ruy6detail36CreateTrMulParamsAssumingColMajorDstILNS_4PathE113EhhisEEvRKNS_3MatIT0_EERKNS3_IT1_EERKNS3_IT3_EERKNS_9MulParamsIT2_SC_EENS_16ChannelDimensionEPNS_3CtxEPNS_11TrMulParamsE]+0x1d9): undefined reference to `ruy::Ctx::GetMainAllocator()',0
* Format image_data_format as strings in doc; add test for channels_first,0
* use cntk padding,0
Make accuracy metrics work with masked outputs (#5866),0
* mnist_tfrecord.py add coordinator,0
* Allow passing fetches and feed_dict to tf.Session.run() in K.Function() in TensorFlow backend.,0
Any update on this or perhaps another way (using the current version of Keras) where I'd be able to do the same thing?,0
2. Some docstring improvement.,0
Allowing auto GPU selection for multi_gpu_model (#9226),0
"Most importantly, references to tf.mixed_precision.experimental.LossScale and its subclasses have been changed to the versions in tf.compat.v1, since the TF2 versions are being removed soon.",0
* Refactor Network to prepare support for Model subclassing,0
PiperOrigin-RevId: 381965239,0
* Reverted to previous commit,0
* Update test_wrappers.py,0
This allows to take advantage of tensorflow’s resize_images operator in UpSampling2D.,0
* Added objective: Kullback Leibler Divergence,0
remove `alpha` and `scale` from docstring,0
* bug fix: tile,0
"get_file() with tar, tgz, tar.bz, zip and sha256, resolves #5861. (#5882)",0
Update pretrained_word_embeddings.py (#13073),0
* Fix learning phase info being left out in multi-input models,0
PiperOrigin-RevId: 429375770,0
"OK so this is as far as I am getting right now, got the image processing code covered.",0
"Historically tensorflow_no_contrib contains keras since its treated as a core API, and estimator/tb relies on it as a build dependency.",0
"I checked it for correctness just now, and it doesn't check out.",0
Update documentation docstring Embedding (#2693),0
"But still, If we face that problem in the future, we think about a solution, back to what we have now.",0
* fix channel shift clip,0
"For all other questions, the full vocab is in the stories and the queries",0
* fixed np.int32 json unserializable error in Remotemonitor,0
"Please think about this carefully: getting the normalization across both forms of weights right is a bit subtle, and I screwed up a number of times before creating this PR.",0
ValueError: Input tensors to a Model must come from keras.layers.Input.,0
"- split biases in GRU(reset_after=True) to two sets
  - in order to distinguish weights of this variant and CuDNNGRU
    based on the bias array shape",0
"Consider upgrading to:

1. `model.save()`
2. `tf.saved_model.save()`",0
"Since this is essentially a workaround for a Theano issue, would you consider also raising the issue with the Theano devs?",0
"3) I can guess what these issues are, but let me focus on 1 and 2 before taking up anyone else's time.",0
"`batch_size` is always `None` , because `steps_per_epoch` and `batch_size` are mutually exclusive.",0
* Changes after review from @gabrieldemarmiesse.,0
@fchollet any clues as to what might be causing this?,0
* New directory iterator testing function,0
* Add test coverage,0
a capsule cnn on cifar-10 (#9193),0
* Fix unit tests.,0
[AutoEncoder] set_previous triggers build,0
* tensorflow only,0
This gives the impression the same kernel is applied to all channels.,0
* Fixed bug.,0
"Do you think this is incompatible with the callback pattern, or should be implemented in a different way?",0
* Embedding visualization is added to TensorBoard callback.,0
WARNING:tensorflow:Gradients do not exist for variables ['p_re_lu/alpha:0'] when minimizing the loss.,0
PiperOrigin-RevId: 428827564,0
* formating,0
test creates its own tiny file to download and extract locally.,0
* Style: double quotes to single quotes,0
If you or anyone else reading this might be able to help I'd appreciate it.,0
* Add callback hooks for `evaluate` and `predict`,0
Feature Requests: 1. Conv1DTransponse and Support padding="same" for LocallyConnected2D and 1D,0
"There was no reason not to be doing this already, this was just a gap.",0
"commit c77267af5fff5642951ae4a2c9bb09fb6d698c30
Author: Brian Nemsick <brian.nemsick@gmail.com>
Date:   Wed May 23 11:54:36 2018 -0700",0
"If this is merged, might I suggest the code explicitly print a performance warning on initialization regarding tensorflow/tensorflow#12948?",0
is there maybe a way to implement this in a custom generator fed into fit_generator?,0
* Add a non-layer "Module" api,0
Adds a new test (#10212),0
* Add UpSampling*D API conversion interface.,0
"h5 is faster, but only marginally so.",0
ValueError: Unknown layer: SomeLayer.,0
* Revert "add unit_test for rnn() with states whose shape is different from that of the output.",0
For the moment only two are displayed.,0
* adding unit tests for checking the validity of `layer_names` and `weights_names` HDF5 file attributes splitting,0
"Calling .compile() is necessary because trainable weights are collected
in compile (model._collected_trainable_weights).",0
* Add an option to create dot model in different directions,0
That's fine.,0
* Fix layer config saving.,0
All strategies are supported except for CentralStorageStrategy and ParameterServerStrategy.,0
* Adding feature to load_weights by name,0
* Refactoring tests.,0
Create bot_config.yml for auto assignment bot which assigns issue to tf-dev-support team.,0
* fix code style;add more comments,0
"skip some tests for tenforflow, @pytest.mark.skipif(K._BACKEND != theano, reason=""Requires Theano backend"")",0
"* remove MusicTaggerCNN, add include_top argument",0
Update models.py,0
"All callers of `convert_to_tensor` which populated `ctx`
retrieved its value from `context.context()` or `context._context`.",0
Set TextVectorization.pad_to_max_tokens default to False,0
I am also not in line with these architectural changes.,0
"I am not sure though, if it will be helpful to create a separate generator without the directory logic.",0
"On method on_epoch_end, to add new keys to the history dict, first it is
verified if a key is not on the history dict and if that is the case, a new key
is created on the history dict with an empty list as value.",0
"commit 65670e69dcb9249f3c7d520167d2701edfa31986
Author: David Silva <davidtvs10@gmail.com>
Date:   Tue Jun 19 06:00:55 2018 +0100",0
PR #43417: Fixes #42872: map_to_outputs_names always returns a copy,0
PiperOrigin-RevId: 420897297,0
"The old inefficient implementation was the result of tensorflow not having the leaky_relu op, but it was recently added.",0
fit/evaluate_generator supporting native tensors (#9816),0
* Fixed warning message,0
_hash_file() now private,0
Handling ndim == 2 in TF batch_dot (#5280),0
* Backport sign by @the-moliver,0
"* Remove lambda, simplify",0
Add kwargs to new optimizer for backward compatibility.,0
* + relus in the deconv,0
"Added a section for training history visualization using matplotlib, inspired by https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/",0
Added note to manually install h5py where needed (#9830),0
I would love to have an opinion from @lukedeo on this since he reviewed the code on the other PR.,0
* account for receptive field size in fan_out,0
"Keep me posted, feel free to request review.",0
- Docker image with CUDA support on ubuntu 14.04,0
- [n] This PR changes the current API [y/n] (all API changes need to be approved by fchollet),0
@fchollet Have you considered something like Sonar?,0
Fix typos and update docs,0
"- Check the conversion registry for a conversion function
and invoke it, if present.",0
* use wraps to preserve docstring,0
Allow class_weight's use with time distributed data,0
* Fix stateful metric test in Theano,0
"Improve docstrings, UX of common user mistakes",0
"* fix PEP8 issue, fix incorrect doc strings",0
"This requires reordering imports to avoid errors caused by
conv_utils trying to import the backend, the backend wanting to
import generic_utils, and utils/__init__.py listing conv_utils
before generic_utils.",0
"commit abd029405c97733de24102695cb4b6cef1f47bff
Author: brge17 <33430930+brge17@users.noreply.github.com>
Date:   Mon May 21 18:42:07 2018 -0700",0
* Final test fix,0
Remove manual check for regularizers (use auto),0
Fix error messages in the test which is currently disabled on TAP.,0
PiperOrigin-RevId: 402681948,0
LSTM error when checking target/ dimensions problem,0
Is there an assumption that the layer is inside a `tf.keras.Model`?,0
Merge pull request #18113 from qibolee:origin/fix_comments,0
* reinit travis ci,0
Feel free to use a debugger to understand what I mean.,0
* added test for conv layer initializations,0
"Update Keras layers to use `tf.xyz` rather than `tf.raw_ops.xyz`.  (E.g., use tf.matmul rather than tf.raw_ops.MatMul.)",0
"This is not new code, we are just moving these utilities directly
into keras from keras-preprocessing.",0
Optionally load weights by name (#3488),0
* spatial dropout in docs,0
* training.py _slice_arrays() fix crash when arrays are None,0
"- Before:
  ```py
  inputs = keras.layers.Input(shape=(32, 32, 3))
  keras.models.Model(inputs, keras.layers.Add()([inputs, inputs])).save('aa.h5')",0
[P] Support merge_repeated in K.ctc_decode() beam search. (#12241),0
* move docker to sub directory,0
* Increase file save hash size,0
* Converted strings to unicode when using python 2.,0
"However, that is not needed because the images are shifted by integer values (crop_left_pixels, crop_top_pixels), and there is nothing to interpolate.",0
https://nvd.nist.gov/vuln/detail/CVE-2019-6446,0
* Make two variants of GRUCell available from GRU with a parameters instead of separate classes.,0
"* add numpy implementation of rnn, cleanup corresponding tests",0
"For any user who rely on the states of the RNN, eg
RNN(return_state=True), please add the extra param
reverse_state_order=True while constructing the StackedRNNCells.",0
* cleaned imports,0
"* Allow steps param in Sequential predict(),predict_proba(),predict_classes()",0
PiperOrigin-RevId: 522082131,0
PiperOrigin-RevId: 421953216,0
Fix redundant functions' module names in auto-gen docs (#10664),0
* pyux,0
Improve docstrings of applications (#10310),0
* Adds new test cases for previously-failing uses,0
* add docstrings for 'interval' and 'force' arguments,0
Update "from sklearn.grid_search import GridSearchCV"  to “from sklearn.model_selection import GridSearchCV”.,0
* Pass Tests,0
Fix typos (#8774),0
* check coding style,0
I don't really know what the expected behaviour is in situations where there are multiple output shapes; I defer to @fchollet for a sense of whether this is okay in that case.,0
"I run the  provided LSTM example (imdb_lstm.py), the accuracy is 0.97,but the test accuracy is only 0.82.",0
"In particular, fix crash when saving LossScaleOptimizer with h5, and when passing LossScaleOptimizer to convert_to_legacy_optimizer().",0
PiperOrigin-RevId: 381567437,0
"commit 9360ea6c25eab90e83aebb32eb187c65ed63c01d
        Author: Yarin <yaringal@gmail.com>
        Date:   Thu Feb 18 23:28:35 2016 +0000",0
PiperOrigin-RevId: 481681052,0
"* Refactor RNN dropout to be self-contained in RNN cells, which is cleaner and fixes a couple of outstanding bugs.",0
the more I think about it the stranger it is that `Sequential` has this special behaviour.,0
Bug fixes,0
* missed one more spot,0
Fix https://github.com/fchollet/keras/issues/2871#issuecomment-237365465,0
"Please ensure this object is passed to the
`custom_objects` argument.",0
"When using tensorflow as backend and the version of tensorflow is under r1.3, the list_devices() function is not available of Session instance.",0
* Allow broadcasting in Merge layer,0
* Add a test of using feed_dict with K.function() and improve the docs.,0
PiperOrigin-RevId: 353314486,0
sparse_categorical_crossentropy requires a single output,0
"commit b8a9f84fad1be2f27365a25b4e7f188d382d70d0
        Merge: a154495 0f3f563
        Author: Fran?ois Chollet <francois.chollet@gmail.com>
        Date:   Thu Feb 18 11:24:42 2016 -0800",0
"And also, if it's assumed to come from softmax, isn't the name categorical_crossentropy misleading since it sounds like combined softmax and CE ?",0
Keras. Error when checking input,0
* Add docstring of `img_to_array()` in `keras/preprocessing/image.py`,0
Remove injecting of `keras_preprocessing`,0
"Also if the sequence length remain same across all the batches, can I assume max_length == time_steps == seq_length ?",0
PiperOrigin-RevId: 382568710,0
* Code formatting,0
"We need to pass the offset information to keras
backend RNG and let it produce different result for different offset
value.",0
* examples/lstm_stateful.py: replaced cosine with random.uniform,0
- GRU(reset_after=True) <-> CuDNNGRU - can be converted,0
PiperOrigin-RevId: 388345855,0
@AnikaTabassum `cd tensorflow` before `git switch ...`.,0
* Changed len(array.shape) into array.ndim.,0
Or do you think it's safe to assume that risk now and merge?,0
Thanks for the PR!,0
* mnist_tfrecord.py add parallelism option,0
bug fix in start_from_epoch condition,0
PiperOrigin-RevId: 406470033,0
2D tensor support for batch_dot,0
PiperOrigin-RevId: 402867690,0
This fix significantly reduces the total V1 + V2 test load by eliminating redundancy.,0
"This PR adds validation and custom errors for negative inputs in various Keras layers throughout the `core`, `convolutional`, and `recurrent` modules.",0
Add output_mode to Hashing layer,0
* Fix Theano concat,0
How do you think we should proceed?,0
Move the RandomGenerator init logic from __init__ to build().,0
Bug fix - Siamese,0
"commit d4ffffc26cf24c8b7927209caad4379aac3db9c5
        Author: Yarin <yaringal@gmail.com>
        Date:   Fri Feb 19 23:47:40 2016 +0000",0
PiperOrigin-RevId: 524406599,0
Update unit test for the upcoming stateless dropout layer change.,0
Can someone please advise?,0
It used train data for validation and ignored `len(val_data)` when `val_data` was instance of `keras.Sequence`,0
* Add documentation for 'subset' argument (flow and flow_from_directory) and for 'interpolation' argument (flow_from_directory),0
Fix typos (#7087),0
tf backend supports bool variable (#7832),0
How does model.fit () calculate loss and acc ?,0
* move AlphaDropout from core layers to noise layers,0
* Fix backend tests,0
add support for pandas DataFrame (#8199),0
"It also makes very little sense to do so, given that `relu` is the only activation function that has additional arguments to it's signature (considering non-advanced activations only, `elu` has its corresponding `ELU` layer to use its argument).",0
"commit 5fcd832b5c5025b164c99f0bd46cb94d707b93d3
Author: Pavithra Vijay <psv@google.com>
Date:   Fri Jun 15 16:29:32 2018 -0700",0
wrappers_test.py quick fix for flaky TimeDistributed test (#7062),0
* Update merge.py,0
"- MakeFile to simplify docker commands for build, run, test, ..etc",0
Also update the metadata info for keras to be align with the tf package.,0
PiperOrigin-RevId: 475455814,0
* Attempt to Fix Failing CTC Cost Tests,0
Added a link to the TextVectorization API Reference Page.,0
* Revert "Fix input shape of OCR model (#7908)",0
This makes the API bit different to previous imagenet utils though.,0
"But since this is an easy fix, let's give h5 the power.",0
Also update dropout layer to use the keras.backend.RandomGenerator.,0
fix dtype error in update_state(),0
- The docs can now be built either by calling `python autogen.py` or by calling `docs.autogen.generate()`.,0
Fix metric correctness issue in distributed setting.,0
* adjusted arguments to Conv2D/Deconv2D,0
"This covers custom models, layers, metrics (class and function), losses, optimizers, and regularizers.",0
* fix DeapthWiseConv2D compute_output_shape,0
"@neggert , for your use case, consider using the on_batch_end callback instead.",0
Because this attribute is added to ResourceVariable after its construction and not all ResourceVariables have this attribute.,0
* Fix documentation and add Travis task,0
* Fix mnist_tfrecord.py runtime errors,0
The recommended approach in v2 is using tf.random.Generator which can be treat as a variable (seed) with stateless RNG op.,0
* with patch('input') as mock:,0
* remove basestring for python3 compatibility,0
PiperOrigin-RevId: 420939364,0
"There were a lot of pattern like this in the codebase:
```python
if len(x) == 1:
    y = x[0]
else:
   y =  x
```",0
"It allows CTC beam search to disable merging adjacent symbols
even if they are separated by a blank symbol and behave
consistently with greedy search.",0
PiperOrigin-RevId: 382775165,0
Added batch histogram computation (#6065),0
"And although this is a couple of lines more, which code seems simpler to you?",0
- added prediction gap parameter,0
* Argument target_tensors from Model.compile: accept single tensor,0
- The activation is not any more special a configuration parameter than any other parameter.,0
"In case I missed something (preventing the packing), and this can be solved more elegant, I would be pleased to know.",0
+ unit test,0
"commit 9bff5b1a55f51ad974c3a3489d7ca2d80f26f770
Author: r-kellerm <34206121+r-kellerm@users.noreply.github.com>
Date:   Mon May 28 03:45:35 2018 +0300",0
Fix typos in docstrings,0
"Before this commit, it raised error if the axis to be
repeated was None.",0
* Added optional field name argument,0
"After training, you have to save the trained weights, create/compile a similar model without Eingenvalue Decay and save this model.",0
PiperOrigin-RevId: 535287708,0
* fix comment,0
"add if statement for stride (1,1,1)",0
* class_mode keyword changed to input + clearer doc.,0
* Fix in doc example,0
typo in documentation (#6809),0
* use tf.reshape instead of tf.expand_dims,0
PiperOrigin-RevId: 442392960,0
"The fixes vary, but there are three particularly common changes:",0
"* batch_size_histogram renamed to batch_size, default set to 32, added spaces around operators",0
2.6 release is cut at https://github.com/keras-team/keras/tree/r2.6,0
* test_model_saving.py load reshape tests all code pathways,0
* DOC: add argument desc,0
* Simplify example.,0
* Add example,0
Update typo in `compute_output_shape`,0
* Try theano,0
assumed = old;,0
[MLIR] Move `assuming_all` ops over assuming regions for broadcast propagation,0
* Max Over Time in imdb_cnn.py,0
* fix to have session.run() called once in batch_set_value(),0
The *1. dummy multiplication was added to avoid having to deal with tf.float32_ref dtypes.,0
"Same as https://github.com/fchollet/keras/commit/89e6eb01f200ef6fa8db926ecfee68b37b229fbc, caused by https://github.com/fchollet/keras/pull/8063",0
* Add train test split to DirectoryIterator,0
Skipping tests when py2 on other backends than tensorflow (#12216),0
* Progbar() unit test,0
* add loop test,0
Cleanup legacy Keras files (#14256),0
PiperOrigin-RevId: 387628150,0
"commit b21764824f181fb7a32fce852e5afcee4042192a
Author: Tommi Koivisto <tkoivisto@users.noreply.github.com>
Date:   Mon Jun 4 20:26:41 2018 +0300",0
This is a really minor typo I noticed today while reading the CIFAR-10 description and thought to make a quick PR fixing it.,0
"Currently the scaling parameter gamma is uniformly sampled between
-0.05 and 0.05.",0
- Do you assume that one whole sequence of the minibatch is translated into null?,0
* Added missing import statement,0
Implement SGD optimizer based on the new optimizer design.,0
what is this mean?,0
* Model.evaluate_generator(): More consistent stateful metrics handling,0
Currently we add layout params to dense and conv2d layer as an example.,0
Tmp bug fix,0
PR #50068: Change profiler dir to non-temporary in Keras TensorBoard callback,0
resolves https://github.com/fchollet/keras/issues/7792,0
Newer TFs expose tf.cond as the public interface.,0
Thanks for the response.,0
Keras Error : Unknown entries in loss dictionary: ['ctc'].,0
Imported from GitHub PR https://github.com/tensorflow/tensorflow/pull/47726,0
* PEP8 for * binary operator.,0
* Changes according to review,0
The one from zlib.net is returning 404 currently.,0
PiperOrigin-RevId: 506052874,0
"commit 672c27401ee345a69592771cfc9ab017642b6af3
        Merge: 9360ea6 b8a9f84
        Author: Yarin <yaringal@gmail.com>
        Date:   Fri Feb 19 00:30:44 2016 +0000",0
Please consider pulling in this minor detail that bugged me while reading the  documentation.,0
- Test now includes original function.,0
"For this specific use case, have you considered just dumping stdout to a file?",0
Update multi-head attention layer to not reuse the initializer for layers.,0
PiperOrigin-RevId: 401340546,0
The behavior of this functionality is as such:,0
test covers md5 sha256 zip and tar,0
Resolved error,0
PiperOrigin-RevId: 478362764,0
Some changes on the new optimizer:,0
I wonder whether this is actually the cause of the problem in `tf.nn.sparse_softmax_cross_entropy_with_logits`; is it assuming the total number of elements is less than `2**31`?,0
Change `batch_size` descriptions to proper ones (#13422),0
Fix typos (#6702),0
Added some other numpy implementation in the docs. (#11576),0
* Add docstring of `save_img()` in `keras/preprocessing/image.py`,0
* Make better tests for CuDNN RNN weight conversion.,0
Fix typo in docs,0
* Added parallel generation of the filenames and labels lists,0
PiperOrigin-RevId: 362173108,0
@tylerpayne thanks for the context and the examples make sense to me - do you imply that the PR should not be further pursued or you intend to work on alternatives?,0
* Add kwarg and documentation for dilation_rate to DepthWiseConv2D,0
"Then, you can use your trained weights with this model, see lines 123-153 of  	CIFAR10_with_Eigenvalue_Decay.py (This is still an open issue).",0
* Add axes labels,0
"When using Keras on TensorFlow (in graph mode), via `tf.keras`, then calling `self.add_weight()` fails if `self.built==True`, so it is best to encourage users to set `self.built=True` at the *end* of their `build()` method, rather than just ""somewhere"".",0
* get_file() tarfile fix (#5861),0
- change "DO NOT EDIT" to "MAIN PROGRAM",0
Fix LeakyReLU return dtype (#2214),0
Sync OSS keras to https://github.com/tensorflow/tensorflow/commit/6af429790a6cf791d53a91d9fbf8a5a4b97da94b (where TF 2.5 RC is cut),0
add: scoring methods for Luong Attention,0
PiperOrigin-RevId: 353295828,0
"* Theano cudnn code now throws Exception when it is not available, need to catch this",0
Because the first index returned from Keras' tokenizer is 1.,0
PiperOrigin-RevId: 362089465,0
Validation loss is different even when should be equal to training.,0
Add pooling options in MobileNetV2 (#10313),0
"* Refactor regularizers, introduce layer.add_weight",0
Added in the documentation an example of custom layer with multiple inputs and outputs. (#10939),0
Please submit your PR at keras-contrib.,0
What's your opinion on this?,0
Bug fix in zca_whitening (#4181),0
I don't know how to test this.,0
PiperOrigin-RevId: 401293708,0
